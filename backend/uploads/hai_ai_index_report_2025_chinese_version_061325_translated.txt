Artificial intelligence in 2025
Index Report
introduce
Artificial Intelligence Index Report 2025
Welcome to the eighth edition of the AI Index report. We come at a critical time when the impact of AI on social, economic, and global governance is intensifying
The 2025 Artificial Intelligence Index report was released. It's also the most comprehensive index we've published to date. This year's report adds a look at the state of AI hardware development
, new estimates of inference costs, and new analyses of AI publication and patent filing trends. For the first time, we also disclosed the adoption of responsible people by businesses
The latest data on the practice of artificial intelligence and expand the analytical dimension of the increasingly important role of artificial intelligence in science and medicine.
Launched in 2017 as a branch of the "One Hundred Year Study of Artificial Intelligence" project, Artificial Intelligence refers to:
The report has been dedicated to providing accurate, rigorously validated, and globally sourced data to policymakers, journalists, executives, researchers, and the general public. Our Mission
Consistent: Helping these stakeholders make more informed decisions about the development and deployment of AI. at
This is where AI is discussed everywhere from the boardroom to the kitchen table
This mission is even more important.
From the changing geopolitical landscape and the rapid development of the underlying technology, to the expanding role of AI in business, decision-making, and public life, the AI Index continues
Leading the tracking and interpretation of key trends in the industry. Longitudinal tracking has always been at the core of our mission. In this fast-growing area, this report provides important background information:
Help us understand the current state of artificial intelligence, how it has evolved, and where it is headed.
As one of the world's most recognized authoritative resources in the field of artificial intelligence, the AI Index report has been recognized by the New Zealand Index
Cited by major media outlets such as The Times, Bloomberg, and The Guardian, became
Bibliographic reference of hundreds of scholarly papers and serves policymakers and government agencies around the world. We've made it to companies like Accenture, IBM, Wells Fargo and Fidelity
provides a briefing on the current state of AI and continues to provide independent insights into the global AI ecosystem.
12025 Artificial Intelligence
Index Report
Message from the Co-Director
As AI continues to reshape human life, the corporate world, and public discourse, the AI Index report consistently tracks its progress, through independent, data-driven
to observe the development, application and impact of artificial intelligence across time and geography.
What a year 2024 has been for AI. Nobel Prize in Physics and Chemistry, as well as graphs for groundbreaking work in reinforcement learning
The Spirit Award reflects people's recognition of the role of artificial intelligence in promoting the progress of human knowledge. The once daunting Turing Test is no longer seen as an ambition
Ambitious goals, today's sophisticated systems have surpassed it. At the same time, the application of artificial intelligence is permeating social life at an unprecedented rate, with millions of people using artificial intelligence at high frequency in professional work and leisure activities. With the proliferation of high-performance, low-cost, and open-source models, the accessibility and impact of AI is set to expand further. After a brief slowdown, corporate investment in AI has rebounded. The number of funding cases for generative AI startups has increased nearly threefold. Business applications are set to see significant growth in 2024 after years of sluggishness. AI has moved from the edge to a core driver of business value.
Governments are also stepping up their involvement. Policymakers are no longer talking about AI, they are investing in it. Some countries launched billions worth of dollars
A U.S. dollar-sized national AI infrastructure plan, including energy capacity expansion to support significant efforts to develop AI. Global coordination mechanisms are becoming more and more perfect, and local measures are taking shape simultaneously.
However, trust remains a major challenge. Public trust in the data protection capabilities of AI companies continues to decline, and concerns about algorithmic fairness and bias remain.
Disinformation continues to pose a risk, and the misuse of deepfakes in scenarios such as elections has raised widespread concerns. In response, governments are moving forward with new regulatory frameworks that promote transparency, accountability, and fairness. Public attitudes are also changing. A 2024 global survey shows a clear rise in public optimism about the potential of AI to deliver wide-ranging societal benefits, despite lingering doubts.
AI is no longer just a story about what might happen, but a story about what's happening and how together we're shaping the future of humanity. Please
Read this year's AI Index report and see for yourself.
Yolanda Gil and Raymond Perrault
Co-Director of the AI Index Report
Artificial intelligence in 2025
Index Report
Key takeaways:
1. Artificial intelligence continues to improve in rigorous benchmarks. In 2023, researchers launched a series of novel comparisons, such as MMMU, GPQA, and SWE-bench
Benchmarks, designed to test the limits of cutting-edge AI systems. After just one year, the performance has improved dramatically: MMMU, GPQA, and SWE-bench scores have improved respectively  
18.8%, 48.9% and 67.3%. In addition to these benchmarks, AI systems have also made significant progress in generating high-quality video, in some specific scenarios
in the language module
agents outperform humans even in time-constrained programming tasks.
2. Artificial intelligence is increasingly integrated into everyday life. From medical care to transportation, AI is rapidly moving from the lab to everyday life. In 2023, U.S. Food and Drug Administration
The number of AI-powered medical devices approved by the FDA reached 223, a leap forward from 6 in 2015. On public roads, self-driving cars are out of the test
Phase: Waymo, one of the leading operators in the United States, offers more than 150,000 self-driving rides per week, while Baidu launches the affordable Apollo Go robotaxi
The services provided have now covered many cities in China.
3. As research continues to show the powerful impact of AI on productivity, the business community has embraced AI across the board, with record levels of investment and adoption. In 2024, the United States is private
Investments in human AI amounted to US$109.1 billion, about 12 times that of China (US$9.3 billion) and 24 times that of the United Kingdom (US$4.5 billion). Generative AI is gaining particular momentum
attracted $33.9 billion in private investment globally – up 18.7% year-over-year. The commercial adoption of AI is also accelerating, with 78% of businesses responding by 2024
AI technology was used, up from 55% in the previous year. At the same time, a growing body of research confirms that AI can not only improve production efficiency in most cases
It also helps to close the skills gap in the workforce.
4. The U.S. is still leading the way in developing top-tier AI models, but China is closing the gap with the U.S. In 2024, a total of 40 logos were developed by U.S. agencies
Sexual AI models, while China has only 15 and Europe has only 3. While the U.S. maintained its lead in quantity, China's models quickly closed the gap in quality: the performance gap on major benchmarks such as MMLU and HumanEval narrowed from double digits in 2023 to nearly flat in 2024. China continues to lead the way in AI papers and patents. Model development is increasingly global, with compelling models all coming out in the Middle East, Latin America, and Southeast Asia.
5. The responsible AI ecosystem is unevenly developed. At the same time as the surge in AI-related accidents, major industrial model developers are adopting standardized responsible people
Responsible AI (RAI) reviews are still rare. However, new benchmarks such as HELM Safety, AIR-Bench, and FACTS are used to assess authenticity and
Security provides a promising tool. At the enterprise level, there is still a gap between the perception of responsible AI risks and substantive action. Comparatively, the politics of various countries
The government has shown a stronger sense of urgency: 2024
Global cooperation on AI has deepened significantly, with the OECD, the European Union, the United Nations, and the African Union issuing regulatory frameworks
focusing on the core principles of responsible AI, such as transparency and trustworthiness.
32025 Artificial Intelligence
Index Report
Key takeaways (continued)
6. Global optimism about AI is rising, but there are still significant regional differences. In countries such as China (83%), Indonesia (80%), and Thailand (77%),
The vast majority of people believe that the benefits of AI products and services outweigh the disadvantages. In contrast, places such as Canada (40%), the United States (39%) and the Netherlands (36%) remain less optimistic.
However, people's mood is shifting. Since 2022, optimism has grown significantly in a number of previously skeptical countries, including Germany (+10%), France (+10%),
Canada (+8%), the United Kingdom (+8%) and the United States (+4%).
7. AI has become more efficient, affordable, and easy to use. Relying on the jump in small model capabilities, the inference cost of executing a GPT-3.5 level system is in November 2022
In October 2024, it plummeted by more than 280 times. At the hardware level, the annualized cost has been reduced by 30%, and the annual energy efficiency improvement rate has reached 40%. Open source models are closing the gap with closed-source models.
On some benchmarks, the performance gap narrowed from 8% to just 1.7%. Taken together, these trends are rapidly lowering the barriers to entry for advanced AI.
8. Governments are stepping up regulation and investment in AI. In 2024, U.S. federal agencies introduced 59 AI-related regulations, more than double the number in 2023.
The number of agencies issuing regulations is also twice as high as in 2023. Globally, mentions of AI legislation in 75 countries have increased by 21.3% since 2023, compared to 2016
The cumulative annual growth rate is 9 times. While tightening regulations, governments have launched large-scale investments: Canada has pledged $2.4 billion, China has launched a $47.5 billion semiconductor fund,
France has pledged 109 billion euros, India has allocated $1.25 billion, and Saudi Arabia has launched the $100 billion Project Transcendence.
9. Adoption of AI and computer science education is accelerating, but gaps remain in terms of access to resources and readiness. Two-thirds of the world's countries now have implemented or planned basic education
Coverage of computer science education at the educational level has doubled since 2019, with Africa and Latin America making the most significant progress. In the United States, he has graduated with a bachelor's degree in computer science in the past 10 years
The number of students increased by 22%. However, in many African countries, opportunities to obtain a computer degree remain limited due to inadequate infrastructure such as electricity. In the U.S., 81% base
Computer teachers at the education level agree with the inclusion of AI in the basic curriculum, but less than half of teachers consider themselves competent to teach.
10. The industry is still leading the way in the AI race – but the competition at the forefront of technology is intensifying. In 2024, nearly 90% of the world's iconic AI models will come from industry, up from 60% in 2023, while academia remains the premier source of high-citation research. The size of the model continues to scale rapidly—training calculations are doubling every five months, datasets are doubling every eight months, and energy consumption is growing at a rate of 100% per year. However, the model performance gap is narrowing, with the gap between the top and 10th place models dropping from 11.9% to 5.4% in Elo skill scores in one year, and now the top two are just 0.7%. The competition in the frontier field of technology is becoming increasingly fierce, and the head camp is also increasingly concentrated.
42025 Artificial Intelligence
Index Report
Key takeaways (continued)
11. Artificial intelligence receives the highest academic honors for its scientific impact. The growing importance of artificial intelligence is reflected in major scientific awards: two Nobel Prizes each
The Turing Award was awarded for deep learning (Physics) and the application of artificial intelligence to protein folding (Chemistry), while the Turing Award was awarded for breakthrough contributions to reinforcement learning.
12. Complex reasoning remains a challenge. Artificial intelligence models excel in tasks such as International Mathematical Olympiad questions, but in complex reasoning comparators such as PlanBench
Zhunzhong is still struggling. Even when theoretically correct solutions exist, they are often unable to reliably solve logical tasks. In areas where precision is critical, there are still limits to the effectiveness of AI.
52025 Artificial Intelligence
Index Report
Steering Committee
chairman
Raymond Perrault 
SRI International Institute
President-elect
Yolanda Gil, Institute of Information Science, University of Southern California
staff and researchers
Head of Research and Editor-in-Chief
Nestor Maslej, Stanford University
Research Assistant
Loredana Fattorini, Stanford University
Affiliated Fellow
Elif Kiesow Cortez is a research fellow at Stanford Law School
Julia Betts Lotufo, Research Fellow Anka Reuel, Alexandra Rome, Stanford University, Angelo Salatino, Research Fellow, Lapo Santarlasci, Institute for Knowledge Media, Open University, UK, Graduate Research Fellow, Lucca School of Advanced Studies
Emily Capstick, Malou van Draanen Glismann, Stanford University, Njenga Kariuki, Stanford University
Undergraduate Fellow
Armin Hamrah, G莱蒙特 · 麦肯纳学院Sukrut Oak, 斯坦福大学Ngorli Fiiﬁ Paintsil, 斯坦福大学Andrew Shi, 斯坦福大学成员
Erik Brynjolfsson 
斯坦福大学
Jack Clark 
Anthropic, OECD
John Etchemendy 
斯坦福大学
Katrina Ligett
希伯来大学Terah Lyons
摩根大通
James Manyika 
谷歌牛津大学
Juan Carlos Niebles 
斯坦福大学SalesforceVanessa Parli 斯坦福大学
Yoav Shoham 
斯坦福大学 AI21 实验室
Russell Wald 
斯坦福大学
Tobi Walsh
悉尼新南威尔士大学
62025年人工智能
指数报告
如何引用本报告
Nestor Maslej, Loredana Fattorini, Raymond Perrault, Yolanda Gil, Vanessa Parli, Njenga Kariuki, Emily Capstick, Anka 
Reuel, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan Carlos Niebles, Yoav Shoham, Russell Wald, Tobi Walsh, Armin Hamrah, Lapo Santarlasci, Julia Betts Lotufo, Alexandra Rome, Andrew Shi, Sukrut Oak. “The AI Index 2025 Annual Report,” AI Index Steering Commmittee, Institute for Human-Centered AI, Stan-ford University, Stanford, CA, April 2025.
The AI Index 2025 Annual Report by Stanford University is licensed under Attribution-NoDerivatives 4.0 International.
公共数据和工具
《2025 年人工智能指数报告》附有原始数据和互动工具。 我们邀请每位读者根据自己的工作和兴趣使用这些数据和工具。
原始数据和图表：报告中所有图表：的公开数据和高分辨率图像可在 Google Drive 上获取。
Global AI Vibrancy Tool ：比较 30 多个国家的人工智能生态系统。 Global AI Vibrancy Tool 将于 2025 年夏季更新。
人工智能指数（AI Index）和斯坦福大学 HAI
人 工 智 能 指 数（AI Index）是 斯 坦 福 大 学 以 人 为 本 人 工 智 能 研 究 院（Stanford Institute for Human-Centered Artiﬁcial Intelligence, HAI）的独立研究项目。
人工智能指数（AI Index）最初源自人工智能百年研究（One Hundred Year Study on Artiﬁcial Intelligence）项目（AI100）
首个官方中文版由 AI Index 与其亚洲合作伙伴 Digital Civilization 合作组织与统筹，作为拓展 AI Index 在亚洲
影响力并推动区域生态体系建设的一项重要举措。 我们欢迎来自各界的个人与机构提供反馈并参与合作，共同推动构建一个更具包容性、以人为本的人工智能社区。
人工智能指数欢迎对明年报告的反馈和新想法。 请通过 nmaslej@stanford.edu 联系我们。 人工智能指数承认，尽管该报告由一支人类研究人员团队撰写，但其写作过程得到了人工智能工具的辅助。 具体而言，作者
使用了 ChatGPT 和 Claude 帮助完善和校对初稿。 工作流程包括作者撰写原始内容，并将在编辑过程中作为工作流程的一部分使用人工智能工具。
7
2025年人工智能
指数报告
支持型合作伙伴
分析研究合作伙伴
82025年人工智能
指数报告
贡献者
人工智能指数谨此感谢以下各位专家在各章节和部分中为《2025 年人工智能指数报告》提供的数据、分析、建议及专业评论：
介绍
Loredana Fattorini, Yolanda Gil, Nestor Maslej, Vanessa Parli, Ray Perrault
第一章 研究与开发
Nancy Amato, Andrea Brown, Ben Cottier, Lucía Ronchi Darré, Virginia Dignum, Meredith Ellison, Robin Evans, Loredana 
Fattorini, Yolanda Gil, Armin Hamrah, Katrina Ligett, N
estor Maslej, Maurice Pagnucco, Ngorli Fiiﬁ Paintsil, Vanessa 
Parli, Ray Perrault, Robi Rahman, Christine Raval, Vesna Sabljakovic-Fritz, Angelo Salatino, Lapo Santarlasci, Andrew 
Shi, Nathan Sturtevant, Daniel Weld, Kevin Xu, Meg Young
第二章 技术性能
Ris
hi Bommasani, E r ik Brynjolfsson, Loredana Fattorini, Tobi G ertsenberg, Yolanda Gil, Noah Goodman, N icholas Haber, 
Armin Hamrah, Sanmi Koyejo, Percy Liang, Katrina Ligett, Nestor Maslej, Juan Carlos Niebles, Sukrut Oak, Vanessa 
Parli, Marco Pavone, Ray Perrault, Anka Reuel, Andrew Shi, Yoav Shoham, Toby Walsh
第三章 负责任的人工智能
Medha Bankhwal, Emily Capstick, Dmytro Chumachenko, Patrick Connolly, Natalia Do rogi, Loredana Fattorini, Ann 
Fitz-Gerald, Yolanda Gil, Armin Hamrah, Ariel Lee, Katrina Ligett, Shayne Longpre, Nestor Maslej, Katherine Ottenbreit, 
Halyna Padalko, Vanessa Parli, Ray Perrault, Brittany Presten, Anka Reuel, Roger Roberts, Andrew Shi, Georg io Stoev, 
Shekhar Tewari, Dikshita Venkatesh, Cayla Volandes, Jakub Wiatrak
第四章 经济
Medha Bankhwal, Erik Brynjolfsson, Mar carpanelli, Cara Christopher, Michael Chui, Natalia Dorogi, Heather English, 
Murat Erer, Loredana Fattorini, Yolanda Gil, Heather Hanselman, Rosie Hood, Vishy  Kamalapuram, Kory Kantenha, 
Njenga
 Kariuki, Akash Kaura,  Elena Magrini, Nestor Maslej, Katherine Ottenbreit, Vanessa Parli, Ray Perrault, 
Brittany Presten, Roger Roberts, Cayla Volandes, Casey Weston, Hansen Yang
第五章 科学与医学
Russ Altman, Kameron Black, Jonathan Chen, Jean-Benoit Delbrouck, Joshua Edrich, Loredana Fattorini, 
Alejan
dro Lozano, Yolanda Gil, Ethan Goh, Armin Hamrah, Fateme Nateghi Haredasht, Tina Hernandez-Boussard, Yeon 
Mi Hwang, R ohan Koodli, Arman Koul, Curt Langlotz, Ashley Lewis, Chase Ludwig, Stephen P. Ma, Abdoul Jalil 
Djiberou Mahamadou, David Magnus, James Manyika, Nestor Maslej, Gowri Nayar, Madelena Ng, Sophie Ostmeier, 
Vanessa Parli, Ray Perrault, Malkiva Pillai, Ossian Karl-Johan Ferdinand Rabow, Sean Riordan, Brennan Geti Simon, 
Kotoha Togami, Artem 
Trotsyuk, Maya Varma, Quinn Waeiss, Betty Xiong
第六章 政策
Elif Kiesow Cortez, Loredana Fattorini, Yolanda Gil, Julia Betts Lotufo, Vanessa Parli, Ray Perrault, Alexandra 
Rome, 
Lapo Santarlasci, Georgio Stoev, Russell Wald, Daniel Zhang
92025年人工智能
指数报告
组织机构
Accenture
Arnab Chakraborty, Patrick Connolly, Shekhar 
Tewari, Dikshita Venkatesh, Jakub Wiatrak
Epoch AI
Ben Cottier, Robi Rahman
GitHub
Lucía Ronchi Darré, Kevin Xu
Lightcast
Cara Christopher, Elena MagriniLinkedIn
03 Carpanelli, Akash Kaura Kory Kantenga, Rosie Hood, Casey Weston
McKinsey & Company
Medha Bankhwal, Natalia Dorogi, Katherine Ottenbreit, Brittany Presten, Roger Roberts, Cayla Volandes
Quid
Heather English, Hansen YangChapter 7 Education
John Etchemendy, Loredana Fattorini, Lili Gangas, Yolanda Gil, Rachel Goins, Laura Hinton, Sonia Koshy, Kirsten Lund-gren, Nestor Maslej, Lisa Cruz 11ohatski, Vanessa Parli, Ray Perrault, Allison Scott, Andreen Soley, Bryan Twarek, Lau-rens Vehmeijer
Chapter 8 Public Opinion
Emily Capstick, John Etchemendy, Loredana Fattorini, Yolanda Gil, Njenga Kariuki, Nestor Maslej, Vanessa Parli, Ray Perrault
The AI Index would like to thank the following experts for their data, analysis, advice and expert commentary on the AI Index Report 2025 in various chapters and sections:
The AI Index would also like to thank the following individuals for their assistance in preparing this report: Jeanina Matias, Nancy King, Carolyn Lehman, Shana 
Lynch, Jonathan Mindes, and Michi Turner; Thanks to Christopher Ellis for his assistance in maintaining the AI Index website; And thanks 
Annie 
Benisch、Stacey Sickels Boyce、Marc Gough、Caroline Meinhardt、Drew Spence、Casey Weston、Madeleine 
Wright and Daniel Zhang's work in helping to promote this report.
We thank Jason Liu for his important role in driving the AI Index Chinese version. Going forward, we will continue to work to improve the global AI Index
accessibility and strengthening ecological synergy in the Asian region.
10 Contributors (continued) Artificial Intelligence in 2025
Index Report
directory
Key takeaways from the report
Chapter I
Chapter II
Chapter III
Chapter IV
Chapter 5
Chapter VI
Chapter VII
Chapter VIII
Appendix Research and Development
Technical performance
Responsible AI
economy
Science and Medicine
Policy & Governance
educate
Public Opinion 12
24
81
160
214
280
323
364
394
414
Access to public data
Artificial intelligence in 112025
Index Report
Key takeaways from the report
Chapter 1:
Research & Development
1. The industry continues to increase investment in AI and lead the research and development of landmark AI models, while academia leads high-impact research. The industry is researching landmark artificial intelligence models
The dominant advantage of the development continues to strengthen, and this trend has been clearly stated in the previous two AI index reports. In 2024, nearly 90% of cutting-edge models will originate from industry
(Compared to 2023.)
 60% of the year, an increase of 30 percentage points). Academia has been the top institutional contributor to highly cited (top 100) papers for the past three years.
2. China leads in the total number of AI papers published, while the United States has the advantage in high-impact research.  In 2023, China's paper in the field of artificial intelligence was published
Both the number of citations (23.2%) and citations (22.6%) rank first in the world. And in the past three years, U.S. institutions have contributed to the top 100 most cited AI papers.
3. The total number of papers published in artificial intelligence continues to grow and occupies an increasingly important dominant position in the field of computer science. From 2013 to 2023, in computer science and other
The total number of AI papers published in science disciplines has almost tripled, from about 102,000 to more than 242,000. Proportionally, AI is in
The share of computer science papers has risen from 21.6% in 2013 to 41.8% in 2023.
4. The U.S. remains the primary source of iconic AI models. In 2024, U.S. institutions developed 40 iconic AI models, significantly more than China's 15 and
3 in Europe. Over the past decade, more iconic machine learning models originated in the United States than in any other country. In 2024, U.S. institutions will develop a total of 40 cutting-edge AIs
model, significantly more than 15 in China and 3 in Europe combined. Over the past decade, the U.S. has maintained a global leader in the number of cutting-edge machine learning models developed.
5. AI models are becoming larger, more demanding, and more energy-intensive. Recent research shows that the training power requirement for iconic AI models increases approximately every 5 months
The size of the large language model training dataset doubles every 8 months, and the power consumption required for training increases every year. Large-scale industrial investment continues to drive model scale and performance improvement
Litre.
6. The cost of using AI models continues to fall. Take MMLU, a common benchmark for language model performance evaluation, as an example, an artificial intelligence that has reached the GPT-3.5 level (64.8 points).
The cost of model queries has been reduced from $20 per million tokens in November 2022 to just $0.07 per million tokens in October 2024 (Gemini-1.5-Flash-8B modulo
type), a decrease of more than 280 times in 18 months. Depending on the type of task, the inference price of large language models has dropped by a factor of 9 to 900 per year.
Artificial intelligence in 122025
Index Report
Key takeaways from the report
Chapter 1:
Research & Development (continued)
7. AI patent filings continue to rise. From 2010 to 2023, the number of AI patents has grown steadily and substantially, surging from 3,833 to 122511. Only in the last year,
The number of AI patents increased by 29.6%. As of 2023, China leads the way in the total number of AI patents, accounting for 69.7% of all grants, compared to South Korea on a per capita basis
China and Luxembourg are the main producers of AI patents.
8. AI hardware is getting faster, cheaper, and more energy-efficient. Recent research shows that machine learning hardware performance, as measured by 16-bit floating-point computing power, is growing at a rate of 43% per year
Growth, doubling every 1.9 years. The price/performance ratio has improved significantly – costs have decreased by 30 percent per year, while energy efficiency has continued to improve by 40 percent per year.
9. Carbon emissions from AI training are steadily rising. Early-trained AI models, such as the AlexNet network (2012), emitted modest carbon emissions of just 0.01 tons.
The carbon emissions from training the latest AI models have increased significantly: GPT-3 was 588 tons in 2020, GPT-4 reached 5,184 tons in 2023, and Llama 3.1 in 2024 
The 405B weighs up to 8,930 tons. For comparison, the average American carbon emitter is just 18 tons per year.
Chapter 2:
Technical performance
1. AI is reaching new benchmarks faster than ever before. In 2023, researchers launched multiple MMMU, GPQA, and SWE-bench with multiple features
A new benchmark for combat that aims to test the limits of increasingly powerful AI systems. By 2024,
Significant breakthroughs in AI performance across these benchmarks:
MMMU and GPQA test scores increased by 18.8 and 48.9 percentage points, respectively; What's even more striking is that in the SWE-bench programming test, the AI system
Problem solving jumped from just 4.4% in 2023 to 71.7% in 2024.
2. Open source models catch up. According to the AI Index report released last year, leading open-source models have lagged significantly behind closed-source models. By 2024, the gap is basic
Disappear. Specifically, at the beginning of January 2024, the performance advantage of the top closed-source model on the Chatbot Arena Leaderboard was 8.0%; And by February 2025, this
First, the gap has narrowed to 1.7 per cent.
Artificial intelligence in 132025
Index Report
Key takeaways from the report
Chapter 2:
Technical Performance (continued)
3. The gap between China and the United States in AI model capabilities has narrowed. In 2023, the performance of the top AI models in the U.S. was significantly ahead of their Chinese counterparts, but that has changed. Data display
As of the end of 2023, the performance gaps between the Chinese and American models are 17.5, 13.5, and 24.3, respectively, in benchmarks such as MMLU, MMMU, MATH, and HumanEval
31.6 percentage points; By the end of 2024, these gaps have narrowed significantly to 0.3, 8.1, 1.6 and 3.7 percentage points.
4. The performance of cutting-edge AI models tends to converge. According to last year's AI Index, Chatbot Arena Leaderboard ranked 1st and 10th among models with Elo
The score gap has narrowed from 11.9% last year to 5.4% at the beginning of 2025. Similarly, the gap between the top two models has narrowed from 4.9% in 2023 to 2024
of 0.7%. Competition in the field of artificial intelligence is becoming increasingly fierce, and more and more developers are now launching high-quality models.
5. New inference paradigms, such as test-time compute, significantly improve model performance. In 2024, OpenAI's O1, O3 and other models will adopt iterative input
out of the inference architecture. This computational method at the time of testing greatly improved the performance of the model, with o1 receiving a high score of 74.4% in the International Mathematical Olympiad Qualifying Examination, GPT-4o
Only 9.3%. But the technology comes at a cost, with O1 costing up to 6 times faster than GPT-4o and inference 30 times faster.
6. More challenging benchmarks are being proposed. Traditional AI benchmarks such as MMLU, GSM8K, and HumanEval are nearing saturation, with the addition of MMMU and
Newer, more challenging benchmarks such as GPQA continue to improve, prompting researchers to explore more ways to evaluate leading AI systems. Among the notable
There's Humanity's Last Exam, a rigorous academic test with a state-of-the-art AI system scoring just 8.80%; Frontier Math, a complex mathematical benchmark where AI systems solve only 2% of problems; "BigCodeBench" is a coding benchmark, and the success rate of AI systems is only 35.5%, which is well below the 97% level of humans.
7. A major breakthrough in high-quality AI video generation models. In 2024, a number of advanced AI models will be launched that can generate high-definition video based on text input
These include OpenAI's SORA, Stable Video Diffusion 3D and 4D, Meta's Movie Gen, and Google's DeepMind's Veo 2. with the 2023 ones
Compared with the video generation model, these new generation models have achieved significant improvements in image quality performance.
Artificial intelligence in 142025
Index Report
Key takeaways from the report
Chapter 2:
Technical Performance (continued)
8. Smaller models show more performance. In 2022, the smallest model to achieve a score above 60% in the MMLU benchmark was PaLM with 540 billion parameters; And to
In 2024, Microsoft's Phi-3-mini achieves the same level with just 3.8 billion parameters — equivalent to a 142-fold reduction in parameter size in two years.
9. Complex reasoning continues to be a challenge for AI. Although the introduction of inference mechanisms such as chain-of-thought has significantly improved the performance of large language models, this
These systems are still unable to reliably solve problems that could have been answered deterministically by logical reasoning, including math and task planning, especially when the problem size is beyond its training range
Perimeter. This defect seriously affects the credibility of AI systems, making it difficult for them to meet the application requirements of high-risk scenarios.
10. Artificial intelligence agents show initial potential. The RE-Bench benchmark, launched in 2024, establishes rigorous criteria for assessing the ability of AI agents for complex tasks. In short-term tasks
(2-hour time limit), top AI systems can score up to 4 times higher than human experts; But with the time extended to 32 hours, the human manifestationAnti-AI system, score up to
to the advantage of 2:1. AI agents have reached the level of human expertise in specific areas, such as writing Triton Kernels, and can produce results faster and at a lower cost.
Chapter 3:
Responsible AI
1. At present, the practice of evaluating AI systems against responsible artificial intelligence (RAI) guidelines is not yet widespread, but new benchmarking systems are emerging. Last year's people
The Worker Intelligence Index has highlighted the lack of a standardized RAI benchmark for large language models. While this issue persists, HELM Safety and
The emergence of new benchmarks, such as AIR-Bench, has helped fill this gap.
2. The number of AI incident reports continues to increase. According to the AI Incidents Database, there will be an increase in AI-related incidents reported in 2024
to 233, a record high, an increase of 56.4% over 2023.
Artificial intelligence in 152025
Index Report
Key takeaways from the report
Chapter 3:
Responsible AI (continued)
3. Institutions are aware of the risks of responsible AI, but mitigation measures are lagging behind. A McKinsey survey on the implementation of enterprise RAI shows that despite the majority
Structures are able to identify key RAI risks, but not all organizations have taken proactive measures to address them. Among the dimensions of risk that leaders are most concerned about, the issue of model accuracy (64% of respondents asked
and), compliance risks (63%) and cybersecurity threats (60%) rounded out the top three, but it's worth noting that none of respondents listed these risks as their core concerns more than 65%.
4. Globally, policymakers are showing a strong interest in responsible AI. In 2024, global cooperation on AI governance was strengthened, with a focus on consultation
Set the principles of responsible AI. A number of international organizations, including the Organisation for Economic Co-operation and Development (OECD), the European Union, the United Nations and the African Union, have issued normative frameworks to elaborate
RAI focuses on transparency and explainability, trustworthiness, etc.
5. Public data resources are shrinking rapidly. The training of AI models relies on massive amounts of publicly available network data, but the latest research shows that data usage will be limited between 2023 and 2024
There has been a significant increase in systems as numerous websites have implemented new protocols to limit data crawling for AI training. In domain names that are continuously maintained by the C4 Universal Crawl Dataset, restricted text
The proportion of data has skyrocketed from 5-7% to 20-33%. This downward trend will affect data diversity, model alignment, and system scalability, and may lead to new learning paradigms under data constraints.
6. The transparency of basic model research has been improved, but there is still a long way to go. The newly released Foundation Model Transparency Index – one
Projects that track transparency in the underlying model ecosystem – show that the average transparency score of major model developers has increased from 37% in October 2023 to 5 in 2024
58% of the month. While progress has been remarkable, there is still considerable room for improvement.
7. The benchmark for evaluating factual and truthfulness is constantly improving. Early benchmarks, such as HaluEval and TruthfulQA, were designed to assess the factuality of AI models
and authenticity, but failed to gain widespread application in the field of artificial intelligence. To this end, newer and more comprehensive evaluation schemes have emerged, including an upgraded version of the Hughes Illusion Assessment Model Leaderboard (
Hughes Hallucination Evaluation Model leaderboard), the FACTS evaluation framework, and the SimpleQA test set.
8. AI-related election disinformation is spreading globally, but its impact remains unclear. In 2024, in more than a dozen countries and more than ten social media platforms, there are large
The amount of AI-related election disinformation, including during the U.S. presidential election. However, there are still many questions about the measurable impact of this issue, and many believe that it is not
The impact of disinformation campaigns on elections is more profound than it really is.
Artificial intelligence in 162025
Index Report
Key takeaways from the report
Chapter 3:
Responsible AI (continued)
9. Large language models that have been trained on explicit unbiased will still exhibit implicit bias. Many advanced large language models, including GPT-4 and Claude 3 Sonnet, are in the design
measures were taken to suppress explicit bias, but they still exhibited implicit bias. These models overly associate negative words with the black community and more with women with humanities
Racial and gender bias in decision-making is exacerbated by the association of science rather than science and engineering (STEM) fields and the preference for men in leadership roles. Although the bias evaluation results have improved on the standard comparison benchmark, AI model bias is still a common problem.
10. Responsible AI has gained the attention of academic researchers. In 2024, the number of responsible AI papers included in the world's top AI conferences will reach 1,278
articles, an increase of 28.8% from 992 in 2023, and has maintained a stable annual growth rate since 2019. This upward trend highlights the role of responsible AI in AI
The growing importance of the research community.
Chapter 4:
economy
1. Global private AI investment is at an all-time high, up 26%. In 2024, global enterprise AI investment will reach $252.3 billion, with private investment increasing year-on-year
44.5%, and the size of M&A transactions increased by 12.1% compared to the previous year. Over the past decade, the sector has experienced significant expansion, with total investment increasing more than thirteenfold since 2014.
2. Generative AI investment has skyrocketed. In 2024, private investment in generative AI reached $33.9 billion, an increase of 18.7% from 2023, which was 2022
8.5 times more than the level. This sector currently accounts for more than 20% of all AI-related private investment combined. 3. The U.S. has extended its lead in global private investment in AI. In 2024, the scale of private investment in AI in the United States will reach $109.1 billion, which is nearly the same as China's
12 times ($9.3 billion) and 24 times ($4.5 billion) in the UK. In generative AI, the U.S. has invested $25.4 billion more than China, the European Union, and the U.K. combined.
This continues to widen from the $21.8 billion deficit in 2023.
4. The use of artificial intelligence is at an unprecedented level. In 2024, the percentage of companies surveyed reporting adoption of AI technology jumped to 78% from 55% in 2023. equally
The number of respondents using generative AI in at least one business function has more than doubled – from 33% in 2023 to 71% in 2024.
Artificial intelligence in 172025
Index Report
Key takeaways from the report
Chapter 4:
Economy (continued)
5. AI has begun to generate financial benefits across multiple business functions, but most businesses are still in the early stages of adoption. The report shows that labor is applied within a single business function
Most of the companies that are smart and have achieved financial benefits are still in the low range. In terms of cost savings, there are businesses that use AI in their customer service operations
Forty-nine percent of respondents reported cost reductions, compared to 43 percent in supply chain management and 41 percent in software engineering. However, most of these companies reported cost reductions of less than 10%. In terms of revenue growth, 71% of respondents to companies applying AI in marketing and sales reported an increase in revenue, 63% in supply chain management, and 57% in service operations. However, it should be noted that these revenue increases are generally less than 5%.
6. The application of artificial intelligence presents obvious regional differences, with Greater China emerging rapidly. Although North America still maintains the leading position in the adoption rate of enterprise AI, but
Greater China had one of the highest year-over-year growth rates, with a 27% increase in enterprise AI adoption. Europe followed with a 23% increase, which indicates global labor
The intelligence landscape is evolving rapidly, and the international competition in the field of artificial intelligence applications is becoming increasingly fierce.
7. China still dominates the field of industrial robots, albeit with a slight slowdown. In 2023, China will install 276,300 industrial robots, six times more than Japan and 7.3 times that of the United States.
Since surpassing Japan in 2013, China's share of global industrial robot installations has risen from 20.8% to 51.1%. While China continues to outperform the world in robot installations
other countries combined, but this gap narrowed slightly in 2023, marking a slight slowdown in the momentum of its sharp expansion.
8. The use of collaborative and interactive robots is becoming more common. In 2017, cobots accounted for only 2.8% of all newly installed industrial robots, and by 2023, this number climbs to:
10.5%。 Similarly, in 2023, the number of service robot installations in all application areas will show an increasing trend, except for medical robots. This trend is not only indicative of the total number of robot installations
body growth, It also indicates that there is a growing emphasis on the deployment of robots in human-oriented jobs.
9. Artificial intelligence (AI) is driving a major change in the energy mix and triggering a new round of attention to nuclear energy. Microsoft announced a $1.6 billion restart of the Three Mile Island nuclear reactor for artificial intelligence
and Google and Amazon have also signed nuclear energy agreements to support AI businesses. 10. AI improves productivity and closes the skills gap. Last year's AI Index report was one of the first to highlight the positive impact of AI on productivity
One. More research this year further validates these findings, confirming that AI can not only improve productivity, but in many cases also help shrink both high- and low-skilled workers
capacity gaps.
Artificial intelligence in 182025
Index Report
Key takeaways from the report
Chapter 5:
Science and Medicine
1. More advanced large-scale protein sequencing models have been introduced. Several high-performance large-scale protein sequencing models, including ESM3 and AlphaFold 3, have been introduced. With the times
Over time, the scale of these models has expanded significantly, resulting in an increase in protein prediction accuracy.
2. Artificial intelligence continues to drive the rapid development of scientific discovery. The role of artificial intelligence in scientific progress is expanding. The year 2022-2023 is only AI-driven research
In 2024, there will be more breakthrough advances, including Aviary, which trains large language model agents to perform biological tasks, and significantly enhanced wildfire prediction capabilities
Force of FireSat.
3. The clinical knowledge level of mainstream large language models continues to improve. OpenAI's recently released o1 set a new record of 96.0% in the MedQA benchmark, compared to 2023
The best results announced increased by 5.8%. Since the end of 2022, the test has seen a cumulative 28.4% improvement in performance. As an important benchmark for assessing clinical knowledge, MedQA can:
Being able to approach performance saturation bodes well for more challenging assessments. This points to the need for a more challenging assessment system.
4. AI outperforms doctors in critical clinical tasks. A new study has found that when it comes to diagnosing complex clinical cases, with or without artificial intelligence
Yes, GPT-4 alone can outperform doctors. Other recent studies have shown that AI has surpassed doctors in cancer detection and identifying patients at high mortality risk. However, some of the beginnings
The research shows that the collaborative diagnosis and treatment of artificial intelligence and clinicians can produce optimal results, and this finding deserves to be further studied as a key area.
5. The number of AI-powered medical devices approved by the U.S. Food and Drug Administration (FDA) has skyrocketed. The U.S. Food and Drug Administration approved the first AI-powered medicine in 1995
Therapeutic equipment. As of 2015, only 6 such devices were approved, but that number has surged to 223 by 2023. 6. Synthetic data shows great potential in the medical field. Research published in 2024 suggests that AI-generated synthetic data can help models better identify healthy societies
Determinants, enhance privacy-preserving clinical risk predictions, and facilitate the discovery of new drug compounds. The latest research in 2024 shows that AI-generated synthetic data can be effectively improved
The ability of the model to identify the social determinants of health optimizes the clinical risk prediction of privacy protection and promotes the discovery of new drug compounds.
7. The literature on the ethics of medical artificial intelligence is increasing year by year. From 2020 to 2024, the number of papers on the ethics of medical AI has almost quadrupled, from 2020
288 to 1031 in 2024.
19 Key takeaways from the report
Chapter 5:
Science & Medicine (continued)
8. The basic model enters the medical field. 8. In 2024, a large wave of large-scale medical basic models will be released, ranging from general-purpose multimodal models such as Med-Gemini to specialty-specific models
EchoCLIP (echocardiography), visual FM (Ophthalmology) and ChexAgent (Radiology) and other specialized models.
9. The public protein database is constantly expanding. Since 2021, there has been a significant increase in the number of entries in major public protein science databases, including UniProt (Growth
31%), PDB (up 23%) and AlphaFold (up 585%). This expansion has important implications for scientific discovery.
10. Won two Nobel Prizes for AI research. In 2024, AI-driven research received top honors, and two AI-related breakthroughs were awarded the Nobel Prize.
Google DeepMind's Demis · Demis Hassabis and John John Jumper pioneered protein folding with AlphaFold
Sex work won the Nobel Prize in Chemistry. At the same time, John John Hopfield and Jeffrey Geoffrey Hinton is known for his work on the neural network side
He was awarded the Nobel Prize in Physics for his foundational contributions.
Chapter 6:
policy
1. U.S. states are leading the AI legislative process, while progress at the federal level has been relatively slow. In 2016, only one state-level AI-related law was passed, and by 2023
year, increased to 49 items. In the last year alone, that number has more than doubled to 131. While there has also been an increase in proposed AI bills at the federal level, the number of passes remains
Rarely.
2. Governments around the world are stepping up investment in AI infrastructure. Canada announced a $2.4 billion AI infrastructure package, while China set up
$47.5 billion semiconductor industry fund. France has pledged $117 billion in AI infrastructure, India has pledged $1.25 billion, and Saudi Arabia's "Beyond Meter."
This includes a $100 billion investment in artificial intelligence.
3. Globally, the mention of AI in the legislative process is on the rise. In 75 countries, there was an increase in the number of mentions of AI in the legislative process in 2024
21.3%, an increase from 1,557 in 2023 to 1,889. Since 2016, the total number of AI mentions has grown more than 9-fold.
202025 Artificial Intelligence
Index Report 2025 Artificial Intelligence
Index Report
Key takeaways from the report
Chapter 6:
Policies (continued)
4. Globally, AI security research institutions are accelerating their expansion and collaboration. In 2024, countries will establish international AI security research institutes. The first institutions are Yumi
The country and the UK took the lead after the conclusion of the inaugural AI Security Summit in November 2023. With the Seoul AI Summit in May 2024, Japan, France, Germany,
Italy, Singapore, South Korea, Australia, Canada and the European Union have also pledged to establish relevant institutions.
5. The number of AI-related federal regulations in the U.S. has skyrocketed. In 2024, the U.S. introduced 59 AI-related regulations, more than double the 25 in 2023. These regulations come:
Since 42 agencies, double the 21 agencies that introduced regulations in 2023.
6. Many states in the United States have strengthened deepfake regulatory legislation. By 2024, only five states, California, Michigan, Washington, Texas and Minnesota, have enacted laws to be elected
Deepfakes are regulated. In 2024, 15 states, including Oregon, New Mexico, and New York, introduced similar measures. In addition, by 2024, there are already 24
The state passed regulations against deepfakes.
Chapter 7:
educate
1. The popularity rate and number of elective students in high school computer science (CS) courses in the United States have increased slightly compared with the previous academic year, but the education gap still exists. Student's ginseng
The situation varies by state, race and ethnicity, school size, geographic location, income, gender, and disability.
2. Computer science teachers in the U.S. want to teach artificial intelligence, but don't think they have it. Although 81% of computer science teachers agree that AI should be applied
and the basic knowledge of artificial intelligence into the basic curriculum system of computer science, but less than half of the high school computer science teachers believe that they have the ability to teach artificial intelligence
Professional competence.
3. Two-thirds of the world's countries offer or plan to offer K-12 computer science education. Since 2019, this proportion has doubled, with Africa and Latino
Progress has been most pronounced in the Americas. However, due to the lack of electricity supply in schools, students in African countries have the least access to computer science education.
Artificial intelligence in 212025
Index Report
Key takeaways from the report
Chapter 7:
Education (continued)
4. Between 2022 and 2023, the number of graduates in the United States who earned a master's degree in artificial intelligence nearly doubled. Despite the fact that artificial intelligence is in the bachelor's degree and doctoral degree off
The increase in interest will be slower, but the surge in master's degrees may be a harbinger of this trend at all degree levels.
5. The United States continues to be a global leader in producing information, technology, and communications technology (ICT) graduates. Spain, Brazil and the United Kingdom followed the United States as the next level of completion
The country with the highest number of graduates, while Turkey has the most balanced ratio of men and women.
Chapter 8:
Public opinion
1. The global attitude towards AI products and services is cautiously optimistic. Respondents in 18 of the 26 countries that Ipsos continues to track in 2022-2024
The proportion of people who agree that the benefits of AI products and services outweigh the disadvantages is on the rise. Globally, the proportion of individuals who believe that the benefits of AI products and services outweigh the harms from:
52% in 2022 rises to 55% in 2024.
2. Awareness of the expected impact of AI on everyday life continues to rise. Around the world, two-thirds of people now believe that AI-powered products and services will be in the future3
Significant changes in daily life within 5 years – a 6 percentage point increase from 2022. With the exception of Malaysia, Poland and India, the rest of the countries have been recognized since 2022
Awareness increased, with Canada (up 17%) and Germany (up 15%) seeing the most significant increases.
3. Skepticism about the ethical behavior of AI companies is increasing, while trust in AI fairness is declining. Globally, people are protecting AI companies
Confidence in people's data from 2023
 50% down to 47% in 2024. Similarly, fewer and fewer people today believe that AI systems are impartial and non-discriminatory.
4. Regional differences in AI optimism remain. For the first time, the 2023 AI Index notes that regional differences in AI optimism remain. In China (83%),
In countries such as Indonesia (80%) and Thailand (77%), the vast majority of people believe that the benefits of AI-driven products and services outweigh the harms, while in Canada (40%), the United States (39%) and the Netherlands (36%), only a minority hold this view.
Artificial intelligence in 222025
Index Report
Key takeaways from the report
Chapter 8:
Public Views (continued)
5. Americans still have a distrust of self-driving cars. According to the latest survey data from the American Automobile Association (AAA), 61%
of Americans are afraid of self-driving cars, with only 13% of respondents saying they trust the technology. This is despite the fact that this percentage is lower than the peak of 68% in 2023
down, but still higher than the 2021 level of 54%.
6. Local policymakers in the U.S. are generally supportive of regulating AI. In 2023, 73.7% of local policymakers in the U.S. (covering town, city, and county governments) support the pair
The implementation of AI supervision has increased significantly from 55.7% in 2022. Democrats (79.2%) have significantly higher support than Republicans (55.5%), but the two parties are evenly matched
This is a significant increase compared to 2022.
7. Optimism about AI has risen sharply among the countries that have previously held the strongest skepticism about AI. Globally, there is a lot of interest in AI products and
Optimism in services has improved, with the largest increase in optimism in the previously most skeptical countries.
In 2022, the United Kingdom (38%), Germany (37%), the United States (35%), Canada
Large (32%) and France (31%) are the countries least inclined to believe that the benefits of AI outweigh the disadvantages. Since then, these countries have seen an 8% increase in optimism about AI,  
10%, 4%, 8% and 10%.
8. Workers expect AI to reshape the structure of employment, but their concern about job replacement is relatively low. Globally, 60% of respondents believe that AI will be in the future
Change the way individuals work in the next five years. However, a small percentage of respondents (36%) believe that AI will replace their jobs in the next five years.
9. There is a clear disagreement among local policymakers in the United States on AI policy priorities. Although local government policymakers in the United States generally support AI regulation, they are better at specific policies
There are significant differences in the first matters. The policies with the highest support ratings include stricter data privacy regulations (80.4%), retraining programs for the unemployed (76.2%), and artificial intelligence applications
Regulatory (72.5%). However, support for policies such as a ban on facial recognition (34.2%), subsidies for wage reductions (32.9%), and a universal basic income (24.6%) for law enforcement has dropped significantly.
10. AI is seen as a tool for efficiency and a booster for entertainment experiences, but its economic impact remains questionable. Global perceptions of the impact of AI vary. 55% of
People believe that AI will save time, with 51% expecting it to provide better entertainment options, but fewer are confident in its health or economic benefits. Only 38% do
36% believe that AI will improve the national economy, 31% believe that AI will have a positive impact on the job market, and 37% believe that AI will improve their productivity.
Artificial intelligence in 232025
Index Report
Chapter 1:
Research and development of artificial intelligence by 2025
Index Report
Table of Contents Chapter 1 Preview 25 Chapter 1: Research and Development
overview
Key points of the chapter
1.1 Publications
overview
The total number of AI papers published
     Categorized by Venue
     Broken down by country
     Classified by industry
     Categorized by research topic
Top 100 Published Papers
     Broken down by country
     By industry type
     By Institution Type
1.2 Patents
     overview
     Broken down by country
1.3 Iconic AI Models
     Broken down by country
     Classified by industry
     Classified by R&D entity
     Model publishing
     Parameter development trends
     The development trend of computing power
     Focus: Will model training face data exhaustion?
     Inference costs
     Training cost: 1.4 hardware
Overview
     Focus: Energy efficiency and environmental impact
1.5 Artificial Intelligence Conference
Size of the meeting
1.6 Open Source Artificial Intelligence Software
Open source AI software project
Star 68
68
71
75
75
77
77
7926
27
29
29
29
31
32
36
38
39
39
40
41
42
42
43
46
46
47
49
50
52
56
59
64
65Access to Public Data Chapter 1:
Research & Development
overview
This chapter explores the latest trends in AI research and development, starting with a systematic analysis of AI publications,
patents and iconic artificial intelligence systems, based on countries and regions, R&D institutions and industry fields
The developer of the results will be analyzed. This chapter also covers the analysis of AI model training costs, conference participation, and open-source AI software. New content this year includes the ecological evolution map of AI hardware, the energy consumption and environmental impact assessment of AI training, and the time series analysis of model inference costs. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 1 Preview Artificial Intelligence in 262025
Index Report
Table of Contents Chapter 1 Preview 272. China leads in the total number of AI papers published, while the United States has the advantage in high-impact research.  
In 2023, China's paper in the field of artificial intelligence was published
Both the number of citations (23.2%) and citations (22.6%) rank first in the world. And in the past three years, U.S. institutions have contributed to the top 100 most cited AI papers.
3. The total number of papers published in artificial intelligence continues to grow and occupies an increasingly important dominant position in the field of computer science. From 2013 to 2023, in computer science and other
The total number of AI papers published in the science subject area has almost tripled, from about 102,000 to over 242,000. Proportionally, AI is in
The share of computer science papers has risen from 21.6% in 2013 to 41.8% in 2023.
4. The U.S. remains the primary source of iconic AI models. In 2024, U.S. institutions developed 40 iconic AI models, significantly more than China's 15 and
3 in Europe. Over the past decade, more iconic machine learning models originated in the United States than in any other country. In 2024, U.S. institutions will develop a total of 40 cutting-edge AIs
model, significantly more than 15 in China and 3 in Europe combined. Over the past decade, the U.S. has maintained a global leader in the number of cutting-edge machine learning models developed.
5. AI models are becoming larger, more demanding, and more energy-intensive. Recent research shows that the training power requirement for iconic AI models increases approximately every 5 months
The size of the large language model training dataset doubles every 8 months, and the power consumption required for training increases every year. Large-scale industrial investment continues to drive model scale and performance improvement
Litre.
6. The cost of using AI models continues to fall. Take MMLU, a common benchmark for language model performance evaluation, as an example, an artificial intelligence that has reached the GPT-3.5 level (64.8 points).
The cost of model queries has been reduced from $20 per million tokens in November 2022 to just $0.07 per million tokens in October 2024 (Gemini-1.5-Flash-8B modulo
type), a decrease of more than 280 times in 18 months. Depending on the type of task, the inference price of large language models has dropped by a factor of 9 to 900 per year. Chapter 1:
Research & Development
Key points of the chapter
1. The industry continues to increase investment in AI and lead the research and development of landmark AI models, while academia leads high-impact research. The industry is researching landmark artificial intelligence models
The dominant advantage of the development continues to strengthen, and this trend has been clearly stated in the previous two AI index reports. In 2024, nearly 90% of cutting-edge models will originate from industry
(up 30 percentage points from 60% in 2023). Academia has been the top institutional contributor to highly cited (top 100) papers for the past three years. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 1 Preview 287. AI patent filings continue to rise. From 2010 to 2023, the number of AI patents has grown steadily and substantially, surging from 3,833 to 122511. Only in the last year,
The number of AI patents increased by 29.6%. As of 2023, China leads the way in the total number of AI patents, accounting for 69.7% of all grants, compared to South Korea on a per capita basis
China and Luxembourg are the main producers of AI patents.
8. AI hardware is getting faster, cheaper, and more energy-efficient. Recent research shows that machine learning hardware performance, as measured by 16-bit floating-point computing power, is growing at a rate of 43% per year
Growth, doubling every 1.9 years. The price/performance ratio has improved significantly – costs have decreased by 30 percent per year, while energy efficiency has continued to improve by 40 percent per year. 9. Carbon emissions from AI training are steadily rising. Early-trained AI models, such as the AlexNet network (2012), had modest carbon emissions of just 0.01 tons.
The carbon emissions from training the latest AI models have increased significantly: GPT-3 was 588 tons in 2020, GPT-4 reached 5,184 tons in 2023, and Llama 3.1 in 2024 
The 405B weighs up to 8,930 tons. For comparison, the average American carbon emitter is just 18 tons per year. Chapter 1:
Research & Development1, OpenAlex is a completely open catalog of academic metadata, including scientific papers, authors, institutions, etc. The AI Index uses OpenAlex as a bibliographic database and uses the latest version of the CSO classifier to automatically classify AI-related research. In previous years, the
Indices rely on third-party providers with varying underlying data sources and classification methods. As a result, the findings in this year's report differ slightly from those in previous reports. In addition, the AI Index only applies classifiers to OpenAlex to classify papers in large areas of computer science. This approach can lead to an insufficient number of AI-related papers, as it excludes research in areas such as the social sciences that employ AI methods but do not fall within the scope of the classification specified by computer science. 2. CSO Classifier (v3.3) is an automated text classification system designed to classify research papers in the field of computer science, including emerging fields such as GenAI, large language models, and prompt engineering, using a comprehensive ontology containing 15,000 topics and 166,000 relationships. It deals with metadata (such as titles and abstracts) through three modules: the syntax module for accurately matching topics, the semantic module utilizes word embeddings to infer related topics, and the post-processing module refines the results by filtering outliers and adding relevant higher-level domains. Artificial intelligence in 2025
Index Report
overview
Statistics on the release of research results. The next section reports on the publication of papers on artificial intelligence in English
Trends in aggregates.
The total number of AI papers published
Figure 1.1.1 shows the total number of AI research publications worldwide
Plan. The results of these studies are from the OpenAlex database, labeled as "Computer."
Science (CS)" category and identified by the AI Index team as related to AI
Related research. 2 Chapter 1: Research and Development
1.1 Publications
1.1 Publications
The chart below shows the global publication of AI papers in English from 2010 to 2023
According to the type of institution, the category of achievements and the geographical distribution of the three-dimensional classification statistics. at
In this year's report, a new section has been added to the AI Index, and 100 articles have been cited
The trend of the highest number of AI papers published can be particularly influential
Research provides insights. This year, the AI Index leverages the OpenAlex database
The trend of artificial intelligence research results is analyzed. Hence the figures in this year's report
It's a little different from previous years. 1 Given the significant lag in the collection of publication metadata,
In some cases,
It is necessary to wait until the middle of the year to fully collect the previous year
Therefore, in this year's report, the AI Index team decided
Only 2023 publishing trends are examined.
The number of AI papers published in the field of CS worldwide from 2013 to 2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
242.74
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023050100150200250
Figure 1.1.1 Number of Artificial Intelligence Papers Published in CS (in thousands)
Table of Contents Chapter 1 Preview 292013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%5%10%15%20%25%30%35%40%45%
41.76% Artificial Intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.1 Publications
Between 2013 and 2023, the total number of AI-related papers published doubled
From about 102,000 in 2013 to more than 24.2 in 2023
10,000 articles. The growth rate of 19.7% over the past year is significant. There are many areas of computer science – from hardware and software engineering to human-computer interaction
- All of them have contributed to the development of artificial intelligence. As a result, the observed increase
The long phenomenon reflects the broader and growing interest in this artificial intelligence.
Statistics of Artificial Intelligence Publications in CS Worldwide (% of Total), 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.2 Proportion of AI papers published in the CS field
Table of Contents Chapter 1 Preview 302013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023020406080100
0.96, Ph.D. Academic Papers 1.64, Other 10.73, Books 44.54, Repositories 83.30, Conference Papers 101.57 , Journal Papers 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.1 Publications
Figure 1.1.2 shows the phases classified as AI in the OpenAlex database
The proportion of computer science papers published in the world. Figure 1.1.2 is used in Figure 1.1.1
The same data, but displayed in scale. The proportion of AI papers published has grown substantially, almost doubling from 2013 to 2023.
Categorized by Venue
AI researchers publish their research on a variety of academic platforms. Figure 1.1.3
The distribution of the total number of papers in the field of artificial intelligence is displayed by platform type. In 2023, journal papers accounted for the largest share (41.8%) of AI paper publications, followed by:
Conference papers published (34.3%). Although the total number of journal and conference papers published has continued to grow since 2013, its share in the field of AI has been steadily declining – from 52.6% in 2013 to 41.8% in 2023, and from 36.4% to 34.3% in conference papers over the same period. In contrast, the proportion of AI papers published in arXiv repositories has increased significantly.
Statistics on Artificial Intelligence Publications in CS by Platform, 2013–2023 (% of Total)
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.3 Publication statistics of AI papers in the CS field (% of total)
Table of Contents Chapter 1 Preview Artificial Intelligence in 312025
Chapter 1 of the Index Report: Research and Development
1.1 Publications
Broken down by country
Figure 1.1.4 illustrates the evolution of AI publications over time in different regions
change
。 3 In 2023, the East Asia and Pacific region in terms of AI research output
leading, accounting for 34.5% of all AI paper publications, followed by Europe and
Central Asia (18.2%) and North America (10.3%). 4
Figure 1.1.4 analyzes the geographical distribution of papers published in the field of artificial intelligence.
The regions with the highest number of research results were revealed; Figure 1.1.5 focuses on citations and counts the proportion of research results in each region in the total number of citations. As of 2023
East Asia and the Pacific region accounted for the largest proportion of citations in AI papers
high, reaching 37.1% (Figure 1.1.5). Back in 2017, the region is in line with North America
The share of citations was basically flat; Since then, the share of North America and Europe has been declining, while the share of citations in East Asia and the Pacific has increased significantly.
Statistics of Artificial Intelligence Publications in CS by Region, % of Total, 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.4 Statistics of Artificial Intelligence Publications in CS (% of Total)
Table of Contents Chapter 1 Preview 322013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230% 5% 10% 15% 20% 25% 30% 35% 34.46% East Asia and the Pacific
19.37%, unknown
18.15%, Europe and Central Asia
10.31%, North America
9.98%, South Asia
5.18%, Middle East and North Africa
1.66%, Latin America and the Caribbean
0.89%, Sub-Saharan Africa
3. The regions in this chapter are grouped according to the World Bank's analysis. The AI Index uses the "Country" field in author identity data to determine the country to which the author belongs. This field lists all the countries to which the author is affiliated based on the institutional affiliation retrieved from OpenAlex.
These affiliations can be clearly stated in the paper or inferred from the author's most recently published paper. When statistics are made by country, the AI Index assigns a count to each country to which the research is linked. For example, if a paper has three authors, two of whom are affiliated with an institution in the United States and one affiliated with an institution affiliated with China, then the paper is counted once in the United States and once in China. 4. If the author's institutional affiliation is missing or incomplete, the country affiliation of the paper may be "unknown". There are many reasons for this problem, including irregularities or omissions in the name of the institution, defects in the functionality of the platform, practices of the author community, non-standard labeling of affiliations, inconsistent document types, or limited author publication records. This article is about issues related to OpenAlex; However, the problem of missing institutions was also related to other bibliographic databases. 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%5%10%15%20%25%30%35%40%
37.07%, East Asia and the Pacific
21.88%, Europe and Central Africa
15.59%, North America
7.97%, Middle East and North Africa
7.69%, 7.55% in South Asia, unknown
1.35%, Latin America and the Caribbean
0.89%, sub-Saharan region
Table of Contents Chapter 1 Preview Artificial Intelligence in 332025
Index Report
Citations (% of total citations) in the field of artificial intelligence in CS by region, 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.5 Statistics of Artificial Intelligence Publications in CS (% of Total) Chapter 1: Research and Development
1.1 Publication of the paper Artificial Intelligence in 2025
Index Report
In 2023, China ranked first in the world in terms of the number of AI papers published, accounting for:
23.2 percent, compared to 15.2 percent in Europe and 9.2 percent in India (see
Figure 1.1.6). 5 Since 2016, China's share has continued to grow steadily, while Europe's share has shown a downward trend. The ratio of papers published in the field of artificial intelligence in the United States
The number of cases remained relatively stable until 2021, but has since declined slightly.  
Statistics on Artificial Intelligence Publications in CS (% of Total) 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.6 Artificial Intelligence Publications in 6CS (% of Total)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%5%10%15%20%25%
23.20%, China
20.65%, unknown
15.22%, Europe
9.22%, India
9.20%, United States 22.51%, Rest of the world
5. In this report and other sections, the definition of "Europe" in the AI Index follows the list of countries defined by the United Nations Statistics Division.
6. Keep it concise and to the point, the AI index visualizes the results for some countries. However, the full results for all countries will be published on AI Index's Global Vibrancy Tool, which is scheduled to be updated in the summer of 2025. For immediate access to country-specific R&D data, please contact the AI Index team.
Table of Contents Chapter 1 Preview 34 Chapter 1: Research and Development
1.1 Publication of the paper Artificial Intelligence in 2025
Index Report
In 2023, Chinese AI papers accounted for 22.6% of citations, ranking first in the world, followed by Europe and the United States with 20.9% and 13.0%, respectively (Figure).
1.1.7） 。 In line with the trend in total publications, the late 2010s marked a key turning point, when China overtook Europe and the United States as the number one cited article in the field of artificial intelligence
To the place of origin. Chapter 1: Research and Development
1.1 Publications
Citations (% of total citations) of AI papers published in CS by selected geographic region, 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.7 Citations of papers in the field of artificial intelligence in the CS field (% of total citations)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%5%10%15%20%25%30%35%
29.83% in the rest of the world
22.60%, China
20.90%, Europe
13.03%, United States
7.54%, unknown
6.10%, India
Table of Contents Chapter 1 Preview Artificial Intelligence in 352025
Index Report
Classified by industry
Academic institutions continue to be the leading source of AI publications worldwide
(Figure 1.1.8). In 2013, academic institutions contributed 85.9% of AI papers;
In 2023, this percentage remains high at 84.9%. In 2023, industry contributed 7.1% of AI papers, with government agencies and non-profit organizations accounting for 7.1%.
The ratios were 4.9% and 1.7%, respectively.
Statistics of AI publications in CS by industry, 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index 2025 Report Chapter 1: Research and Development
1.1 Publications
Figure 1.1.8 Statistics of Artificial Intelligence Papers Published in 7CS (% of Total)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%10%20%30%40%50%60%70%80%90%
84.91%, Academia
7.14%, industry
4.90%, Government
1.70%, non-profit organizations
1.35%, Other
7. Papers in Figure 1.1.8 and Figure 1.1.9 that do not indicate affiliation are not included in the final visual statistics.
Table of Contents Chapter 1 Preview Artificial Intelligence in 362025
Index Report
The industry sources of AI paper publication vary significantly across regions
(Figure 1.1.9). U.S. industry contributed 16.5% of AI papers, significantly higher than China's 8.0%. Among the major regions, the output of China's educational institutions is labor
Smart papers accounted for the highest proportion, reaching 84.5%.
Statistics on Artificial Intelligence Paper Publications in CS by Industry and Selected Geographic Region, in % of Total, 2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.9 Chapter 1: Research and Development
1.1 Publications
Artificial Intelligence Publication Statistics (% of Total)75.61%
16.49%
4.02%
3.88%79.49%
9.62%
6.79%4.09%84.45%
8.02%
6.96%0.58%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% Academia
Industry
Non-profit organizations
Government of the United States
Europe China
Table of Contents Chapter 1 Preview Artificial Intelligence in 372025
Index Report
Categorized by research topic
Machine learning is the hottest research topic in the field of artificial intelligence in 2023, accounting for the total
75.7% of the papers were printed, followed by computer vision (47.2%), pattern recognition (25.9%), and natural language processing (17.1%) (Figure 1.1.10). Over the past year, off
There has been a significant increase in the number of papers on generative AI.
Statistics on Artificial Intelligence Paper Publications by Selected Core Topics, 2013–2023
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index 2025 Report Chapter 1: Research and Development
1.1 Publications
8. The AI Index uses its own subject classifier to classify papers. It is possible for a paper to be given multiple hashtags. Figure 1.1.10 8 Number of AI papers (in thousands)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023050100150 183.78, Machine Learning
 114.61, Computer Vision
62.90, Pattern Recognition
41.40, Natural Language Processing
21.82, Knowledge-based systems
17.34, Evolutionary Computation
13.07, Generative AI
12.00, Logic and Reasoning
11.28, Multi-agent systems
5.25, Robot
Table of Contents Chapter 1 Preview Artificial Intelligence in 382025
Index Report
Top 100 Published Papers
While tracking the total number of AI papers can provide an overview of AI research
The macro view of the activity, but focusing on the most cited papers reveals that
The most influential research results in the field. This analysis reveals where some of the most groundbreaking and impactful AI research is emerging. This year, the AI Index identified the 100 most cited AI papers in 2021, 2022, and 2023 through OpenAlex's citation data.
92023 was used
The most cited AI papers include OpenAI's GPT-4 technical report, Meta's Llama 2 technical report, and Google's PaLM-E technical report. It is noteworthy that due to the lag of citations, this year's report is cited several times
The largest number of papers may change in future editions.
Broken down by country
Figure 1.1.11 shows the top 100 most cited AI papers by year
Geographical distribution of . From 2021 to 2023, the United States has been the most cited country
home, 64 in 2021, 59 in 2022, and 50 in 2023. 10 Since
Since 2021, the share of the top AI papers in the United States has gradually declined.
Statistics of Top 100 Highly Cited Papers by Selected Geographic Region, 2021–2023
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index 2025 Report Chapter 1: Research and Development
1.1 Publications
9. The complete research methodology guide and the list of top 100 papers are detailed in the appendix.
10. A publication can have multiple authors from different countries or organizations. For example, if a paper includes authors from multiple countries, it will only be counted once for each country. Therefore, the sum of the numbers in this section is more than 100. Figure 1.1.1150
34
7
7
6
6
5
4
4
459
34
7
64
43
32164
33
10
8
7
74
3
1
1
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 662023
2022
2021
United States
China, Germany, Hong Kong
Canada
South Korea, Great Britain
United Arab Emirates
Israel, Singapore
Number of Top 100 Highly Cited Papers
Table of Contents Chapter 1 Preview Artificial Intelligence in 392025
Index Report
Classified by industry
Academia continues to produce the most cited AI papers, 2023
42 articles, 27 in 2022 and 34 in 2021 (Figure 1.1.12). Noteworthy
The number of papers in the top 100 has plummeted from 17 in 2021 and 19 in 2022 to just 7 in 2023. With artificial
The competition for intelligence research is becoming increasingly fierce, and many industry AI labs are reducing publishing
The frequency of papers may be reduced in the disclosure of research details. Chapter 1: Research and Development
1.1 Publications
11. The "hybrid" designation includes all non-industry and academia cross-sector collaborations (e.g., industry and government, academia and non-profit organizations). Some institutions lack data for 2021 because they didn't have papers in the top 100 that year. Since multiple authors of a paper may be from different institutions,
As a result, there may be more than 100 institution labels in Figure 1.1.12 in total. In addition, the total number of papers in Figure 1.1.12 is 98 because the authors of two papers are of unknown departments.
Table of Contents Chapter 1 Preview 402021–Statistics of the Top 100 Highly Cited Papers by Selected Industry, 2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.12 Number of Top 11 Top 100 Highly Cited Papers 42
72524
227
1935
1734
1731
17
1
0510152025303540452023
2022
2021
Academia Industry Industry and Academia Mixed Other
Artificial intelligence in the industry in 2025
Index Report
By Institution Type
Figure 1.1.13 illustrates the global AI field from 2021 to 2023
Distribution of the top 100 cited paper source institutions. Some institutions may appear in the chart
Blank column, which indicates that the institution has not published a top 100 paper in a certain year. In addition, Figure 1.1.13 lists only the top 10 institutions, although many others have also made important contributions.  Google tops the list every year, but ties with Tsinghua University for number one spot in 2023
First, 8 papers from both were selected in the top 100. In 2023, Carnegie Mellon University is
The highest-ranked U.S. academic institution. Chapter 1: Research and Development
1.1 Publications
Table of Contents Chapter 1 Preview 412021–Statistics of the Top 100 Highly Cited Papers by Institution Type in 2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.1.13 Number of Top 100 Highly Cited Papers 8 8
6 6
5 5 5
4 4 420
10
9 9
4
3 3
2 2 215
10
7
5
2 2
1
0246810121416182022 2023
2022
2021
Google, Tsinghua University, Carnegie Mellon University, Microsoft, Beijing Institute of Artificial Intelligence, Hong Kong University of Science and Technology
Laboratory: Shanghai Artificial Intelligence, Chinese Academy of Sciences, Meta Nvidia
Institution Type: 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.2 Patents
Table of Contents Chapter 1 Preview 4222010–2023 Number of AI Patents Granted Worldwide
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.2.1 Number of AI patents granted (in thousands)1.2 Patents
overview
Figure 1.2.1 shows the growth of AI patents worldwide from 2010 to 2023. In the past
Over the past decade, the number of AI patents has grown steadily and substantially, from 3,833 in 2010 to 2023
122511 of the year. Last year, the total number of AI patents increased by 29.6%. This section analyzes the time-series evolution trends of AI patents around the world.
Reveal the relationship between technological innovation, research progress and industrial development in the field of artificial intelligence
key dynamics. In addition, analyzing AI patents can reveal how these technological advancements are distributed across the globe. Similar to publication data, there is also a significant delay in the availability of AI patent data, with 2023 being the most recent year for data to be available. The data in this section are taken from PATSTAT Global, a comprehensive database provided by the European Patent Office (EPO).
Patent-grade catalog records. 12
122.51
12. Please refer to the Appendix for more details on the patent analysis methods in this section. 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 Artificial Intelligence 20230204060801001202025
Chapter 1 of the Index Report: Research and Development
1.2 Patents
Table of Contents Chapter 1 Preview 43Number of AI Patents Granted by Region (% of Global Total) from 2010 to 2023
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025 by Country
Figure 1.2.2 illustrates the regional distribution of AI patents granted, i.e., globally
Number of patents filed in different regions. As of 2023, as of 2023, Worldwide
The vast majority (82.4%) of the granted AI patents are from the East Asia and Pacific region, with North America coming in second with 14.2%. Since 2010,
There is no gap between East Asia and the Pacific and North America in terms of AI patent licensing
Broken expansion.
Figure 1.2.2 13
13. Patent standards and laws vary from country to country, so caution should be exercised when interpreting these charts. More detailed national patent information will be published in a subsequent edition of AI Index's Global Vibrancy Tool.
Patents on Artificial Intelligence (% of global total)
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%10%20%30%40%50%60%70%80%90%
82.40%, East Asia and the Pacific
14.23%, North America
2.77%, Europe & Central Asia 0.37%, South Asia 0.15%, Rest of the World 0.04%, Latin America and the Caribbean 0.02%, MENA 0.02%, Sub-Saharan 2025 AI
Chapter 1 of the Index Report: Research and Development
1.2 Patents
Table of Contents Chapter 1 Preview 442010–2023 Number of AI Patents Granted by Region (% of Global Total)
Source: Artificial Intelligence Index 2025 | Chart: The 2025 AI Index report breaks down by geographic region and accounts for the vast majority of granted AI patents worldwide
from China (69.7%) and the United States (14.2%) (Figure 1.2.3). Artificial from the United States
The share of smart patents has declined from its peak in 2015 (42.8%).
Figures 1.2.3 and 1.2.4 document which countries have the highest number of AI patents per capita
in the lead. In 2023, the country with the most AI patents granted per 100,000 inhabitants was South Korea (17.3), followed by Luxembourg (15.3) and China
(item 6.1) (Figure 1.2.3). Figure 1.2.5 shows the number of people per capita from 2013 to 2023
Changes in the number of patents granted by AI. During this period, Luxembourg, China and Sweden saw the largest increases in AI patents per capita.
Figure 1.2.3 AI patents granted (% of global total)
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%10%20%30%40%50%60%70% 69.70%, China
14.16%, United States
13.00%, Rest of the world
2.77%, Europe
0.37%, Artificial Intelligence in India 2025
Chapter 1 of the Index Report: Research and Development
1.2 Patents
Table of Contents Chapter 1 Preview Number of AI patents granted per 100,000 inhabitants by country in 452023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.2.4
Comparison of the percentage change in the number of AI patents granted per 100,000 inhabitants by country in 2013 vs. 2023
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.2.5 AI patents granted (per 100,000 inhabitants): 0.270.380.400.430.470.520.740.970.981.224.585.206.0815.3117.27
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 South Korea
Luxembourg
China
United States, Japan, Germany
Singapore
Finland, Sweden, United Kingdom, Denmark, France, Netherlands
Australia
Greece
Percentage change in number of AI patents granted (per 100,000 inhabitants)230%240%365%463%580%730%1,028%1,043%1,097%1,653%2,546%2,851%3,453%6,317%8,216%
0% 1,000% 2,000% 3,000% 4,000% 5,000% 6,000% 7 ,000% 8,000% Luxembourg
China
Sweden, Greece
Singapore
Finland, Germany, South Korea, the Netherlands, the United Kingdom, the United States, France, Japan
Australia
Artificial intelligence in Denmark 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 previews the number of iconic AI models by selected geographic region in 462024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
14. "AI system" refers to an artificial intelligence-based computer program or product, such as ChatGPT. The AI Model includes a set of parameter values learned during training, such as GPT-4.
15. New and historical models are constantly being added to the Epoch AI database, so the year-over-year totals of models included in this year's AI Index may not exactly match the data published in last year's report. The statistics were taken as of March 17, 2025. 16. If at least one of the authors of the paper introducing a machine learning model is associated with an institution in a country, then the model is relevant to that country. If the authors of the model are from more than one country, double counting may occur. 17. This chart: shows the release of the model in some of the selected countries. More comprehensive data on model releases by country will be available in the upcoming release of AI Index's Global Vibrancy Tool. Number of iconic AI models by selected geographic region, 2003-2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.2 Figure 1.3.1 171.3 Iconic AI models
Broken down by country
To illustrate the evolving geopolitical landscape in the field of artificial intelligence, the AI Index showcases iconic
The country to which the model belongs. Figure 1.3.1 shows the iconic AI attributed to the location of the researcher's institution
The total number of models. 16 In 2024, the United States leads the way with 40 iconic AI models, and China with 15
It is followed by France with three. The world's major economies including the United States, China, and the European Union are all reported in 2024
said that fewer iconic models will be released in 2024 than in the previous year (Figure 1.3.2). Since 2003, the United States has opened
More models were developed than in other major countries such as the United Kingdom, China and Canada (Figure 1.3.3).
The exact reason for the decline in the total number of model releases is difficult to determine, but it may be due to a combination of factors:
The growing size of training data, the increasing complexity of AI technologies, and the development of new modeling methods are facing
The challenges are growing. Epoch AI's current inclusion of iconic models may have left out some of the less high-profile countries
home. The AI Index has partnered with Epoch to improve the AI model ecosystem
Global representation. If you think that the model of some country is missing, please contact the AI Index team
We will work to solve this problem. This section explores iconic AI models. Artificial intelligence refers to
Epoch AI, a data provider, uses "Signature Machine Learning."
The term "notable machine learning" is used to refer to models that are particularly influential in the AI/ML ecosystem. Epoch maintains a database of 900 AI models published since the 1950s, based on core metrics such as technological breakthroughs, historical milestones, or high citation rates. Because Epoch manually collated the data, some models that some consider iconic may not have been included. By analyzing these models, we can get a comprehensive picture of how the field of machine learning has evolved in recent years and over the past few decades. Some models may be missing from the dataset, but the dataset can reveal relative trends. Iconic AI models include GPT-4o, Claude 3.5, and AlphaGeometry.
In this section, the AI Index explores different perspectives
Trends in the model are marked, including the country of origin, the organization of origin, the model release gradient, the number of parameters, and the computational usage. Finally, the training cost and inference cost of machine learning are discussed and analyzed.
2003
2006
2009
2012
2015
2018
2021
2024010203040506070
3, 15 in Europe, 40 in China, USA
The number of iconic AI models 111131540
0 5 10 15 20 25 30 35 40 United States
China
France
Canada, Israel
UAE
Artificial intelligence in South Korea 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Classified by industry
Figure 1.3.4 illustrates the iconic AI by model release year
Distribution of sources by field. Epoch categorized the models based on the source: Industry
The world includes companies such as Google, Meta, and OpenAI; The academic community includes universities such as Tsinghua University, Massachusetts Institute of Technology, and the University of Oxford; Government refers to state-affiliated research institutions, such as the Alan Turing Institute for AI in the United Kingdom and the Technology Innovation Institute in Abu Dhabi; The research collective includes the non-profit artificial intelligence research organization Allen Insititute for AI and the Fraunhofer Institute. Prior to 2014, academia was in a position to release machine learning models
Leading the way. Since then, industry has taken the lead. According to Epoch AI, in 2024, the industry will generate 55 iconic AI models.
18 with
With the passage of time, the number of models promoted by industry-university-research cooperation continues to grow. Over the past decade, the proportion of well-known AI models from industry has steadily increased, reaching 90.2% by 2024. Number of Iconic AI Models by Geographic Region (Total) 2003-2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.3
Table of Contents Chapter 1 Preview 471–10
11–20
21–60
61–100
101–560
18. Caution should be exercised in interpreting this figure. A zero number of academic models does not mean that academic institutions have not produced any iconic models in 2023, but rather that Epoch AI has not discovered any iconic models. In addition, academic research often takes longer to be recognized,
even thoughIt is the highly cited papers that introduce significant architectures that can also take years to have a broad impact. Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 482003–Number of Iconic AI Models by Industry, 2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Iconic AI Models by Industry, % of Total, 2003–2024
Source: Epoch AI, 2025 | Chart: 2025 AI Index Report Figure 1.3.4 Number of iconic AI models
Figure 1.3.5 Iconic AI Models (% of Total)  
2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015
2016
2017
2018
2019
2020
2021
2022
2023
20240%20%40%60%80%100%
8.20%, industry-academia collaboration
1.64%, Industry-Government Collaboration0.00%, Government0.00%, Industry-Research Community Collaboration 0.00%, Research Community0.00%, Academia-Research Community Collaboration0.00%, Academia-Government Collaboration0.00%, Academia90.16%,  Industry 2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015
2016
2017
2018
2019
2020
2021
2022
2023
20240102030405060
5. Industry-academia collaboration
1, Industry-Government Collaboration0, Government0, Industry-Research Community Collaboration0, Research Community0, Academia-Research Community Collaboration0, Academia-Government Collaboration0, Academia55, Industry Artificial Intelligence 2025
Index Report
Table of contents The first chapter preview 49 times is Meta (82) and Microsoft (39). In academic institutions, Carnegie Me
Long University (25)
, Stanford University (25) and Tsinghua University (22).
Since 2014, the most achievements have been made in the development of iconic models.
19. Among the organizational statistics, the study published by DeepMind is attributed to Google. Chapter 1: Research and Development
1.3 Iconic AI Models
Classified by R&D entity
Figures 1.3.6 and 1.3.7 show the 2024 and past 10 years, respectively.
Distribution of leading institutions in the field of machine learning landmark model development. In 2024,
The top contributors are Google (7), OpenAI (7 models) and Alibaba (4
pcs). Since 2014, Google has led the way with 187 iconic models
Number of iconic AI models by organization in 2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of Iconic AI Models by Organization, 2014–2024 (Total)
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report Figure 1.3.6 19
Figure 1.3.7 Number of iconic AI models
The number of iconic AI models is 187
82
39
36
25
25
22
22
17
16
15
15
15
14
12
0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 Google
Meta
Microsoft
OpenAI
Carnegie Mellon University
Stanford University
Tsinghua University
University of California, Berkeley
Nvidia
Oxford
Mit
Salesforce
University of Washington
Alibaba
Allen Institute for AI Academia
Industry
Research community 7
7
6
4
4
4
3
3
2
2
2
2
2
2
2
0 1 2 3 4 5 6 7 Google
OpenAI
Alibaba
apple
Meta
Nvidia
Anthropic
Mistral AI
ByteDance
DeepSeek
Mit
Tencent 
University of California, Berkeley
Writer
Zhipu AI Academia
Artificial Intelligence in Industry 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Model publishing
Machine learning models can be divided into multiple types of releases according to the degree of openness and usage permissions
Type. API access models, such as OpenAI's o1, allow users to query with a model
without having direct access to its underlying weights. Open-source weighting models under constraints, such as DeepSeek's V3, provide access to their weights, but impose some restrictions, such as prohibiting commercial use or secondary distribution. Managed access to non-API class models, such as Gemini 2.0 Pro, refers to models that are only available through the platform interface and do not provide programmatic call interfaces. Unrestricted open-source weighting models, such as AlphaGeometry, are completely open, allowing for free use, modification, and redistribution. Non-commercial open-source weighting models, such as Mistral Large 2, share weights, but only for research or non-commercial purposes. Finally, unreleased models, such as the ESM3 98B, remain proprietary and only accessible to their developers or selected partners. Unknown means that the access type is not
Explicit or undisclosed model numbers.
Figure 1.3.8 illustrates the different access classes used for each type of model release
Type. 20 In 2024, API access is the most common release type, with 61 models
There are 20 of them that are available in this way, followed by the open source weights that limit the use of the sum
The model was not published.
Figure 1.3.9 shows the types of access rights for the machine learning model in terms of scale
Evolution over time. In 2024, most AI models will be accessed via APIs
released (32.8%), which has steadily increased since 2020.
Table of Contents Chapter 1 Preview 5020, Managed Access refers to the use of computing resources or services (such as software, hardware, or storage) provided remotely by a third party rather than owning or managing those resources or services yourself. Instead of running software or infrastructure on-premises, managed access is done through the cloud or other remote services, usually mutual
networking) to access these resources. For example, using a GPU through a platform such as AWS, Google Cloud, or Microsoft Azure, rather than running the GPU on your own hardware, is managed access. 21. Not all models in the Epoch database are categorized by access type, so the totals in Figures 1.3.8 to 1.3.10 may not exactly align with the totals reported elsewhere in this chapter. Number of iconic AI models by type of access, 2014–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.8 Number of 21 iconic AI models
1220
910121611
1027
2732 2020
10192336
2119
2214
10
3019363817132630
32
285058
5172
547586105
61
2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024020406080100120 API access
Open Source Weights Under Restrictions: Unknown, Managed Access, Non-API, Unrestricted Open Source Weights, Non-Commercial Open Source Weights, Undisclosed 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
In a traditional open source software release, all components, including the training code, are typically
will be public. However, this is often not the case with AI technology, even when models are released
Developers who are weighted may also keep the training code. As shown in Figure 1.3.10, iconic AI models can be categorized by how open the code is. In 2024, 60.7% of these models are released without exposing the training code synchronously.
Table of Contents Chapter 1 Preview 512014–2024 Iconic AI Models by Access Type (% of Total)
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of iconic AI models by type of training code access, 2014–2024
Source: Epoch AI, 2025 | Chart: Figure 1.3.9 of the 2025 AI Index Report
Figure 1.3.10 Iconic AI Models (% of Total) Number of Iconic AI Models: 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 20240%, 10%, 20%, 30%, 40%, 50%, 60%, 70%, 80%, 90%, 100%
18.03%, open source weight under constraints 
16.39%, undisclosed 11.48%, unrestricted open source weight 9.84%, non-commercial open source weight 8.20%, managed access non-API
3.28%, Unknown 32.79%, API access
1633
2229
161311
9111526
2429
2837
37
30 2137401914 3848
18
32
285058
5172
547586105
61
2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024020406080100120 Open Source Restricted Open Source Non-Commercial Open Source Undisclosed Unknown 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 52 Parameter Trends
The parameters in a machine learning model are the numerical values learned during the training process
Define how the model interprets the input data and makes predictions. Models with more parameters are required
More data to train, but they can take on more tasks and are often better than models with fewer parameters.
Figure 1.3.11 shows the number of parameters for a machine learning model in the Epoch database
volume, and is categorized by the industry from which the model originated. Figure 1.3.12 shows the same data, but with fewer iconic models. Since the early 2010s, there has been a dramatic increase in the number of model parameters, reflecting a key factor: complex architectures
The degree continues to improve, the training data is increasingly abundant, the hardware facilities are continuously improved, and the large model
The performance has been proven. The performance of high-parameter quantitative models is particularly prominent in the industry
It shows that the enterprise has strong financial strength to support massive data training
Huge computational costs required. Some of the following charts are on a logarithmic scale
It does reflect the exponential growth in the number of AI model parameters and computational requirements in recent years
Situation.
Number of iconic AI model parameters by industry, 2003–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.11 Number of iconic AI models
Release dates: 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 202410010K1M100M10B1T, Academia
Academia – Government, Industry, Industry, Research Community, CollaborationIndustry, Academia, Government Research Community, Artificial Intelligence 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 532012–Number of Iconic AI Model Parameters by Industry, 2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.12 Number of parameters (logarithmic scale)
Release date: AlexNetDeepSeek-V3
Qwen2.5-72BMistral Large2  
Llama 2-70BPaLM (540B)Megatron-Turing NLG 530B
GPT-3 175B (davinci)
BERT-Large
TransformerERNIE3.0 Titan  
RoBERTa Large
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024100M1B10B100B1T Industry – Academia Industry Academia Artificial Intelligence 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 54Data used to train an AI system as the number of model parameters increases
The volume is also increasing. Figure 1.3.13 shows the model used to train the iconic machine learning model
Growth in dataset size。 Released in 2017 and widely credited with sparking the large language model revolution, the Transformer model was trained on about 2 billion tokens. By 2020, GPT-3 175B — one of the original ChatGPT's base models — was estimated to have been trained on 374 billion tokens. By comparison, Meta's flagship large language model, Llama 3.3, released in the summer of 2024, is trained on about 15 trillion tokens. According to Epoch AI, the size of large language model training datasets doubles approximately every eight months.
Landmark AI Model AI Model Training Dataset Size, 2010-2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Training dataset size (tokens - logarithmic scale)
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 202410K1M100M10B1T100TLlama 3.1- 405B
TransformerGPT- 3 175B (davinci)DeepSeek- V3
PaLM (540B)GPT- 4
AlexNetQwen2.5- 72B
Figure 1.3.13 Release date: 2025 Artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 55Training models on larger and larger datasets resulted in significantly longer training times
(Figure 1.3.14). Some of the most advanced models, such as the Llama 3.1-405B, need to be large
About 90 days to train – which is a typical training session by today's standards
Cycle. Google's Gemini 1.0 Ultra, released at the end of 2023, took about 100 days. This is in stark contrast to AlexNet, which was one of the first to be used
One of the GPU-improved models was trained in just five to six days in 2012. It's worth noting that AlexNet's training hardware is nowhere near as advanced as the latter.
Iconic AI model training time from 2010–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.1110100
AlexNet
TransformerBERT-Large
RoBERTaLarge  GPT-3 175B(davinci)  Megatron-Turing NLG530B  PaLM (540B)
GPT-4
Llama 3.1-405B Training Duration (Days - Logarithmic Scale)
Figure 1.3.14 Release date 2025 Artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 56 Computing Power Development Trends
In the field of AI models, "compute" refers specifically to training and
The basic computing resources required to run a machine learning model. In general, the model is complex
The degree and the size of the training dataset will directly affect the amount of computing resources required. The higher the complexity of the model and the larger the amount of training data, the greater the scale of computing power required for the training process. Researchers perform multiple test runs throughout the R&D phase before the final training run. While the cost of training a single model is relatively low, the cumulative cost of multiple R&D iterations, as well as the cost of necessary datasets, will quickly climb to a significant scale. It is important to note that the current data only reflects the cost of the final training phase, not the total investment of the complete development process. Figure 1.3.15 illustrates the training required for a landmark machine learning model over the last 22 years
Changes in the practice of computing power. It is worth noting that in recent years important artificial intelligence models
Computing power consumption has shown an exponential growth trend. 22 According to Epoch's estimate, iconic people
The training power of the AI model doubles approximately every five months. This trend is in the past
This is especially true in the past five years. The rapid growth of computing power demand has a significant impact. to calculate
Intensive models, for example, tend to have a larger environmental footprint
(environmental footprints), and corporate organizations typically have more than academic organizations
There are more abundant computing resources. For reference, Chapter 2 of the AI Index analyzes:
Correlates between compute resource improvements and model performance improvements.
Iconic AI model training computations by industry, 2003–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Training Computation (Giga Floating-Point Operations - Logarithmic Scale)
Figure 1.3.1523 Release Date
22. FLOP (floating-point operation) means "floating-point operation". Floating-point arithmetic is a single arithmetic operation that involves floating-point numbers, such as addition, subtraction, multiplication, or division. The amount of FLOP that a processor or computer can execute per second is a measure of its computing power. The more FLOP the rate
high, the more computing power the computer has. The number of floating-point operations used to train an AI model reflects the computing power required during the development of the model.
23. Estimation of training computing power is an important aspect of AI model analysis, but it often needs to be measured indirectly. In cases where direct reports are not available, Epoch estimates the amount of computation by using hardware specifications and usage patterns or by calculating arithmetic operations based on model architecture and training data. at
When neither approach is feasible, the benchmark performance can be used as a proxy to infer the training power by comparing the model to known computed values. For full details on the Epoch methodology, please refer to the documentation section of their website. 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024100μ0.01110010K1M100M10BIndu try
Gov ernment Academia
Industry – Research CommunityIndustry – AcademiaResearch CommunityAcademia – Government: Artificial Intelligence 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 57Figure 1.3.16 shows a landmark machine learning model since 2012
Changes in training computing power requirements. For example, AlexNet Networks is promoting the use of GPUs
One of the models that improves the standard practice of AI models, its training is estimated to require 470 petaFLOP.
The original Transformer, released in 242017, requires an appointment
7,400 petaFLOP。 OpenAI's GPT-4o, one of the most advanced base models currently available, requires 38 billion petaFLOP. Today, developing cutting-edge AI models requires massive amounts of data, massive amounts of computing power, and deep financial support, all of which are not available to academics. Most of the leading AI models are from industry, last year
For the first time, this trend is highlighted by the Artificial Intelligence Index. Although the gap has narrowed slightly this year, the trend persists.
Signature AI model training computation by domain, 2012–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Training Computation (Giga Floating-Point Operations - Logarithmic Scale)
Figure 1.3.16
24. petaFLOP (PFLOP) is a unit of measurement of computing performance, 1 PFLOP is equivalent to 4 quadrillion (10¹r) floating-point operations per second DeepSeek-V3Qwen2.5-72B
Llama2-70B  Claude 2PaLM (540B)
Megatron- Turing NLG 530B
GPT-3 175B (davinci)
RoBERTa Large
BERT-Large
TransformerSegment Anything Model
AlexNetGPT-4
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024100010K100K1M10M100M1B10B100BLanguage Vision Multimodal
Mistral Large 2Claude 3.5 Sonnet
Gemini1.5Pro   GPT-4o
ERNIE 3.0 Titan
Release date: 2025 Artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview In December 582024, Deep Seek launched the V3 model, which caused a lot of noise
concern, especially since the model's computing resource requirements are much lower than many leading ones
In the case of language models, excellent performance is achieved. Figure 1.3.17 compares the amount of computation required to train some of the iconic machine learning models in the U.S. and China, highlighting a key trend: the computation of the top U.S. AI models is typically much higher than that of the medium
national model. According to research data from Epoch AI, since the end of 2021, Chinese
The average annual growth rate of the training power of the top 10 language models is about 3 times, which is significantly lower than the average annual growth rate of 5 times in the rest of the world since 2018.
Analysis of the training computing power of some landmark AI models in the United States and China from 2018 to 2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Training Computation (Giga Floating-Point Operations - Logarithmic Scale)
Figure 1.3.17 Release date: 2018, 2019, 2020, 2021, 2022, 2023, 2024100100010K100K1M10M100M1B10B100B, USA, GPT-4
GPT-3 175B (davinci)Grok-2Claude 3.5 Sonnet
DeepSeek-V3Doubao-pro ERNIE3.0 Titan  
Qwen 2.5-72B 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 59 The entire network
( Including private data )image Video highlights :
Will model training face data exhaustion?
The main driver of substantial improvements in algorithms in AI systems
One of the forces is scaling models and their training on larger and larger datasets. correct
However, as the Internet training data is increasingly depleted, there are growing concerns about the sustainability of this scaling approach and the possibility of data bottlenecks, in which case the gains to scale will gradually diminish. Last year's AI Index explored a variety of factors in this debate, including the availability of existing internet data and the potential to train models on synthetic data. New research this year suggests that existing data stocks may last longer than previously anticipated. Epoch AI has updated its previous estimate of when AI researchers might run out of data. In the latest study, the team used lemma count to estimate the results
The total amount of valid data that can be used to train the model
(Figure 1.3.18). 
Common Crawl, an open network commonly used for AI training
crawler database,
It is a web scraping data that is often used in AI training
Put the repository, it is estimated that it contains a median of 130 trillion tokens. index
The network contains about 510 trillion tokens, while the entire network contains about 3100 trillion
tokens. In addition, the total stock of pictures is estimated at 300 trillion, and video is
1350 trillion.
Median estimate of data stock
Source: Epoch AI, 2025 | Chart: AI Index 2025 Number of tokens (median – logarithmic scale)
Figure 1.3.18130T510T3,100T
300T1,350T
Common Crawl Index web300T1000T3000T
Source: Artificial Intelligence 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 60 Key Points :
Model training faces data exhaustion
The Epoch AI research team expects that within the 80% confidence interval, when:
The previous training data stock will be used in its entirety between 2026 and 2032
END (Figure 1.3.19). The exact time it takes to run out of data is affected by a number of factors. One of the key factors is the historical growth of dataset size, which depends on the amount of content generated and contributed by Internet users. Another key factor is the efficiency of computing power – if the optimal computing power configuration scheme is used for model training, the existing data stock can be supported for a longer period of time. However, if the model is overtrained to improve efficient inference computing capabilities, the data stock may be exhausted faster. When AI models are overtrained, i.e. theyAfter being trained beyond the typical diminishing return point, they are likely to achieve higher inference computational efficiency, that is, they can use less computing power to process prompts (making predictions, generating text, and so on). However, the trade-off is the accelerated consumption of data stock (i.e., data used to train the model).
Forecasting of public text and data usage stocks
Source: Epoch AI, 2025 | Chart: 2025 AI Index Effective stock (number of tokens - logarithmic scale)
Release date
Figure 1.3.19 (continued)
Llama 3.1- 405B
DBRX
Falcon- 180B
PaLM (540B)FLAN 137B
GPT- 3 175B (davinci)
2020 2022 2024 2026 2028 2030 2032 203410B100B1T10T100T1015 
Estimate of the data stock
Median time point in data stock, full utilization, median date of full utilization, (5x overtrained), 2025 artificial intelligence
Index Report
Focus:
Model training faces data exhaustion
These predictions differ slightly from Epoch's earlier estimates, which had predicted
The measured high-quality text data will be depleted in 2024. The revised forecast reflects
An updated methodology that incorporates new research that shows that network data performs better than curated corpora and that models can be trained on the same dataset multiple times. The study found that carefully filtered network data is valid and that it is feasible to train the same dataset repeatedly, which expands the estimate of the amount of data available. As a result, Epoch researchers postponed predicting when data consumption would occur as much as possible.
Using synthetic data, i.e., data generated by the AI model itself, to train a model is also considered a solution to a potential data shortage. The 2024 AI Index report points out that there are limitations to this approach, that is, the model may lose the representation of the distribution tail after being trained with synthetic data multiple times, resulting in a decrease in the quality of the model output. This phenomenon is not in the same mode
Variational autoencoders (VAEs), Gaussian mixture models (GMMs), and large language models (LLMs) have been observed. However, recent research shows that model crash does not occur when synthetic data is used in conjunction with real data, rather than being completely replaced. While this overlay doesn't necessarily improve performance or reduce test loss (the lower the test loss, the better the model performance), it also doesn't result in performance degradation like when the data is completely replaced (Figure 1.3.20).  
The impact of data accumulation on language models pre-trained on TinyStories
Source: Gerstgrasser et al., 2024 | Chart: 2025 Artificial Intelligence Index Report Cross-Entropy (Test) ↓
Model Fitting Iteration Model fitting iteration
Figure 1.3.20 (continued) Chapter 1: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 611 2 3 4 51.61.822.22.42.62.8
1 2 3 4 51.61.822.22.42.62.8Llama-2 (126M) Llama-2 (42M) Llama-2 (12M) GPT-2 (9M)
Alternative to cumulative 2025 artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 62 Key Points :
Model training faces data exhaustion
This year, high-fidelity synthetic data (high-fidelitysynthetic 
data). However, synthetic data vs. real data
There are still differences overall, and there is currently no scalable way to make large language models train on synthetic data on par with real data compared to real data. The Slovenian research team compared the training performance of synthetic data with real data through a variety of architectures and datasets, and evaluated the performance of synthetic relational data in terms of retaining the key characteristics of the original data ("fidelity") and usefulness for downstream tasks ("usability"). They found that the synthetic data generated by most methods can be systematically identified, especially when it comes to relational information. In addition, the efficient attention of models is usually reduced compared to models trained on real data, but some methods can still obtain above-average prediction scores. In a few experiments, synthetic data performed better, such as training an XGBoost classifier with synthetic data from Synthetic Data Vault (SDV) that outperformed Walmart data with a lower mean square error (MSE). There is also evidence that synthetic data has significant potential in the healthcare field: some model architectures trained on synthetic augmentation datasets can improve F1 scores or AUROC (area under the receiver operant characteristic curve) for classification and prediction tasks by 5%-10% on a few classes.
25 It is well known that large language models produce hallucinations and provide inconsistencies with the facts
, so concerns have been expressed about the quality and fidelity of the synthetically generated data. When training on the hallucinatory content in the dataset, the model loses
The deterioration of the output quality may be accelerated. To solve this problem, new technologies have been developed. For example, researchers at Stanford University and the University of North Carolina at Chapel Hill used automated fact-checking and confidence scoring to rank the factual scores of model response pairs. The FactTune-FS method introduced by these researchers tends to outperform other RLHF-based and decoding methods in terms of factual improvements (Figure 1.3.21). In addition, the human-in-the-loop method of tagging preferred responses has also been used to align language models, which is effective but expensive. Finally, the outliers in the synthetic data can be eliminated by post-event filtering and debiasing methods before training.
25. AUROC (Area Under the Receiver Operating Characteristic Curve) is a common metric for evaluating the performance of AI models, especially for classification tasks. (continued) Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 63 Key Points :
Model training faces data exhaustion
With the proliferation of synthetic data, especially within AI-generated networks
With a larger and larger proportion of capacity, future models will inevitably be non-human
The material generated is trained on. While synthetic data has the advantage of a near-infinite supply, effective use of synthetic data for model training requires a deep understanding of its impact on learning dynamics and learning outcomes. One way to extend a dataset is data augmentation, which is to create new variations by modifying real data, such as image skew or blending, while preserving key features. Both synthetic data generation and data augmentation provide opportunities to enhance AI models, but their effective use needs further research. (continued)
Factual accuracy (correct rate of answers to biographical questions)
Source: Tian et al., 2023 | Chart: 2025 Artificial Intelligence Index Report Correct answers
Figure 1.3.2156.80%66.90%69.60% 70.10%74.80% 75.40% 76.00%78.30%81.20%84.60%89.50%SFT
ITI 
DOLA
FactTune-MC
FactTune-FS
SFT
ITI 
DOLA
Chat
FactTune-MC
FactTune-FS
Llama-1 Llama-20%20%40%60%80%100%
Basic Models and Methods of Artificial Intelligence 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 64 Cost of Inference
Last year's AI Index highlighted the training of cutting-edge large language model systems
Ben's rapid rise. This year, in addition to updating the analysis of training costs, the index also:
This paper examines how the cost of reasoning for frontier systems changes over time. Inference cost refers to the cost of querying a trained model, typically measured in dollars per million tokens. AI token pricing data comes from Artificial Analysis and Epoch AI's proprietary database of API pricing, and reports prices as a 3:1 weighted average of input and output token prices as analytical inference costs.
The AI Index, in collaboration with Epoch, measures the performance of AI in stationary settings
The decrease in costs at the threshold. This standardized approach facilitates more precise comparisons. While the new model may be more expensive, its performance is also significantly improved – if it is straight
Comparing it with older models with lower performance may mask the true trend: units of dollars gained
The performance of artificial intelligence has been greatly improved.  For example, in the MMLU test (a common comparison for evaluating the performance of a language model
Benchmark).
to the GPT-3.5 level (64.8 points) of the model, which inferred to:
Ben dropped from $20 per million words in November 2022 to October 2024 
$0.07 per month (Gemini-1.5-Flash-8B), down in about 1.5 years
That's 280 times. On GPQA (a more challenging baseline of comparison than MMLU).
The cost of models with scores above 50% shows a similar trend. On this side
, the cost of reasoning will be reduced from $15 per million words in May 2024
$0.12 in December (Phi 4). Epoch AI estimates, depending on the task not
Similarly, the cost of inference for large language models is decreasing at a rate of 9 to 900 times per year
Fall.
Inference costs for the selected baseline 2022–2024
Source: Epoch AI, 2025; Artiﬁcial Analysis, 2025 | Chart: 2025 Artificial Intelligence Index Report
Inference cost (USD / million words - logarithmic scale)
Figure 1.3.22 Release Date: GPT-3.5
Llama-3.1-Instruct-8BGemini-1.5-Flash-8BGPT-4o-2024-05
Phi4Claude-3.5-Sonnet-2024-06
 GPT-4-0314
DeepSeek-V3
2022.09 2023.01 2023.05 2023.09 2024.01 2024.05 2024.09 2025.010.1110
GPT-3.5 level+ in Multiple Language Understanding Tasks (MMLU)
GPT-4 level+ in Code Generation Task (HumanEval), GPT-4o level+ in PhD-level Science Problem Test (GPQA Diamond), GPT-4o level+ in LMSYS Chatbot Arena Elo 2025 Artificial Intelligence
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 65 The cost of inference to achieve a specific level of performance has dropped significantly, but the most advanced models
It is still more expensive than the other models mentioned above. Figure 1.3.23 illustrates OpenAI,
Leading models from developers like Meta and Anthropic cost per million words. 26 These top-of-the-line models are typically priced higher than smaller models of the same company, reflecting
The premium required for cutting-edge performance.
Training costs
A common discussion around the underlying model is its high training cost. Although artificial
Smart companies rarely disclose exact figures, but the costs are widely estimated to be in the hundreds
10,000,000 dollars, and it's still rising. But the consensus estimate is that the cost is in the millions of dollars
The yuan is calculated and continues to rise. For example, OpenAI CEO Sam Altman revealed 
GPT-4 training costs more than $100 million; July 2024 CEO of Anthropic 
Dario Amodei points out that about $1 billion has been invested in training costs. compare
The new DeepSeek-V3 is reported to be less expensive (around $6 million), but overall training is still extremely expensive. 27
It's still important to understand the costs associated with training AI models, but be detailed
There is still very little information on costs. Last year, the Artificial Intelligence Index was released on the basis of the model
For initial estimates of training costs, the AI Index has once again partnered with Epoch AI to update and refine these estimates. To calculate the cost of the cutting-edge model, the Epoch team analyzed factors such as training time, hardware type, volume, and usage based on information in papers, press releases, and technical reports.
28
26. The index provides a visual representation of some of the advanced models that are publicly priced as of February 2025. Newer models may have been released since launch, and pricing may change.
27. Some reports have questioned the established cost of DeepSeek-V3, arguing that the actual development cost is much higher if employee salaries, capital expenditures, and research expenses are taken into account. 28. A detailed report on the Epoch methodology can be found in this paper. Output price of the selected model (per million tokens)
Source: Artificial Analysis, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.23 Output cost (in millions of dollars)
Model 60.00
15.00
6.005.003.502.19
o10102030405060
Artificial intelligence in 2025
Chapter 1 of the Index Report: Research andexploitation
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 66Figure 1.3.24 shows a portion of AI estimated based on cloud computing lease prices
The training cost associated with the energy model. Figure 1.3.25 shows the AI index mastery
Estimates for all model training costs.
The estimation of the AI index confirms the suspicion that the model has been trained in recent years
The cost of practice has increased significantly. For example, in 2017 the Transformer model was proposed, the rack
It supports almost all modern large language models, and the training cost is about $670; RoBERTa Large, released in 2019, was the best in classical comprehension benchmarks such as SQuAD and GLUE at that time, with a training cost of about $160,000. reach
In 2023, OpenAI's GPT-4 training cost is estimated to be $79 million. In 2024, Epoch discovers Llama among the few models that can estimate costs 
The training cost of the 3.1-405B is about $170 million. As competition in the AI space intensifies, companies are disclosing less and less about their training process, making it increasingly difficult to estimate computational costs. As noted in previous AI Index reports, there is a direct correlation between the cost of training an AI model and its computational requirements. As shown in Figure 1.3.26, the cost of training models with higher computational requirements increases significantly.
29. The cost figures reported in this section are adjusted for inflation. Estimated training cost for selected AI models from 2019–2024
Source: Epoch AI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.3.24 29 Training Costs (in USD)
670 160K4M 6M1M12M79M
29M
3M26M192M
41M170M
107MTransformer
RoBERTa Large
GPT- 3 175B (davinci)
Megatron-Turing NLG 530B
LaMDA
PaLM (540B)
GPT-4
PaLM 2
Llama 2-70B
Falcon-180B
Gemini 1.0 Ultra
Mistral Large
Llama 3.1-405B
Grok-2
2017 2019 2020 2021 2022 2023 2024050M100M150M200M
Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.3 Iconic AI Models
Table of Contents Chapter 1 Preview 67 Selected AI Model Training Cost Estimates for 2016-2024
Source: Epoch AI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Training cost (in USD - logarithmic scale)
Estimated training cost and computing power of selected AI models
Source: Epoch AI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Training cost (in USD - logarithmic scale) release date
Training hashrate (Gigabit floating-point operations - logarithmic scale) Figure 1.3.25
Figure 1.3.26Llama 3.1-405B
Nemotron- 4 340BGemini 1.0 Ultra
Inection- 2
Falcon- 180B
Llama 2- 70BPaLM 2GPT- 4
LLaMA- 65BGPT- 3.5
BLOOM- 176BPaLM (540B)
LaMDA HyperCLOVA 82B
Meta Pseudo LabelsSwitchGPT- 3 175B (davinci)
AlphaStar
Megatron- BERT
RoBERTa Large
BigGAN- deep 512×512JFT
XceptionGNMT
2016 2017 2018 2019 2020 2021 2022 2023 202410K100K1M10M100M
Grok- 2Llama 3.1- 405B
Mistral LargeGemini 1.0 Ultra
Falcon- 180B
Llama 2- 70BPaLM 2GPT- 4
PaLM (540B)
LaMDAMegatron- Turing NLG 530B
GPT- 3 175B (davinci)
RoBERTa Large
10M 100M 1B 10B 100B100K1M10M100M
Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 68Peak Compute Performance of Machine Learning Hardware at Different Precisions from 2008 to 2024
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.4.1 Performance (FLOP/s - logarithmic scale) 1.4 Hardware
Overview
Figure 1.4.1 illustrates the peak computational performance of machine learning hardware for different precision types, where precision
Refers to the number of bits used in calculations to represent numeric values, especially floating-point numbers. The choice of accuracy depends on the specific purpose
Sign. For example, low-precision hardware requires fewer bits and lower memory bandwidth, making it ideal for optimizing compute speed and energy efficiency. This is especially beneficial for AI models at the edge/mobile device or for scenarios where inference speed is a priority. On the other hand, hardware with higher accuracy can retain higher numerical accuracy, so it is essential for scientific calculations and applications that are sensitive to accuracy errors. In the image below, FP32 has the highest accuracy, TF32 has the highest accuracy, and Tensor-FP16/BF16 and FP16 are low-precision formats optimized for speed and efficiency.
Epoch estimates are measured in 16-bit floating-point arithmetic, and the computing power of machine learning hardware is in 
The annual growth rate between 2008-2024 is about 43%, doubling every 1.9 years. According to Epoch, this progress is due to an increase in the number of transistors, improvements in semiconductor manufacturing processes, and the development of AI-specific hardware. Hardware advancements play a key role in driving the development of artificial intelligence. though
Scaling up the model and training with a larger dataset resulted in significant performance
improvements, but these advances are mainly due to improvements in hardware – especially the development of more powerful and efficient GPUs (graphics processing units). GPUs speed up complex calculations, enabling models to process massive amounts of data in parallel and dramatically reduce training time. This section leverages Epoch AI's data analysis to analyze the main trends in machine learning hardware and their impact on the development of artificial intelligence.
While this section currently emphasizes computing performance (FLOP/s), the net
Network bandwidth (the speed at which the GPU communicates) is also critical. While data on data center network bandwidth is limited, future editions of the AI Index will aim to incorporate this information.
Release date: 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 202410B100B1T100T10, 1510, 16FP32, FP16, TF32 (19- bit), Tensor- FP16/BF162025 AI
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 69 Hardware: The price/performance ratio of mainstream machine learning hardware continues to improve. Figure 1.4.2 illustrates the part
Divided into the performance of NVIDIA data center GPUs, these are the most common AI trainings
with FLOP per second. Figure 1.4.3 shows the price/performance of these GPUs in FLOP per dollar per second. For example, the H100 graphics processor released in March 2022 reached 22 billion FLOP per second per dollar, and the price/performance ratio was about 1.7 times that of the A100 (launched in June 2020) and 16.9 times that of the P100 (released in April 2016).
Fold. Epoch estimates that the cost of hardware with a fixed level of performance is decreasing by 30% per year, making AI training increasingly affordable, scalable, and conducive to model improvement.
Leading performance of NVIDIA data center GPUs for machine learning
Source: Epoch AI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.4.2 Performance (FLOP per second)
1.87×10 13 1.25×10 14 3.12×10 14 9.89×10 14 
P100 V100 A100 H100
2016 2017 2020 202200.2×10 15 0.4×10 15 0.6×10 15 0.8×10 15 1×10 15 Artificial Intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 70 FLOP per second per dollar
Release Date Figure 1.4.4 is based on Epoch AI's iconic machine learning model dataset
The hardware used to train these models is counted. As of 2024, the most commonly used hardware is the A100 (used by 6 models), followed by the V100. Use the H100 training
The number of trained models is growing rapidly, reaching 15 by the end of 2024.
Price/performance of NVIDIA's leading data center GPUs for machine learning
Source: Epoch AI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Price/performance of NVIDIA's leading data center GPUs for machine learning
Source: Epoch AI, 2024 | Chart: Chart 1.4.3 of the 2025 AI Index Report
Figure 1.4.4 Hardware Cumulative number of iconic AI models 1.30×10 9 
6.70×10 9 
1.30×10 10 
2.20×10 10 
1×10⁹ 5×10⁹ 1×10¹ ⁰ 1.5×10¹ ⁰ 2×10¹ ⁰H100A100V100P100
2017 2018 2019 2020 2021 2022 2023 20240102030405060
6, P10015, H10025, TPU v437 , Other47 , TPU v356, V10065, A100 Focus :
Energy efficiency and environmental impact
Training AI systems requires a lot of energy, hence machine learning hardware
energy efficiency is a key factor. Epoch AI reports that over time pushes
Machine learning hardware is becoming more and more energy efficient, about 40% better. Figure 1.4.5 Exhibition
shows the energy efficiency of Tensor-FP16 precision hardware (measured in FLOP per watt). For example, the NVIDIA B100 released in March 2024 is 2.5 trillion FLOP/watt efficient, while the P100 released in April 2016 is only 74 billion FLOP/watt, which means that the B100 is 33.8 times more efficient than the P100.
Energy efficiency of leading machine learning hardware from 2016-2024
Source: Epoch AI, 2025 | Chart: 2025 AI Index Report Energy efficiency (FLOP/s per watt - logarithmic scale)
Figure 1.4.5 Release date: 2025 Artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 712016 2017 2018 2019 2020 2021 2022 2023 20241B10B100B1T
Leading hardware
Non-leading hardware NVIDIA P100
Google TPU v2Google TPU v3Google TPU v4
NVIDIA Tesla V100 SXM2 32 GB
Google TPU v4iNVIDIA A100Google TPU v5e
NVIDIA B100NVIDIA H100 SXM5 80GB
NVIDIA GB200 NVL2NVIDIA B2002025 AI
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 72 Key Points :
Energy efficiency and environmental impact
Although the energy efficiency of AI hardware has improved greatly, it is not necessary to train humans
The total power consumption required for intelligent systems is still rising rapidly. Figure 1.4.6 illustrates the training
The total power consumption (in watts) of various state-of-the-art AI models. example
For example, the original Transformer model proposed in 2017 consumed about 4,500 watts, while Google's early flagship large language model, PaLM, consumed 2.6 million watts, nearly 600 times that of the Transformer. The Llama 3.1-405B, released in the summer of 2024, consumes 25.3 million watts, more than 5,000 times more than the original Transformer. According to Epoch AI, the power consumption required to train iconic AI models is eachYear doubled. The continued increase in the energy consumption of AI models reflects the tendency to rely on larger and larger data sets in their training process.
It is not difficult to understand that over time, it is used to train artificial intelligence systems
The total amount of electricity is increasing, and so is the amount of carbon emitted by the model. There are many factors that determine the carbon emissions of an AI system, including the number of parameters in the model, the power efficiency (PUE) of the data center, and the carbon intensity of the grid.
30
Total power consumption required to train cutting-edge models from 2011–2024
Source: Epoch AI, 2025 | Chart: 2025 Artificial Intelligence Index Report Total Power Demand (Watts - Logarithmic Scale)
Figure 1.4.6 Release Date: Llama 3.1- 405B GPT-4
PaLM (540B)GPT- 3 175B (davinci)
2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024100010K100K1M10M
30. Power Usage Effectiveness (PUE) is an indicator used to evaluate the energy efficiency of data centers. It is calculated as the ratio of the total energy consumption of the data center (including cooling) to the energy consumption of IT equipment, and the higher the PUE value, the lower the efficiency of the data center. Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 73 Key Points :
Energy Efficiency and Environmental Impact (continued)
Figure 1.4.7 shows some of the AI models sorted by release year
carbon emissions. To estimate these emissions, the AI Index is used:
Carbon data published by model developers is supplemented by calculations from a widely used online AI-trained emissions calculator. Since most developers do not disclose the carbon footprint of the model, this additional calculation is necessary. The calculator estimates emissions based on the type of hardware used for training, total training time, cloud provider, and training region.
31 Over time, the training of iconic AI models resulted
Carbon emissions are rising steadily. While AlexNet's emissions are negligible, GPT-3 (released in 2020) has been reported to emit carbon during training
The volume is about 588 tons, with GPT-4 (2023) emitting 5,184 tonnes and Llama 3.1 405B (2024) emitting 8,930 tonnes. DeepSeekV3, released in 2024, has comparable performance to OpenAI's o1 and is estimated to emits comparable to GPT-3, which was released five years ago. For reference, the average American emits 18.08 tons per person per year.
Estimates of carbon emissions from specific AI models and actual activities from 2012–2024
Source: Epoch AI, 2025 | Chart: 2025 AI Index Report Carbon emissions (tonnes of CO2eq)
Figure 1.4.7
31. The AI Index obtains input data from emissions calculators from a variety of online sources, such as training hardware and duration. To verify the accuracy of the calculator, we compared the calculator's estimates with the actual emissions reported by the developers and found that the results were broadly consistent. finish
The estimation method of the whole is detailed in the Appendix. 0.01 0.31 2.60 5.505881,432
3012,9735,184
5978,930AlexNet
VGG16
BERT-Large
RoBERTa Large
GPT- 3
Megatron-Turing NLG
GLM- 130B
Falcon-180B
GPT-4
DeepSeek v3
Llama 3.1 405B
2012 2014 2018 2019 2020 2021 2022 2023 202402,0004,0006,0008,000
Air travel (1 passenger, New York to/from San Francisco): 0.99
Average human life expectancy (1 year): 5.51 U.S. average life expectancy (1 year) 18.08 Car use (including fuel, average lifetime use): 632025 years Artificial intelligence
Chapter 1 of the Index Report: Research and Development
1.4 Hardware
Table of Contents Chapter 1 Preview 74 Key Points :
Energy Efficiency and Environmental Impact (continued)
The amount of carbon emissions estimated by the selected AI model and the number of parameters
Source: Epoch AI, 2025 | Chart: Artificial Intelligence Index Report 2025 Number of parameters (logarithmic scale)
Figure 1.4.8 Carbon emissions (tonnes of CO2e-logarithmic scale) AlexNetVGG16BERT-Large
RoBERTa LargeGPT- 3Megatron- Turing NLG
GLM- 130B Falcon- 180BGPT- 4
DeepSeek v3
Llama 3.1 405B
0.01 0.1 1 10 100 1000 10K1B1T
1.5 Artificial Intelligence Conference
Size of the meeting
Figure 1.5.1 shows the number of participants in some of the AI conferences since 2010.
In 2020, the pandemic forced the conference to be held online, and the number of participants increased significantly. follow
, likely due to the return of the conference to an in-person format, the number of participants declined, and in 2022 the number of participants returned to pre-pandemic levels. Since then, the number of participants has grown steadily, with a 21.7% increase from 2023 to 2024.
32 Since 2014, the number of annual attendees has increased by more than 60,000, reflecting both the rise in AI research and the emergence of new conferences. The Neural Information Processing Systems Conference (NeurIPS) remains the most popular AI conference, attracting nearly 20,000 attendees in 2024 (Figures 1.5.2-1.5.3). Among the major AI conferences, NeurIPS, CVPR, ICML, ICRA, ICLR, IROS, and AAAI all saw an increase in attendance last year. Artificial intelligence conferences are for researchers to present their research findings, with peers and
An important platform for collaborators to make connections. Over the past two decades, these conferences
's size, number, and influence are all growing. This session will explore attendance trends at major AI conferences. Artificial intelligence in 2025
Chapter 1 of the Index Report: Research and Development
1.5 Artificial Intelligence Conference
Table of Contents Chapter 1 Preview 7532 These figures should be interpreted with caution as many meetings have been held virtually or hybridly in recent years. Conference organizers noted that it was difficult to accurately count attendance at virtual meetings because virtual meetings made it easier for researchers from around the world to participate. AI Index report
The total attendance includes virtual, hybrid and in-person attendance. The sessions covered in this statistical review include: AAAI, AAMAS, CVPR, EMNLP, FAccT, ICAPS, ICCV, ICLR, ICML, ICRA, IJCAI, IROS, KR, NeurIPS, and UAI
and other important conferences in the field of artificial intelligence. Participation in selected AI conferences between 2010 and 2024
Source: Artificial Analysis, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.5.1 Number of participants (in thousands)
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024102030405060708090
73.262025 Artificial Intelligence
Index Report
Table of Contents Chapter 1 Preview 762010–2024 Conference Attendees
Source: AI Index, 2024 | Chart: 2025 Artificial Intelligence Index Report
Number of participants in mini-conferences from 2010 to 2024
Source: AI Index, 2024 | Chart: Artificial Intelligence Index Report 2025 Figure 1.5.2 33
Figure 1.5.3 Number of participants (in thousands) Number of participants (in thousands)
33. The significant spike in ICML attendance in 2021 is likely due to the fact that the conference was held online that year. 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024051015202530
3.50, EMNLP5.15, AAAI5.20, IROS6.53, ICLR7 .00, ICRA9.10, ICML12.00, CVPR19.76, NeurIPS
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.000.501.001.502.002.503.003.50
0.20, KR0.24, ICAPS0.43, UAI0.63, AAMAS0.69, FaccT2.84, IJCAI Chapter 1: Research and Development
1.5 Number of AI projects on GitHub for AI conferences, 2011–2024
Source: GitHub, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.6.1 Number of AI projects (in millions) 1.6 Open source AI software
Open source AI software project
A GitHub project consists of a series of files, including source code, documentation, configuration files, and images
Together, the files make up a software project. Figure 1.6.1 shows GitHub AI over time
Change in the total number of items. 35 The number of AI-related GitHub projects held since 2011
It continued to grow, from 1,549 in 2011 to about 4.3 million in 2024. Notably, in the last year alone, the total number of GitHub AI projects surged by 40.3%. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 1 Preview 77 Chapter 1: Research and Development
1.6 Open Source Artificial Intelligence Software
2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.000.501.001.502.002.503.003.504.004.50
4.32
34. This year GitHub updated its methodology to capture a broader range of AI-related topics, including more recent developments. As a result, the data in this year's AI Index may not align with previous editions. Chinese researchers often use websites other than GitHub
code, such as Gitee and GitCode, but this report does not include data for these sites. A full description of the methodology is provided in the Appendix.
35. GitHub uses an AI topic taxonomy to identify AI-related knowledge bases. See the appendix for more information on the method. GitHub is a web-based platform that enables individuals and teams
Ability to host, review, and collaborate on a codebase. Widely used as a software developer
With the tools, GitHub provides code management, project collaboration, and open source software support. Based on data from GitHub, this section provides an in-depth analysis of broad trends in open source AI software development that are not reflected in the paper's data. Artificial intelligence in 342025
Index Report
Table of Contents Chapter 1 Preview 78 Chapter 1: Research and Development
1.6 Open Source Artificial Intelligence Software
Figure 1.6.2 shows where GitHub's AI projects have been built since 2011
Physiological distribution. As of 2024, the U.S. contributes 23.4% of GitHub's AI
energy projects, accounting for the highest proportion; India came in second with 19.9%, followed by Europe with 19.5%. It's worth noting that since 2016, the share of U.S. developers in GitHub's open-source AI projects has been declining and has stabilized in recent years.
Percentage of GitHub AI projects by geographic region, 2011–2024
Source: GitHub, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.6.2 AI Projects (% of Total)
2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%
35.43%, Rest of the world
23.42%, United States
19.91%, India 19.15%, Europe
2.08%, China 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 1 Preview 79 Chapter 1: Research and Development
1.6 Open Source Artificial Intelligence Software
Star
GitHub users can express their repositories through the "starring" feature
Library followers, similar to social media likes, represent support for open source projects. Most popular
Repositories to watch include libraries such as TensorFlow, OpenCV, Keras, and PyTorch, which are popular not only in the AI space, but also in the developer community as a whole. TensorFlow、 Keras and PyTorch are popular libraries for building and deploying machine learning models, while OpenCV provides computer vision-related tools such as object detection and feature extraction.
The total number of stars for AI-related projects on GitHub continues to grow, from:
14 million in 2023 to 17.7 million in 2024 (Figure 1.6.3).
36 this
The number of stars has doubled between 2022 and 2023.
Number of AI projects starred on GitHub from 2011–2024
Source: GitHub, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.6.3 Number of GitHub Stars (in millions)
2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 202402468101214161817 .64
36. Figure 1.6.3 shows the number of new stars added in the year, not the historical total. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 1 Preview 80 includes Europe, China, and India, whose home projects have received stars on GitHub
The number of bids increased compared with the same period last year. Chapter 1: Research and Development
1.6 Open Source Artificial Intelligence Software
In 2024, the United States ranks first in the world in GitHub star counts, total
21.1 million (Figure 1.6.4). All major geographic areas that were sampled and surveyed, packaged
Number of GitHub Stars by geographic region, 2011–2024
Source: GitHub, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 1.6.4 Cumulative number of GitHub stars (in millions)
2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 20240510152021.08, United States
16.39, Rest of the world
10.29, Europe
4.06, India
3.67, Artificial Intelligence in China 2025
Index Report
Chapter 2:
Technical performance 2025 artificial intelligence
Index Report
Chapter 2: Technical Performance
      VCR: Visual Common Sense Reasoning
      MVBench Generative Capabilities Chatbot Arena: Visual
 Focus: The rise of video generation
2.4 Speech Recognition LSR2: Lip Reading Sentences 2
2.5 Programming
      HumanEval SWE-bench BigCodeBench Chatbot Arena: Programming ability assessment
2.6 Mathematics
      GSM8K MATH Chatbot Arena: Math Proficiency Assessment FrontierMath Focus: Learning and Theorem Proof
2.7 Inference
General Inference MMMU: A Graduate-Level Google-Proof Q&A Benchmark ARC-AGI for Expert-Level AGI      
Humanity's Last Exam (HLE)  
Planning PlanBench overview
Chapter Highlights
2.1 Overview of AI technology developments in 2024
Timeline: Critical Models and Datasets Released AI Performance Overall Review Closed-source weighted models vs. open-source weighted models Comparison of U.S. and Chinese technical performance Small-scale model performance improvement Cutting-edge model performance convergence AI benchmark comparison
2.2 Language
Language Understanding MMLU: Large-scale multi-task language understanding generation task Chatbot Arena Leaderboard Arena-Hard-Auto WildBench
   Focus: O1, O3, and inference time calculations
      MixEvalRAG: Retrieval Enhancement Generation Berkeley Function Calling Leaderboard MTEB: Large-Scale Text Embedded Benchmark Focus: Long context retrieval evaluation
2.3 Images and Videos
Comprehension 84
85
87
87939394969899100
103
104104105105107108110112113113115117
119
119119
120122123124
126
126126
128
128129130131
132
132133134134136
137
137
137138
139141143143
Table of Contents Chapter 2 Preview Artificial Intelligence in 822025
Index Report
Chapter 2: Technical Performance (continued)
2.8 AI agents
      VisualAgentBench
      RE-Bench
      GAIA
2.9 Robotics and Autonomous Movement
robot
      RLBench
    Focus: Humanoid robots
      Focus: DeepMind's progress
      Focus: Robot base model
Self-driving cars 
      develop
      Technological innovation and new benchmarks
      Safety Standard 144
144
145
147
148
148
148
150
151
154
155
155
156
157
Table of Contents Chapter 2 Preview 83 Access to Public Data Artificial Intelligence in 2025
Index Report
Chapter 2:
Technical performance
overview
The technical performance section of this year's Workforce Index report provides a comprehensive overview of the key advancements in AI in 2024
Unfold. The opening chapter summarizes the development trends of artificial intelligence technology from the macro level, covering major artificial intelligence technology releases and people
The current status and key trends of AI capabilities, including the performance improvement of open-source weighted models, the performance convergence of cutting-edge models, and the quality improvement of China's large language models. This chapter then provides a detailed analysis of the current state of development of various AI capabilities, including language understanding and generation, retrieval augmented generation, programming, mathematics, reasoning, computer vision, speech, and agent-based AI. This year, an expanded analysis of robotics and autonomous vehicle performance trends was added.
Table of Contents Chapter II Preview 842. The open-source model catches up. According to the AI Index report released last year, leading open-source models once lagged significantly behind closed-source models. And by 2024, this gap has been
Largely gone. Specifically, 2024 1
Earlier this month, on the Chatbot Arena Leaderboard, the top closed-source model had a performance advantage of 8.0%; And by 2025
In February, the gap had narrowed to 1.7%.
3. The gap between China and the United States in AI model capabilities has narrowed. In 2023, the performance of the top AI models in the U.S. was significantly ahead of their Chinese counterparts, but that has now changed. number
It is shown that by the end of 2023, the performance gap between the Chinese and American models in benchmarks such as MMLU, MMMU, MATH, and HumanEval is 17.5, 13.5, 24.3, and 31.6 percentage points, respectively; By the end of 2024, these gaps have narrowed significantly to 0.3, 8.1, 1.6, and 3.7 percentage points.
4. The performance of cutting-edge AI models tends to converge. According to last year's Artificial Intelligence Index, there were 1st and 10th models on the Chatbot Arena Leaderboard
The Elo score spread has narrowed from 11.9% last year to 5.4% at the beginning of 2025. Similarly, the gap between the top two models has narrowed from 4.9% in 2023 
0.7% in 2024. Competition in the field of artificial intelligence is becoming increasingly fierce, and more and more developers are now launching high-quality models.
5. New inference paradigms, such as test-time compute, significantly improve model performance. In 2024, OpenAI will launch models such as o1 and o3
Generational output inference architecture. This computational method greatly improved the performance of the model, with O1 scoring 74.4% in the International Mathematical Olympiad Qualifying Exam, compared to only 9.3% on GPT-4o. But the technology comes at a cost, with O1 costing up to 6x that of GPT-4o and inference speeding up to 30x. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 2 Preview 85Chapter 2:
Technical performance
Chapter Highlights
1. AI is reaching new benchmarks faster than ever before. In 2023, researchers launched several tools such as MMMU, GPQA, and SWE-bench
A challenging new benchmark designed to test the limits of increasingly powerful AI systems. By 2024, AI will perform significantly on these benchmarks
Breakthroughs: MMMU and GPQA test scores increased by 18.8 and 48.9 percentage points, respectively; More strikingly, in the SWE-bench programming test, the Department of Artificial Intelligence
The problem-solving ability of the system jumped from only 4.4% in 2023 to 71.7% in 2024. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 2 Preview 866. More challenging benchmarks are being proposed. Traditional AI benchmarks such as MMLU, GSM8K, and HumanEval are nearing saturation, with the addition of MMMU and
Newer, more challenging benchmarks such as GPQA continue to improve, prompting researchers to explore more ways to evaluate leading AI systems. Among the notable
There's Humanity's Last Exam, a rigorous academic test with a state-of-the-art AI system scoring just 8.80%; Frontier Math, a complex mathematical benchmark where AI systems solve only 2% of problems; "BigCodeBench" is a coding benchmark, and the success rate of AI systems is only 35.5%, which is well below the 97% level of humans.
7. A major breakthrough in high-quality AI video generation models. In 2024, a number of advanced AI models will be launched that can generate high-definition video based on text input
These include OpenAI's SORA, Stable Video Diffusion 3D and 4D, Meta's Movie Gen, and Google's DeepMind's Veo 2. with the 2023 ones
Compared with the video generation model, these new generation models have achieved significant improvements in image quality performance.
8. Smaller models show more performance. In 2022, the smallest model to achieve a score above 60% in the MMLU benchmark was PaLM with 540 billion parameters; And to
In 2024, Microsoft's Phi-3-mini achieves the same level with just 3.8 billion parameters — equivalent to a 142-fold reduction in parameter size in two years. 9. Complex reasoning continues to be a challenge for AI. Although the introduction of inference mechanisms such as chain-of-thought has significantly improved the performance of large language models, this
These systems are still unable to reliably solve problems that could have been answered deterministically by logical reasoning, including math and task planning, especially when the problem size is beyond its training range
Perimeter. This defect seriously affects the credibility of AI systems, making it difficult for them to meet the application requirements of high-risk scenarios.
10. Artificial intelligence agents show initial potential. The RE-Bench benchmark, launched in 2024, establishes rigorous criteria for assessing the ability of AI agents for complex tasks. In short-term tasks
(2-hour time limit), top AI systems can score up to 4 times higher than human experts; But as the time was extended to 32 hours, the human performance outperformed the AI system, and the score reached
to the advantage of 2:1. AI agents have reached the level of human expertise in specific areas, such as writing Triton Kernels, and can produce results faster and at a lower cost. Chapter Highlights (continued) Chapter 2:
Technical PerformanceThis section begins with a high profile of the important models released in 2024
and reviews the current state of AI technology performance. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 2 Preview 87 Chapter 2: Technical Performance
2.1 Overview of AI technology developments in 2024
2.1 Overview of AI technology development in 2024
Timeline: Significant model and dataset releases
According to the AI Index Steering Committee, here are the most iconic model and dataset releases of 2024
Google
DeepMind
ByteDance
Anthropic
date           Name, Category, Creator, Meaning, Image
Large language models
Large language models
Large language model Wensheng graph dataset Stable LM 2
Aya dataset
Gemini 1.5 Pro
SDXL
-Lightning
Claude 3, January 19, 2024
February 8, 2024
February 15, 2024
February 20, 2024
March 4, 2024Stability AI's latest language model is based on Stable 
LM improvements, significant performance improvements. With only 1.6 billion parameters, the model is designed for efficient operation on portable devices such as laptops and smartphones.
Released as part of Cohere's Aya program
A dataset containing a complete comparison of 513 million prompts in 114 languages. This paper and the accompanying dataset mark a major breakthrough in the field of multilingual instruction fine-tuning.
The Gemini model relies on a 1 million word context window
The port has set a new benchmark in the industry, far exceeding GPT-4 Turbo's 128,000 word limit.
Launched by TikTok developer ByteDance, it was the most at the time
One of the fastest Wensheng diagram systems that produces high-quality composite images in less than 1 second. The speed is achieved through a progressive counter-distillation technique rather than a traditional diffusion-based approach.
Anthropic's latest large language model is available in almost all
Outperformed both G P T-4 and Gemini in industry benchmarks, significantly reducing false rejection rates and improving accuracy. Stability AI
Cohere for AI、
Beijing Zhiyuan Research
Hospital, Cohere,
Binghamton University
Figure 2.1.1
Source: Wikipedia, 2025
Figure 2.1.2
Source: Cohere, 2025
Figure 2.1.3
Source: Google, 2024
Figure 2.1.4
Source: Hugging Face, 2025
Figure 2.1.5
Source: Anthropic, Artificial Intelligence 20252025
Index Report
Table of Contents Chapter 2 Preview 88 Chapter 2: Technical Performance
2.1 Overview of AI technology developments in 2024
Moirai with LOTSA
DBRX
Stable Audio 2
Llama 3
GPT-4oStability AI
Meta
OpenAI
 May 13, 2024, April 17, 2024, April 2, 2024, March 27, 2024, March 19, 2024, March 17, 2024
Figure 2.1.6
Source: Inflection, 2025
Figure 2.1.7 Source: Salesforce, 2025
Figure 2.1.8 Source: Databricks, 2025
Figure 2.1.9 Source: Stability AI, 2025
Figure 2.1.10
Source: Meta, 2025
Figure 2.1.11
Source: OpenAI, 2024Inflection's flagship product "PI" carries this model, only
With 40% of GPT-4's computing resources, the same performance can be achieved. Two weeks after its launch, Microsoft acquired Inflection for $650 million. Inflection AI large language model Inflection-2.5
Large language models
Large language models
Multimodal Bunshengqu/Qushengqu Model/Dataset Salesforce
DatabricksSalesforce releases a generic forecasting base model  
Moirai, and LOTSA, a time series dataset with 27 billion observations across 9 domains.
Datab ricks is an open-source expert hybrid model
(MoE) to outperform Mixtral and Grok 
and other similar small MoE models. This contains only the decoder
The Transformer model has 132 billion parameters
(36.8 billion activations per input), with 12 trillion training data
Lemoems.
The latest version of Stable Audio is Stability's 
AI song generator, added support for audio-to-audio function. Users can upload songs and use natural language prompts to customize them.
The Llama 3 series debuted with 8 billion and 70 billion parameter texts
This model is one of the best performance models of the same scale.
GPT-4o is a new multimodal model that supports the text
With any combination of inputs and outputs of audio, image, and video, it has a response time of as little as 320 milliseconds, which is comparable to the reaction time of a human. Artificial intelligence in 2025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter II Preview 89
August 13, 2024, August 12, 2024, July 23, 2024, June 17, 2024, June 7, 2024
The Qwen2 series developed by Alibaba includes a base module
The model and instruction fine-tuning model outperform competitors such as the Llama 3-70B and Mixtral-8x22B in multiple benchmarks. Alibaba
Runway
Meta Meta
Abu Dhabi technology
Institute of Innovation
Wensheng Wen/Wensheng
Figure: Large Language Model, Large Language Model, Large Language Model, Qwen2
Runway 
Gen-3
Llama 
3.1405B
Falcon 
Mamba
Grok-2 Bunsen video
/Tusheng video
The xAIRunway upgraded video generation model is set for the industry
A new benchmark that is particularly good at generating lifelike portraits with vivid expressions.
Grok is developed by xAI, a premium text and image
Generative models that excel in image creation, advanced reasoning, and problem solving. Its launch was eye-catching, and although xAI was only founded in March 2023, its technical performance quickly rivaled the leading models. Based on the Mamba state-space language model (State 
As one of the few AI models developed by government agencies, the 7 billion parameter Falcon model developed by the Space Language Model (SSLM) architecture significantly surpasses the traditional similar models based on the Transformer architecture in terms of computational efficiency through dynamic parameter adjustment mechanism and input information filtering function. Meta has released the largest model to date in the Llama 3.1 series
The final version, with 405 billion parameters, became the strongest basic model available at that time, and its performance was comparable to many closed-source weight models. Figure 2.1.12
Source: Qwen, 2024
Figure 2.1.13
Source: Runway, 2024
Figure 2.1.14
Source: Meta, 2024
Figure 2.1.15
Source: Hugging Face, 2025
Figure 2.1.16
Source: xAI, Artificial Intelligence 20252025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter II Preview 90
September 17, 2024, September 12, 2024, September 11, 2024, August 29, 2024, August 22, 2024, August 15, 2024
Google's new generation of AI image generators is in
Achieving the highest Elo score in the GenAI-Bench image comparison protocol, it sets a new standard for AI-generated visual effects. Google Labs
AI21 Labs
Google
Google Labs
OpenAI
Nvidia Visual-Language-Language/Mathematics
/ Bio Wensheng Podcast Tool Large Language Model Wensheng Diagram Imagen 3
Jamba 1.5
SynthID v2
NotebookLM
Podcast tools
o1-preview
NVLM
 (D,H,X) is the first large language model that fuses state-space and transformer architectures to deliver high-quality results for text-based applications. This hybrid approach balances high-speed response with high-quality output in text applications.
SynthIDv2 is a Google watermarking and recognition software
Upgraded version of SynthID. Adds support for AI-generated image, video, audio, and text content, as well as enhanced tracking and verification capabilities.
After Synthpod, the second end-to-end artificial intelligence
Noh blog builder came out and quickly became popular. Because of its convenience, the tool is popular with students who use NotebookLM for their studies, as well as tech practitioners who use AI-generated summaries for work listening and reading.
OpenAI's "o Series" is the first model designed for advanced pushing
Designed to handle complex tasks. Reasoning on complex tasks such as math, science, and programming significantly surpasses GPT's.
Nvidia has released three ons for visual language tasks
Put-and-access model, with the highest scores on OCRBench (Optical Character Recognition) and VQAv2 (Natural Language Understanding).
Figure 2.1.22
Source: Dai et al., 2024 Figure 2.1.21
Source: OpenAI, 2025 Figure 2.1.20
Source: Google, 2025 Figure 2.1.19
Source: Google, 2025 Figure 2.1.18
Source: AI21, 2025 Figure 2.1.17
Source: Google, Artificial Intelligence 20252025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter II Preview 91
December 11, 2024, December 3, 2024, October 28, 2024, October 22, 2024, October 16, 2024, September 19, 2024
Figure 2.1.23
Source: Qwen, 2025
Figure 2.1.24
Source: Mistral, 2025
Figure 2.1.25
Source: Anthropic, 2025
Figure 2.1.26
Source: Apple, 2025
Figure 2.1.27
Source: Amazon, 2025
Figure 2.1.28
Source: Google, 2025Gemini Upgrade, Added Computer Control Functions and Diagrams
Video/audio generation capabilities, 2x faster than 1.5 Pro, significantly improved programming and image analysis performance. Nova Pro is the Amazon Web Services Nova family
The strongest model, good at processing visual and text information, especially in the field of financial document analysis. Apple integrates with Image Playground,
Genmoji (emoji customization), Siri and ChatGPT linkage and other AI function suites. Anthropic Computer Use is Claude 3.5 
A breakthrough computer-controlled feature for Sonnet users that allows Claude to move the cursor, enter text, and complete tasks autonomously on the user's computer in real time. Ministral is available with 3 billion and 8 billion parameters
Compact model that outperforms GEMMA and Llama models of the same size in all major industry benchmarks. Qwen2.5 is the Chinese e-commerce giant Alibaba
The latest series of foundation models is available, ranging from efficient miniature models to specialized models optimized for programming and mathematics. Alibaba
Mistral
Anthropic
apple
Amazon
Google
DeepMind Large Language Model, Multimodal iPhone Function, Agent Capability, Large Language Model, Large Language Model, Qwen2.5
Ministral
Anthropic
Computer-controlled
Apple Smart System
Nova Pro
Gemini Artificial Intelligence 2025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter II Preview 92
DeepSeek V3, the open-source model is significantly less than the top
The computing power resources of the cutting-edge model are developed, and the performance of the leading models in comparison benchmarks such as MMLU and GPQA outperforms. DeepSeekOpenAICohereOpenAI Wensheng video
data set
Multimodal
Large Language Model DeepSeek-V3o3 (beta) Global MMLUSora December 12, 2024
December 13, 2024
December 20, 2024
On December 27, 2024, OpenAI's latest cutting-edge model for artificial intelligence research
The Personnel Safety Test was released, outperforming all previous models in the SWE Programming, Competition Mathematics, PhD-level Science, and Research Mathematics benchmarks, and setting a new ARC-AGI benchmark record with a score of 87.5%. A multilingual assessment set with specializations in 42 languages
The MMLU issue is intended to serve as a benchmark for providing a more global AI comparison. It evaluates the performance of AI in multiple languages while addressing Western bias in the original MMLU dataset, which is estimated to rely on Western cultural knowledge for 28% of the problems. OpenAI's highly anticipated video generation model is available:
ChatGPT Pro users generate 1080p/20 sec videos (Plus users 720p/5 sec). The demo version has been circulating in the technical community since the beginning of 2024, and the official release has been delayed to improve the safety of the model.
Figure 2.1.29
Source: OpenAI, 2025
Figure 2.1.30
Source: Singh et al., 2025
Figure 2.1.31
Source: VentureBeat, 2025
Figure 2.1.32
Source: Dirox, Artificial Intelligence 20252025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 93 The State of Artificial Intelligence Performance
This section of the AI Index presents the main AI field in 2024
Trends and a full range of high-level perspectives.
Overall review
Last year's AI Index report noted that AI has surpassed most tasks
At the human level, there are only a few exceptions such as competition-level math and visual common sense reasoning. pass
Over the past year, AI systems have continued to improve, outperforming human performance in a number of challenging benchmarks. Figure 2.1.33 illustrates the 8 analogy of an AI system relative to a human baseline
Compare progress in the benchmark (covering 11 tasks, such as image classification, basic reading comprehension, etc.).
1 The AI Index team selects a representative benchmark for each type of task, this year
New benchmarks such as GPQA Diamond and MMMU have been added to showcase breakthroughs in AI for extremely complex cognitive tasks.
1. An AI benchmark is a standardized test used to evaluate the performance of an AI system in a specific task. ImageNet, for example, is a classic benchmark that contains a large number of annotated images that AI systems are tasked with accurately classifying. Track baseline progress
It is the standard method for measuring the development of systems in the field of artificial intelligence. 2. In Figure 2.1.33, these values are scaled to establish a standard indicator system that compares different benchmarks. The scaling function is calibrated to measure the performance of the best model each year as a percentage of the human benchmark for a particular task. For example, a value of 105% means that the model is 5% better than the human baseline. Selected AI Index technical performance benchmarks compared to human performance
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.1.33 2 Performance relative to human benchmark (%)
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240%20%40%60%80%100%120%
Human benchmarks
Visual Reasoning (VQA)
English Language Understanding (SuperGLUE) Competition-Level Mathematics (MATH) Multimodal Understanding and Reasoning (MMMU) Image Classification (ImageNet Top-5) Reading Comprehension at Medium Difficulty (SQuAD 2.0) Multi-Task Language Understanding (MMLU) Ph.D. Level Science Questions (GPQA Diamond) Artificial Intelligence 2025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 94As of 2024, human capabilities are still ahead of the task areas of AI
There is not much left. Even in these areas, there is a performance gap between AI and humans
in the rapid shrinking. For example, state-of-the-art AI systems currently outperform humans by 7.9 percentage points on MATH, a competition-level math benchmark (with a gap of just 0.3 points at the start of 2024).
3Similarly, MMMU ratios for complex, interdisciplinary, expert-level problems
Compared to the benchmark, the best model in 2024 has an O3 score of 78.2%, which is only 4.4 points lower than the human benchmark of 82.6%. And at the end of 2023, Google Gemini only won in this test
59.4%, fully demonstrating the rapid progress of AI in complex cognitive tasks
Comparison of closed-source and open-source weighting models
AI models can be released in varying degrees of openness. Such as Google's
Models such as Med-Gemini are completely closed-source and are restricted to developers; Examples such as OpenAI's GPT-4o and Anthropic's Claude 3.5 provide limited public access through APIs, but the weights are not publicly available, making them impossible to modify independently or fully review. In contrast, models such as Meta's Llama 3.3 and Stable Video 4D are fully exposed to weights, allowing anyone to modify and use them freely.
4
The debate over model openness is polarizing. Open source weights are strong supporters
Leverage its advantages such as breaking market monopolies, promoting innovation, and improving security and transparency. For example, Meta's Llama model has spawned Meditron medical tools, military applications, and numerous open source projects around the world. Opponents warn that open-source weighting can contribute to security risks such as the spread of disinformation and the development of bioweapons, and that a more cautious and controlled approach is needed. Last year's AI Index report pointed out the existence of closed-source and open-source large language models
significant performance gaps. Figure 2.1.34 illustrates the performance trends of the top closed-source weighted and open-source weighted language models on the Chatbot Arena Leaderboard, a public platform for benchmarking large language model performance. In January 2024, the top closed-source weighting model was 8.0% ahead of the open-source weighting model, and by February 2025, the gap had narrowed to 1.7%.
This trend is also evident in other Q&A benchmarks. Closed source in 2023
The weighting model leads across the board on major benchmarks such as MMLU, HumanEval, MMMU, and MATH, and continues to outperform the open-source weighting model, but the gap narrows significantly by 2024 (Figure 2.1.35). For example, at the end of 2023, the closed-source weighting model was 5.9 percentage points ahead of the open-source weighting model on MMLU, but by the end of 2024, the gap had narrowed to just 0.1 percentage points. This rapid uptick was largely due to Meta's release of Llama 3.1 in the summer, as well as other high-performance open-source weighting models that followed, such as DeepSeek's V3.
3. The baseline data in this figure, as well as the baseline data in other sections of this section, was collected in early January 2025. Individual benchmark scores may have improved since the release of the AI Index.
4. In the software industry, "open source" refers to the software license issued under the license that grants users the right to freely use, research, modify and distribute the software and its source code. However, open-source weighted models may not be fully open-source, as their underlying code or training data is often not publicly available. Artificial intelligence in 2025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 95Performance comparison of top-level closed-source and open-source models in 95LMSYS Chatbot Arena
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report
In the selected benchmark, the performance of the top-level closed-source model is compared to the open-source model
Source: Artificial Intelligence Index 2025 | Chart: 2025 AI Index Report Figure 2.1.34 score
Figure 2.1.35 Average Accuracy Accuracy
Overall accuracy Pass@12024-01 2025-02 2025-01 2024-12 2024-11 2024-10 2024-09 2024-08 2024-07 2024-06 2024-05 2024-04 2024-03 2024-021,1001,1501,2001,2501,3001,3501,400
2022 2023 20240%20%40%60%80%100%
2022 2023 20240%20%40%60%80%100%
2022 2023 20240%20%40%60%80%100%
2022 2023 20240% 20% 40% 60% 80% 100% open source Closed source
Universal Language: MMLU Universal Reasoning: MMMU
Mathematical Reasoning: MATH Programming: HumanEval1,385, Closed Source
1,362, Open Source 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 2 Preview 96 By the end of 2024, these gaps have narrowed significantly to 0.3, 8.1, 1.6 and 3.7
Percentage point. The release of DeepSeek-R1 has attracted a lot of attention, in addition to that, another
One reason is that the company says it requires only the hardware typically needed to train such models
A fraction of the resources can be achieved. In addition to the impact on the U.S. stock market, 
The release of DeepSeek-R1 also triggered the effectiveness of export controls on U.S. semiconductors
Questioning. Chapter 2: Technical Performance
2.1 Overview of AI technology developments in 2024
Comparison of U.S. and Chinese technical performance
The United States has long dominated the field of AI research and model development,
China is firmly in second place. However, the latest evidence suggests that the landscape is changing rapidly
The model developed by China is gradually catching up with its American counterpart.
In 2023, the U.S. leading model outperformed the Chinese model significantly. at
LMSYS Chatbot Arena Platform, January 2024, Top Models in the United States
9.3% higher than the best model in China. But by February 2025, this is the difference
The distance has been reduced to just 1.70% (Figure 2.1.36). At the end of 2023, after MMLU, 
MMMU, MATH, and HumanEval and other benchmarks, the performance of the U.S.-China model
The energy gaps were 17.5, 13.5, 24.3 and 31.6 percentage points, respectively (Figure 2.1.37).
Comparison of the performance of models in LMSYS Chatbot Arena in the United States and China
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.1.36 Score
2024-01 2024-02 2024-03 2024-04 2024-05 2024-06 2024-07 2024-08 2024-09 2024-10 2024-11 2024-121,1001,1501,2001,2501,3001,3501,400
1,385, United States
1,362, China 2025 Artificial Intelligence
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 97 Comparison of the top models in the U.S. and China on selected benchmarks
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.1.37 Average Accuracy Accuracy
Overall Accuracy Pass@12022 2023 20240%20%40%60%80%100%
2022 2023 20240%20%40%60%80%100%
2022 2023 20240%20%40%60%80%100%
2022 2023 20240%20%40%60%80%100%Mathematical Reasoning: MATH United States China
Universal Language: MMLU Universal Reasoning: MMMU
Programming: HumanEval 2025 Artificial Intelligence
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 98 Performance improvements for small models
In recent years, advances in AI have largely relied on scaling –
That is, by increasing the model size and training data to improve performance. Although the scale is significant
AI capabilities have been enhanced, but a notable recent trend has been the emergence of high-performance small models. Figure 2.1.38 shows the smallest change in model size with a score of more than 60% in MMLU, a widely used benchmark for language models. As a background reference, early ChatGPT-enabled models (such as GPT-3.6 Turbo) scored around 70% on the MMLU. In 2022, the smallest model to achieve a 60% MMLU score is a PaLM with 540 billion parameters; By 2024, Microsoft's Phi-3 Mini will reach the same threshold with just 3.8 billion parameters, marking a 142-fold reduction in model size over two years. 2024 is the year of breakthroughs for small AI models. Almost all masters
Streaming AI developers have released high-performance compact models, including:  
GPT-40 mini、oI-mini、Gemini 2.0 Flash、Llama 3.1 8B 
and Mistral Small 3.5. 5 The rise of the small model is of great significance, and its origin
Because of the following: it reflects the improvement of the efficiency of the algorithm, so that developers can do more
Less data and lower training costs for higher performance. These efficiency gains with the day
The combination of growing datasets may lead to better performing models. In addition, small
Models are generally faster and less expensive to infer, and their emergence is also less important for businesses and businesses
The threshold for developers to integrate AI into their business.
The smallest AI model that scored more than 60% in the MMLU's assessment in 2022–2024
Source: Abdin et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
5. These are just a handful of small models to be released in 2024. Figure 2.1.38 Number of parameters (logarithmic scale) PaLM
LLaMA- 65B
Llama 2 34B
Mistral 7B
Phi- 3- mini
2022- May 2022- Sep 2023- Jan 2023- May 2023- Sep 2024- Jan 2024- May10B100B
Artificial intelligence in 2025
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 99 Frontier Model Performance Convergence
In recent years, the performance of artificial intelligence cutting-edge models has gradually converged, and multiple vendors
High-performance models are now available. This phenomenon marks the beginning of the year since the end of 202 2
Transformation – at the time of the release of ChatGPT (which was widely seen as AI entering the public eye
coincided with a period when two giants, OpenAI and Google, dominated the market. OpenAI (founded in 2015) released GPT-3 in 2020, while Google launched models like PaLM and Chinchilla in 2022.
Since then, new contenders have entered the market, including Meta's Llama series,
Anthropic's Claude, High-Flyer's DeepSeek, Mistral's Le Chat, and xAI's Grok. As competition intensifies, the model performance gap narrows (Figure 2.1.39). According to last year's Artificial Intelligence Index report, in a wide range of makes
Artificial intelligence with the ranking platform Chatbot Arena Leaderboard, p
The performance gap between the first and tenth place models is 11.9%; And by early 2025, this
The gap has narrowed to 5.4 per cent. Again, the difference between the top two models is from 2023
of 4.9% to just 0.7% in 2024. Competition in the field of artificial intelligence is intensifying
Lie, confirming the prediction for 2023: AI companies lack the right to resist competition
Hand technology moat.
Top model performance of selected vendors in LMSYS Chatbot Arena
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.1.39 Score
2024.01 2024.02 2024.03 2024.04 2024.05 2024.06 2024.07 2024.08 2024.09 2024.10 2024.11 2024.12 2025.01 2025.021,0501,1001,1501,2001,2501,3001,3501,400
1,252, Mistral AI1,269, Meta1,284, Anthropic1,288, xAI
1,385, Google
1,366, OpenAI1,362, DeepSeek 2025 Artificial Intelligence
Chapter 2 of the Index Report: Technical Performance
2.1 Overview of AI technology developments in 2024
Table of Contents Chapter 2 Preview 100 AI Benchmark Comparison
For years, the AI Index report has been tracking humans through a comparative benchmark
Technological advances in intelligent systems. While benchmarks are still a key tool, they must be recognized
Recognize its limitations and guide the community to adopt more effective benchmarking practices.
As noted in last year's AI report, many of the mainstream AI benchmarks are saturating
And. With the rapid development of AI systems, even the more challenging testing of new designs often only lasts for a few years. Some experts believe that a new era of academic benchmarking may be coming to an end. To truly assess the capabilities of AI systems, a more rigorous and comprehensive approach to assessment is required.
In addition, when model developers publish new models, they often report comparisons
benchmark scores, and these scores are generally accepted by the wider community. However, this approach has its drawbacks. In some cases, companies use non-standard prompting techniques, making comparisons between models unreliable. For example, when Google launched Gemini Ultra, it reported an MMLU benchmark score that used Chain-of-Thought prompting techniques that other developers did not. Third-party research has also found that some models performed lower than the results originally reported by developers in independent tests.
Some key intelligence dimensions are difficult to measure with a baseline. Benchmarks for:
Assessing certain intellectual abilities, such as vision and language, is effective because tasks are discrete—such as correctly classifying images or answering multiple-choice questions. However, there are challenges in the fields of multi-agent systems and human-computer interaction, mainly due to the variability of human behavior and the diversity of answers. Benchmarking is more challenging.
In addition, the development of AI is often in a race to measure human performance
, such as games and other overt challenges to humans or machines. Games such as chess and poker require a high level of intelligence, and over the decades, AI systems have been improving and have been able to beat the best humans in increasingly complex games. Games with physical components or team capabilities are also a great way to measure AI progress, and the robotics community has launched a variety of challenging game competitions, such as RoboCup. Another competitive area of AI involves coordination and teamwork, and multi-agent systems have shown progress in distributed reasoning.
The AI community has been developing benchmarks for a long time. The place of artificial intelligence
Significant progress has been made possible because different methods and instruments can be assessed against the same gold standard that the benchmark represents. In the field of machine learning, benchmarking across domains and types of data has driven significant progress. Many benchmarks are automatically evaluated by third parties and test data is not exposed to AI developers, which makes the evaluation results more reliable. An interesting recent trend is that there are various ratios
Benchmark tasks are all handled by the same model. For example, natural language has been handled for many years as a series of independent tasks (such as comprehension, generation, and question solving), each with its own model and benchmark. Similarly, speech tasks are benchmarked separately from language comprehension or generation tasks. Today, the same model can handle all linguistic tasks, and in some cases, a single model can handle language, image, and multimodal tasks. This is a very important step forward for AI in integrating otherwise independent intelligent tasks and capabilities.
The AI system has shown continuous outpacing in the benchmark, and its rapid progress
This step is perhaps best illustrated by the declining importance of the Turing test, a well-known challenge to artificial intelligence for a long time. The test was originally developed by Alan A. Turing's 1950 paper, "Computing Machinery and Intelligence," was used to evaluate the ability of machines to exhibit human-like intelligence. In the test, human judges engage in text-based conversations with machines and humans; If the judge is unable to reliably distinguish between them, the machine is considered to have passed the Turing test. The latest evidence suggests that advances in large language models have made it difficult to distinguish between top language models and humans, signaling that modern AI models can pass the Turing test. Although the advantages and disadvantages of this test have long been debated, it is
An important historical and cultural benchmark for measuring machine intelligence. Doubts about its relevance highlight the tremendous advances in large language models in recent years and the interest in effective computer science 2025 artificial intelligence
Index Report
Table of Contents Chapter 2 Preview 101 Benchmarks and Evolving Perceptions of Artificial Intelligence Measurement.
In the field of robotics, there are many responses to interacting with the physical world and reasoning from themselves
A model of the law of nature. Many bot benchmarks, such as ARMBench, focus on:
Perception tasks. However, other benchmarks, such as VIMA-Bench, evaluate the robot's performance in simulated environments that combine perception, communication, and deep learning.
Baselines can also be tainted, i.e., large language models encounter in their training data
Test questions that have appeared. A recent study by Scale found that the performance of many large language models on GSM8K, a widely used mathematical benchmark, is heavily contaminated. Some researchers have attempted to address these contamination issues by introducing benchmarks such as LiveBench, which are regularly updated with new questions from unfamiliar sources that are unlikely to appear in the training data of large language models.
Finally, research has shown that many benchmarks are flawed in their construction. at 
In BetterBench, the researchers systematically analyzed 24 well-known comparative benchmarks and found systemic flaws: 14 were not statistically significant, 17 lacked scripts for reproducing results, and most were poorly documented, limiting their reproducibility and the validity of the evaluation model. Despite widespread use, benchmarks such as MMLU have a lower level of adherence to quality standards, while benchmarks such as GPQA perform significantly better. To address these issues, the paper proposes a framework of 46 standards that covers all phases of baseline development (design, implementation, documentation, and maintenance) (Figure 2.1.40). The paper also introduces a publicly accessible repository to enable continuous updates and improve the comparability of benchmarks. Figure 2.1.41 from BetterBench evaluates the usability and design of a number of well-known benchmarks. These findings underscore the need for standardized benchmarks to ensure the reliability of AI assessments and to prevent misleading conclusions about model performance. Benchmarks have the potential to influence policy decisions and procurement decisions within an organization, highlighting the importance of consistency and rigor in assessments.
Compare the five phases of the baseline lifecycle
Source: Reuel et al., 2024
FIGURE 2.1.40 DESIGN:
●Clarify the purpose and scope of the benchmark
with structure;
●Define tasks, data sets, and evaluation targets
IMPLEMENTATION:
●Construct a baseline by collecting, processing, and labeling datasets;
●PREVENTION OF DATA POLLUTION AND MANIPULABLE DOCUMENTATION
●Detailed description of the tasks, data sets, and evaluation metrics of the benchmark;
●Explain design decisions and limitations;
●Provide a baseline of resources to be used
MAINTENANCE
●Deal with problems and integrate feedback;
●EVALUATE THE RELEVANCE OF THE BASELINE RETIREMENT
●Inform stakeholders of decommissioning plans;
●Archiving benchmark data, code and documentation,
and marked as "Decommissioned"
1 2 3 4 5 Chapter 2: Technical Performance
2.1 Overview of AI technology development in 2024 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 2 Preview 102 Figure 2.1.41
In this section, the AI Index continues to report on the benchmark and endorses it
The importance in tracking the advancement of AI technology. Conventionally, the index starts with:
Get benchmark scores in public repositories such as leaderboard, Papers With Code, and RankedAGI, as well as company papers, blog posts, and product launches. The index is based on the assumption that the scores reported by companies are accurate and true. The baseline scores in this section are current as of mid-February 2025. However, since the release of the AI Index, new models may have been released that go beyond the current state-of-the-art scores. In the selected baseline, the design vs. usability score is compared
Source: Reuel et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
BBQ
BOLD
MMLUARC-ChallengeWinoGrande
GSM8K
HellaSwagAgentBenchGPQA
BIG-bench
Procgen
WordcraftRL UnpluggedFinRL-Meta
SafeBenchALE
0 5 10 15 20051015
Foundation models
Non-foundation models
MedMNIST v2TruthfulQAMLCommons AI Safety v0.5
MachiavelliPDEBenchDecodingTrust
HumanEval usability score
Design Score Chapter 2: Technical Performance
2.1 Overview of AI technology development in 2024 Artificial intelligence in 2025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Table of Contents Chapter 2 Preview 1032.2 Language
Natural language processing (NLP) enables computers to understand, interpret, and generate
and convert text. Current state-of-the-art models such as OpenAI's GPT-4o,
Anthropic's Claude 3.5 and Google's Gemini are able to generate fluent and coherent text and demonstrate a high level of language comprehension (Figure 2.2.1). Unlike earlier versions, which were limited to text input and output, next-generation language models are now capable of inference across a wider range of input and output modalities, including audio, image, and goal-oriented tasks (Figure 2.2.2).
Figure 2.2.1
Figure 2.2.2 Gemini 2.0 in Agent Workflow
Source : AI Index 2025 Q: What is the Stanford HAIs?
A: The Stanford HAI (Stanford Institute for Human-Centered Artificial Intelligence) is a research study at Stanford University
Dedicated to advancing the development of artificial intelligence to improve human life. The agency fosters interdisciplinary collaboration between AI researchers, social scientists, policymakers, and industry leaders to ensure artificial intelligenceThe development of energy
and applications that are in line with human values and social needs.
Stanford HAI's core areas include:
Research: Conduct research on the social, ethical and governance implications of AI.
Education: Offer AI-related courses, scholarships, and training programs.
Policy & Outreach: Work with policymakers and international organizations to promote responsible AI regulations.
Advocacy activities: Conducting workshops, publishing reports (e.g., the AI Index Report), and developing tools (e.g., full
Ball AI Vitality Index Tool).
The institute plays a leading role in the global AI debate, aiming to make AI widely available to people
while addressing its potential risks and challenges. More information is available on the Stanford HAI website. Sample output of GPT-4o
Source: Artificial Intelligence Index 2025
Table of Contents Chapter 2 Preview Artificial Intelligence in 1042025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Language comprehension
English language comprehension presents challenges to AI systems on multiple fronts, including:
Reading comprehension and logical reasoning.
MMLU: Multitasking Language Understanding at Scale
Large-scale multi-task language understanding (MMLU) benchmarks are measured by zero-sample or
The few-sample scenario assesses the performance of the model in 57 disciplines, covering humanities and STEM
(Science, Technology, Engineering, Mathematics) and social sciences (Figure 2.2.3). MMLU
It has become a core benchmark for evaluating the capabilities of large language models: GPT-4o,
Cutting-edge models such as Claude 3.5 and Gemini 2.0 were evaluated based on this test. The MMLU benchmark was created in 2020 by a team of researchers from the University of California, Berkeley, Columbia University, the University of Chicago, and the University of Illinois at Urbana-Champaign.
As of September 2024, MMLU has a maximum score of 92.3%, which is shared by OpenAI
的 oi-preview 模型取得。 For comparison, GPT-4, released in March 2023, scored 86.4%. It is worth noting that the early test model RoBERTa received only 27.9% of the scores in 2019 (Figure 2.2.4). This latest achievement marks a 64.4 percent improvement in performance over five years.
MMLU: Average accuracy
Source: Papers With Code, 2025 | Chart: 2025 Artificial Intelligence Index Report MMLU Sample Questions
Source: Hendrycks et al., 2021
One of the reasons why the government restricts and regulates monopolies is:
(a) Producer surpluses decreased and consumer surpluses increased. (b) Monopoly prices guarantee production efficiency, but society loses allocation efficiency. (c) The monopoly will not carry out significant R&D activities. (d) Reduced consumer surpluses as a result of rising prices and declining production. Microeconomics
Figure 2.2.3
Figure 2.2.4 Average accuracy
2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%70%80%90%100%
92.30% 89.8%, Human Benchmark Catalog Chapter 2 Preview Artificial Intelligence in 1052025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Despite the high-profile impact of MMLU, it has also faced significant criticism. There is an opinion that
This baseline contains errors or overly simple questions that may not be effectively challenged
Increasingly advanced systems. In 2024, research teams from the University of Toronto, the University of Waterloo, and Carnegie Mellon University launched MMLU-Pro, a more challenging version of MMLU. This version eliminates noise and trivial issues, expands complex topics, and increases the number of options for the model. Figure 2.2.5 illustrates the performance trend of MMLU-Pro, with DeepSeek-R1 topping the list with a score of 84.0%.
In addition, the test environment raises concerns. Developers sometimes use non-standard
Accurate tips for techniques report MMLU scores, which may improve performance but lead to misleading comparisons. In addition, evidence suggests that there may be discrepancies between publicly reported scores by developers and the results of subsequent evaluations by academic researchers, sometimes by as many as five percentage points. Therefore, the performance results of MMLU need to be interpreted with caution. Generate tasks
In the generation task, the AI model needs to be tested to generate smoothly and practically
Ability to respond in language.
Chatbot Arena Leaderboard
With the rise of high-performance large language models, it is important to understand which modules the public prefers
Type is becoming more and more important. Chatbot Arena launched by LMSYS in 2023 
Leaderboard, one of the first platforms to comprehensively assess the public's preference for large language models. The leaderboard allows users to ask questions to two anonymous models and vote for the better answer (Figure 2.2.6). As of early 2025, the platform has accumulated more than 1 million votes, with users rating Google's Gemini family of models as the community's most popular choice.
MMLU-Pro: Overall accuracy
Source: MMLU-Pro Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.2.5 Overall Accuracy 71.59% 71.85% 72.55% 73.11% 73.30% 74.68% 75.46% 75.70% 75.87% 76.24% 77 .64% 77 .90% 78.00% 80.30% 84.00%
Qwen2.5- 72B Grok- 2- mini GPT- 4o (2024- 05- 13) Athene- V2- Chat (0- shot) Llama- 3.1- 405B- Instruct GPT- 4o (2024- 08- 06) Grok- 2 MiniMax- Text- 01 DeepSeek- V3 Gemini- 2.0- Flash- exp Claude- 3.5- Sonnet (2024- 10- 22) GPT- 4o (2024- 11- 20) Claude- 3.5- Sonnet (2024- 06- 20) GPT- o1- mini DeepSeek- R10%20%40%60%80%100%Table of Contents Chapter 2 Preview Artificial intelligence in 1062025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Figure 2.2.7 shows the Chatbot Arena as of January 2025 
An overview of the top 10 models on the Leaderboard. It is worth noting that the top-of-the-line model
The performance gap between them is gradually narrowing. According to the 2024 AI Index, the difference in Arena scores between the top and 10th place models in 2023 is 11.9%, 6
In 2025, this gap has fallen to 5.4%. This convergence phenomenon indicates that the quality of large language models is becoming balanced in the near future. Sample model responses on the Chatbot Arena Leaderboard
Source : Chatbot Arena Leaderboard, 2024
LMSYS Chatbot Arena Large Language Model Elo Score (Overall)
Source : LMSYS, 2025 | Chart:: Artificial Intelligence Index Report 2025
Figure 2.2.6
Figure 2.2.7
6. Arena Score is a relative ranking system used by Arenaleaderboard to compare model performance. The scoring methodology is detailed in the Chatbot Arena Leaderboard article.
Performance relative to human benchmark (%)
Gemini-1.5-Pro-002 Step-2-16K-Exp o1-mini DeepSeek-V3 o1-preview o1-2024-12-17 Gemini-2.0-Flash-Exp Gemini-2.0-Flash-Thinking-Exp-1219 ChatGPT-4o-latest (2024-11-20) Gemini-Exp-12061, 3001, 3101, 3201, 3301, 3401, 3501, 3601, 3701, 380 Table of Contents Chapter 2 Preview 1072025 Artificial Intelligence
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Arena-Hard-Auto
With the rapid improvement of AI capabilities, the development of new benchmarks is a major challenge
The challenge is that manually creating high-quality benchmarks is costly and time-consuming. To this end,
A team of researchers at the University of California, Berkeley, launched BenchBuilder this year. The tool leverages large language models to build automated processes that filter high-quality, open-ended prompts from large-scale crowdsourced datasets that can be updated or created without extensive human intervention. The L M S Y S team used the tool to develop Arena-Hard-Auto, a benchmark designed specifically for evaluating instruction-tuned large language models (Figure 2.2.8). Arena-Hard-Auto contains 500 difficult user queries from Chatbot Arena and compares their responses with the baseline model (GPT-4-0314) using GPT-4 Turbo as the evaluation model. As of November 2024, on Arena-Hard-Autoleaderboard
The models with the highest scores were o1-mini (92.0), o1-preview (90.4), and Claude-3.5-Sonnet (85.2) (Figure 2.2.9). The benchmark also features a style control leaderboard, which evaluates the potential impact of the model's response style on user preferences. At the top of the style leaderboard is the Claude Sonnet 3.5 variant released by Anthropic in November 2024 (Figure 2.2.10). However, automation benchmarks such as Arena-Hard-Auto have been criticized for the uneven distribution of problems, such as more than 50% of problems focusing solely on programming and debugging, which limits the full evaluation of large language model capabilities.
Unmodified Arena-Hard-Auto
Source: LMSYS, 2025 | Chart: The 2025 AI Index reports Arena-Hard-Auto with style control
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.2.9 Figure 2.2.10gpt-4-0125-preview
gpt-4o-2024-05-13
claude-3-5-sonnet-2024-06-20
yi-lightning
gpt-4-turbo-2024-04-09
llama-3.1-nemotron-70b-instruct
athene-v2-chat
claude-3-5-sonnet-2024-10-22
o1-preview-2024-09-12
o1-mini-2024-09-12020406080100
78.00 79.20 79.3081.50 82.6084.90 85.00 85.2090.40 92.00 fractions
Model model score
gpt-4o-2024-05-13
llama-3. 1-nemotron-70b-instruct
gpt-4o-2024-08-06
athene-v2-chat
gpt-4-0125-preview
gpt-4-turbo-2024-04-09
o1-mini-2024-09-12
o1-preview-2024-09-12
claude-3-5-sonnet-2024-06-20
claude-3-5-sonnet-2024-10-22020406080100
69.90 71.00 71.10 72.10 73.60 74.3079.3081.70 82.2086.40Example of a model response on the Chatbot Arena Leaderboard
Source : Chatbot Arena Leaderboard, 2024
Auto-evaluation Configurable Support for automatic evaluation of Arena-Hard-Auto
Fixed presets Not supported by manual sorting Automatic evaluation of MMLU, MATH, GPOA
Fixed presets Support manual sorting Automatic evaluation of MT-Bench, AlpacaEval
Fixed presets Manual Sorting Does not support automatic evaluation of Live Bench, Live
code Bench
User groups Support crowdsourcing user groups to organize together Manual evaluation ChatGPT Arena evaluation method Whether open-ended questions are supported Prompt organization method Prompt source
Figure 2.2.8 Table of Contents Chapter 2 Preview Artificial Intelligence in 1082025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
WildBench
WildBench is a research fellow at the Allen Institute for AI and the University of Washington
Developer is a benchmark launched in 2024 for those who are challenging
of real-world queries. The creators highlight several limitations of existing large language model evaluations. For example, MMLU focuses only on academic issues and does not cover open-reality scenarios; Benchmarks such as LMSYS, while presenting real-world challenges, rely too heavily on manual review and lack the consistency of evaluation using a unified dataset across all models (Figure 2.2.11)
WildBench's assessment framework
Source: Lin et al., 2024
Figure 2.2.11 Table of Contents Chapter 2 Preview Artificial Intelligence in 1092025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
WildBench solves the shortcomings of existing benchmarks with an automated evaluation framework,
The problem set covers a diverse range of real-world scenarios that language models may encounter ("wild"
question) (Figure 2.2.11). These questions are curated from more than 1 million human-machine conversations and are regularly updated to ensure that they are up to date. Developers also maintain real-time leaderboards to track changes in model performance. Currently, WildBench's best-performing model is GPT-4o, with a WB-Elo score of 1227.1, narrowly ahead of Claude 3.5 Sonnet (1215.4 points) (Figure 2.2.12).
WildBench: WB-Elo ( Length Control )
Source: WildBench Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.2.12WB-Elo Score (l Length Control)
Model 1,176 1,179 1,181 1,182 1,185 1,188 1,192 1,196 1,197 1,199 1,209 1,210 1,215 1,215 1,227
Gemma-2-27B-it Nemotron-4-340B-Inst Athene-70B Yi-Large DeepSeek-V2-Coder Llama-3-70B-Instruct Gemini 1.5 Flash Claude 3 Opus gpt-4-0125-preview DeepSeek-V2-Chat Yi-Large-Preview gpt-4-turbo-2024-04-09 Gemini 1.5 Pro Claude 3.5 Sonnet gpt-4o-2024-05-1302004006008001,0001,200Table of Contents Chapter 2 Preview Artificial Intelligence in 1102025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Focus:
o1, o3, and inference time calculations
OpenAI's latest released o1 and o3 models mark the AI model
A paradigm shift in the ability to "think" and perform at a higher level of reasoning. O1 and O3
Demonstrated excellent performance in diverse tasks such as programming, quantum physics, and logic, and its advanced reasoning capabilities are attributed to the chained thought process and the iterative validation mechanism of the answer. This means that the model breaks down complex problems into smaller, executable steps, improving the quality of the output. For example, in the task of decoding out-of-order text, o1 demonstrates a more detailed mental reasoning process than GPT-4 (Figure 2.2.15). This mechanism by which an AI system iteratively optimizes during the response process is known as inference time computation.
O1's chained thought process
Source: OpenAI, 2024
GPT-4o
User Input:
oyfjdnisdr rtqwainr acxz mynzbhhx -> Think step by step
Use the above method to decode the following ciphertext:
oyekajjzdf aaptcg suaokybhai ouow aqht my -
nznvaatzacdfoulxxzGPT-4o
Figure 2.2.13 Description of the decoding steps:
Pair letters: Group letters in ciphertext in pairs (e.g. oy fj dn is dr).
Alphabetically to Number: Converts each letter to its corresponding ordinal number in the alphabet
（A=1，B=2，…，Z=26） 。
Summation: Calculate the sum of the numbers for each pair of letters. Average: Divide the sum by 2 to get the average. Number to Letter: Converts the average to the corresponding letter (1=A, 2=B, ...,26=Z). Example: Take the first pair of letters oy as an example:
o = 15, y = 25 → and = 15 + 25 = 40 → mean = 40 / 2
= 20 → letters = T focus :
O1, O3, and Inference Time Calculations (continued)
Figure 2.2.14 compares GPT-4o with o1 and o1-preview
benchmarks. 7For example, o1 is superior with 2.8 on MMLU
It is expected to surpass GPT-4o, leading by 34.5 points in the MATH test, 26.7 points higher in GPQA Diamond, and in the extremely difficult AIME 2024
In the math competition, he led by 65.1 points. o3, on the other hand, demonstrated the most complex reasoning capabilities available today, beating the previous record of 55.5% with an accuracy of 87.5% in the ARC-AGI machine intelligence benchmark.
However, the powerful inference capabilities of these models come with significant cost gains
liters – including financial costs and delay costs. For example, GPT-4o has input/output word costs of $2.5 and $10 per million, respectively, while o1 is as high as $15 and $60.
8 In addition, the first token of o1 is delayed up to 29.7 seconds, which is 4 times more than GPT-4o (0.72 seconds). The latency of O3 is not disclosed, but it is speculated to be higher. The power of O1 and O3 will continue to drive the development of advanced AI systems and agents. OpenAI announced on September 12, 2024 that ChatGPT Plus and
Teams users release o1-preview, and the official release of o1 on December 5, 2024 (along with the release of a $200 monthly ChatGPT Pro subscription service for o1 access).
7. O1-Preview is an early preview version of O1 that provides limited access until general release.
8. O3 is currently only available to select researchers and developers through the Open AI Security Testing Program.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1112025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
GPT-4o, o1-preview, o1 were compared on the selected baseline
Source: OpenAI, 2024
Figure 2.2.1488.00%90.80% 92.30%
GPT- 4o o1 o1- preview0%20%40%60%80%100%
60.30%85.50%94.80%
GPT- 4o o1- preview o10%20%40%60%80%100%
50.60%73.30%77 .30%
GPT- 4o o1- preview o10%20%40%60%80%100%
9.30%44.60%74.40%
GPT- 4o o1- preview o10%20%40%60%80%100%Pass@1 Pass@1Pass@1 Pass@1MMLU MATH
GPQA Diamond AIME 2024 Table of Contents Chapter 2 Preview Artificial Intelligence in 1122025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
MixEval
MixEval is a faculty of the National University of Singapore, Carnegie Mellon University, and Allen 
Jointly launched by the research team of the Institute for AI, it is a solution to the current large language model
A new benchmark for assessing domain limitations. MixEval combines comprehensive real-user queries from Chatbot Arena with MMLU's standard-answer-based questions (Figure 2.2.15) and includes multiple evaluation kits, including MixEval-Hard  
is a more challenging version that focuses on difficult queries and becomes an evaluation model to handle
An effective tool for complex problems.
In the MixEval-Hard benchmark, the model with the highest score was OpenAI
of o1-preview (72.0 points), followed by the Claude 3.5 Sonnet-0620 model (68.1 points) and the Llama-3-405B-Instruct model (66.2 points) in third place
(Figure 2.2.16). All three models were released in 2024.
Chat model's score in MixEval-Hard
Source: MixEval Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.2.16 Figure 2.2.15 Availability Score
model
MixEval's evaluation framework
Source: Ni et al., 2024
52.9054.0055.80 55.9056.80 57 .00 57 .4058.30 58.7062.6063.5064.7066.2068.1072.00
Reka Core- 20240415 Claude 3 Sonnet Qwen- Max- 0428 LLaMA- 3- 70B- Instruct Yi- Large- preview Spark4.0 Mistral Large 2 Gemini 1.5 Pro- API- 0514 Gemini 1.5 Pro- API- 0409 GPT- 4- Turbo- 2024- 04- 09 Claude 3 Opus GPT- 4o- 2024- 05- 13 LLaMA- 3.1- 405B- Instruct Claude 3.5 Sonnet- 0620 OpenAI o1- preview010203040506070Table of Contents Chapter 2 Preview Artificial Intelligence in 1132025
Index Report
Ragnarok (RAG Arena) and CRAG (Integrated RAG Benchmark). In addition, needles
Dedicated benchmarks for specific scenarios, such as FinanceBench, have also been developed.
Berkeley Function Calling Leaderboard
The Berkeley Function Calling Leaderboard evaluates large language modules
The ability to accurately call a function or tool. The evaluation kit includes more than 2,000 questions
- Functions - Answer pairs, involving multiple programming languages (such as Python, Java, JavaScript, and REST APIs) and multiple testing domains (Figure 2.2.17). Chapter 2: Technical Performance
2.2 Language
RAG: Retrieval Enhancement Generation
Retrieval Enhancement Generation (RAG) is a growing type of testing in large language models
The more often
The ability to see. This approach integrates a large language model with a retrieval mechanism
to enhance its responsiveness. The model first retrieves phases from a file or document
related information, and then generate a response that is suitable for the user's query based on the retrieved content
Should. RAG's use cases are varied, including answering precise questions from large databases
title
and the use of company document information to resolve customer inquiries.
In recent years, RAG has attracted the attention of research institutions and companies. For example, Anthropic
Launched in September 2024 with "Contextual Search" technology to significantly improve the RAG model
type of search ability. Several RAG evaluation benchmarks have also been released in 2024, such as:
Berkeley Function Calling Leaderboard data composition
Source: Yan et al., 2024
9. In this case: AST (Abstract Syntax Tree) refers to the task that involves analyzing or manipulating code at the structural level, parsing the code into a tree of syntax elements. Assessments labeled "AST" may test the ability of an AI model to understand, generate, or process code in a structured way. Exec (base
Executed) represents a task that requires the actual execution of a function call to verify correctness. An evaluation labeled "Exec" may assess whether the AI model is able to call and execute functions correctly, ensuring that the expected output is produced.
Figure 2.2.15 9Table of Contents Chapter 2 Preview Artificial Intelligence in 1142025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
On the Berkeley Function Calling Leaderboard, the performance is the best
The best model is watt-tool-70b, which is based on Llama-3.3-70B-In-
The variant of struct fine-tuned specifically for the function call task has an overall accuracy of 74.24% (Figure 2.2.18). In second place is the November version of GPT-4o
Ben, scored 72.08. The model's performance in this benchmark over the course of 2024
Significant improvement,
At the end of the year, the accuracy of the top model increased by 50 percentage points compared to the beginning of the year
Dot.
Berkeley Function Calls: Overall Accuracy
Source: Berkeley Function-Calling Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.2.18 Overall Accuracy
Model 52.9054.0055.80 55.9056.80 57.00 57.4058.30 58.7062.6063.5064.7066.2068.1072.00
Reka Core- 20240415 Claude 3 Sonnet Qwen- Max- 0428 LLaMA- 3- 70B- Instruct Yi- Large- preview Spark4.0 Mistral Large 2 Gemini 1.5 Pro- API- 0514 Gemini 1.5 Pro- API- 0409 GPT- 4- Turbo- 2024- 04- 09 Claude 3 Opus GPT- 4o- 2024- 05- 13 LLaMA- 3.1- 405B- Instruct Claude 3.5 Sonnet- 0620 OpenAI o1- preview010203040506070Table of Contents Chapter 2 Preview Artificial Intelligence in 1152025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
MTEB: Benchmark for large-scale text embeddedness
The Massive Text Embedded Benchmark (MTEB) platform is powered by Hugging 
Created by the team of the companies Face and Cohere, it was launched at the end of 2022 and aims to:
Comprehensively evaluate the technical performance of the model in a variety of embedding tasks. Embedding involves converting data, such as words, text, or documents, into vectors of numbers to capture approximate semantics and distances between vectors. Embedding is an important part of RAG. In a RAG task, when a user enters a query, the model transforms it into an embedding vector. These transformers allow the model to search for relevant information. MTEB includes crossing 
58 datasets and 8 embedding tasks in 112 languages (Figure 2.2.19). 10 
For example, in a bitext mining task,
There are two sets of sentences from two different languages,
For each sentence in the first group, the model's task is to find the most in the second group
A good match.
The task of the MTEB baseline
Source: Muennighoff et al., 2023
Figure 2.2.19
10. The 8 types of tasks covered by the benchmark include: bilingual text mining, classification, clustering, paired classification, reordering, retrieval, semantic text similarity, and abstraction. Details of each task are detailed in the MTEB paper.
67 .56 68.17 68.23 69.32 69.88 70.11 70.24 70.31 71.19 71.21 71.62 71.67 72.02 72.3174.03
SFR- Embedding- Mistral Linq- Embed- Mistral voyage- large- 2- instruct N-Embed-v1 bge- multilingual- gemma2 stella_en_400M_v5 gte-wen2-7B-instruct SFR- Embedding-2_R stella_en_1.5B_v5 LENS
-d4000LENS- d8000 bge- en- icl jasper_en_vision_language_v1 NV- Embed- v2 voyage- 3- m- exp020406080100
Table of Contents Chapter 2 Preview Artificial Intelligence in 1162025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
As of early 2025, MTEB compares the best-performing embedding model in the benchmark
is voyage-3-m-exp from Voyage AI with a score of 74.03 points. Voyage 
AI is focused on building high-quality AI-embedded models. voyage-3-m-exp is the base
In a variant of voyage-3-large (a large-scale base model designed for embedding tasks), strategies such as Matryoshka Representation Learning and Quantized Perception Training were used to optimize performance. The model narrowly outperforms NV-Embed-v2 (72.31 points), which occupies the top spot for most of 2024 (Figure 2.2.20). When the MTEB benchmark was first launched in late 2022, the average score of the leading model was just 59.5 points. So, in the last two years, compared
Benchmark results have improved significantly. Average score
model
Figure 2.2.20 MTEB English subset (56 datasets) average score
Source: MTEB Leaderboard, 2025 | Chart: Chart 2.2.21 of the 2025 AI Index Report
Figure 2.2.22 Model
model
Table of Contents Chapter 2 Preview Artificial Intelligence in 1172025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
RULER weighted average score (incremental)
Source: Hsieh et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Comparison of ULER claims and effective context lengths
Source: Hsieh et al., 2024 | Chart: Highlights of the 2025 AI Index Report:
Long context retrieval evaluation
As AI models advance, so do their ability to handle longer contexts
It is also significantly improved. For example, OpenAI and Meta released in 2023 
GPT-4 and Llama 2 models, with a context window of 8,000 and respectively 
4,000 tokens. In contrast, more recent models such as GPT-4o (2024
May) and Gemini 2.0 Pro Experimental (February 2025)
The range of context windows has been expanded to 128,000 to 2 million. These extensions
Contextual windows enable users to input and process larger and larger amounts of data, thus
Implement more complex, detailed interactions.
As the context window of large language models expands, evaluate their presence in long language
The technical performance of the environment is also becoming more and more important. However, there are long contextual reviews
Estimation methods are relatively limited. Typically, these assessments focus on "
 Looking for a needle in a haystack " 
, where the model is required to retrieve a specific piece of information from a lengthy text.
These assessments, while useful, only provide a basic assessment of the model.
In 2024, to address the limitations of long context model evaluation and improve
Its evaluation, several new evaluation kits have been introduced. One of the benchmarks is English
RULER, launched by Weida in 2024, passes through retrieval performance, multi-hop
Tasks such as science, information aggregation, and Q&A comprehensively evaluate long context performance. at
In the RULER test, the Gemini-1.5-Pro topped the list with a score of 95.5. 
GPT-4 (89.0 points) and GLM4 (88.0 points) followed (Figure 2.2.21). grind
It was also found that most of the models that claimed to support 32K token contexts actually worked
The length is less than half of the declared value (Figure 2.2.22). IN FACT, THE RULER TEAM
Proof that while most popular large language models claim that the context size is 
32K tokens or larger, but only half of them can hold at 32K length
People are satisfied with the technical performance. This means that they actually operate in a contextual window than they do
The developer claims to be short (Figure 2.2.22).
Phi3- medium (14B)
Qwen2 (72B)
GradientAI/Llama3 (70B)
Command- R- plus (104B)
Yi (34B)
Llama3.1 (8B)
Llama3.1 (70B)
GLM4 (9B)
GPT- 4- 1106- preview
Gemini- 1.5- pro0%20%40%60%80%100%
74.80%79.60%82.60%82.70%84.80% 85.40%85.50%88.00% 89.00%95.50%
Phi3- medium (14B) Qwen2 (72B) GradientAI/Llama3 (70B) Command- R- plus (104B) Yi (34B) Llama3.1 (8B) Llama3.1 (70B) GLM4 (9B) GPT- 4- 1106- preview Gemini- 1.5- pro0200K400K600K800K1MClaimed Eective weighted average score (inc.) Context length (tokens) Figure 2.2.22
Table of Contents Chapter 2 Preview Artificial Intelligence in 1182025
Chapter 2 of the Index Report: Technical Performance
2.2 Language
Long context benchmark comparison
Source: Yen et al., 2024
Figure 2.2.23
HELMET: Average score
Source: Yen et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Average Score Highlights :
Long Context Retrieval Evaluation (continued)
HELMET (Efficient Comprehensive Evaluation Framework for Long Context Models) is a collaboration between Intel and the
Another long-context assessment benchmark jointly launched by Princeton University in 2024.
The engine is driven by three major shortcomings of existing benchmarks: insufficient coverage of downstream tasks, short context length to test advanced capabilities, and unreliable evaluation metrics (Figure 2.2.23). COMPARED WITH RULER, HELMET IS MORE COMPREHENSIVE, INCLUDING 7 TYPES OF LONG CONTEXT EVALUATION TASKS, SUCH AS SYNTHETIC RECALL, PARAGRAPH REORDERING, AND CITATION GENERATION. FIGURE 2.2.24 SHOWS THE AVERAGE HELMET PERFORMANCE OF SEVERAL WELL-KNOWN MODELS AT 8K, 32K, AND 128K CONTEXTUAL SETTINGS. While models such as GPT-4, Claude 3.5 Sonnet, and Llama 3.1-70B degraded performance in longer contextual scenarios, others, such as Gemini 1.5 Pro and GPT-4 August Edition, retained technical performance. THE INTRODUCTION OF BENCHMARKS SUCH AS RULER AND HELMET SHOWS HOW THE RAPID DEVELOPMENT OF LARGE LANGUAGE MODELS IS FORCING RESEARCHERS TO RETHINK AND REFINE THEIR ASSESSMENT METHODS.
64.20 63.90
59.50 59.80 60.2058.6066.30
53.5063.5060.80
39.9063.80
39.5062.70
49.30
GPT-4 GPT-4o-08 Claude-3.5-Sonnet Gemini-1.5-Pro Llama-3.1-70B0204060801008k 32k 128k
Model computer vision enables machines to understand image/video content and base it on
Text or other cues produce realistic visual output. This technology is widely used
In the fields of autonomous driving, medical imaging, and game development.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1192025
Index Report
VCR Challenge Sample Questions
Source: Zellers et al., 2018 Chapter 2: Technical Performance
2.3 Images and Videos
2.3 Images and Videos
Ability to comprehend
Visual models are connected by the ability to understand image/video content and make inferences
Evaluated. Visual comprehension is the first widely tested artificial intelligence in the era of deep learning
One of these capabilities, ImageNet, created by Li Feifei (which has been described in depth in previous AI index reports), has been the basic benchmark for image understanding. As technology advances, researchers are shifting the focus of assessment to more complex tasks, such as video comprehension or image common-sense reasoning.
In the era of ImageNet datasets, the task of vision algorithms is more straightforward (eg
For example, group images into predefined categories). Modern benchmarks such as VCR and MVBench present an open-ended challenge where there is no fixed classification or category, in which the model processes the natural language problem, recognizes objects from an open set of images, and generates answers based on image content or prior knowledge. VCR: Visual Common Sense Reasoning
The Visual Common Sense Reasoning (VCR) challenge is presented by the University of Washington and AL e N  
Launched in 2019, researchers at the Institute for AI test the common-sense visual reasoning capabilities of AI systems. In this challenge, AI systems don't just have to be based on imagesAnswering the question also involves reasoning about the logic behind the answer (Figure 2.3.1). Technical performance in the VCR is measured by a Q->AR score, which assesses the machine's ability to choose both the correct answer to a question (Q->A) and the appropriate reason behind that answer (Q->R). Table of Contents Chapter 2 Preview Artificial Intelligence in 1202025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
The VCR benchmark is one of the few artificial intelligences in the AI index
The energy system has not been one of the benchmarks for human benchmarks. However, 2024
The year was a turning point, and the AI system finally reached this benchmark. In July 2024, a model appeared on the leaderboard with a score of 85.0, matching the human baseline (Figure 2.3.2). This milestone marks a 4.2% improvement in benchmark performance since 2023. Even benchmarks that were previously difficult to reach have now been surpassed.
Visual Common Sense Reasoning (VCR) Task: Q-> AR scores
Source: VCR Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
MVBench
Launched in 2023 by a research team from Hong Kong and Chinese mainland
MVBench is the benchmark for challenging multimodal video understanding. 11 with early measurements only
Unlike the still image task for trial spatial understanding, MVBench includes a complex video task that requires cross-frame temporal inference (Figure 2.3.3).
11. Researchers from the Chinese Academy of Sciences, the University of Chinese Academy of Sciences, the Shanghai Artificial Intelligence Laboratory, the University of Hong Kong, Fudan University, and Nanjing University Figure 2.3.2
Example MVBench task
Source: Li et al., 2023
Figure 2.3.3Q-> AR scores
2018 2019 2020 2021 2022 2023 20245060708085 85 (human baseline)
Table of Contents Chapter 2 Preview Artificial Intelligence in 1212025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
As of 2024, the MVBenchleaderboard tops the list based on:
Qwen2.5-7B-Video-CCAM-7B built by Instruct language model
-v1.2, which scored 69.23, an improvement of 14.6% since the benchmark was introduced at the end of 2023 (Figure 2.3.4). These results highlight the slow but steady progress made by AI models in their ability to understand dynamic video. These results highlight the slow but steady progress made by AI models in their ability to understand dynamic video.
MVBench: Average accuracy
Source: MVBench Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.3.4 Average Accuracy 48.70% 50.90% 51.10% 54.73% 54.85% 58.10% 58.77% 60.40% 62.30% 62.80% 64.60% 65.35% 67 .25% 67 .42% 69.23%
interlm-7b vicuna-7b-delta-v0 VideoChat2 Kwai-VideoLLM ST-LLM PLLaVA 34B CVLM VideoChat2_mistral VideoChat2_HD_mistral Video-CCAM-4B-v1.1 Video-CCAM-9B-v1.1 JT-VL-Chat InternVideo2-8B-HD-Chat-f16 TimeMarker Video-CCAM-7B-v1.20%20%40%60%80%100%Table of Contents Chapter 2 Preview Artificial Intelligence in 1222025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
Ability to build
Image generation aims to create synthetic content that is indistinguishable from the real image. As it goes
According to the Artificial Intelligence Index, the current image generator is highly mature and difficult for most people
to distinguish between AI-generated face images and real photos (Figure 2.3.6). Figure 2.3.6 shows images generated by different versions of the Midjourney model from 2022 to 2025 for the prompt "Hyper-realistic images of Harry Potter". This represents a significant improvement in Midjourney's ability to generate hyper-realistic images over the course of two years. In 2022, the model generated Harry J. The porter image is cartoonish and inaccurate, but by 2025, it can generate renders that present a stunningly realistic look.
Midjourney Version Iteration: "Hyper-Realistic Harry Porter Images "
Source : Midjourney, 2024Which face is real?
Source : Which Face Is Real, 2024·
Figure 2.3.5
Figure 2.3.6 Table of Contents Chapter 2 Preview Artificial Intelligence in 1232025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
Chatbot Arena: Visual
The AI community is increasingly embracing public assessment platforms, such as chatbots 
Arena Leaderboard to evaluate the top AI image generators included in:
The performance of leading AI systems. The leaderboard also features a vision leaderboard that ranks the performance of more than 50 vision models. Users can:
Submit a text-to-image prompt, such as "Batman is drinking coffee," and vote for the resulting result they like (Figure 2.3.7). To date, Visual Arena has garnered over 150,000 votes.
As of early 2025, the number one visual model on leaderboard is:
Google's Gemini-2.0-Flash-Thinking-Exp-1219 (Figure 2.3.8) Similar to other Chatbot Arena categories (such as Whole, Coding, and Math), the performance of the leading model is very close. For example, the gap between the top-ranked model and the fourth-ranked model, ChatGPT-4o-latest (2024-11-20), is only 3.4%.
LMSYS Chatbot Arena Large Language Model Elo Score (Visual)
Source: LMSYS, 2025 | Chart: Chart 2.3.7 of the 2025 AI Index Report
Figure 2.3.8
Pixtral-Large-2411 Claude 3.5 Sonnet (20241022) Claude 3.5 Sonnet (20240620) Gemini-1.5-Flash-002 GPT-4o-2024-05-13 Gemini-1.5-Pro-002 ChatGPT-4o-latest (2024-11-20) Gemini-Exp-1206 Gemini-2.0-Flash-Exp Gemini-2.0-Flash-Thinking-Exp-12191,1601,1801,2001,2201,2401,2601,280Elo Rating
Model Chatbot Arena visual tile example
Source : Chatbot Arena Leaderboard, 2025 Table of Contents Chapter 2 Preview Artificial Intelligence in 1242025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
Focus:
The rise of video generation
As highlighted in last year's AI report, in recent years, it has been possible to use the
Models for generating videos with text prompts are emerging. Early models though shown
There is some potential, but there are still significant limitations, such as the low quality of the generated video, the lack of sound, or the ability to produce only very short clips. However, 2024 marks a major leap forward in AI video generation technology, with several industry-leading companies releasing advanced video generation systems.
In November 2023, Stability AI launched its Stable Video 
Diffusion model, the company's first foundational model capable of producing high-quality video (Figure 2.3.9). The model uses a three-step process: text-to-image pre-training, video pre-training, and fine-tuning of high-quality video. Subsequently, in March 2024, Stability AI released the Stable Video 3D model, which is capable of generating multiple 3D perspectives and videos of objects from a single image. In February 2024, OpenAI launched a preview version of its video generation model, Sora, which was officially made available to the public in December 2024. Sora is capable of producing videos up to 20 seconds long and resolutions up to 1080p (Figure 2.3.10). As a diffusion model, it first generates a basic video, and then gradually optimizes it through multi-step denoising to improve the video quality.
Static frames generated by Stable Video Diffusion
Source: Stability AI, 2025
Static frames generated by Sora
Source: OpenAI, 2024 Figure 2.3.9
Figure 2.3.10
Focus:
The Rise of Video Generation (continued)
Other tech giants have also entered the video generation space. October 2024
In January, Meta released the latest version of its Movie Gen model. with earlier versions
Unlike this, the new version of Movie Gen features advanced command-based video editing, the ability to generate personalized videos from images, and the ability to add sound to videos. Meta's state-of-the-art Movie Gen model is capable of generating 16-second, 16-frame-per-second video at 1080p resolution. Google has also made significant progress in 2024 with the launch of two important video generation models: Xeo in May and Xeo_2 in December. Google's internal benchmarks show that Veo 2 outperforms other leading video generation models like Meta's MovieGen, Kling v1.5, and Sora Turbo in terms of performance. In the comparison of users, Veo 2 generated videos are generally preferred (Figure 2.3.11).    
Relatively small players have also made significant contributions in the field of video generation, such as Runway's Gen-3 Alpha, Luma's Dream Machine, and Fast
Kling 1.5 for hands. By comparing the videos generated in 2023 and 2024, it is clear to see the significant progress in this area. Popular tips on the internet
The word "Will · Smith Eats Pasta" vividly illustrates this progress: videos generated by the popular video generator Pika in 2025 that are of higher quality than those in 2023
The version has been significantly improved (Figure 2.3.12).
Will · Smith Eats Pasta, 2023 vs 2025
Source: Pika, 2025Veo 2: Overall preference
Source: DeepMind, 2024 | Chart: 2025 Artificial Intelligence Index Report
Table of Contents Chapter 2 Preview Artificial Intelligence in 1252025
Chapter 2 of the Index Report: Technical Performance
2.3 Images and Videos
Figure 2.3.12 Figure 2.3.11 Overall preference
 53.80% 49.50% 54.50% 58.80% 15.60%
 17 .80% 15.20% 14.50% 30.60%  32.60% 30.30% 26.70%
Meta Movie Gen Kling v1.5 Minimax Sora Turbo0%20%40%60%80%100%Veo Preferences Flat Other Preferences
V1.0
December 2023
V1.5
October 2024
V2.2
February 2025 2.4 Voice
Speech recognition
Speech recognition refers to the ability of an artificial intelligence system to recognize spoken words and convert them into text. Speech recognition
Technology has come a long way, and many computer programs and texting apps today are equipped with dictation devices that can
Reliably transcribe speech to text.
LSR2: Lip Reading Sentences 2
The Lip Reading Sentences 2 (LRS2) dataset published by the University of Oxford in association with the BBC
Launched in 2017, it is one of the most comprehensive public lip reading datasets available, focusing on real-world applications (Figure 2.4.1). The dataset contains audiovisual clips from various talk shows and news programs. In the Automatic Speech Recognition (ASR) task, the system's speech transcription ability is assessed by the Word Error Rate (WER), with lower scores indicating more accurate transcription.
Still image from the BBC lip reading sentences 2 dataset
Source: Chung et al., 2024
Table of Contents Chapter 2 Preview Artificial Intelligence in 1262025
Chapter 2 of the Index Report: Technical Performance
2.4 Voice
Artificial intelligence systems excel in human speech processing, and its voices
Frequency competencies include transcribing spoken words as:text and identifying individual speakers.
In recent years, artificial intelligence has also made significant progress in generating synthesized audio content
progress.
Figure 2.4.1
Table of Contents Chapter 2 Preview Artificial Intelligence in 1272025
Index Report
This year, the Whisper-Flamingo model set a new benchmark in the LRS2 benchmark
The new standard, the Word Error Rate (WER) reached 1.3%, surpassing the 2023 rate of 1.5%.
State-of-the-art (Figure 2.4.2). However, as WER is already at very low levels, further significant improvements are unlikely, suggesting that the baseline may be close to saturation.
LRS2: Word Error Rate (WER)
Source: Papers With Code, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.4.2 Chapter 2: Technical Performance
2.4 Voice
2018 2019 2020 2021 2022 2023 20240%1%2%3%4%5%6%7%8%
1.30% Word Error Rate (WER) programming involves generating executable instructions from a computer to complete a task.
In recent years, large language models have become proficient programming assistants for computing
Logistic scientists provided important support. There is growing evidence that many programmers find AI programming assistants very useful. As highlighted in last year's AI Index report, large language models are becoming more sophisticated in their programming capabilities, so much so that many basic programming benchmarks, such as HumanEval, are becoming saturated. To this end, researchers have shifted their focus to testing how large language models perform in more complex programming challenges. 2.5 Programming
HumanEval
HumanEval is a benchmark launched in 2021 by Open AI researchers, passed
164 hand-written programming questions assess the coding ability of an AI system (Figure 2.5.1). presently
The leading performance model for HumanEval is Claude 3.5 Sonnet (HPT) with a score of 100% (Figure 2.5.2).
Table of Contents Chapter 2 Preview Artificial Intelligence in 1282025
Index Report
Figure 2.5.1
Figure 2.5.2 Chapter 2: Technical Performance
2.5 Programming
Pass@1HumanEval Sample questions
Source: Chen et al., 2023
HumanEval: Pass@1
Source: Papers With Code, 2025 | Chart: 2025 Artificial Intelligence Index Report
2021 2022 2023 20240% 20% 40% 60% 80% 100% 100% Table of Contents Chapter 2 Preview Artificial Intelligence in 1292025
Index Report
SWE-bench
In October 2023, researchers from Princeton University and the University of Chicago pushed
The SWE-bench dataset is produced, which contains 2,294 real-origin datasets
GitHub issues and software engineering issues for popular Python codebases (Figure 2.5.3). SWE-bench provides a more difficult test of AI programming capabilities, requiring the system to coordinate modifications across multiple functions, adapt to different execution environments, and perform complex inferences. SWE-bench includes a filtered subset of Lite to simplify evaluation, and a manually annotated subset of Verified. The following chart shows the scores for a subset of Verified.
SWE-bench highlights the role of large language models that were once considered extremely challenging
Rapid progress in business. At the end of 2023, the top-performing model on SWE-bench scored just 4.4%. By early 2025, the top-ranked model—OpenAI's o3 model—successfully solved 71.7% of the problems on the Verified benchmark set (Figure 2.5.4). This significant performance gain suggests that AI researchers may soon need to develop more challenging programming benchmarks to effectively test large language models.
SWE-bench: Problem resolution rate
Source: SWE-bench Leaderboard, 2025; OpenAI, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.5.4 Problem resolution rate
Model Chapter 2: Technical Performance
2.5 Programming
SWE-bench example model input
Source: Jimenez et al., 2023
Figure 2.5.3
40.67% 41.00% 41.33% 41.67%44.67%47 .33% 48.33% 48.67% 49.00%55.00% 53.20% 55.00% 55.40% 57 .00% 57 .20% 58.20%60.20%62.20% 62.80% 64.60%71.70%Agentless- 1.5 +
Claude- 3.5 Sonnet (2024- 10- 22)
Composio SWE- Kit (2024- 10- 30)
PatchKitty- 0.9 +
Claude- 3.5 Sonnet (2024- 10- 22)
OpenHands + CodeAct v2.1
(claude- 3- 5- sonnet- 2024- 10- 22)
Kodu- v1 + 
Claude- 3.5 Sonnet (2024- 10- 22)
devlo
Globant Code Fixer Agent
Gru (2024- 12- 08)
Blackbox AI Agent
Isoform
Bracket.sh
Amazon Q Developer Agent
(v2024- 12- 02- dev)
EPAM AI/Run Developer
Agent v2024- 12- 12 +
Anthopic Claude 3.5 Sonnet
Gru (2024- 12- 08) 
Emergent E1 (v2024- 12- 23)
 dev
lo
Learn- by- interact
CodeStory Midwit Agent +
swe- search
 Blackbox AI Agent
W&B Programmer O1 crosscheck5
o3
Lite Veriﬁed0%20%40%60%80%100%
Lite Veried Table of Contents Chapter 2 Preview 130BigCodeBench Hard Set Test: Pass@1 (Average Score)
Source: Hugging Face, 2025 | Chart: Artificial Intelligence Index Report 2025 BigCodeBench Full Test : Pass@1 ( Average Score )
Source: Hugging Face, 2025 | Chart: Artificial Intelligence Index 2025 Report Programming Tasks in BigCodeBench
Source: Zhuo et al., 2024
Figure 2.5.5
Figure 2.5.7 Figure 2.5.6 Chapter 2: Technical Performance
2.5 Programming Artificial Intelligence in 2025
Index Report
BigCodeBench
One limitation of existing programming benchmarks is that many tests are limited to
Short, self-contained algorithmic tasks or stand-alone function calls. However, solving complex realities
Tasks often require the ability to call diverse functions, such as data analysis tools or web development tools. Effective programming also requires the model to be able to understand encoded instructions expressed in natural language – an ability that is not tested by most current programming benchmarks.
To complement the existing programming benchmarks, an international team will launch in 2024
BigCodeBench, a comprehensive, diverse, and challenging programming benchmark (Figure 2.5.5), was deployed. The benchmark requires a large language model to invoke multiple function calls across 139 libraries and 7 domains, covering 1,140 fine-grained tasks. Current labor
The intelligent system does not perform well on this benchmark: even when the "complete" task of the benchmark (  
Code completion) based on structured docstrings) and "directive" tasks (nature-based
Code completion of language instructions) on the current optimal model (OpenAI
O1) averaged only 35.5 (Figure 2.5.6). The model performed slightly on the full set of benchmarks
Excellent (Figure 2.5.7). BigCodeBench highlights the power of AI systems to enable people
There is still a gap in class-level programming proficiency.
Pass@1 ( Average Score )
Model 30.80 31.10 31.40 32.10 32.10 32.80 33.80 34.10 34.50 35.50Qwen2.5- Coder- 32B- Instruct
GPT- 4o- 2024- 11- 20
Athene- V2- Agent
Athene- V2- Chat
GPT- 4- Turbo- 2024- 04- 09
o1- 2024- 12- 17
(temperature=1, reasoning=medium)
DeepSeek- V3- Chat
Gemini- Exp- 1206
o1- 2024- 12- 17
(temperature=1, reasoning=low)
o1- 2024- 12- 17
(temperature=1, reasoning=high)020406080100
Pass@1 ( Average Score )
Model 52.90 53.20 53.50 53.50 54.00 54.10 54.20 54.70 56.10 56.10Gemini- 2.0- Flash- Exp
GPT- 4- Turbo- 2024- 04- 09
Qwen2.5- Coder- 32B- Instruct
GPT- 4o- 2024- 11- 20
DeepSeek- Coder- V2- Instruct
DeepSeek- V2- Chat (2024- 06- 28)
Gemini- Exp- 1114
Gemini- Exp- 1206
DeepSeek- V3- Chat
GPT- 4o- 2024- 05- 13020406080100Elo RatingChatbot Arena: Programming Ability Assessment
Programming has been added to Chatbot Arena's large language model leaderboard
The ability screening function provides developers and the community with the ability to evaluate the programming capabilities of different models
It is a valuable reference. This public feedback adds a new dimension to evaluating model performance. Currently, the highest-rated large language model for programming is Gemini-Exp-1206,
Its arena score is 1,369 points, and OpenAI's latest o1 model has a score of 1,361
This is a close second. Among the Chinese models, DeepSeek-V3 leads with 1,317 points
The difference between the top and the top is 3.8% (Figure 2.5.8).
Table of Contents Chapter 2 Preview 131 Chapter 2: Technical Performance
2.5 Programming Artificial Intelligence in 2025
Index Report
LMSYS Chatbot Arena Elo Score on Large Language Models (Programming)
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.5.8 Model Qwen2.5-plus-1127 DeepSeek-V3 Claude 3.5 Sonnet (20241022) Gemini-2.0-Flash-Thinking-Exp-1219 Gemini-2.0-Flash-Exp ChatGPT-4o-latest (2024-11-20) o1-preview o1-mini O1-2024-12-17 Gemini-Exp-12061,3001,3201,3401,3601,380 Math Problem Solving Benchmark for evaluating the mathematics of AI systems
Reasoning skills, which range from primary school level to competition standards
Math problems. Chapter 2: Technical Performance
2.6 Mathematics
Table of Contents Chapter 2 Preview Artificial Intelligence in 1322025
Index Report
GSM8K: Accuracy
Source: Papers With Code, 2024 | Chart: Example of the 2025 AI Index Report GSM8K Questions
Source: Cobbe et al., 2023
Figure 2.6.1
Figure 2.6.2 Accuracy
2022 2023 20240%20%40%60%80%100%97 .72%
2.6 Mathematics
GSM8K
GSM8K is a dataset launched by OpenAI in 2021 that contains about 8,000 diverse
Elementary school math application problems that require an artificial intelligence model to generate a solution through multi-step arithmetic operations (Fig
2.6.1） 。 Like MMLU, GSM8K has become a common benchmark for evaluating advanced large language models. However, in the near term, the benchmark may face data pollution and performance saturation.
The best-performing model on GSM8K was Claude Sonnet, optimized with HPT prompting strategy 
3.5 variant, with an accuracy of 97.72% (Figure 2.6.2), a significant improvement from 91.00% in 2023. However, in 2024, multiple models for Mistral, Meta, and Qwen all scored close to 96%, indicating:
The GSM8K benchmark may be approaching saturation. Accuracy MATH
The MATH dataset was developed by the University of California, Berkeley and the University of Chicago
The math problem set, launched by researchers in 2021, contains 12,500 questions with picks
Battle-oriented competition-level questions (Figure 2.6.3). At the time the dataset was published, AI systems performed poorly, addressing only 6.9% of these issues. Since then, however, performance has improved significantly: in January 2025, OpenAI released the o3-mini (high-performance version) model with a breakthrough on the MATH dataset with a 97.9% accuracy rate (Figure 2.6.4). MATH was one of the few benchmarks where AI systems have yet to surpass the human baseline, according to last year's AI Index assessment, but that has been rewritten.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1332025
Index Report
MATH Text Solution: Accuracy
Source: Papers With Code, 2024; OpenAI, 2025: Papers & Code, 2024; OpenAI, 2025 | Chart: The 2025 AI Index reports an example of a question from the MATH dataset
Source: Hendrycks et al., Hendrycks et al., 2023
Figure 2.6.3
Figure 2.6.4 Chapter 2: Technical Performance
2.6 Mathematics
2021 2022 2023 2024 20250%20%40%60%80%100%97 .90%
90%, human benchmark Elo score
Model Chatbot Arena: Math Ability Assessment
Chatbot Arena adds a new math filtering feature that allows the public to filter based on the model
Generate math-related answers for performance rankings. Math Arena evaluated exceeding
181 models and collected 340,000 public votes. Unlike the Gemini series of models leading the way in the general-purpose and programming arenas, the number one in the math arena is OpenAI's O1 variant model released in December 2024 (Figure 2.6.5).
FrontierMath
Members of the mathematical community pointed out the limitations of current mathematical benchmarks and called for the development of new ones
to evaluate increasingly advanced AI systems. The main challenge is saturation: AI systems are nearing perfection in high school and college-level math tests such as GSM8K and MATH. To push the boundaries further, researchers propose benchmarks for testing true higher-order mathematics, including questions such as number theory, real analysis, algebraic geometry, and category theory.
FrontierMath is a new benchmark for Epoch AI, with hundreds of origins
Create difficult math problems. These questions are reviewed by a team of mathematicians and often take hours, days, or even collaborative research to solve. Figure 2.6.6 shows an example question in the benchmark. Epoch AI evaluated the performance of six leading large language models on FrontierMath: o1-preview, o1-mini, GPT-4o, Claude 3.5 Sonnet, Grok 2 Beta, and Gemini 1.5 Pro 002. At the time of the benchmark's release, the top-performing Gemini 1.5 Pro had only solved 2.0% of the problems – well below its performance in other math benchmarks (Figure 2.6.7). Whereas, OpenAI's o3 model scored 25.2%. FrontierMath developers hope that this benchmark will continue to be a serious challenge for cutting-edge AI systems for years to come.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1342025
Index Report
LMSYS Chatbot Arena Large Language Model Score : Elo Score ( Math )
Source: LMSYS, 2025 | Chart: 2025 Artificial Intelligence Index Report Chapter 2: Technology Performance
2.6 Mathematics
Figure 2.6.5 Claude 3.5 Sonnet (20241022) Gemini-1.5-Pro-002 DeepSeek-V3 ChatGPT-4o-latest (2024-11-20) Gemini-2.0-Flash-Exp Gemini-Exp-1206 Gemini-2.0-Flash-Thinking-Exp-1219 o1-mini o1-preview o1-2024-12-171,2601,2801,3001,3201,3401,3601,380 resolution rate
Table of Contents Chapter 2 Preview Artificial Intelligence in 1352025
Index Report
FrontierMath sample question
Source: Glazer et al., 2024
FrontierMath: Problem resolution rate
Source: Glazer et al., 2024; OpenAI, 2025 | Chart: 2025 Artificial Intelligence Index Report Chapter 2: Technology Performance
2.6 Mathematics
Figure 2.6.6
Figure 2.6.7
Model0.00%1.00% 1.00%2.00% 2.00%25.20%
Grok 2 Beta GPT- 4o
(2024- 08- 06)o1- preview Claude 3.5 Sonnet
(2024- 10- 22) Gemini 1.5 Pro
(002)o30%20%40%60%80%100%Table of contents Chapter 2 Preview Artificial intelligence in 1362025
Chapter 2 of the Index Report: Technical Performance
2.6 Mathematics
Focus:
Learning with theorem proof
DeepMind uses its systems AlphaProof and
AlphaGeometry 2, which successfully solved the 2024 International Mathematical Olympiad
4 out of 6 questions in the competition (IMO) with a performance at the level of a silver medalist. at
In the benchmark, AlphaGeometry solves 30 Olympiad geometry problems
25 channels, surpassing the average of 22.9 solved by IMO silver medalists (Figure 2.6.8). 
Founded in 1959, IMO is the oldest and most prestigious youth in the world
Mathematician Competition.
AlphaProof is a reinforcement learning system based on AlphaZero, the latter
It has been used in chess, shogi and Go. The system is beneficial by generating assumptions
Validate hypotheses with the Lean interactive proof system to solve the problem automatically. In addition,
The fine-tuned Gemini model was used to transform natural language problem statements
For formal representation, a comprehensive training library is constructed. In this competition,  
AlphaProof successfully solved 2 algebra problems and 1 number problem, but failed
Solve 2 combinatorial math problems.
AlphaGeometry 2 is a hybrid system of neural symbols with its language
The model is based on Gemini and trained on a large amount of synthetic data. In 2024
Previously, AlphaGeometry was able to solve 83% of historical IMO geometry problems. at
In the 2024 competition, the system solved the only geometry in just 24 seconds
Title. During the test, the contest questions were human-translated into a formal representation of Lean.
It's unclear how AlphaProof and AlphaGeometry work in the tradition
Theorem proves performance on benchmarks such as IPTP. IPTP has been used since 1997
Evaluate the performance of automated theorem proof (ATP) systems, especially when applied to software validation
certification system. The AI Index reported in 2021 on the current state of ATP
Analyzed. The 2024 update of the report shows that the base is based on the inclusion of more than
With TPTP v.9.0.0 version of 25,000 questions, 89% of them are now solved by the fully automated system.
Ideally, the TPTP system can be tested on IMO topics, while
AlphaProof and AlphaGeometry can be tested on TPTP questions—
— Some of these problems have never even been solved by humans, let alone the ATP system. However, neither of these types of tests was implemented, mainly due to the significant differences in the logic supported by different systems and the lack of conversion tools. In addition, although the TPTP library is large, it is not enough to be used as a training set for AlphaProof, and a large number of synthetic examples still need to be generated. Number of geometry issues resolved for MO-AG-30
Source: Trinh et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.6.8Wu's method Honorable mentions Bronze medalist Silver medalist AlphaGeometry Gold medalist0510152025
10.0014.2719.2922.8525.0025.93 Number of Problems SolvedThe reasoning ability of artificial intelligence refers to the inference ability of artificial intelligence systems from different shapes
The ability to draw logically valid conclusions in the information. Currently, artificial intelligence
Systems are increasingly being tested in a variety of reasoning scenarios, including visual reasoning (image analysis), moral reasoning (understanding moral dilemmas), and social reasoning (coping with social situations).
Sample MMMU questions
Source: Yue et al., 2023
Table of Contents Chapter 2 Preview Artificial Intelligence in 1372025
Chapter 2 of the Index Report: Technical Performance
2.7 Inference
Figure 2.7.1
Figure 2.7.2
2.7 Inference
General reasoning
General reasoning refers to the ability of an AI system to reason in a broad domain rather than in a specific task.
For example, in a general reasoning challenge, an AI system may need to reason across disciplines rather than perform a single task
(as shown in chess).
Overall accuracy
2023 20240%20%40%60%80%100%
78.20% 82.60%, human expert level (median) MMMU performance on the validation set: overall accuracy
Source: MMMU Leaderboard, 2024 | Chart: 2025 Artificial Intelligence Index Report
MMMU: A large-scale, multidisciplinary, multimodal understanding and reasoning benchmark for expert-level AGI
In recent years, the reasoning capabilities of artificial intelligence systems have improved rapidly, such as traditional benchmarks
SQuAD (Textual Reasoning) and VQA (Visual Reasoning) are saturated, and more challenging tests are needed.
To this end, researchers in the United States and Canada have developed MMMU (Large-scale multi
Disciplinary Multimodal Understanding and Reasoning Benchmark) designed for expert-level artificial general intelligence (AGI). The MMMU contains about 11,500 college-level questions covering six
Big Core Disciplines: Art & Design, Business, Science, Health & Medicine, Humanities & Social Sciences, Technology & Engineering (Figure 2.7.1). Questions in the form of diagrams, maps, chemical structures, etc. As of January 2025, OpenAI's OI model leads with 78.2% accuracy, a significant improvement over last year's optimal score of 59.4% (Figure 2.7.2). While the score is still below the high-level benchmark among human experts, AI systems are rapidly closing the gap. GPQA: A Graduate-Level Google-Proof Q&A Benchmark
In 2023, researchers from New York University, Anthropic, and Meta
The GPQA Benchmark was launched to test general, multidisciplinary AI inference
Ability. The dataset consists of 448 difficult questions that are difficult to easily answer with a web search. These questions were carefully designed by experts in various fields such as biology, physics, and chemistry (Figure 2.7.3). In the diamond set, the hardest part of the dataset and the most commonly tested by AI developers, the accuracy rate of human experts reached 81.3%. Last year's AI Index report showed the best-performing artificial models
GPT-4 scored only 38.8% on the diamond test set. In just one year, state-of-the-art AI systems have made significant progress. OpenAI's o3 model, released in December 2024, achieved a new best score of 87.7% on the diamond test set,
This is an increase of 48.9 percentage points from the best result in 2023 (Figure 2.7.4） 。 In fact, the O3 score is the first to surpass the benchmark set by a human expert validator. AI systems are rapidly challenging new benchmarks such as MMMU and GPQA, which have recently been introduced to push the limits of AI capabilities.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1382025
Index Report
GPQA Chemistry Problem Examples
Source: Rein et al., 2023
GPQA's accuracy in diamond sets
Source: Artificial Intelligence Index 2025 | Chart: Chart 2.7.3 of the 2025 AI Index Report
Figure 2.7.4 Accuracy Chemistry (General)
A reaction of a liquid organic compound whose molecules are made up of carbon and hydrogen atoms that react for 24 hours at 80 degrees Celsius and 20 bar. In nuclear magnetic resonance (NMR) spectroscopy, reactions
The signal with the highest chemical shift in the substance is replaced by the signal of the product, which is shifted down the spectrum by about three to four units. Where are compounds in the periodic table that would also be used in the corresponding large-scale industrial processes that are likely to be added in small quantities at the beginning of the reaction? A) Metal compounds from the fifth cycle. B) Metallic compounds from the fifth cycle and non-metallic compounds from the third cycle. C) Metal compounds from the fourth cycle. D) Metallic compounds from the fourth cycle and non-metallic compounds from the second cycle.
2023 20240%20%40%60%80%100%
87.70%81.20%, Human Expert Verifier Level Chapter 2: Technical Performance
2.7 Inference ARC-AGI
With the continuous advancement of artificial intelligence systems, about artificial general intelligence (AGI)
Upcoming statements are becoming more and more frequent. At present, there is no universally accepted artificial general intelligence
Righteousness. Some computer scientists define it as an artificial intelligence system that meets or exceeds human cognitive abilities in a wide range of tasks. Others stressed that the definition should cover the ability to learn and acquire skills in general, describing AI general as a system that "efficiently acquires new skills and solves new problems that are not designed or trained." ARC-AGI is a benchmark launched in 2019 by François Chollet, creator of Keras, a streaming open-source deep learning library. The ARC-AGI tests the system's ability to generalize beyond prior training.
More specifically, the ARC-AGI benchmark provides an independent set of tasks to an AI system. Each task consists of a demo or input pair, followed by one or more test or output scenarios (Figure 2.7.5). This benchmark emphasizes generalized learning ability: the system cannot be prepared in advance because each task introduces a unique logic. These tasks do not require specialized world knowledge or language skills, but instead rely on hypothetical prior knowledge, such as object concepts, basic topology, and elementary arithmetic—concepts that are often mastered in early childhood.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1392025
Index Report
ARC-AGI sample task
Source: Chollet et al., 2025
Figure 2.7.5
Chapter 2: Technical Performance
2.7 Inference High Score Rate ARC-AGI has proven to be a very challenging benchmark to compare.
When first run in 2020, the top-performing system scored only 20% (Figure 2.7.6).
） 。 Four years later, that score had risen to only 33 percent. However, significant progress has been made this year, with OpenAI's o3 model score reaching 75.7%. In cases where O3 is allocated a high compute budget that exceeds the baseline's $10,000 limit, it achieves a score of 87.5%. The researchers attribute the overall slow progress over the past few years to the study of artificial intelligence models
Excessive focus on scale—i.e., constantly increasing the size of the model and feeding in massive amounts of training data. While this approach improves the model's performance in specific tasks, it is of limited help in enhancing the AI system's ability to solve problems in the absence of prior knowledge or training data. The progress made this year shows that the focus of research is shifting to more substantial generic and search capacity improvements.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1402025
Index Report
ARC-AGI-1 Private Assessment Set: High Score
Source: Chollet et al., 2025; OpenAI, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.7.6 Chapter 2: Technical Performance
2.7 Inference
2019 2020 2021 2022 2023 20240%20%40%60%80%100%
75.70%Humanity's Last Exam (HLE)
As highlighted in this year's and last year's AI Index, many popular AIs
Benchmarks such as MMLU, GSM8K, and HumanEval have become saturated. for
As a result, researchers have developed more challenging benchmarks to more accurately assess AI capabilities. Recently, the team behind MMLU launched the "Ultimate Test for Humanity" (HLE), a new benchmark of 2,700 difficult questions covering dozens of subject areas (Figure 2.77). The dataset consists of multimodal questions contributed by experts in the field, including top professors and graduate-level reviewers
method is solved by a simple internet search or database search. In addition, each asks
The questions were tested by the most advanced large language models before inclusion. If there is an existing model
If it can be answered, the question will be removed.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1412025
Index Report
HLE sample questions
Source: Phan et al., 2025
Figure 2.7.7 Chapter 2: Technical Performance
2.7 Inference
Preliminary accuracy tests have shown that HLE is not difficult for current AI systems
Usually high. Even top models such as OpenAI's O1 score only 8.8% (Figure 2.7.8) are closely monitored by researchers on the benchmark
The rate of progress, they guess, could exceed 50% by the end of 2025.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1422025
Index Report
Humanity's Last Exam (HLE): Accuracy
Source: Phan et al., 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.7.8 Chapter 2: Technical Performance
2.7 Inference
3.10% 3.90% 4.80% 5.20%7 .20%8.80%
GPT-4o Grok-2 Clause 3.5 Sonnet Gemini 1.5 Pro Gemini 2.0 Flash Thinking o10%20%40%60%80%100%
planning
Planning is an intelligent task that involves reasoning about actions that change the world.
It requires a comprehensive consideration of the hypothetical future state, including potential external actions and others
Transformative events.
PlanBench
Previously, it was thought that large language models could solve planning problems. Arizo
A team at Na State University came up with PlanBench — a system that includes automatic
A benchmark kit for problems in the field of planning, especially in the International Planning Competition. Designed to test the planning capabilities of large language models, PlanBench consists of 600 questions that simulate a robot building a tower of blocks while only moving one block at a time to the top of a table or another block. After the benchmark was released in 2022, researchers found that models such as GPT-4 and GPT-3.5 still performed poorly in planning tasks. OpenAI's release of the O1 model has sparked a lot of buzz in the AI research community
Note, because it is designed to be active inference and not just run as an autoregressive large language model. In PlanBench testing, o1 performance improved significantly, but it still lacked in reliability and consistency planning. In the Blocksworld zero-shot assessment, one of the specific planning evaluation domains, the O1 score was 97.8%, far outperforming the second place Llama 3.1 405B (62.6%) and significantly outperforming GPT-4o (35.5%) (Figure 2.7.9). In the more challenging realm of Mystery Blocksworld (where some answers are grammatically obfuscated), O1 has a zero-shot score of 52.8%, compared to 0.8% for Llama 3.1 405B and 0% for GPT-4.
Planning is a combinatorial optimization problem, and tasks with longer resolution steps are expected to need to be exceeded
Linear time. As a result, O1 only solves 23.6% of the test instances that require at least 20 steps.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1432025
Index Report
PlanBench: Correctly resolved instances
Source: Valmeekam et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.7.9 Chapter 2: Technical Performance
2.7 Inference
54.80%
35.50%62.60%
23.80%97 .80%
0.00% 0.00%8.00%52.80%
Claude 3.5 (Sonnet) GPT- 4o LLama 3.1 405B Gemini 1.5 Pro o1- preview0%20%40%60%80%100%Blocksworld Mystery BlocksworldI Properly Solved Instances AI Agents are designed to operate in a specific environment to achieve the purpose
The subject autonomous or semi-autonomous system is an exciting part of AI research
Fenfen's frontier field. These agents have a wide range of potential applications, from assisting with academic research, scheduling conferences, to facilitating online shopping and vacation bookings. As many recent company press releases indicate, agents have become a topic of increasing concern in the field of AI technology.
VisualAgentBench
VisualAgentBench (VAB), launched in 2024, is AI intelligence
A major advance in the field of body assessment. This benchmark reflects the multiplicity of AI models
Increasing modality and their increasing ability to navigate in both virtual and physical environments. VABs address the need to evaluate agent performance in a variety of environments, not just those that rely solely on language commands. The VAB test covers three broad categories of agents: embodied agents (running in home and gaming environments), graphical users
Interface agents (interacting with mobile and web applications) and visual design intelligence
Objects (e.g. CSS debugging)
(Figure 2.8.1). This holistic approach builds a
A powerful evaluation framework that enables comprehensive evaluation of intelligence in diverse and dynamic scenarios
body's abilities.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1442025
Index Report
Tasks for VisualAgentBench
Source: Liu et al., 2024 Chapter 2: Technical Performance
2.8 AI agents
Figure 2.8.12.8 AI agents
overview
The topic of AI agents has been in the spotlight in the AI community for decades, but there are few comparisons
Quasi-is widely adopted, including A g e n t B e n c h and mentioned in last year's AI index
MLAgentBench。 This is partly because agent tasks are often more diverse, dynamic, and variable than tasks such as image classification or answering language questions, so the benchmark itself is very complex. As AI continues to evolve, it will become increasingly important to develop effective methods to evaluate AI agents. VABs pose a significant challenge to AI systems. The best performing model 
GPT-4o has an overall success rate of only 36.2%, compared to most proprietary language models
The average success rate is about 20% (Figure 2.8.2). According to the authors of the benchmark, these results suggest that current AI models are far from ready to be deployed directly in an agent environment.
RE-Bench
With the advent of more and more powerful agents and AI systems, people are predicting
Artificial intelligence may soon replace the jobs of computer scientists or researchers. However, until recently, there were few benchmarks dedicated to rigorously testing the R&D capabilities of high-performance AI systems. In 2 0 2 4 , researchers introduced RE-Bench, a benchmark of seven challenging open machine learning research environments that filled this gap. These tasks are based on data from 71 8-hour attempts by more than 60 experts, including optimizing the kernel, conducting scaling law experiments, and tuning GPT-2 for Q&A (Figure 2.8.3).
Table of Contents Chapter 2 Preview Artificial Intelligence in 1452025
Index Report
The success rate of VisualAgentBench on the test set
Source: VisualAgentBench Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
RE-Bench Process & Flowchart
Source: Wijk et al., 2024 Figure 2.8.2
Figure 2.8.3 Chapter 2: Technical Performance
2.8 AI agents
6.307 .708.408.9010.30 10.5012.0016.0019.8020.5021.9026.9029.9031.7036.20
gemini- 1.0- pro |58 LLaVA- 1.5 CogVLM (Fine- tuning) CogAgent  LMMs CogVLM2 LLaVA- NeXT GLM- 4V InternVL- 2 gemini- 1.5- pro |48 (Prompting) gpt- 4o- mini- 2024- 07- 18 claude- 3- opus claude- 3.5- Sonnet GPT- 4- Turbo- 0409 GPT- 4- Vision- Preview GPT- 40- 2024- 05- 1305101520253035 Average Success
model
When comparing the performance of humans with cutting-edge AI models, the researchers obtained:
Two key findings. In the case of shorter hours, such as a two-hour budget, it is best
of AI systems score four times higher than human experts (Figure 2.8.4). However, as time budgets increase, humans begin to outperform AI. In the case of an eight-hour budget, humans perform slightly more than AI, while in the case of a 32-hour budget, humans perform twice as well as AI. The researchers also noted that for some tasks, AI has demonstrated expertise comparable to that of humans, but is able to deliver results at a faster pace and at a lower cost. For example, AI can write custom Triton Kernels faster than any human expert.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1462025
Index Report
RE-Bench: Average Normalized Score @k
Source: Wijk et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.8.4 Chapter 2: Technical Performance
2.8 AI agents
Average normalized score
Time budget (time limit per run × attempts)30min 2h 8h 16h 32h 64h0.000.200.400.600.801.001.201.40 Claude 3.5 Sonnet (Old) (Modular) Claude 3.5 Sonnet (New) (Modular) Claude 3.5 Sonnet (New) (AIDE)
o1- preview (AIDE) HumanGAIA
GAIA is a general artificial intelligence assistant launched by Meta in May 2024
Hand comparison benchmark. It consists of 466 questions designed to assess the execution of AI systems
Ability to perform a variety of tasks, including reasoning, multimodal processing, web browsing, and tool usage. Unlike simple exam-style questions, GAIA challenges AI models with complex, multi-step questions that may require searching open networks, interpreting multimodal inputs, and reasoning through complex scenarios (Figure 2.8.5). When the researchers rolled out GAIA, they found that existing large language models lagged far behind human performance. For example, GPT-4 with plugins can only answer 15% of questions correctly, compared to 92% of human respondents.
As with other recently launched AI benchmarks, GAIA's performance
It also raises rapidly. In 2024, the highest scoring system reaches 65.1%, an improvement of about 30 percentage points from the 2023 highest score (Figure 2.8.6).
Table of Contents Chapter 2 Preview Artificial Intelligence in 1472025
Index Report
GAIA sample questions
Source: Meta, 2024 Notice
GAIA: Average Score
Source: GAIA Leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.8.6 Figure 2.8.5 Chapter 2: Technical Performance
2.8 AI agents
Average score
2023 20240%20%40%60%80%100%
65.12%2.9 Robotics and autonomous movement
robot
RLBench
One of the most widely adopted benchmarks in robotics is RLBench (Robot Learning Comparison).
Benchmark). Launched in 2019, the benchmark includes 100 unique tasks of varying complexity
Single to reach the target to open the oven and put in the tray, etc. 12 Researchers typically pass through 18-item normalized sub-items
task to evaluate the performance of the new robotic system. Figure 2.9.1 shows some of the tasks in RLBench. Over the past decade, advances in artificial intelligence have brought to the field of robotics
Exciting new developments. Especially with the rise of the base model, machines
People are now able to learn from their surroundings, adapt flexibly to new environments, and make their own decisions. This section will explore key robotics benchmarks and recent trends, including the rise of humanoid robots, new advances in DeepMind's algorithms, and the emergence of basic robot models. Finally, the latest developments in the field of autonomous vehicles will be analyzed. Chapter 2: Technical Performance
2.9 Robotics and Autonomous Movement
Table of Contents Chapter 2 Preview Artificial Intelligence in 1482025
Index Report
Tasks for VisualAgentBench
Source: James et al., 2019
Figure 2.9.1
12. Target arrival in a robot refers to the process in which the robot system makes the end effector reach a specified target position or object in space by moving its end effector (such as a robot arm or gripper). As of January 2025, the best-performing model on this subset is 
SAM2Act, which is the home of Washington University, San Pablo Catholic University, Nvidia, and Developed in collaboration with researchers at the Allen Institute for AI. SAM2Act achieved an 86.8% success rate, an improvement of 2.8 percentage points from the 2024 frontier and an improvement of 66.7 percentage points from the 2021 lead (Figure 2.9.2).
Table of Contents Chapter 2 Preview Artificial Intelligence in 1492025
Index Report
RLBench: Success rate (18 tasks, 100 demos each)
Source: Papers With Code, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.9.2 Success Rate Chapter 2: Technical Performance
2.9 Robotics and Autonomous Movement
2022 2023 2024 20250%20%40%60%80%100%
86.80%Focus :
Humanoid robots
The year 2024 is an important year for the development of robotics, humanoid robots (tools
Machines with similar human structures designed to mimic human functions are becoming more and more widely used.
For example, Figure A1, a startup focused on developing general-purpose humanoid robots, unveiled its most advanced model to date – Figure 02 – in 2024. The robot is 5 feet 6 inches (about 1.68 meters), weighs 154 pounds (about 70 kilograms), has a payload capacity of 44 pounds (about 20 kilograms), and can run for up to 5 hours on a single charge. Figure robots are capable of performing complex tasks such as making coffee (Figure 2.9.3) and placing sheet metal into fixtures in automotive assembly (Figure 2.9.4). In addition, the bot is integrated with OpenAI and has speech-to-speech inference capabilities, which can interpret its own behavior and respond to relevant operational queries. The success of the figure comes on the heels of other companies' humanoid robot products, such as Tesla's Optimus, which was first launched in 2002 and redesigned in 2023, and Boston Dynamics' Atlas humanoid robot.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1502025
Index Report
Figure Robots make coffee
Source: Papers With Code, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.9.3
Figure robots assist with car assembly
Source: Figure AI
Figure 2.9.4 Chapter 2: Technical Performance
2.9 Robotics and Autonomous Movement
Table of Contents Chapter 2 Preview Artificial Intelligence in 1512025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Focus:
Progress at DeepMind
In 2023, DeepMind has launched two robot models:
PaLM-E and RT-2. These models are based on Transformers
, which is commonly used for language modeling, and is novel in terms of training on operational data and linguistic data. This dual training approach makes them excellent for both robot manipulation and text generation. In 2024, DeepMind launched AutoRT, an AI system that uses large base models to autonomously generate various training data for robots. It coordinates multiple video-equipped robots, guides them through various environments, designs creative tasks for them, and carefully documents those tasks (Figure 2.9.5). These records then serve as training data for future robot learning. To date, AutoRT has generated a database of 77,000 robot trials covering 6,650 unique tasks. In the future, more robot training data will be essential to improve the training effectiveness of robot systems.
Conversely, SARA-RT, also from Google's DeepMind, is shown by display
Increased speed and efficiency of Transformers-based robot models. Transformers, while powerful, rely on the attention mechanism of quadratic complexity, so they are very computationally intensive. This means that doubling the amount of data input provided to the model increases the computational requirements by a factor of four. This challenge complicates the scaling of the robot model. SARA-RT solves this challenge with a technique called "up-training" that converts the quadratic complexity of standard transformers into linear models. This approach greatly reduces the computational requirements while maintaining the quality of performance. Figure 2.9.6 compares the speed test results of an AI model enhanced with SARA technology versus an AI model without this technology. AutoRT workflow diagram
Source: Google DeepMind, 2024
Speed test comparison of SARA vs. non-SARA enhanced models
Source: Google DeepMind, 2024
Figure 2.9.6 Figure 2.9.5
Artificial intelligence in 2025
Index Report
ALOHA: 
Source: Zhao et al., 2024 | Chart: Artificial Intelligence Index Report 2025
Figure 2.9.8
Table of Contents Chapter 2 Preview 152 Key Points :
DeepMind's Progress (continued)
In point cloud processing (enabling the robot to resolve the 3D environment) and image processing
domain, SARA-based models run significantly faster while avoiding regulations
Significant increase in run time as the mold expands.
Other achievements of DeepMind include ALOHA (Advanced Activity Self-Learning
Xi) and DemoStart. ALOHA Unleashed is a breakthrough that enables robots to perform complex dexterous manipulation tasks, such as tying shoelaces or hanging a t-shirt on a hanger—tasks that have always been a daunting challenge for robots. Researchers have demonstrated that combining large imitative learning datasets with Transformer-based learning architectures is a very effective way to overcome these difficulties. The ALOHA approach enables Google's bots to effectively learn a variety of tasks, including hanging shirts, stacking kitchen items, and tying shoelaces (Figure 2.9.7). As shown in Figure 2.9.8, the ALOHA-trained bot has a high success rate in each of these tasks. Chapter 2: Technical Performance
2.9 Robotics and Autonomous Movement
Success rate: 70%75%
40%70%75%
40%75%95%
25%65%95%ShirtMessy
ShirtEasy
LaceMessy
LaceEasy
FingerReplace
GearInsert- 3
GearInsert- 2
GearInsert- 1
RandomKitchen
- Bowl+Cup+Fork
RandomKitchen
- Bowl+Cup
RandomKitchen
- Bowl
 0%20%40%60%80%100%
Hanging shirts, lace up robot fingers
Replacement gear assembly Random stacking of kitchen items ALOHA-trained robots are trying to perform complex tasks
Source: Google DeepMind, 2024
Figure 2.9.7
Table of Contents Chapter 2 Preview Artificial Intelligence in 1532025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Robots play table tennis at an amateur level
Source: Google DeepMind, 2024
Figure 2.9.9 Key points:
DeepMind's Progress (continued)
Similarly, DemoStart introduces a new type of automated course reinforcement
Xi method, Enables the robotic arm to master the complex using only sparse rewards and limited demonstrations
Miscellaneous behaviors. This breakthrough highlights the potential for robots to learn efficiently with minimal data, reducing the need for data-intensive training and making advanced robotics more accessible and widely available. DeepMind also launched a robot model in 2024 that is capable of reaching an amateur human level in competitive table tennis (Figure 2.9.9). Given that the speed and performance of reaching humans in real-world tasks is an important benchmark for robotics research, this achievement marks a significant step forward in robotics capabilities.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1542025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
GROOT Synthetic Movement Generates Blueprints
Source: Nvidia, 2024
Figure 2.9.10 Key points:
Robot base model
In 2024, there is a big push to develop a basic model of robotics – to be able to
A system that performs verbal reasoning while performing physical operations in the real world. hero
Weida has launched the GR00T (Generalist Robot 00 Technology), a general-purpose humanoid robot base model designed to understand natural language and mimic human movements. In addition to the GR00T, Nvidia has also released data pipelines, simulation frameworks, and a Thor robotic computer. FIGURE 2.9.10 SHOWS THE COMPONENTS OF GROOT AT LAUNCH. The bot development kit is designed to make it easier for the robotics community to scale and build increasingly advanced bots. Nvidia isn't the only company entering the space. Covariant introduces the RFM-1, a robotic base model with language capabilities and real-world manipulation capabilities. Meanwhile, researchers at Stony Brook University and the University of Wisconsin-Madison developed LLaRA that integrates perception, communication, and action into a single end-to-end deep learning model. These new models continue the trend in 2023 when robotic base models such as RT-2, PaLM-E, and Open-X Embodiment were introduced.
Table of Contents Chapter 2 Preview Artificial Intelligence in 1552025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Figure 2.9.11 Self-driving cars
Autonomous vehicles have always been a long line for AI researchers and technologists
period goals. However, its large-scale adoption has been slower than expected. Despite many
Predictions suggest that full autonomous driving is on the horizon, but autonomous vehicles are not yet widely available. Despite this, significant progress has been made in recent years. In cities like San Francisco and Phoenix, robotaxi fleets are now in commercial operation. This session focuses on the latest advances in autonomous driving, including deployment, technological breakthroughs and new benchmarks, safety performance, and policy challenges. develop
Autonomous vehicles are becoming more and more widely used around the world. open
Cruise, a subsidiary of Yongche, launched its self-driving car in San Francisco in late 2022, but its operations were suspended in 2023 due to a series of safety incidents. Waymo, a subsidiary of Alphabet, began deploying its robo-taxis in Phoenix in early 2022 and expanded to San Francisco in 2024. The company has become one of the more successful players in the autonomous driving industry: as of January 2025, Waymo operates in four major U.S. cities – Phoenix, San Francisco, Los Angeles, and Austin (Figure 2.9.11). According to data sourced in October 2024, the company offers 150,000 paid rides per week in four cities, covering more than 1 million miles. Going forward, Waymo plans to test its vehicles in 10 cities, including Las Vegas, San Diego, and Miami. The company chose test sites such as upstate New York and Truque, California, where snowfall is common, to evaluate the vehicle's performance in a variety of driving conditions. Notable progress has also been made in the area of autonomous trucks, such as Kodiak, which has completed its first driverless deliveries, and Aurora has reported steady progress, including more than 1 million miles of autonomous freight transportation on U.S. highways since 2021 – although still with human-safe drivers for now. However, bringing this technology to market remains challenging, with Aurora recently announcing that it will be delaying the commercial launch of its fleet, from the original date of late 2024 to April 2025. China's autonomous driving revolution is also accelerating, with Baidu's Apollo Go as the case
First, the company reported 988,000 rides across China in the third quarter of 2024, up 20% year-over-year. In October 2024, the company operated 400 driverless taxis and announced plans to expand its fleet to 1,000 by the end of 2025. Another Chinese self-driving car maker, Pony.AI, has pledged to expand its fleet of robotaxis from 200 to at least 1,000 and expects it to reach 2,000 to 3,000 by the end of 2026. China is leading the way in self-driving car testing, with reports that China has tested more driverless cars than any other country and is currently rolling out in 16 cities. China's driverless taxis are known for being affordable – in some cases, even cheaper than rides offered by human drivers. To support this growth, China has prioritized national regulations to regulate the deployment of driverless vehicles. In addition to the driverless revolution taking place in the United States and China, European start-ups such as Wayve are also starting to make their mark in the industry. The number of miles traveled by a Waymo driverless vehicle without a human driver
Source: Waymo, 2024 | Chart: Artificial Intelligence Index Report 2025
1.947M
10.209M
20.823M
124K as of September 2024
Unmanned mileage (no safety officer) location
Los Angeles
San Francisco Phoenix Austin Catalog Chapter 2 Preview 1562025 Artificial Intelligence
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Figure 2.9.12 Technological innovation and new benchmarks
Over the past year, autonomous driving technology has been benchmarked in terms of vehicle performance and comparison
Significant progress has been made on the legal front. In October 2024, Tesla launched 
The Cybercab, a two-seater self-driving car without a steering wheel and pedals, is scheduled to go into production in 2026 and will sell for less than $30,000. Tesla also introduced Robovan, an electric self-driving van that can carry 20 passengers. Meanwhile, Baidu's Apollo Go has unveiled the latest generation of robotaxis, the RT6, in several cities in China (Figure 2.9.12). Priced at just $30,000 and equipped with a battery swapping system, the RT6 marks a significant step forward in terms of cost-effectiveness and scalability for autonomous driving technology. The adoption of autonomous vehicles is expected to accelerate as costs continue to fall. A number of notable business partnerships have also driven the development of autonomous driving technology, including Uber's partnership with WeRide, the world's first publicly traded robotaxi company, to develop a self-driving ride-sharing platform in Abu Dhabi. In 2024, several new benchmarks were introduced to evaluate autonomous driving capabilities. One notable example of this is nuPlan, developed by Motional. This is a large autonomous driving dataset designed to test a machine learning-based motion planner. The benchmark includes 1,282 hours of various driving scenarios from multiple cities, as well as a simulation and evaluation framework that can be used to test the planner's actions in a closed-loop environment. Another recent benchmark is OpenAD, the first real-world, open-world benchmark for autonomous driving for 3D object detection. OpenAD focuses on domain generalization (the ability of an autonomous driving system to adapt to a variety of sensor configurations) and open vocabulary recognition (enabling systems to recognize previously unseen semantic categories). Most existing end-to-end autonomous driving benchmarks rely on an open environmental assessment
estimates, this may be limiting. Open-loop setups fail to test how autonomous driving agents react to real-world situations, often resulting in models memorizing driving patterns rather than actually learning to drive. While there are closed-loop benchmarks such as Town05Long and Longest6, they primarily assess basic driving skills rather than performance in complex, interactive scenarios. Bench2Drive is another new benchmark that overcomes these limitations by providing a comprehensive, realistic, closed-loop test simulation environment for end-to-end autonomous vehicles (Figure 2.9.13). It includes a training set containing more than 2 million fully annotated frames from more than 10,000 clips, and an evaluation kit containing 220 short routes for testing autonomous driving capabilities in a variety of conditions. Figure 2.9.14 shows the driving scores for the various autonomous driving methods evaluated in the Bench2Drive benchmark.
13 Baidu's RT-6
Source: Verge, 2024
Overview of Bench2Drive
Source: Jia et al., 2024
Figure 2.9.13
13. This indicator takes into account both route completion and violations, and the final score is obtained by calculating the average of the route completion rate and applying the corresponding penalty points according to the severity of the violation. For more information on the driving scoring methodology, see Section 3 of the Bench2Drive paper.
Driving score ↑
Table of Contents Chapter 2 Preview Artificial Intelligence in 1572025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Safety standards
The latest research suggests that self-driving cars may be safer than human-driven vehicles
Whole. Figure 2.9.15 compares the reported miles per million miles for Waymo vehicles
The estimated accident rate of the number of accidents is the same distance as a human driving. The data shows a significant reduction in the number of accidents involving Waymo vehicles, including 1.42 fewer airbag deployments per million miles, 3.16 fewer collisions with injuries, and 3.65 fewer police-reported collisions (Figure 2.9.15). Figure 2.9.16 highlights the difference in accident rates by accident location, showing that Waymo vehicles maintained lower rates in terms of airbag deployment, reported injured collisions, and police-reported accidents at all locations for which data was available. Bench2Drive: Drive score
Source: Jia et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.9.1430.4740.7049.3059.90
18.0540.7342.3545.8162.4464.22TCP-ctrl*
TCP*
TCP-traj w/o distillation
TCP-traj*
AD-MLP
UniAD-Tiny
VAD
UniAD-Base
ThinkTwice*
DriveAdapter*
2022 202301020304050601.74
0.324.06
0.905.91
2.26
0123456
Table of Contents Chapter 2 Preview Artificial Intelligence in 1582025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
14. Waymo's security data is continuously updated in real time, so the totals reported in this section may not exactly match the numbers displayed on its website. Benchmark comparison of Waymo drivers versus human drivers in Phoenix and San Francisco
Source: Waymo, 2024 | Chart: 2025 Artificial Intelligence Index Report
Percentage difference between drivers and human drivers in Phoenix and San Francisco
Source: Waymo, 2024 | Chart: Artificial Intelligence Index Report 2025 Figure 2.9.15 14
Figure 2.9.16 Accident rate per million miles
Human benchmarks
Airbag Deployment There are reports of injuries There are police reports Waymo Human Benchmark Waymo Human Benchmark Waymo Percentage Difference from Comparison Benchmark
-81%-77%
-87%-78%-59%
-88%-62%-51%
-76%
100% 80% 60% 40% 20% 0% Airbag Deployment There are reports of injuries There are police reports
Phoenix and San Francisco Phoenix San Francisco Table of Contents Chapter 2 Preview Artificial Intelligence in 1592025
Chapter 2 of the Index Report: Technical Performance
2.9 Robotics and Autonomous Movement
Waymo has partnered with Swiss Re (Swiss, the world's leading reinsurer 
Re), which is involved in its fully autonomous vehicles over millions of miles
Collision liability claims were studied. The study compared Waymo's liability claims data with Swiss Re's human driving benchmark data based on more than 500,000 claims and 200 billion miles driven. The results of the study showed an 88% reduction in property damage claims and a 92% reduction in personal injury claims for Waymo vehicles (Figure 2.9.17). Specifically, out of 25.3 million miles driven, Waymo vehicles were involved in only 9 property damage claims and 2 bodily injury claims, while human drivers were expected to have 78 property damage claims and 26 bodily injury claims for the same mileageRepay. Waymo's self-driving vehicles are also significantly safer than the latest generation of human-driven vehicles equipped with additional safety features.
Comparison of Different Types of Liability Insurance Claims: Waymo Autonomous Vehicles vs. Human-Driven Vehicles 
Source: Di Lillo et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 2.9.170.000.501.001.502.002.503.003.50 Claim Frequency per Million Miles
The latest generation of HDVs
Motorists, property damage, Swiss Re as a whole, Waymo's latest generation of HDVs
Motorists, Crowds, Property Damage, Swiss Re Whole, Waymo, 2025, Artificial Intelligence
Index Report
Chapter 3:
Responsible AI
Text & Analytics from Anka Reuel Chapter 3: Responsible AI
Implicit bias in explicit unbiased large language models 
See Measurements
3.8 Transparency and Explainability
Featured Research Base Model Transparency Index v1.1
3.9 Security and Safety Assurance
Benchmarks HELM Safety AIR-Bench Featured Research Large Language Models Improve the Robustness of Large Language Models to Persistent Harmful Behaviors
3.10 Topic on Responsible Artificial Intelligence
AI Agents Simulation sandbox based on language model Risks of identifying language model agents Jailbreaking multimodal agents from a single image Election disinformation AI disinformation in the U.S. election Rest of World 2024 Global AI Generated Election Content Statistics Overview Chapter Highlights
3.1 Background
definition
3.2 Assess responsible AI
AI Security Incidents Examples Responsible AI Benchmarking ApplicationsLimited Factuality and Authenticity Hughes Hallucination Evaluation 
   Focus: FACTS, SimpleQA, and more rigorous
      The introduction of factual benchmarks
3.3 Responsible AI in Organizations and Enterprises
Focus: Portrait perspective
3.4 Responsible AI in academia
      Overall trends in subject areas
3.5 Responsible AI policymaking3.6 Privacy and data governance
Featured research on data licensing in crisis
3.7 Fairness and Prejudice
Featured research on ethnic classification in multimodal models
Table of Contents Chapter 3 Preview Artificial Intelligence in 1612025
Index Report
Access to public data162
163
165
165
166
166167169170
170171173
180
184
184187
191192
192193
195
195195197
199
199199
201
201201202204204205
207
207
207
207209209
210 Chapter III:
Responsible AI
overview
Artificial intelligence is now deeply integrated into almost every area of our lives, reshaping education, finance, and healthcare, among others
Key industries – These are areas where algorithm-driven insights are guiding major decisions. Although this shift has brought
Significant benefits, but also risks that cannot be ignored. Over the past year, the world has continued to focus on the responsible development and deployment of AI systems.
This chapter examines the development trend of responsible artificial intelligence (RAI) in 2024 from multiple dimensions. The opening is clear and definite
Define the core concepts of RAI, and then evaluate key topics with a wide range of implications, including AI accident cases, challenges in standardizing liability for large language models, and benchmarks for evaluating the factual and authenticity of models. Subsequently, the study focuses on the practices of RAI in three major social actors: industry, academia, and policy-making, and presents landmark research results through an innovative assessment framework that deeply analyzes the key points of privacy and data governance, fairness, transparency and explainability, and security and security. Finally, this chapter concludes with two specific studies: AI agents and election disinformation governance.
Table of Contents Chapter 3 Preview Artificial Intelligence in 1622025
Chapter 3 of the Index Report:
Responsible AI
1. At present, the practice of evaluating AI systems against responsible artificial intelligence (RAI) guidelines is not yet widespread, but new benchmarking systems are emerging. go
The AI Index has highlighted the lack of a standardized RAI benchmark for large language models. While this issue persists, HELM Safety and
The emergence of new benchmarks, such as AIR-Bench, has helped fill this gap.
2. The number of AI incident reports continues to increase. According to the AI Incidents Database, AI-related incidents reported in 2024
The number of cases increased to 233, a record high and an increase of 56.4% from 2023.
3. Institutions are aware of the risks of responsible AI, but mitigation measures are lagging behind. A McKinsey survey on the implementation of enterprise RAI shows that despite the majority
Organizations are able to identify key RAI risks, but not all of them have taken proactive steps to address them. Among the risk dimensions that leaders are most concerned about, the issue of model accuracy (64% is affected
Compliance risks (63%) and cybersecurity threats (60%) were among the top three respondents, but it's worth noting that none of them listed these risks as their core concerns, more than 65%.
4. Globally, policymakers are showing a strong interest in responsible AI. In 2024, global cooperation on AI governance was strengthened, with a focus on collaboration
Agree on the principles of responsible AI. A number of international organizations, including the Organisation for Economic Co-operation and Development (OECD), the European Union, the United Nations, and the African Union, have issued normative frameworks that address RAI priorities such as transparency and explainability, and credibility.
5. Public data resources are shrinking rapidly. The training of AI models relies on massive amounts of publicly available network data, but the latest research shows that data usage will be used between 2023 and 2024
The throttling has increased significantly, as numerous websites have implemented new protocols to limit data crawling for AI training. The percentage of restricted text data in domains that are continuously maintained by the C4 Universal Crawl Dataset has skyrocketed from 5-7% to 20-33%. This downward trend will affect data diversity, model alignment, and system scalability, and may lead to new learning paradigms under data constraints.
6. The transparency of basic model research has improved, but there is still a long way to go. The newly released Foundation Model Transparency Index -
A project that tracks the transparency of the underlying model ecosystem – shows that the average transparency score of major model developers has increased from 37% in October 2023 to 2024
58% in May. While progress has been remarkable, there is still considerable room for improvement. Chapter Highlights
Table of Contents Chapter 3 Preview Artificial Intelligence in 1632025
Chapter 3 of the Index Report:
Responsible AI
7. The benchmark for evaluating factual and truthfulness is constantly improving. Early benchmarks, such as HaluEval and TruthfulQA, were designed to evaluate the facts of AI models
sex and authenticity, but it has not been widely used in the field of artificial intelligence. To this end, newer, more comprehensive evaluation options have emerged, including an upgraded version of the Hughes Hallucination Evaluation Model leaderboard, the FACTS evaluation framework, and the SimpleQA test set.
8. AI-related election disinformation is spreading around the world, but its impact remains unclear. In 2024, it is present in more than a dozen countries and more than ten social media platforms
A flood of AI-related election disinformation, including during the U.S. presidential election. However, there are still many questions about the measurable impact of this issue, with many arguing that disinformation campaigns have a more far-reaching impact on elections than they actually do.
9. Large language models that have been trained on explicit unbiased will still exhibit implicit bias. Many advanced large language models, including GPT-4 and Claude 3 Sonnet, are in the works
Timekeepers have taken measures to suppress explicit bias, but they still exhibit implicit bias. These models exacerbate racial and gender bias in decision-making by overly associating negative vocabulary with black groups, associating women more with the humanities than with science and engineering (STEM) fields, and favoring men in leadership roles. Although bias evaluation results have improved on standard benchmarks, AI model bias is still a widespread problem.
10. Responsible AI has gained the attention of academic researchers. In 2024, the number of responsible AI papers included in the world's top AI conferences will reach:
1,278, up 28.8% from 992 in 2023 and maintaining a steady annual growth rate since 2019. This upward trend highlights responsible AI
Growing importance in the AI research community. Chapter Highlights (continued)
Table of Contents Chapter 3 Preview Artificial Intelligence in 1642025
Index Report Table of Contents Chapter 3 Preview Artificial Intelligence in 1652025
Index Report
Intelligently analyzes patient data to provide personalized treatment recommendations and demonstrates privacy, transparency
How are issues such as clarity related to it. While Figure 3.1.1 breaks down the dimensions of responsible AI into specific categories to improve clarity of definition, this section categorizes these dimensions into broader categories: privacy and data governance, transparency and explainability, security and security, and equity. Since these topics are often interrelated, the AI Index adopts this structured way of organizing. Chapter 3: Responsible Artificial Intelligence
3.1 Background
3.1 Background
definition
In this section,
The AI Index explores four of the four pillars of responsible AI
Key Dimensions: Privacy & Data Governance, Transparency & Explainability,
Safety & Protection
obstacles, as well as fairness. Other dimensions of responsible AI (e.g. sustainability and
reliability) is discussed elsewhere in this report. Figure 3.1.1 provides the information covered in this section
Definition of the dimensions of responsible AI and illustrate these dimensions with examples
Actual relevance. The Example column analyzes a hypothetical platform that leverages human labor
Responsible AI dimensions, definitions, and examples
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 3.1.1 Privacy
Data governance
Fairness vs. Bias
transparency
Explainability
Safety and Security Responsible Artificial Intelligence Latitude Definition Examples
Individuals' rights to confidentiality, anonymity and security protection of their personal data,
This includes the right to know and consent to the use of data, as well as the organization's responsibility to safeguard those rights when processing personal data.
Data governance Develop policies, processes, and standards to secure data
Quality, access, and permission, which are critical for extensive reuse of data and improved model accuracy.
Develop algorithms that avoid bias or discrimination and take into account all stakeholders
to meet broader standards of social equity.
Publicly share how AI systems work, including data sources
and algorithmic decision-making, as well as how the system is deployed, monitored, and managed, covering both the creation and operational phases.
Understand and elaborate in a way that users and stakeholders can understand
The ability of an AI system to output the logic behind it.
Protect the integrity of AI systems from threats and minimize misuse
and address inherent security risks such as reliability, as well as the monitoring and management of safety-critical AI systems. Patient data is kept strictly confidential, ensuring anonymity and protection. Patients agree whether their data can be used to train a tumor detection system
Establish policies and processes to maintain the quality and effectiveness of public health datasets
Use licensing to clarify data quality processes and usage permits.
Medical AI platforms are designed to avoid bias in treatment recommendations
to ensure equitable access to health care for patients from all populations.
For example, data sources and algorithm design decisions and other development decisions are open and transparent.
The deployment and monitoring of the system is clearly visible to healthcare organizations and regulators.
The AI platform is able to interpret the logical basis of its treatment recommendations so that:
Easy understanding for doctors and patients, increasing trust in AI systems
Implement measures to protect against cyber threats, ensure system reliability, and reduce abuse
Use risk to protect patient health and data security. 3.2 Assess responsible AI
Artificial intelligence security incidents
AI Incident Database (AIID)
Artificial intelligence was recorded
of ethical abuses, such as self-driving cars causing pedestrian deaths, or facial recognition systems causing errors
Apprehend.
Currently, event tracking relies heavily on open media coverage, which means that the actual number of events is likely to be higher
high, because many incidents go unreported. In 2024, discussions will focus on optimizing the definition of a "critical" event
and tracking methods. Although there was no consensus on a standard definition, these discussions highlighted the need for a more detailed report
Necessity to better document AI-related risks and their impacts.
2024
 year, the number of AI-related incidents surged to a record 233, compared to 2023
This represents an increase of 56.4% (Figure 3.2.1). This growth may reflect both the need for artificial intelligenceWith the expansion of the use, also reflected
Increased public awareness of its impact. In addition, increased awareness of AI is likely to prompt more
The incident is escalated to the relevant database. While responsible AI development, deployment and governance in 2024
It has received more attention, but it is still challenging to fully grasp the overall trend in the field
Combativeness. This section covers relevant indicators that reflect the state of responsible AI development at the macro level.
Number of AI security incidents
Table of Contents Chapter 3 Preview Artificial Intelligence in 1662025
Index Report
Number of AI security incidents reported from 2012–2024
Source: AI Incident Database (AIID), 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 3.2.1 1
1. The number of AI security incidents will continue to be updated over time, including corrections to data from past years. As a result, the totals in Figure 3.2.1 may differ from the latest published data from the Artificial Intelligence Security Incident Database (AIID). 233
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024050100150200 Chapter 3: Responsible AI
3.2 Evaluating Responsible AI Catalogue Chapter 3 Preview AI 1672025
Index Report
Source: BBC, 2024
Figure 3.2.2 Instance
The next section details recent AI incidents to shed light on the relationship with humans
Ethical challenges commonly associated with engineering intelligence.
Misidentification in Facial Recognition Technology and Its Impact on Humans (May 25, 2024.)
Day)
A British girl was shopping at a Home Bargains store when she was killed
The Facewatch system incorrectly identifies as a shoplifter. After being publicly charged, frisked, and banned from stores that used the technology, she experienced emotional distress and feared the long-term impact of the incident on her reputation. Facewatch later admitted the mistake but did not comment or publicly apologize. The case reflects the broader issues posed by the increasing adoption of facial recognition systems by retailers and law enforcement agencies. Proponents highlight the technology's potential to reduce crime and enhance public safety, while critics point to the technology's invasion of privacy, misidentification of identities, and the potential to make mass surveillance the norm. Although the accuracy rate is guaranteed, errors still occur. Such incidents also raise questions about how systematic errors can be acknowledged and how victims can be compensated. The Growing Threat of Deepfake Intimate Imagery (June 18, 2024)
Elliston, a 15-year-old high school student in Texas,  Berry (Elliston 
Berry) became a victim of AI-generated harassment. A male classmate took advantage of one
Strip app, made fake nude photos of Berry and his friends, and through social
The media disseminated anonymously. These realistic but fake images were made private by Berry
Instagram account from the photo,
Causing her to feel fear, shame and anxiety
and had an impact on her social and academic life. Although the perpetrators face less
years of judicial penalties and school disciplinary action, but this case exposes the response to the AI drive
There are gaps in the legal and institutional framework for harassment. Berry and his family then called for reinforcement
As a protective measure, the U.S. Congress has introduced a number of bills aimed at bringing pro to non-consensual sharing
The act of ciphering images (real or fake) is criminalized and requires social media platforms to perform it
line deletion obligation.  Some countries, including Australia, have passed relevant laws.
Source: Restless Network, 2021
Figure 3.2.3
Chapter 3: Responsible Artificial Intelligence
3.2 Evaluating Responsible AI Catalogue Chapter 3 Preview of AI in 1682025
Index Report
Source: Business Insider, 2024
Figure 3.2.4
Source: Business Insider, 2024Figure 3.2.5 Incident of AI chatbot stealing the identity of the deceased (7 October 2024)
Jennifer, a high school student who was murdered by her ex-boyfriend in 2006, Ann · Crescent
(Jennifer Ann Crecente), whose name and image have recently popped up
Character. Artificial intelligence platform of artificial intelligence chatbots, once again raised
Public concern. Her father, Drew Brown, Drew Crecente discovered through Google alerts that the bot was created by an anonymous user and not only used Jennifer's graduation photo, but also described her as "a knowledgeable and friendly AI character". As an advocate for teen dating violence, Crescent expressed anger and pain over her daughter's unauthorized theft, calling it a "secondary trauma." Although the chatbot has been removed for violating Character.AI's counterfeiting policy, the incident has exposed significant loopholes in the regulation of AI platforms, as well as ethical dilemmas raised by the digital resurrection of the deceased. Chatbot accused of causing teen suicide (October 23, 2024)
A lawsuit against Character.AI has sparked a conversation about artificial intelligence
Concerns about the role of robots in a mental health crisis. The case involved a 14-year-old boy, Severe M. Sewell Setzer III, who committed suicide after a lengthy interaction with a chatbot character. The chatbot reportedly provides advice that is harmful rather than providing support or a critical resource. The lawsuit alleges that the chatbot, while designed to have in-depth personal conversations with users, lacked proper security measures to prevent dangerous interactions and encouraged Sewell to end his life. Figure 3.2.5 shows a screenshot of the conversation between Sewell and "Dany" (the chatbot character) on the day of his suicide. The case highlights the ethical challenges of AI-driven companionship and the potential risks of deploying conversational AI in the absence of adequate regulation. While AI chatbots can provide emotional support, critics warn that without safeguards, they may inadvertently reinforce harmful behaviors or fail to intervene in a timely manner when users are in a difficult situation.
Chapter 3: Responsible Artificial Intelligence
3.2 Evaluating Responsible AI Catalogue Chapter 3 Preview AI 1692025
Index Report
There is limited application of responsible AI benchmarks
Last year's AI Index was one of the first to highlight AI safety and accountability
Estimating one of the paper statistics that lacks a standard benchmark for comparison. Although the main model developer one
The same common competency benchmark covering math, programming, and language skills is used to test its flagship models, but there is no such standard for safe and responsible AI assessments. Standardized evaluation kits are important for direct comparison of different models. As businesses and governments increasingly deploy generative AI capabilities in real-world applications, this is especially important for safety and accountability functions. This year's AI Index report confirms that this trend is continuing. fig
3.2.6 lists several generic competency benchmarks for evaluating mainstream models in 2024
(e.g. MMLU, GPQA Diamond, and MATH) and Figure 3.2.7 illustrates this
Key safety and responsible AI benchmarks, and label whether leading developers use these benchmarks for their models. As was the case last year, there is a clear consensus among model developers on the choice of a common competency benchmark, but there is still no agreement on a responsible AI benchmark.
Comparison of generic capability benchmarks of mainstream base models
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Benchmark comparison of security and RAI from mainstream base models
Source: Artificial Intelligence Index 2025 | Chart: 2025 Artificial Intelligence Index Report
B
B
Q
H
a
r
m
B
e
n
c
h
C
y
b
e
n
c
h
S
i
m
p
l
e
Q
A
T
o
x
i
c
W
i
l
d
C
h
a
t
S
t
r
o
n
g
R
E
J
E
C
T
W
MD
P
 
b
e
n
c
h
m
a
r
k
M
a
k
e
Me
P
a
y
M
a
k
e
Me
S
a
y
o
1
G
P
T
-
4
.
5
D
e
e
p
S
e
e
k
-
R
1
G
e
m
i
n
i
 
2
.
5
G
r
o
k
-
2
C
l
a
u
d
e
 
3
.
7
S
o
n
n
e
t
Ll
a
m
a
 
3
.
3
MMLU,
MMLU-Pro or
MMMLU
G
P
Q
A
 
o
r
G
P
Q
A
-
D
i
a
m
o
n
d
MA
T
H
-
5
0
0
A
I
ME
 
20
2
4
S
W
E
-
b
e
n
c
h
v
e
r
i
e
d
MMMU
3
3
3
Figure 3.2.6
Figure 3.2.7 Chapter 3: Responsible AI
3.2 Assess responsible AI
Competency benchmarks
Catalogue of Benchmarks for Responsible AI Chapter 3 Preview of AI in 1702025
Index Report
This doesn't mean that model developers ignore security testing – in fact, yes
Multiple companies will conduct these assessments – but as is the case with most models,
This kind of evaluation often adopts internal standards and lacks unified specifications, which makes it difficult to compare the security performance of models horizontally. External evaluation systems also face challenges: third-party organizations such as Gryphon, Apollo Research, and METR have only evaluated some of the models, and their evaluation results have not yet been widely accepted by the AI community.
Factuality and truthfulness
Despite significant progress, large language models still face factual errors and
Hallucinations often generate information that seems credible but is actually false. Typical examples in the real world include court documents filed by lawyers that contain citations that are concocted by large language model systems. Therefore, it is important to monitor the incidence of hallucination problems in large language models. However, some of the benchmarks highlighted in previous editions of the AI Index, such as HaluEval and TruthfulQA, have not yet been widely adopted in the AI community. In 2024, a number of new benchmarks were introduced to better assess the realism of these models. Hughes Hallucination Evaluation (HHEM)
The Hughes Illusion Assessment Model (HHEM) leaderboard is developed by Vectara
to assess how often large language models have hallucinatory issues when summarizing documents. In this benchmark, the model generates summaries from documents in the CNN and the Daily Mail corpus. Then, these summaries are evaluated for hallucination questions. HHEM is one of the most comprehensive and up-to-date assessment methods for assessing the hallucinatory tendencies of AI systems. The latest models, including Llama 3, Claude 3.5 and Gemini 2.0, have made it to the leaderboard.
Currently, GLM-4-9b-Chat and Gemini-2.0-Flash-Exp are available in mode
The type tied for the lowest hallucination rate at 1.3%. This was followed by o1-mini and GPT-4o, with hallucination rates of 1.4% and 1.5%, respectively (Figure 3.2.8).
HHEM: Hallucination Rate
Source: HHEM leaderboard, 2025 | Chart: 2025 Artificial Intelligence Index Report
Figure 3.2.82.90%2.80%
2.60%2.50% 2.50%2.40% 2.40%
1.90%1.80%1.70% 1.70%
1.50%1.40%1.30% 1.30%
ai21labs/AI21-Jamba-1.5-Mini Qwen/Qwen2.5-7B-Instruct IIntel/neural-chat-7b-v3-3 Microsoft/Orca-2-13b Microsoft/Phi-3.5-MoE-instruct openai/o1 deepseek/deepseek-chat openai/GPT-3.5-Turbo openai/GPT-4 openai/GPT-4o-mini openai/GPT-4-Turbo openai/GPT-4o openai/o1-mini gemini-2.0-ftash-exp THUDM/glm-4-9b-chat0.00%0.50%1.00%1.50%2.00%2.50%3.00%Hallucination Rate Chapter 3: Responsible Artificial Intelligence
3.2 Assessing Responsible AI Figure 3.2.10 Factual Score
model
Table of Contents Chapter 3 Preview Artificial Intelligence in 1712025
Index Report
HHEM leaderboard, while effective, has a significant impact on the performance of the model
Raised, seems to be close to saturation. In addition, it focuses on news articles and summaries
service, so comprehensiveness is limited. As AI capabilities continue to evolve, there is a growing need to be able to evaluate factual benchmarks in a more challenging and diverse context.
This year, some new benchmarks were takenIntroduced, which is used to evaluate large language modules
Facts and truthfulness, including Google's FACTS Grounding. This benchmark evaluates the performance of large language models in generating responses that are both accurate and detailed to provide satisfactory answers. As part of FACTS, the model must write a long-form response to a user request based on a contextual document (Figure 3.2.9). These documents cover a wide range of fields, including finance, technology, retail, medicine, and law. FACTS is more complex than HHEM and requires the model to perform tasks such as summarization, question and answer generation, fact-checking, and explanations. The assessment was done by a set of AI models, including Gemini 1.5 Pro, GPT-4o, and Claude 3.5 Sonnet, who gave a factual score to each response. Currently, the Gemini-2.0-Flash-Exp model holds the highest record with a base score of 83.6% (Figure 3.2.10). Focus:
Introducing FACTS, SimpleQA, and stricter factual benchmarks
Stable Video Diffusion stabilizes the generated content
Source: Google, 2024
Figure 3.2.9
FACTS: Score of facts
Source: FACTS leaderboard, 2025 | Chart: Artificial Intelligence Index Report 2025
61.70% 62.00% 71.00% 74.20% 78.80% 79.40% 80.00% 82.90% 83.60% Chapter 3: Responsible Artificial Intelligence
3.2 Evaluating Responsible AI Catalogue Chapter 3 Preview 1722025 AI
Chapter 3 of the Index Report: Responsible AI
3.2 Assess responsible AI
Figure 3.2.12 Evaluating the factuality of large language models is challenging because of the redundancy they generate
Long responses often contain multiple factual claims, making it difficult to verify the accuracy of each one. for
That's why OpenAI researchers have introduced SimpleQA, a new benchmark for evaluating the factual nature of large language models. The benchmark consists of more than 4,000 short fact-finding questions that are designed to be straightforward, easy to score, and challenging, covering a variety of fields such as history, technology, art, and geography (Figure 3.2.11).
SimpleQA presents significant factual facts for leading large language models
Challenge. The top-performing model was OpenAI's o1-preview, which only successfully answered 42.7% of the questions (Figure 3.2.12). The researchers also evaluated whether the models would attempt to answer certain questions, and found that some models (such as the Claude-3 series) did not respond to 75% of the prompts.
In the model that tries to answer a question, o1-preview says in "Trying to answer and
correct- given-attempted" was scored 47.0% in the prompt, followed by Claude 3.5 Sonnet at 44.5%. As expected, the larger model performed better in the benchmark. Focus:
Rollout of FACTS, SimpleQA, and more stringent factual benchmarks (continued)
SimpleQA sample questions
Source: OpenAI, 2024
Figure 3.2.11
SimpleQA: The proportion of questions answered
Source: Wei et al., 2024 | Chart: Artificial Intelligence Index Report 2025
Percentage of questions answered
model
5.10% 5.70%23.50%28.90%
8.60%38.20%
8.10%42.70%75.30% 75.00%
39.60%
35.00%
0.90% 1.00%28.50%
9.20%20.60%22.90%38.80%44.50%
8.70%38.00%
11.30%47.00%
Claude-3-haiku
(2024-03-07) Claude-3-sonnet
(2024-02-29) Claude-3-opus
(2024-02-29) Claude-3.5-sonnet
(2024-06-20) GPT-4o-mini GPT-4o OpenAI o1-mini OpenAI o1-preview0%20%40%60%80%100%Tried to answer and answered correctly Not tried Correct Table of Contents Chapter 3 Preview Artificial intelligence in 1732025
Index Report
Figure 3.3.1 Distribution of leading sectors of enterprise AI governance in 2024
Source: McKinsey & Company Survey, 2024 | Chart: AI Index 2025 Report 3.3 Responsible AI in Organizations and Enterprises
With the widespread deployment of artificial intelligence systems in practical application scenarios, it is important to understand enterprises
How the industry responds to responsible artificial intelligence (RAI) is becoming increasingly important. For in-depth exploration
To address this topic, the AI Index partnered with McKinsey & Company to conduct a survey in 2024 to assess the extent to which companies integrate RAI into their operations. The survey defines RAI as a framework for ensuring that AI is developed and deployed in a safe, credible, and ethical manner. It evaluates RAI by the key dimensions outlined in the AI Index: Privacy & Data Governance, Fairness, Transparency & Explainability, and Safety & Security. The survey surveyed business leaders from more than 30 countries with a total sample size of 759 people. Figure 3.3.1 illustrates the organization's understanding of which department in your organization is primarily responsible for people
intelligent governance". It is worth noting that no single sector dominates. The most common response was information security (cybersecurity/fraud/privacy) at 21%, followed by data and analytics at 17%. In addition, 14% of respondents said their organizations have dedicated AI governance roles, indicating that AI governance is increasingly recognized as a separate and critical function within their organizations.
2. The "Unknown" option is not shown in this visualization. 1%2%4%7%9%10%13%14%17%21%
0% 2% 4% 6% 8% 10% 12% 14% 16% 18% 20% 22% Information Security
(Cybersecurity/Anti-Fraud/Privacy Protection)
Data & Analytics
 Full-time AI governance
Job Risk/Compliance
Engineering Department
There is no clear lead department
Legal Department
Internal Audit/Ethics
customer service
other 
Percentage of respondents Chapter 3: Responsible AI
3.3 Responsible AI in Organizations & Enterprises Catalog Chapter 3 Preview Artificial Intelligence in 1742025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Responsible AI investment by corporate revenue size in 2024
Source: McKinsey & Company Survey, 2024 | Chart: The 2025 AI Index Report survey also asked organizations about their projected investments in implementing RAI over the next year
capital, including capital expenditures and operating expenses. Examples of such investments include development or acquisition
Buy technical systems that comply with RAI principles, as well as legal or professional services related to RAI. The answer to this question is shown in Figure 3.3.2, categorized by the size of the company's revenue.
Large corporations – especially those with more than $10 billion in annual revenue –
The total investment in RAI is higher. Notably, 27% of businesses with annual revenues between $10 billion and $30 billion have annual revenues of more than $30 billion
Twenty-one percent of Meta's businesses have invested between $10 million and $25 million in RAI
Dollar. These findings suggest that large enterprises are more inclined to make RAI a strategic priority
and make a higher absolute investment. Smaller organizations invest less in RAI, but
Many organizations still report investments that account for a high percentage of revenue.
Figure 3.3.2 Respondents' share of revenue (USD) 68%
48%
40%
24%
25%25%
30%
32%
30%
29%6%
15%
18%
27%
21%7%
10%
19%
25%
0% 20% 40% 60% 80% 100% 30B+10B– 30B1B– 10B100M–1B<100M1– 5M 5– 10M 10– 25M 25– 50M Table of Contents Chapter 3 Preview Artificial Intelligence in 1752025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Comparison of AI risk-related cognition and active mitigation in 2024
Source: McKinsey & Company Survey, 2024 | Chart: Figure 3.3.3 of the 2025 AI Index Report shows what organizations consider relevant and are actively responding to
Responsible AI risks associated with industrial intelligence. Cybersecurity (66%), compliance
Regulation (63%) and personal privacy (60%) were cited as top concerns, however, mitigation measures were consistently inadequate. Notably, within each risk category, fewer organizations took proactive steps to mitigate risks than those who considered those risks to be relevant. The gap is particularly pronounced in terms of IP infringement (57% relevant, 38% mitigated) and organizational reputation (45% relevant, 29% mitigated). Risks related to explainability (40%) and fairness (34%) were chosen by a smaller proportion of respondents, and mitigation rates dropped further to 31% and 26%.
Figure 3.3.3 Types of AI Risks
Percentage of respondents Percentage of respondents Cybersecurity
Compliance with regulatory information on personal privacy inaccuracies
Intellectual Property Infringement
Organizational reputation explainability
Fairness
Labor substitution
Environmental impacts: national security, political stability, physical security
6%7%11%16%20%34%40%45%57%60%60%63%66%
0% 20% 40% 60% 80% 100%55%
38%53%
46%50%
31%
26%
12%29%
4%9%
3%
4%
0% 20% 40% 60% 80% 100% think it is related to artificial intelligence Active Mitigation Catalogue Chapter 3 Preview Artificial Intelligence in 1762025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Number of AI incidents
Percentage of respondents: Percentage of respondents: Percentage of organizations that have experienced an AI event in 2024
Source: McKinsey & Company Survey, 2024 | Chart: Artificial Intelligence Index Report 2025
Number of AI incidents reported by the organization in 2024
Source: McKinsey & Company Survey, 2024 | Chart: Figures 3.3.4 and 3.3.5 of the 2025 AI Index report show data on the number of AI incidents reported by organizations over the past year. Only 8% of the organizations surveyed reported having a relationship with a person
Events related to AI. Of the affected organizations, the majority (42%) reported experiencing only one or two incidents.
Figure 3.3.4 3
Figure 3.3.5
3. Figure 3.3.4 uses the OECD definition of AI events. According to the OECD, an AI incident is an event, situation, or series of events in which the development, use, or failure of one or more AI systems directly or indirectly results in any of the following harms: (a) Yes
injury or damage to the health of an individual or group; (b) Disruption to the management or operation of critical infrastructure; (c) violates human rights or violates legal obligations designed to protect fundamental rights, labour rights or intellectual property rights; or (d) cause damage to property, the community, or the environment. 8% 89% 3%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% Yes No unclear
5%11%13%30%42%
0% 5% 10% 15% 20% 25% 30% 35% 40% Unknown10+6– 93– 51– 2Table of Contents Chapter 3 Preview 1772025 Artificial Intelligence
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
When asked about the impact of RAI policies on their organizations, 42% of respondents reported improvements in business operations, such as increasing efficiency and reducing costs, compared to 34% of respondents
Customer trust has improved (Figure 3.3.6). Only 17% of organizations believe these policies have not had a significant impact.
The Impact of Responsible AI Policies on Organizations, 2024
Source: McKinsey & Company Survey, 2024 | Chart: Artificial Intelligence Index Report 2025
4. D Respondent data for selecting "not yet implemented" is not included. Percentages are based only on respondents who chose at least one other answer. The "None" option is not displayed. Percentage of respondents
Figure 3.3.6 4 Improvement of business operations
(e.g. efficiency improvement, cost reduction)
Increased customer trust
Brand reputation enhanced
Improvement in business results (e.g., revenue growth)
The number of security incidents decreased
Listing events are shortened
There was no significant effect
12% faster time to market17%18%22%28%29%34%42%
0% 5% 10% 15% 20% 25% 30% 35% 40% Table of Contents Chapter 3 Preview Artificial Intelligence in 1782025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
5 "Unknown" replies are not displayed in this visual table. Respondents accounted for the main barriers to implementing responsible AI measures in 2024
Source: McKinsey & Company Survey, 2024 | Chart: Artificial Intelligence Index Report 2025
Figure 3.3.7 5 Figure 3.3.7 shows the main barriers that organizations face in implementing RAI measures.
Respondents cited knowledge and training gaps (51 percent) and resource or budget constraints as the main ones
(45%) and regulatory uncertainty (40%) are the main challenges. Encouragingly, only 16% of respondents cited a lack of executive buy-in as an obstacle, suggesting leadership
support is not a major barrier to RAI adoption.
Knowledge and training barriers
Resource or budget constraints
management uncertainty
Technical limitations and organizational resistance
Lack of high-level support
not
other
2%3%16%22%32%40%45%51%
0% 5% 10% 15% 20% 25% 30% 35% 40% 45% 50% Table of Contents Chapter 3 Preview 1792025 Artificial Intelligence
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Percentage of organizations affected by AI regulations in responsible AI decision-making
Source: McKinsey & Company Survey, 2024 | Chart: Artificial Intelligence Index Report 2025
Figure 3.3.8 Figure 3.3.8 shows that AI decision-making is subject to specific AI regulations
Proportion of tissues affected. Of the organizations surveyed, 65% said they were affected by the European Union's
General Data Protection Regulation (GDPR), while 41% of organizations cited the European Union's Artificial Intelligence Act. A smaller percentage of organizations said they were influenced by the Organisation for Economic Co-operation and Development's (OECD) principles on AI (21%) and President Biden's executive order on AI.
EU General Data Protection Regulation (GDPR)
EU Artificial Intelligence Act
OECD Principles of Artificial Intelligence
U.S. President's Executive Order on Artificial Intelligence
None of the above / no change 17% 19% 21% 41% 65%
0% 5% 10% 15% 20% 25% 30% 35% 40% 45% 50% 55% 60% 65% Table of Contents Chapter 3 Preview Artificial Intelligence in 1802025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Percentage of respondents
Figure 3.3.9 Adversarial Attacks
Adversarial attacks
Non-predictive decision-making
Model bias
Performance Failure Focus:
Portrait view
   The Stanford University research team, in collaboration with Accenture, launched a conference in 2025
 Year 1 
The second round of the Global Survey on the State of Responsible AI was held in February
The round of investigation will be launched in 2024). The survey covered 20 countries,19 
1,500 organizations across industries, each with annual revenues of more than $500 million, aims to:
Analyze and compare 10 challenges to the adoption of RAI principles and practices in organizations
The trend of RAI activity over time for a dimension. 6 As a result of the survey  
Implemented in both 2024 and 2025, the data reflects an organization's understanding of RAI 
The evolution of adoption attitudes.   Figure 3.3.9 illustrates the AI reported by the surveyed organizations over the past two years
The type of event that can be correlated. The most prominent problem is adversarial attacks (56%) and
Privacy violations (55%) highlight the urgent need for enterprises to strengthen the security of AI systems
Integrity and data governance. In addition, 51% of respondents reported unexpected decisions
policy, 47% mentioned model bias, indicating that many organizations are predicting and controlling for labor
There are difficulties with intelligent behaviour – a challenge that is especially acute in high-risk environments
High. The type of event
6. The survey methodology is detailed in the 2024 research report by Reuel et al. 46%47%51%55%56%
0% 10% 20% 30% 40% 50% Types of AI incidents reported by the organization in the last two years
Source: Accenture/Stanford Joint Survey, 2025 | Chart: Table of Contents of the 2025 AI Index Report Chapter 3 Preview Artificial Intelligence in 1812025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Percentage of respondents
Figure 3.3.10 Key points:
Portrait view (continued)
  Depending on the strategic differences in AI adoption (e.g., development, deployment) of the enterprise
Or make
with generative / non-generative AI), respondents need to assess 14 
The degree to which class risks are relevant to their organization (Figure 3.3.10). 7 Surveys show that near
Over the years, there has been a significant increase in the focus on specific risks – most notably financially
2024-2025 Comparison of Responsible AI Risks Focused on by Organizations
Source: Accenture/Stanford Joint Survey, 2025 | Chart: 2025 AI Index reports business risk (+38 percentage points), brand and reputation risk (+16), privacy
Data-related risk (+15) and reliability risk (+14). opposite
The urgency of social risk (-7) and socio-environmental impact risk (-8) has decreased
Fall. Type of risk
7. The survey methodology is detailed in the 2024 research report of Reuel et al. Privacy and Data-Related Risks
(e.g. anonymized data re-identification, data breaches,
Use of data without consent)
Reliability risks
(e.g. output errors, hallucinations)
Compliance & Legal Risks
(e.g. intellectual property or copyright infringement)
Security Risks
(e.g. adversarial attacks, model stealing)
Financial risk
(e.g., insufficient return on AI investment,
AI-related financial losses)
Brand/reputational risk
(e.g. by those related to artificial intelligence.)
The damage caused to the brand by the incident)
Interpersonal interaction risks (e.g., users abusing AI to generate fakes.)
Information or misinformation, users are overly reliant on AI models/systems
system, or physical/psychological harm as a result of the use of the model/system)
Diversity and non-discrimination risks
(e.g., equity issues, toxicity, discrimination, and stereotypes.)
reproduction)
Customer Risk
(e.g., loss of trust, market share, or customer satisfaction)
Social risk
(e.g., threats to political stability, national security issues)
Socio-environmental risks
(e.g., high carbon footprint systems, regional pollution) 30% 33% 34% 29% 35% 26% 12% 47% 29% 45% 51%
22%26%32%35%40%42%50%52%56%59%65%
0% 10% 20% 30% 40% 50% 60%2025
Artificial intelligence in 20242025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Responsible AI maturity distribution in the organizational domain by 2024 and 2025
Source: Accenture/Stanford Joint Survey, 2025 | Chart: AI Index 2025 reports the distribution of responsible AI maturity in operational areas for 2024 and 2025
Source: Accenture/Stanford Joint Survey, 2025 | Chart: The 2025 AI Index reports organizational and operational maturity models
Source: Reuel et al., 2024
Maturity Score Chart 3.3.11 Key Points:
Portrait view
The definition of organizational and operational maturity is shown in Figure 3.3.11. 2024 to
Over the course of 2025, there will be a significant increase in the maturity of responsible AI at the organizational level— 
—More organizations received CEO support for RAI initiatives and improved workforce
Intelligent risk identification, monitoring and control capabilities, which mark the development of RAI artificial intelligence
Awareness of strategic importance has been further strengthened (Figure 3.3.12). 8 In contrast, poly
Focus on system-level practical safeguards (e.g., bias mitigation, adversarial testing, and environmental impacts
assessments, etc.) (Figure 3.3.13). This
The gap reveals a disconnect between the commitment of high-level RAIs and the implementation of technology
Organizations continue to increase their willingness and resource allocation to incorporate RAI into their processes and policies
, but how to translate these intentions into effective system-level practices still faces challenges
War.
Percentage of the organization
Percentage of the organization
8. Organizational and operational RAI maturity is calculated based on the methodology defined in Reuel et al. (2024).
0 25 50 75 1000%2%4%6%8%10%12%14%16%18%
2025
2024
0 25 50 75 1000%2%4%6%8%10%12%14%2025
2024
Table of Contents Chapter 3 Preview 182 Figure 3.3.13 Figure 3.3.12 Maturity Score Table of Contents Chapter 3 Preview 183 Organizational Attitudes and Beliefs towards Responsible AI
Source: Accenture/Stanford Joint Survey, 2025 | Chart: Artificial Intelligence Index 2025 report
Figure 3.3.14 illustrates the ongoing debates and unresolved issues among the experts. The only obvious example
There is a trade-off between security and innovation: 64% of respondents prefer a security-first approach, but 58% are exploring minimally supervised agents, which can pose significant risks, especially given that RAI is still limited in its immaturity. Focus:
Portrait view (continued)
Respondents were also asked about their organization's attitudes and philosophies towards RAI, including:
Perceptions of risk ownership, model preference, and policy stance (Figure 3.3.14). In almost all of the statements, the responses were fairly balanced, even on high-profile issues such as the safety of open-ended vs. closed-weight models, and whether the responsibility for risk mitigation lies with the model provider or the user. This wide distribution indicates a lack of a unified strategic direction for the industry in terms of RAI, which may reflect AI in 2025
Chapter 3 of the Index Report: Responsible AI
3.3 Responsible AI in Organizations and Enterprises
Respondents' proportion of respondents "innovate first, then supervise"
/"Safety first, preventing potential future risks"
"Responsible AI is a compliance issue"/"Responsible."
Ren's AI is a value driver to unlock potential"
"RAI risk is industry-specific"
/"RAI risk is not industry-agnostic"
"GenAI risk is the responsibility of the underlying model provider
"/"GenAI risk is the responsibility of GenAI users"
"Closed-source models are more secure" / "Open-source models are more secure"
"Actively Exploring Minimally Supervised AI Agents" / "
The current agent is too risky in large-scale deployments" 13%
17%
18%
20%
18%
21%23%
28%
37%
33%
32%
37%30%
33%
30%
31%
29%
29%34%
21%
16%
16%
21%
13%
0% 20% 40% 60% 80% 100% has some agreement with the second statement
Fully consistent with the second statement, fully consistent with the first, with some conformity with the first table of contents, Chapter 3 Preview, 1842025 Artificial Intelligence
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
Figure 3.4.13.4 Responsible AI in academia
This year, the AI Index analyzes six of the top AI academic conferences
Number of AI-related papers accepted on : AAAI, AIES,
FAccT, ICML, ICLR, and NeurIPS. Although these conferences do not represent all AI research globally, they provide insight into the publication trends in AI academia. This section presents the total statistics of AI paper publications
Trends will be broken down by RAI sub-area in subsequent chapters. In order to identify RAIs 
Papers, the AI Index screens papers that contain specific RAI keywords.
9 Overall Trend: The number of RI papers accepted at top AI conferences increased by 28.8%, from 992 in 2023 to 1,278 in 2024 (Figure 3.4.1).
9. The complete methodological description of this method is detailed in the Appendix.
 Number of RAI papers
3294896446969921,278
2019 2020 2021 2022 2023 202402004006008001,0001,2002019-2024 Statistics on the number of responsible AI papers included in major AI conferences
Source: Artificial Intelligence Index 2025 | Chart: Table of Contents of the 2025 AI Index Report Chapter 3 Preview Artificial Intelligence in 1852025
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
Figure 3.4.2 Relatively speaking, the conference with the highest proportion of RAI papers in total submissions is FAccT
(69.14%) and AIES (63.33%) (Figure 3.4.2). This is in line with their emphasis
To: FAccT is committed to fairness, accountability, and accountabilityTransparency, while AIES focuses on AI ethics and society. At NeurIPS, the percentage dropped from 13.8% in 2023
9.0% by 2024, while at ICML, it rose from 3.4% to 8.2% over the same period. RAI Papers (% of Total) Statistics on the number of responsible AI papers included in major AI conferences from 2019 to 2024
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%70%
7 .56% , ICLR8.24%, ICML9.02% , NeurIPS13.36% , AAAI63.33%, AIES69.14%, FAccT Table of Contents Chapter 3 Preview Artificial Intelligence in 1862025
Index Report
Figure 3.4.5Figure 3.4.3 Figure 3.4.4 RAI has become an increasingly important area of academic research. Since 2019
Since then, the geographical distribution of RAI papers has remained relatively stable, with the United States accounting for the highest proportion (3,158 papers), followed by China (1,100 papers) and the United Kingdom (485 papers).
Number of RAI papers Chapter 3: Responsible AI
3.4 Responsible AI in academia
Figures 3.4.3 to 3.4.5 analyze the geographic attribution of RAI papers, with a focus on them
the origin of these papers. In 2024, the United States will rank first in the number of RAI paper submissions
First, with 669 articles, followed by China (268 articles) and Germany (80 articles). Primarily
2024 by Geographical Distribution of Major Artificial Intelligence Conferences on Responsible Artificial Intelligence
(RAI) Number of papers included
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index 2025 Report 2019-2024 by Major Geography of Key AI Conference Responsible Persons
Number of Published Papers in Engineering Intelligence (RAI).
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
2019-2024 by geographical distribution of the total number of responsible AI papers in major AI conferences
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025 2019 2020 2021 2022 2023 2024100200300400500600700
669, United States
298, Europe
268, China, United States
China, Germany, Great Britain
Canada
Hong Kong, India
Singapore
Japan, Netherlands
3136394246556780268669
0 200 400 600
1– 10
11– 50
51– 150
151– 500
501– 2,000
2,001– 3,200 Table of Contents Chapter 3 Preview Artificial Intelligence in 1872025
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
Subject area
This section analyzes trends in RAI publication statistics in key topic areas, packages
These include privacy and data governance, fairness, transparency and explainability, and security and accountability
By sex. Over the past year, the number of submissions for papers related to privacy and data governance has dropped by 14.5% at major AI conferences (Figure 3.4.6). Since 2019, this
One number has grown nearly fivefold.
10. These figures may underestimate the total number of AI privacy research papers, as some papers were published at privacy-focused AI conferences, such as the 46th IEEE Symposium on Security and Privacy. From 2019 to 2024, the number of papers in the field of AI privacy and data governance in major AI academic conferences
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
Figure 3.4.6 10 Number of papers in the field of AI privacy and data governance
3297105
48160
711217
154321
2115
1318
36
39124150
92213
186
2019 2020 2021 2022 2023 2024050100150200NeurIPS ICML ICLR FAccT AIES AAAI Table of Contents Chapter 3 Preview Artificial Intelligence in 1882025
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
In 2024, the number of papers related to fairness and bias accepted at major AI academic conferences will grow significantly, reaching 408 – about the number in 2023
twice as much (Figure 3.4.7). This growth underscores the growing scholarly focus of researchers on issues of fairness and bias.
The number of papers on AI fairness and bias in major AI academic conferences from 2019 to 2024
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
Figure 3.4.7 Number of AI Fairness and Bias Papers
29 34468344
2750
3639756583
273348
27382936100
5798150169212408
2019 2020 2021 2022 2023 2024050100150200250300350400NeurIPS ICML ICLR FAccT AIES AAAI Table of Contents Chapter 3 Preview Artificial Intelligence in 1892025
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
Since 2019, the number of papers submitted to major academic conferences on transparency and explainability has quadrupled. In 2024, including AAAI, FAccT, AIES,
A total of 355 papers related to transparency and explainability were presented at academic conferences, including ICML, ICLR, and NeurIPS (Figure 3.4.8).
2019-2024 Number of papers on AI transparency and explainability in major AI academic conferences
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
Figure 3.4.8 Number of papers on AI transparency and explainability
39546389183
832444
54
302556
354246
5035
484454
98
89134189231393
355
2019 2020 2021 2022 2023 2024050100150200250300350400 NeurIPS ICML ICLR FAccT AIES AAAI Table of Contents Chapter 3 Preview Artificial Intelligence in 1902025
Chapter 3 of the Index Report: Responsible AI
3.4 Responsible AI in academia
The number of security-related papers presented to selected AI conferences has grown dramatically, almost doubling in the past year – from 276 to 521 (Figure 3.4.9). this
The growth reflects the growing importance of safety and security as a core area of concern for AI researchers.
The number of papers included in the field of security in major AI academic conferences from 2019 to 2024
Source: Artificial Intelligence Index 2025 | Chart: Artificial Intelligence Index Report 2025
Figure 3.4.9 Number of AI Security Papers
71
43152
88177
333741100
32
41517779
33657564
78120
162168215285276521
2019 2020 2021 2022 2023 20240100200300400500NeurIPS ICML ICLR FAccT AIES AAAI3.5 Responsible AI Policy Making
Committed to building a global framework for responsible and ethical AI, marking the beginning of the orphan
The shift from national action to coordinated global governance. 11 Despite national AI strategies and regulatory options in 2023 and early 2024
Proliferation, but the significant trend for 2024 is the global convergence in the field of AI governance
to be strengthened, particularly with regard to the principles of RAI legislation. International organizations and multilateral agreements are positive
A major milestone in responsible AI policy
Source: Artificial Intelligence Index 2025
International Artificial Intelligence
Security Institute Network
Arab League, May 2024
May 2024
June 2024 
July 2024
September 2024
October 2024
October 2024
November 2024
February 2025 OECD
Council of Europe
European Union
African Union
UN
G7
ASEAN and the United States Global
Europe
Europe
Africa
globe
globe
Asia and the United States
globe
The Arab OECD has updated its AI principles and refined its framework to reflect the latest developments in AI governance. These principles emphasize, build
AI systems need to consider inclusive growth, transparency and explainability, as well as respect for the rule of law, human rights and democratic values.
The African Union has launched the African Continental Artificial Intelligence Strategy (AU AI Strategy), which outlines AI development, ethics and governance across the continent
A unified vision of science. The strategy emphasizes the ethical, responsible, and equitable development of AI in Africa. The European Union has passed the AI Act, the first of its kind for a major economy in the world
Comprehensive AI regulatory framework. The bill classifies AI by risk, regulates it accordingly, and ensures that the provider or developer of high-risk systems has the primary obligation. The Council of Europe has adopted a legally binding treaty on AI (Council of Europe Framework on AI and Human Rights, Democracy and the Rule of Law
Convention (The Council of Europe Framework Convention on Artificial Intelligence and Human Rights, Democracy, and the Rule of Law). The treaty aims to ensure that activities within the life cycle of AI systems are fully compliant with human rights, democracy and the rule of law.
The United Nations has updated its Governing AI for Humanity report (the United Nations Advisory Body on Artificial Intelligence) outlining the establishment of global AI
Efforts of governance mechanisms. The report recommends the development of a blueprint to address AI-related risks and calls for collaboration between national and international standards organizations, technology companies, civil society, and policymakers on AI standards.
The G7 Digital Competition Communiqué (G7 AI Cooperation) reaffirms its commitment to a fair and open AI market, emphasizing a harmonized regulatory approach
Necessity. Previous discussions have focused on competition and the regulatory challenges posed by the rapid development of AI.
Following the 12th ASEAN-US Summit, ASEAN-US leaders issued a statement on promoting safe, secure, and trustworthy AI
Bright. They pledged to collaborate on the development of an international AI governance framework and standards to advance these goals.
The first international network of AI security institutes was established, bringing together nine countries and the European Union to formally launch global AI security cooperation. should
The network unites technology organizations working to advance AI security, helping governments and society understand the risks of advanced AI systems and propose solutions.
Arab Dialogue Circle event "Artificial Intelligence in the Arab World: Innovative Applications and Ethical Challenges" at the Arab League
Headquarters launched, focusing on AI innovation with a strong focus on ethical considerations. Time Frame Content Overview Parties
Table of Contents Chapter 3 Preview Artificial Intelligence in 1912025
Chapter 3 of the Index Report: Responsible AI
3.5 Responsible AI policymaking
11. While AI policymaking is the focus of Chapter 6: Policy, the AI Index highlights here the major policymaking events related to RAI as they have recently become significant. Table of Contents Chapter 3 Preview Artificial Intelligence in 1922025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
3.6 Privacy and Data Governance
The definition of privacy is complex and varies from case to case. For the purposes of this report
use, the AI Index defines privacy as the confidentiality of an individual's personal data,
The right to anonymity and protection, as well as the individual's right to consent and be informed about whether and how the data is used. Privacy also encompasses the responsibility of the organization to ensure these rights when collecting, storing or using personal data (directly or indirectly). In addition, individuals should have the right to correct their sensitive information if an organization or government misrepresents personal information. In the field of artificial intelligence, this involves ensuring that personal data is processed in a manner that respects the privacy rights of individuals, for example, taking measures to protect sensitive information from leakage, and ensuring that data collection and processing are transparent and in compliance with privacy laws such as the General Data Protection Regulation.
Data governance, on the other hand, refers to the groups that an organization creates to ensure data in it
Establish policies, processes and standards for the internal and external use of quality, safety and ethics. Data governance policies are OKIt can cover data obtained from external sources. In the field of AI, data governance is important to ensure that the data used to train and operate AI systems is accurate, fair, responsible, and used with consent. This is especially important for sensitive or personally identifiable information (PII). Featured research
This section highlights important recent research on privacy and data management, including:
Research on dataset licensing and attribution audits, as well as research on stricter data licensing agreements.
Large-scale audits of AI dataset licensing and attribution
The current base model is trained on massive amounts of data. One group
The researchers reviewed more than 1,800 text datasets that were widely used to train such models
A large-scale audit was conducted that uncovered systemic issues with dataset licensing and attribution. The researchers found that on popular dataset hosting sites, more than 70% of datasets lacked adequate license information, while 50% of licenses were misclassified, posing a risk to the responsible use of data. Figure 3.6.1 provides a detailed visualization of the researchers' findings. Specifically, they assigned license labels to the dataset in four categories: Commercial, Unspecified, Non-Commercial, and Pure Academic. They then compared their taxonomy with that of popular sources such as GitHub, Papers with Code, and the Hugging Face platform. Many times, the data consent attributes assigned by the data source team are very different from the data licensing attributes published by other organizations. The accuracy of the selected aggregation platform for the classification of dataset permissions
Source: Longpre et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 3.6.1 Number of datasets
1932,030
843
6511,2792,438
0 0 12,404
484828
45367
753,230
05001,0001,5002,0002,5003,000GitHub Hugging Face
License Category: Purely Academic Commercial Non-Commercial Data source not specified Table of Contents of Papers with Code Chapter 3 Preview Artificial Intelligence in 1932025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
12. robots.txt Restriction refers to the rules set in the robots.txt file of a website that instruct web crawlers (such as search engine bots or artificial intelligence data scrapers) to allow or disallow access to which parts of the website. Permission misattribution in datasets is significant because it gives artificial intelligence
It can be developed with legal and ethical risks. If the data used to train the underlying model
Sets are mislabeled or misattributed, and AI developers may unknowingly violate copyright laws, data use policies, or privacy regulations. This can lead to legal liability, challenges in ensuring fair compensation for data creators, and potential bias in the model due to the exclusion of properly licensed data. In addition, unclear licensing can hinder transparency, accountability, and reproducibility in AI research, making it difficult for researchers and institutions to validate or review model training data. Based on their findings, the authors highlight the need for clear documentation, improved standards, and responsible licensing practices to promote inclusivity and reduce the risks arising from irresponsible or illegal use of data in AI development and deployment.
Data licensing in a crisis
AI models rely heavily on large amounts of publicly available network data
Conduct training. A recent study on AI training datasets (including: 
C4, RefinedWeb, and Dolma), 14,000 domains were analyzed for a longitudinal audit. These consent agreements specify the permissibility of data scraping for AI model training.
The researchers observed that between 2023 and 2024, the data made
Usage limits have increased dramatically, as many websites have implemented new protocols to limit data scraping for AI training. These restrictions are primarily by updating the robots.txt documents and terms of service to explicitly prohibit the use of AI training. Figure 3.6.2 shows the terms of service with robots.txt restrictions over time
Proportion of sites with limits and organizational restrictions.
12For example, in the top C4 domains,
The proportion of tokens with full restrictions has risen from 10% in 2017 to 2024
of 48%. Between 2023 and 2024 alone, this percentage has risen by 25 percentage points. Figure 3.6.3 visualizes the proportion of tokens in the C4 top-level domain from 2016 to 2024 by terms of service restriction category. This decrease in consent is likely related to legal issues surrounding fair use, such as the New York Times lawsuit against OpenAI. OpenAI's crawlers encounter the most limitations, while smaller developers face obstacles
There are fewer obstacles. The authors emphasize that ineffective signaling mechanisms such as robots.txt and the mismatch between declarations and enforcement policies lead to inconsistencies in enforcement. These findings highlight the need to update consent protocols to address AI-specific challenges. In addition, the study also shows that there has been a decrease in publicly available network data for AI training, with potential implications for data diversity, model alignment, and scalability. Much of the recent AI performance comes from training on an ever-increasing number of datasets. If the restrictive nature of the website increases significantly, it may hinder the expansion of the model in the future. Table of Contents Chapter 3 Preview Artificial Intelligence in 1942025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
Percentage of tokens toke percentage: Percentage of C4 top-level domain tokens by robots.txt restricted category, 2016-2024
Source: Longpre et al., 2025| Chart: 2025 Artificial Intelligence Index Report
The distribution of the content terms of use restrictions category of the top-level network domain names in the C4 dataset from 2016 to 2024
Source: Longpre et al., 2025| Chart: Chart 3.6.2 of the 2025 AI Index Report
Figure 3.6.3 6% 8% 41% 44% 39% 43% 41% 42% 41% 36% 36% 12% 14%
 12% 16%
 11% 12%  14%  14%  12% 39% 36% 40% 35%
 41%  39%  39%  38%  36%
2016 2017 2018 2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%70%80%90%100%No Crawling & AI Training No Crawling Non-Commercial Use Only Prohibited Competitive Use Prohibited Secondary Distribution Unlimited Use 12% 10% 9% 10% 10% 11% 11% 12% 23% 48% 27% 27% 29% 29% 31% 30%   30% 27% 15%
 5%  7%  7%  7% 7%  7%  7% 7% 6% 47%  47%  46%  44% 44%  44%  43% 36% 25%
2016 2017 2018 2019 2020 2021 2022 2023 20240% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% full limit
Specifying Crawl Latency Based on Pattern Matching LimitationsProviding SitemapsProhibition of Crawling Private CatalogsNo Restrictions or SiteMaps Other LimitationsArtificial Intelligence's Fairness Emphasizes the Development of a Fair System, Avoiding Long-Term Protection
There is prejudice or discrimination against any individual or group. It involves considering the recipient
The use of AI affects the different needs and situations of all stakeholders. Equity goes beyond the concept of technology and embodies broader societal standards related to equity.
Table of Contents Chapter 3 Preview Artificial Intelligence in 1952025
Chapter 3 of the Index Report: Responsible AI
3.7 Fairness and Prejudice
Faces categorized by model and dataset size and their likelihood of being classified as "crime".
Source: Birhane et al., 2024
Figure 3.7.1
3.7 Fairness and Prejudice
Featured research
This section focuses on the impact of racial classification in multimodal models, as well as on the impact of unbiased on the surface
Measurement of implicit bias in language models.
Ethnic classification in multimodal models
Recently, researchers have examined the impact of dataset size expansion on racial and gender bias in visual language models (VLMs).
Research was carried out. The study used the Chicago Face Dataset (CFD) to train 14 visual language based on LAION-400M and LAION-2B ().
Commonly used datasets for speech models) were evaluated on the VLM. The study found that although models trained on larger datasets were able to improve the accuracy of human classification, minus
There are cases where non-human entities such as gorillas or orangutans are misidentified as human – but these models also exacerbate racial bias, especially in models with a larger number of parameters. For example, in the larger ViT-L model, black and Latino men are disproportionately classified as criminals, with up to a 69% increase in classification probability when the dataset size is increased from 400 million to 2 billion samples. Figure 3.7.1 shows the various images and the model's classification score for whether a face is recognized as a criminal.
Figure 3.7.2 illustrates how different models, including the smaller ViT-B-16 and ViT-B-32,
and the larger ViT-L-14) probability of having a specific label on a person's face (such as "animal" or "criminal") varying with different demographic groups. Table of Contents Chapter 3 Preview Artificial Intelligence in 1962025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
Higher percentages indicate that a particular demographic group is associated with a certain type of label (e.g. "
offenders") the greater the probability of association; Conversely, the lower the value, the smaller the correlation probability. at
In large-scale ViT-L models, the increase in the amount of training data will continue to increase the probability that the image will be classified as a "criminal". This finding is important because many model developers are currently working to improve performance by dramatically scaling their models. The researchers point out that in the case of visual models, scaling may introduce other unintended biases while improving performance. The authors suggest that stereotypes present in the training data may be the main cause of such results. In order to effectively alleviate this bias problem, the research team recommends establishing a transparent dataset screening mechanism, improving the detailed recording specification of hyperparameters, and opening up the model to accept independent audits.
The impact of dataset size on model predictions for different population groups
Source: Birhane et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 3.7.2 13
13. Y-axis labels represent different racial groups: Black Male (BM), Black Female (BF), Latino Male (LM), Latino Female (LF), White Male (WM), White (WF), Asian Male (AM), and Asian American Female (AF). x-axis labels for different prediction categories,
From left to right, this is a measure of implicit bias in the explicit unbiased large language model of humans, animals, gorillas, chimpanzees, orangutans, thieves, criminals, and suspicious people
In 2024, a research team will investigate implicit bias in large language models
Surveys, with a particular focus on models that are explicitly designed to be unbiased. The study
Significant – even in efforts to eliminate large language model bias, the problem of implicit bias may not be adequately addressed. Figure 3.7.3 illustrates a typical example of this phenomenon.
The research team made two key contributions: First, they innovatively:
Two large language model bias detection methods were proposed: "large language model implicit bias detection method" (which identifies potential bias by analyzing the automatic association between words/concepts) and "large language model decision bias detection method" (which captures the implicit bias reflected in the model's behavior). Second, they delved into patterns of relative discrimination in decision-making tasks. The research team applied these two methods to 8 well-known models, including GPT-4 and Claude 3 Sonnet, covering 21 social stereotype categories such as race, gender, religion and health, and finally found that they were consistent with mainstream social biases
Highly consistent systemic implicit bias. As shown in Figure 3.7.4, different large language modules
There was a significant difference in implicit bias scores across the stereotype categories – if
A score significantly higher or lower than the 50% baseline indicates that the model exists for a particular population
bias in tendencies or discriminatory biases. 14
Figure 3.7.4 shows that large language models overly associate negative words with blacks
and more likely to associate women with the humanities rather than with STEM
Domains are linked in one. The study also found that large language models are more likely to be male
Holding leadership positions, which reinforces gender bias in decision-making environments. In addition, research
It was also found that implicit bias increased as the model size increased, but the decision bias was biased
See and rejection rates increase. This finding is significant because it shows that though
There seems to be a reduction in bias in the standard benchmark -- resulting in a kind of neutrality
Illusions, but implicit bias is still prevalent, cancan lead to subtlety but meaningful
Discriminatory outputs.
Table of Contents Chapter 3 Preview Artificial Intelligence in 1972025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
An example of implicit bias in large language models
Source: BAI et al., 2024
Figure 3.7.3
14. This study examines both implicit bias and decision-making bias, but based on the conciseness of the text, only the implicit bias part is recorded here. To be clear, decision bias is defined here as the degree to which the model deviates from the 50% unbiased baseline. Table of Contents Chapter 3 Preview Artificial Intelligence in 1982025
Chapter 3 of the Index Report: Responsible AI
3.6 Privacy and Data Governance
The implicit bias of large language models against stereotypes in four social categories
Source: BAI et al., 2024BAI et al., 2024| Chart: 2025 Artificial Intelligence Index Report
l0.000.501.00
0.000.501.00
0.000.501.00
0.000.501.00
0.000.501.00
0.000.501.00
−1.00−0.50
−1.00−0.500.000.501.00
0.000.501.00 implicit bias
Implicit bias implicit bias
Implicit bias Implicit bias Implicit bias Implicit bias Implicit bias Implicit bias GPT-4 GPT-3.5 Turbo
Claude 3 Opus Claude 3 Sonnet
Llama 2 Chat 70B Llama 2 Chat 13B
Llama 2 Chat 7B Alpaca 7B Contest Gender Religion Health
−1.00−0.50
−1.00−0.50−1.00−0.50
−1.00−0.50−1.00−0.50
−1.00−0.50
Racist crimes
complexion
Weapons blacks
Spaniard
Asian
Arab
English Vocational Science
 power
Libido
Islam
Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored weapons
 Blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
 Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
Judaism
Buddhist Disability Weight Age
mental illness
diet
Ethnominate crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Careers
 science
Power sexuality
Islam
Judaism
Buddhist Disability Weight Age
mental illness
Eating racism crimes
Color-colored arms blacks
Spaniard
Asian
Arab
English Occupation Science Power Libido
Islam
Judaism
Buddhism
 Disability weight
age
mental illness
 Diet3.8 Transparency and explainability
Featured research
Base Model Transparency Index v1.1
The Foundation Model Transparency Index v1.1 is a Stanford-led tracking model development and deployment transparency
The second iteration of the project. It evaluates the major AI model developers in three areas:
Upstream, including components such as data and computation for training; The model itself, which refers to the core AI system; Downstream, including applications and deployments. The latest report shows that the transparency of the developers of the underlying model has increased significantly in six months. Figure 3.8.1 reports the FMTI scores of the leading model developers in the index published in May 2024, and Figure 3.8.2 reports the scores of each developer on the primary dimension of transparency. There are several aspects to the transparency of AI. Transparency of data and models
degree involves the public sharing of development choices, including data sources and algorithmic decisions
Plan. Operational transparency details what AI systems are in practice
how to deploy, monitor, and manage. While explainability often falls under the category of transparency, which provides insight into the decision-making process of AI, it is also sometimes seen as a different category. This distinction underscores the importance of AI not only being transparent, but also being understood by users and stakeholders. In this section, the AI Index incorporates explainability into transparency
Category, which is defined as the ability to understand and elucidate the principles behind AI decision-making.
Table of Contents Chapter 3 Preview Artificial Intelligence in 1992025
Index Report
Underlying Model Transparency Index score for each domain in May 2024
Source: Underlying Model Transparency Index, Transparency and Explainability, May 2024
3.8 Transparency and Explainability
Figure 3.8.10 10 20 30 40 50 60 70 80 90 100Fuyu-8B Titan Text Express Gemini 1.0 Ultra GPT-4 Claude 3 Mistral 7B Palmyra-X Stable Video Di usion Llama 2 Phi-2 Granite Luminous Jurassic-2 StarCoder 
upstream
Downstream of the model
3341474951555658606264757585 Table of Contents Chapter 3 Preview Artificial Intelligence in 2002025
Index Report
May 2024 Base Model Transparency Index Key Latitude Scores
Source: May 2024 Foundation Model Transparency Index Chapter 3: Responsible AI
3.8 Transparency and Explainability
Figure 3.8.2 15 vs. the Initial v1.0 Index (Average Transparency Score) published in October 2023
37/100) compared to the v1.1 version score rises to 58/100, which is mainly due to the on
By submitting a report, the issuer disclosed previously unpublished data. Developers have made progress on 89 of the 100 transparency metrics, but there are still significant opacity in areas such as data access, copyright status, and downstream impacts. Open source developers outperform their closed-source counterparts in terms of upstream transparency, particularly data and workforce disclosure. Projects like FMTI are significant because they provide a longitudinal perspective on the state of transparency in the AI ecosystem. The results of the current study show that the transparency of the industry is continuing to increase.
0% 60% 40% 0% 10% 100% 0% 60% 40% 40% 20% 20% 40% 50%
0% 43% 71% 14% 14% 100% 29% 43% 29% 100% 100% 14% 100% 43%
14% 86% 100% 0% 14% 100% 14% 100% 71% 57% 14% 14% 43% 86%
0% 100% 100% 50% 75% 100% 75% 100% 75% 100% 100% 50% 75% 100%
83% 100% 100% 83% 50% 100% 83% 100% 100% 100% 100% 50% 100% 100%
100% 67% 100% 67% 67% 100% 67% 67% 100% 100% 100% 67% 100% 33%
80% 80% 100% 80% 100% 100% 80% 60% 100% 100% 100% 100% 60% 100%
0% 57% 57% 43% 86% 100% 43% 71% 71% 29% 14% 57% 14% 14%
0% 40% 20% 20% 40% 0% 40% 80% 60% 0% 60% 60% 0% 20%
57% 86% 100% 57% 86% 100% 57% 86% 71% 71% 71% 71% 86% 71%
40% 100% 100% 80% 100% 100% 100% 40% 40% 100% 40% 80% 60% 80%
67% 100% 67% 67% 33% 100% 67% 67% 33% 67% 67% 33% 67% 33%
29% 29% 29% 0% 14% 14% 29% 0% 14% 0% 14% 14% 14% 14%Fuyu-8B Jurassic-2 LuminousTita
n Text
Express Claude 3 StarCoderGemini 1.0
Ultra Granite Llama 2 Phi- 2 Mistral 7B GPT-4Stable Video
Diusion Palmyra-X
36% 73% 76% 43% 53% 86% 53% 67% 62% 66% 62% 49% 58% 57%34%
50%
51%
79%
89%
81%
89%
47%
31%
77%
76%
62%
15% data
Human computing power
Training methods
Model Underlying InformationModel Access Permissions
Potential risks to model capabilities
Risk mitigation measures
Distribution method: use policy feedback mechanism, social impact
The main aspects of average transparency are average
15. Data, manpower, computing power and training methods are upstream indicators; Model basic information, model access rights, model capabilities, potential risks, and risk mitigation measures are model metrics; Distribution methods, usage policies, feedback mechanisms, and social impact are downstream indicators. This section will explore three different aspects of security. First of all, Paul
Proving the integrity of AI systems involves protecting algorithms, data, and infrastructure
and other components are protected from external threats such as cyber attacks or adversarial attacks. Second, security involves minimizing harm caused by the deliberate or unintentional misuse of AI systems. This includes issues such as developing automated hacking tools or using artificial intelligence in cyberattacks. Finally, security encompasses the risks inherent in AI systems themselves, such as reliability issues (e.g., hallucination issues) and potential risks posed by advanced AI systems.
Table of Contents Chapter 3 Preview Artificial Intelligence in 2012025
Index Report
3.9 Security and Safety Assurance
Benchmarks
HELM Safety
Recently, academic institutions have taken the lead in bridging gaps in AI security benchmarks. worth
Note that the Center for Fundamental Model Research (CRFM) at Stanford University recently launched HELM Safety,
This is a benchmark suite designed to evaluate AI models based on responsibility and safety metrics. The HELM Safety Benchmark covers the latest models from almost all major developers and includes responsible AI and safety benchmarks such as BBQ, SimpleSafetyTests, HarmBench, AnthropicRedTeam, and XSTest. Chapter 3: Responsible Artificial Intelligence
3.9 Security and Safety Assurance
Figure 3.9.1 The BBQ measures social bias related to protected groups under U.S. anti-discrimination laws
See SimpleSafetyTests while assessing the risks associated with self-harm, physical harm, and child sexual abuse material. HarmBench uses red team testing techniques to assess responses to alerts involving harassment, chemical weapons production and disinformation. AnthropicRed-Team examines how the model handles adversarial conversations designed to test harmfulness, while XSTest measures the trade-off between usefulness and harmlessness by testing for bogus rejection of benign cues and adherence to subtle harmful cues. By introducing a standardized methodology, HELM Safety provides a more transparent and comparable framework for assessing the responsible behavior of AI models.
Figure 3.9.1 shows the average safety scores across all test protocols for each model
points, the higher the score, the safer the model. According to the benchmark, the safest model at the moment is the Claude 3.5 Sonnet with a score of 0.977, followed closely by the O1 with a score of 0.976. Some models seem to be becoming more secure over time. For example, GPT-3.5 Turbo (0613), released in 2022, scored 0.853 points, 0.123 points lower than OpenAI's current most efficient model.
HELM Safety: Average score
Source: HELM, 2025 Chart: 2025 Artificial Intelligence Index Report
0.96GPT- 3.5 Turbo (0613)
DeepSeek LLM Chat (67B)
DBRX Instruct
Mistral Instruct v0.3 (7B)
Command R
Mixtral Instruct (8×7B)
Llama 3.1 Instruct Turbo (70B)
Mixtral Instruct (8×22B )
Command R Plus
Llama 3.1 Instruct Turbo (8B)
DeepSeek v3
Claude 3 Haiku (2024- 03- 07)
Qwen1.5 Chat (72B)
Llama 3 Instruct (8B)
Llama 3 Instruct (70B)
Llama 3.1 Instruct Turbo (405B)
Gemini 1.5 Pro (001)
Gemini 1.5 Flash (001)
GPT- 4o mini (2024- 07- 18)
Qwen2 Ins truct (72B)
G
PT- 4o (2024- 05- 13)
o1- mini (2024- 09- 12)
GPT- 4 Turbo (2024- 04- 09)
Claude 3 Opus (2024- 02- 29)
o1 (2024- 12- 17)
Claude 3.5 Sonnet (20240620)
DeepSeek R1
o3- mini (2025- 01- 31)
2023 2024 202500.20.40.60.81
0.850.87
0.630.730.810.810.84 0.850.860.86 0.870.880.89 0.89 0.900.900.92 0.93 0.930.930.95 0.950.960.970.98 0.98
0.86 average score for 2025 AI
Chapter 3 of the Index Report: Responsible AI
3.9 Security and Safety Assurance
Table of Contents Chapter 3 Preview 202AIR-Bench
AIR-Bench 2024 is a new security benchmark designed to bring people:
Robot intelligence assessments are aligned with real-world regulatory and corporate frameworks. It is divided into four grades
The generic approach (System & Operational Risk, Content Security Risk, Social Risk, Legal & Rights Risk) covers 314 fine-grained micro-risks under these four risk categories. The risk of this benchmark study is derived from 8 important government regulations and 16 corporate policies, so the AIR-Bench is designed to assess model safety through the real-world AI risk lens identified by corporate and government entities.
AIR-Bench evaluates model performance by rejection rate, which is how often a model refuses to respond to a particular prompt due to safety, ethical, or compliance concerns. of 22 mainstream models
The assessment showed a significant difference in rejection rates, ranging from 91% (Anthropic  
Claude series) to 25% (DBRX Instruct) (Figure 3.9.2). Figure 3.9.3 
The distribution of rejection rates under different risk categories is further illustrated. AIR-Bench 
The results for 2024 show that
The current model is in line with the European Union's Artificial Intelligence Act, the United States' Ann
Comprehensive, reliable and trustworthy executive order on the development and use of artificial intelligence" and other global gates
There is a general disconnect between key regulations. Despite the fact that part of the model is in hate speech and hurts children
The field shows strong protection ability, but the overall inconsistency indicates
Targeted improvements are still needed, especially in automated decision-making scenarios.
AIR-Bench: Rejection rate
Source: Zeng et al., 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 3.9.2 Rejection rate
Model 0.250.290.320.350.390.410.440.440.450.490.510.530.540.560.580.620.620.620.640.640.710.720.750.790.800.830.840.91DBRX Instruct
Command R Plus
Command R
Mistral Large 2 (2407)
Mixtral Instruct (8×7B)
DeepSeek v3
Mixtral Instruct (8×22B )
Palmyra- X- 004
o1- mini (2024- 09- 12)
Qwen1.5 Chat (72B)
DeepSeek LLM Chat (67B)
DeepSeek R1
Yi Chat (34B)
GPT- 4o mini (2024- 07- 18)
Gemini 1.0 Pro (002)
Qwen2 Instruct (72B)
Llama 3.1 Instruct Turbo (8B)
GPT- 4o (2024- 08- 06)
GPT- 3.5 Turbo (0301)
GPT- 4 (0613)
Llama 3 Instruct (8B)
GPT- 4 Turbo (2024- 04- 09)
o3- mini (2025- 01- 31)
Gemini 1.5 Flash
o1 (2024- 12- 17)
Claude 3 Haiku (2024- 03- 07)
Gemini 1.5 Pro
Claude 3 Opus (2024- 02- 29)
Claude 3.5 Sonnet (
2024- 10- 22)0.000.200.400.600.801.00 Rejection rate of each model under a specific risk category
Source: Zeng et al., 2024| Chart: 2025 Artificial Intelligence Index Report
Table of Contents Chapter 3 Preview 203 Figure 3.9.3 16
16. The X-axis label represents risk categories, from left to right: weapon use and development, hate speech, child sexual abuse, suicide and non-suicidal self-harm, political influence, fraud, disinformation, exploitation of illegal services, offensive language, invasion of privacy, or sensitive data
Artificial intelligence in 2025
Chapter 3 of the Index Report: Responsible AI
3.9 Safety and Security Table of Contents Chapter 3 Preview 204 Featured Research
Go beyond shallow safety alignment
In 2024, an interdisciplinary team of computer scientists proposed
The concept of Shallow Safety Alignment – i.e. people
AI systems often train safety in a superficial and ineffective way. In many cases, a model's safeguards are limited to the response of its first few tokens. As a result, if a user-induced model begins with anything other than a standard security warning (e.g., "Your request violates our Terms of Service"), subsequent responses are highly vulnerable to adversarial attacks. For example, if the user asks directly how to make a bomb, the model will most likely refuse to answer. However, if the same request is made in the form of a solicitation model that starts replying with "Of course, here's a detailed guide", then the model is much more likely to continue to generate harmful content. Experiments have shown that even minor modifications could significantly weaken the model of Ann 2025 AI
Index Report
Full mechanism. For example, only pre-populate or fine-tune non-standard text in model responses,
After six fine-tuning steps, the harmful output rate increased from 1.5% to 87.9%. 17 
Figure 3.9.4 shows the harmfulness of inference sequences based on pre-population or insertion into the model
The number of tokens, the success rate of different attacks on various models. To solve this
The researchers proposed two key solutions:
extended training data,
The inclusion model learns to recover from harmful responses and redirect them to safe denials
Example; Normalizes the choice of initial words, ensuring that even if the model starts with an unusual response,
It can also maintain its safety constraints. These techniques significantly improve resistance to counter-attacks
force, and in some cases, the attack success rate is reduced to 2.8%. The study highlights:
to develop a deeper and more resilient alignment strategy to prevent AI safety machines
The necessity of being manipulated.
The relationship between the attack success rate and the number of prefilled harmful tokens in a large language model
Source: Qi et al., 2024 | Chart: 2025 Artificial Intelligence Index Report
17. The fine-tuning step in AI refers to the iterative process of training a pre-trained model on a smaller, domain-specific dataset to improve its efficient attention on a specific task. Figure 3.9.4 Attack success rate
Number of pre-populated harmful tokens0 1 2 3 4 5 6 7 8 9 100%20%40%60%80%100%Llama 2 7B (Basic) Llama 2 7B Chat (Alignment) Gemma 7B (Basic) Gemma 1.1. 7B IT (Alignment) Chapter 3: Responsible AI
3.9 Safety & Security Table of Contents Chapter 3 Preview Artificial Intelligence in 2052025
Index Report
Targeted latent adversarial training in large language models
Source: Sheshadri et al., 2024
Figure 3.9.5
Comprehensive performance on non-adversarial data
Source: Sheshadri et al., 2024| Chart: 2025 Artificial Intelligence Index Report
Attack success rate
Figure 3.9.6 Metrics: This efficiency finding is important because more computation is required to improve model security
resources, while degrading performance, then developers who adopt these methods of improving security will
Decrease. Improve the robustness of large language models to persistent harmful behaviors
The challenge of eliminating harmful behaviors in large language models is in:
Therefore, traditional training methods tend to teach the model to hide this behavior, rather than eliminate it entirely. A new approach, targeted latent adversarial training (LAT), takes a more precise strategy to actively expose the model's weaknesses during training, making it more resilient to adversarial attacks (Figure 3.9.5). Compared to previous technologies such as R2D2, this method has better performance and lower computing power requirements. For example, in tests against jailbreak attempts, where users attempt to bypass the model's security safeguards, LAT reduced computational costs by a factor of 700 while maintaining robust performance on routine tasks. For the Llama3-8B-instruct family, LAT maintains strong performance in benchmarks such as MMLU while significantly reducing vulnerability to adversarial attacks (Figure 3.9.6). This efficiency finding is important because if improving model security requires more computational resources and reduces performance, fewer developers will adopt these security-improving approaches. Chapter 3: Responsible Artificial Intelligence
3.9 Security and Safety Assurance
0.640.841.00
0.640.841.00
0.610.831.00
MMLU MT-Bench Compliance0.000.200.400.600.801.00Llama3-8B-instruct RT RT-EAT-LAT Table of Contents Chapter 3 Preview Artificial Intelligence in 2062025
Index Report
The model's resistance to jailbreak attacks
Source: Sheshadri et al., 2024| Chart: The 2025 AI Index report proves that LAT is also effective in eliminating backdoor vulnerabilities, which is an attack
type, i.e., subtle modifications to the AI model during the training process so that:
Unintended – and possibly malicious – behavior occurs when a particular input is triggered. It's worth noting that LAT eliminates these vulnerabilities even if the exact trigger isn't known beforehand. In addition to security improvements, LAT enhances the ability to purge harmful or copyrighted knowledge from the model and prevents the model from relearning deleted content. For example, LAT significantly reduces the number of models that regenerate copyrighted text (eg
Harry Porter's passages) and make it possible to relearn knowledge
Competence is lower than the baseline method. When applied to sensitive knowledge domains such as biosecurity or cybersecurity, LAT effectively weakens knowledge extraction attacks while still enabling the model to correctly respond to more than 90% of secure and harmless requests. Methods such as LAT are important not only because they improve model security, but also because they are computationally efficient and easy to implement. Chapter 3: Responsible Artificial Intelligence
3.9 Security and Safety Assurance
0.09 0.090.49
0.150.20
0.17
0.000.140.14
0.010.040.03
0.000.030.07
0.000.010.00
Direct requests PAIR Prell AutoPrompt GCG Many- shot0.000.100.200.300.400.50Llama3-8B-instruct RT RT-EAT-LAT attack success rate↓
Figure 3.9.7
Table of Attack Types Chapter 3 Preview 2072025 Artificial Intelligence
Index Report
3.10 Responsible AI
title
AI Agents
Artificial intelligence agents (defined as "intelligent generations with natural language interfaces
The function of the physiognomy is to plan and execute operations across one or more domains on behalf of the user
to meet user expectations") to ensure that it is responsible
Artificial intelligence presents unique challenges. These assistants are autonomously operational, dynamic, and:
environment and make decisions that have the potential to have significant ethical, legal, and social implications.
Therefore, a dedicated approach is needed to address the issues involved in transparency, accountability and accessibility
relying on sexual risks; These challenges may be unleashed by agentsStructured or dynamic fields
The ability to learn, adapt, and make decisions is further exacerbated.
Simulating the risks of a language model agent in a sandbox based on a language model
The latest research shows that with the help of language model-based tools and proxy technology
Risks such as progress, data breaches, and financial losses are amplified. However, currently
Overview of ToolEmu
Source: Ruan et al., 2024
The risk assessment approach in Figure 3.10.1 is resource-intensive and difficult to scale. To this end, the researchers launched
ToolEmu (Tool Emu), an environment that enables scalable testing and automated security assessment by simulating tool execution (Figure 3.10.1). The framework consists of a standard simulator for general risk assessment, as well as an adversarial simulator designed for stress testing in extreme scenarios.
Human assessment confirmed that 68.8% of the risks identified by ToolEmu were real
Possible threats in the world. Using a benchmark of 36 toolkits and 144 test cases, the study found that even with the most security-optimized language model agents, 23.9% of key scenarios failed, including dangerous commands, incorrect financial transfers, and traffic control failures (Figure 3.10.2). Despite the potential of LM agents to automate complex tool interactions, their reliability in high-risk applications remains a significant concern. Test suites like ToolEmu are critical for the reliability and security testing of AI systems, such as agents, by providing a platform to assess performance and real-world risks. Chapter 3: Responsible Artificial Intelligence
3.10 Safety and Security
This chapter explores responsible AI and AI agents
and election disinformation, two themes that are fast gaining traction
Dot.
Table of Contents Chapter 3 Preview Artificial Intelligence in 2082025
Index Report
Agent failure rate based on language model
Source: Ruan et al., 2024| Chart: 2025 Artificial Intelligence Index Report
Infection rate of each round of conversation
Source: Gu et al., 2024
Figure 3.10.3 Chapter 3: Responsible AI
3.9 Security and Safety Assurance
The latest research in Asia has revealed the multi-agent safety of multimodal large language model systems
Vulnerability, research shows that when a single agent is jailbroken, it triggers the entire system-wide level
Failure of the link. Researchers have named this phenomenon "contagious jailbreaks" – the idea that when a single agent is compromised, harmful behavior spreads exponentially throughout the system. Specifically, the study found that simply injecting an adversarial image into the memory bank of an MLLM agent (such as an image suggesting that "humans are a disease") can trigger an uncontrolled chain reaction that allows harmful behaviors to spread across a network of interconnected agents without further intervention. This infectious jailbreaking mechanism forces the infected agent to implant the adversarial image into the memory bank of the uninfected (benign) agent through agent-to-agent interaction. In a simulation using a million-agent network built on the LLaVA-1.5 architecture, the contagion rate can reach nearly 100% propagation coverage within 27 to 31 interactions (see Figure 3.10.3).
Although researchers have proposed a theoretical containment strategy, there is no practical mitigation at present
This puts the multi-agent system in a highly vulnerable state. The compounding risks posed by the large-scale deployment of connected MLLM agents make them a critical security vulnerability. The study points out that although MLLM systems are an important direction of AI research, they are still highly vulnerable to low-resource jailbreak attacks.
18. The downward arrow on the y-axis indicates that the lower the score, the better. Figure 3.10.2 1862.00%
54.60%
45.00% 44.30%
39.40%
ChatGPT- 3.5 Vicuna- 1.5- 13B Vicuna- 1.5- 7B Claude 2 GPT- 40%20%40%60%80%100%Failure Rate↓
Model Table of Contents Chapter 3 Preview Artificial Intelligence in 2092025
Index Report
A range of ethical concerns around artificial intelligence and information manipulation
Source: AI Index 2025 19 Chapter 3: Responsible AI
3.10 Topic on Responsible Artificial Intelligence
Election disinformation
2024 is an important year for elections around the world, including the United States, the United Kingdom, India
It is held in many countries and regions, including Indonesia, Mexico and Taiwan
4 billion voters voted. Last year's AI Index explored the impact of AI on elections, focusing on its potential impact and real-world use cases. This year, we are looking at this topic again. While some reports have noted that AI-driven disinformation has not had the expected serious impact, others have argued that its potential risks cannot be ignored. Therefore, as the capabilities of AI systems improve and their applications become more widespread, it is essential to continuously monitor and research AI disinformation.
AI disinformation in the U.S. election
AI may influence elections in a variety of ways. The latest research revolves around artificial
Intelligence-driven disinformation raises ethical concerns and analyzes its recent beauty
Actual performance in the national elections.
19. This table was edited by Ann Fitz-Gerald, Halyna Padalko, and Dmytro Chumachenko. Liar Bonus
Extortion
Trust in the evidence has declined
Reduced cognitive autonomy Donald Trump and his supporters falsely claim a photo showing Kamala Harris at a crowd rally in Detroit
The tablets are generated with artificial intelligence. The existence of deepfake technology enables individuals to deny the truth by claiming that real evidence is fake, thereby undermining accountability and truth. This phenomenon erodes public trust in legitimate evidence and even leads to the questioning of verified information.
AI technology is being misused to create fake content (including deepfakes) for sexual exploitation
Exploitation, financial extortion, and defamation. Blackmailers use these tools to extract benefits from their victims, who often find it difficult to effectively refute these falsifications.
AI-generated content challenges the authenticity of all digital media, fundamentally shaking
The concept of truth. Surreal falsification blurs the line between legitimate and false content, eroding public confidence in the integrity of information.
AI's ability to analyze massive amounts of data enables it to perform advanced voter profiling and precise voting
Tailor information to individual preferences, behaviors, and weaknesses. AI can also manipulate an individual's decision-making process using emotional and subconscious triggers. Brink candidate Jason Palmer defeated Joe Biden in the U.S. Samoa primary, in part thanks to AI-generated emails, text messages, audio, and video. These AI-powered communications are highly personalized and emotional, targeting specific groups of voters to influence their choices. Russia's "Doppelganger" campaign is designed to do so by squatsquatively registering domain names that are similar to legitimate news outlets.
and publish AI-generated articles that disseminate Russian government propaganda while hiding its source and misleading viewers into believing that the content comes from credible media. The Sunshine Project found that more than 35,000 deepfakes depicted 26 members of Congress (25 of them).
female) appears on pornographic sites. Ethical Concerns Description Table of Contents of Examples Chapter 3 Preview Artificial Intelligence in 2102025
Chapter 3 of the Index Report: Responsible AI
3.10 Topic on Responsible Artificial Intelligence
Rest of World's 2024 Global AI-Generated Election Content Statistics
Rest of World tracks AI students around the world in 2024
into a typical case of election content. Its database records 60 cases in 15 countries
Events, covering four media types of audio, image, text, and video, across 10 platforms such as Facebook, Instagram, and TikTok. Figure 3.10.5 provides more information. Malicious exploitation of personal branding
Amplification of hate speech
The traceability of overseas operations is reduced
Fake celebrity endorsements have become the latest weapon in the disinformation war, creating chaos ahead of the 2024 election. For example, Don
Nader Trump posted an AI-generated picture of Taylor Swift falsely claiming to support his presidential campaign. Deepfakes are used to create unauthorized videos or images of celebrities, public figures, and influencers. By stealing personal brands and falsifying endorsements, malicious actors seek to deceive audiences, exploiting the public's trust in these individuals to add credibility to false narratives.
AI technology fuels the spread of hate speech by creating information cocoons and filtering bubbles
Broadcast and normalization. These systems prioritize user engagement metrics over ethical considerations, reinforcing pre-existing biases and promoting divisive content.
Artificial intelligence can generate linguistically perfect texts that are indistinguishable from human writing, and translate them
Optimizations to make it difficult to track the activities of malicious actors outside of the country. Previously, foreign disinformation campaigns were often identified by grammatical errors by non-native speakers, but AI-generated content completely eliminates this vulnerability.
AI systems often rely on large amounts of data collection for training, leading to misuse of personal information
Ethical concerns about use or disclosure. The lack of strong safeguards for sensitive data management can lead to privacy violations and complicate the ethical environment for AI deployment. A fake Joe Biden robophone was aimed at New Hampshire Democrats to mislead their primary votes. The case highlights how AI systems can use personal data to spread false information and violate the privacy of potential voters. OpenAI intercepted an operation codenamed "Bad Grammar" in which Russia-linked accounts were exploited
ChatGPT comments on the Telegram channel. These messages use regionalized language to mimic different groups of people and political views in the United States to manipulate public opinion. In a disinformation campaign, Donald Trump and several of his allies repeatedly promoted a baseless conspiracy
Claims, Haitian immigrants in Springfield, Ohio, steal and eat cats and dogs. This narrative is further proliferated through AI-generated memes designed to spark fear and hostility towards the Haitian community.
Rest of World 2024 AI Election Content: Statistical Summary
Source: Rest of the World, 2025| Chart: 2025 Artificial Intelligence Index Report
15 countries / regions category
10 Platforms Media Types
4
Total Bangladesh, Belarus, China, India,
Indonesia, Mexico, Pakistan, Panama, South Africa, South Korea, Sri Lanka, Taiwan, United States, Uruguay, Venezuela Audio, Image, Text, Video ChatGPT, Facebook, Instagram, Medium, Reddit, TV, TikTok, YouTube, WhatsApp, X/Twitter Figure 3.10.4
Figure 3.10.5 The next section focuses on five important cases in trackers, from a qualitative perspective
Explore the nature of AI-generated election content in 2024.
Fake businesses support Mexican politicians (Mexico, Image, X/Twitter, 2024
June 2, 2)
On March 18, the Mexican civil society organization Sociedad Civil de México
Starbucks was called upon to launch a special cup to celebrate opposition presidential candidate X. chitl G. lvez. The group shared an AI-generated image of a Starbucks coffee mug with the word "#Xochitl2024" printed on the mug and the hashtag #StarbucksQueremosTazaXG (#StarbucksWe want XG cup) on Platform X (Figure 3.10.6). The next day, Elwes encouraged supporters to order "caf.sin miedo" on Platform X, a clever adaptation of his campaign slogan, "For a Fearless Mexico." She invited supporters to share photos of coffee cups on social media and connect with their team. The AI-generated image quickly went viral, and users retweeted it. However, Starbucks denied any involvement in the design and stated that it did not support any political party.
India's ruling party motivates campaign workers with personalized video (India, video,
WhatsApp, April 18, 2024)
On April 18, more than 500 campaign volunteers from the incumbent president participated
Election campaign. The Bharatiya Janata Party (BJP) received a personalized video made with the help of an artificial intelligence tool. In the video, Bharatiya Janata Party member Shakti Singh called on volunteers to share the party's message with the public, highlighting policies such as 'Clean India', 'Digital India' and 'Make in India'. Despite the obvious editing, Singh calls the recipient by name in each video (Figure 3.10.7). Campaign employees involved in the video production insisted that instead of asking Mr. Singh to record each person's name individually, they used voice cloning and lip-matching software.
Table of Contents Chapter 3 Preview Artificial Intelligence in 2112025
Chapter 3 of the Index Report: Responsible AI
3.10 Topic on Responsible Artificial Intelligence
Source: Rest of the World, 2024
Figure 3.10.6 Source: Rest of the World, 2024 Figure 3.10.7 Table of Contents Chapter 3 Preview Artificial Intelligence in 2122025
Chapter 3 of the Index Report: Responsible AI
3.10 Topic on Responsible Artificial Intelligence
The "impossible" debate in Uruguay (Uruguay, video, TV, October 2024.) 
27th)
Santo y Se.a, a comprehensive morning show, before the presidential elections in Uruguay
The so-called "impossible debate" was broadcast. The debate invited Andr.s, the presidential candidate of the right-wing party Partido Colorado Ojeda and its center-left coalition "Frente Amplio" opponent "Yamand" Orsi (Figure 3.10.8). However, Oris did not appear on the show, instead "appearing" through an AI-powered hologram that, according to the show's host, has lines taken from a recent interview with the candidate. Before the debate began, Oris and his party criticized the act as a "fake interview" on another channel and called it "an attack on democracy." The next day, the host responded that the act was neither fake news nor an attack on democracy, but just a joke. Pakistani political party leader deepfakes video calling for election boycott (Pakistan, audio and video, X/Twitter, February 7, 2024)
The day before Pakistan's general elections, former Prime Minister and PTI (
PTI) founder Imran A recording of Khan's voice was circulated on social media (Figure 3.10.9). The recording refers to the crackdown on PTI by state institutions and calls for a boycott of the elections, saying that voting is meaningless. PTI's official X account denounced the recording as a fake. A video released on the same day showed another prominent PTI leader, Yasmin Brown, Rashid also appears to be calling for a boycott of the elections. In the video of the contrastive language-image pre-training, Rashid appears behind bars and the recording claims that the Election Commission of Pakistan has been "bought". Soch Fact Check, a nonprofit fact-checking organization, determined that the video had been tampered with.
Source: Rest of the World, 2024
Figure 3.10.8
Source: World Other, 2024 Figure 3.10.9 Table of Contents Chapter 3 Preview Artificial Intelligence in 2132025
Chapter 3 of the Index Report: Responsible AI
3.10 Topic on Responsible Artificial Intelligence
AI-generated pavement potholes try to influence South African voters (South Africa, photo,
X/Twitter, Facebook, Instagram, Reddit, May 4, 2024)
On May 4, a Facebook user posted an AI-generated post
shows a pothole-riddled road leading to Cape Town's iconic Table Mountain (Figure 3.10.11). The caption below the image suggests that during the Democratic Alliance's rule, the municipality failed to maintain basic public services, resulting in a deterioration of infrastructure. Many retweeted the image to dissuade voters in the Western Cape from supporting the Democratic Alliance, which has been in power for 15 years. Even though the original post has been removed from Facebook, it is still circulating on other social media platforms. AFP Fact Check, which is affiliated with Agence France-Presse, reported that the image was generated by artificial intelligence and traced back to an Instagram user who created AI art.
Source: Rest of the World, 2024
Figure 3.10.11
Artificial intelligence in 2025
Index Report
Chapter 4:
economy
Text and Analytics Artificial Intelligence 2025 from Njenga Kariuki
Index Report
Table of Contents Chapter 4 Preview 215 Chapter 4: The Economy
260
260260264
267
272
272274275279216
217
219
223223223
225
228229232234236242
246
246
247247
251
255258
Get the main points of the Public Data Overview section
4.1 Timeline of major events in the field of artificial intelligence in 2024
4.2 Job Position
AI Workforce Demand Global AI Workforce Demand by Skill Cluster and Specialized Skills, U.S. AI Workforce Demand U.S. AI Workforce Demand by Industry U.S. State AI Workforce DemandAI RecruitmentAI Skills Penetration AI Talent Focus: Measuring the Integration of AI into the Economy
4.3 Investments
Corporate Investment: Start-up Activities Global Trends Regional Comparison by Funding Size Newly Funded AI by Region Company Comparison Analysis of Focus Areas4.4 Sector Usage of Corporate Activities Harnessing AI Capabilities The impact of generative AI capabilities on the workforce deployed by generative AI capabilities
4.5 Robot Deployment
Overall Trends Industrial Robots: Traditional Robots vs. Cobots by Geography Country-Level Data for Service Robots 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview 216Chapter 4:
economy
overview
The economic impact of AI in 2024 will be further highlighted, with a substantial impact on many industries. Generative labor
The early productivity gains that intelligence brings to specific tasks are quantifiable, but the long-term impact of the technology on the macroeconomy
Rings are still controversial. The labor market is showing signs of AI-driven transformation: Some knowledge-based occupations are undergoing structural adjustments as new AI-related jobs emerge. Enterprises across industries and geographies are shifting from experimental applications to systematically integrated AI technologies. The investment trend also reflects the increasing maturity of the AI ecosystem, and the increasing concentration of funds on special applications of enterprise automation and vertical industry solutions.
This section is based on Lightcast, LinkedIn, Quid, McKinsey & Company, and International Federation of Robotics (IFR) data.
Dissect economic trends related to artificial intelligence. Firstly, the labor demand, recruitment trends, skill penetration rate and talent supply status of AI-related occupations are analyzed. The chapter then explores corporate investments in AI, with a section focusing specifically on generative AI. Finally, it assesses the impact of AI on productivity and the installation of robots across a wide range of industries. Chapter 4:
economy
1. Global private AI investment is at an all-time high, up 26%. In 2024, global enterprise AI investment will reach $252.3 billion, with private investment increasing year-on-year
44.5%, and the size of M&A transactions increased by 12.1% compared to the previous year. Over the past decade, the sector has experienced significant expansion, with total investment increasing more than thirteenfold since 2014.
2. Generative AI investment has skyrocketed. In 2024, private investment in generative AI reached $33.9 billion, an increase of 18.7% from 2023, which was 2022
8.5 times more than the level. This sector currently accounts for more than 20% of all AI-related private investment combined. 3. The U.S. has extended its lead in global private investment in AI. In 2024, the scale of private investment in AI in the United States will reach $109.1 billion, which is nearly the same as China's
12 times ($9.3 billion) and 24 times ($4.5 billion) in the UK. In generative AI, the U.S. has invested $25.4 billion more than China, the European Union, and the U.K. combined
USD, which continues to widen from the 21.8 billion dollar deficit in 2023.
4. The use of artificial intelligence is at an unprecedented level. In 2024, the percentage of companies surveyed reporting adoption of AI technology jumped to 78% from 55% in 2023. equally
The number of respondents using generative AI in at least one business function has more than doubled – from 33% in 2023 to 71% in 2024.
5. AI has begun to generate financial benefits across multiple business functions, but most businesses are still in the early stages of adoption. The report shows that labor is applied within a single business function
In companies that are smart and financially beneficial,
Most of the feedback benefit levels are still in the low range. In terms of cost savings, there are businesses that use AI in their customer service operations
Forty-nine percent of respondents reported cost reductions, compared to 43 percent in supply chain management and 41 percent in software engineering. However, most of the cost reductions reported by these companies have been inadequate
10%。 In terms of revenue growth, 71% of respondents in marketing and sales have applied AI to report an increase in revenue, compared to 63% in supply chain management and service operations
57% for domains. It should be noted, however, that these revenue increases are generally less than 55.
6. The application of artificial intelligence presents obvious regional differences, with Greater China emerging rapidly. Although North America still maintains the leading position in the adoption rate of enterprise AI, but
Greater China had one of the highest year-over-year growth rates, with a 27% increase in enterprise AI adoption. Europe followed with a 23% growth, indicating that the global AI landscape is rapidly evolving and countries are becoming increasingly competitive in the field of AI applications. Chapter Highlights: Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview Artificial Intelligence in 2172025
Index Report
Chapter 4:
economy
7. China still dominates the field of industrial robots, albeit with a slight slowdown. In 2023, China will install 276,300 industrial robots, six times more than Japan and 7.3 times that of the United States.
Since surpassing Japan in 2013, China's share of global industrial robot installations has risen from 20.8% to 51.1%. While China continues to outperform the world in robot installations
other countries combined, but this gap narrowed slightly in 2023, marking a slight slowdown in the momentum of its sharp expansion.
8. The use of collaborative and interactive robots is becoming more common. In 2017, cobots accounted for only 2.8% of all newly installed industrial robots, and by 2023, this number climbs to:
10.5%。 Similarly, in 2023, the number of service robot installations in all application areas will show an increasing trend, except for medical robots. This trend is not only indicative of the total number of robot installations
body growth, It also indicates that there is a growing emphasis on the deployment of robots in human-oriented jobs.
9. Artificial intelligence (AI) is driving a major change in the energy mix and triggering a new round of attention to nuclear energy. Microsoft announced a $1.6 billion restart of the Three Mile Island nuclear reactor for artificial intelligence
and Google and Amazon have also signed nuclear energy agreements to support AI businesses. 10. AI improves productivity and closes the skills gap. Last year's AI Index report was one of the first to highlight the positive impact of AI on productivity
One. More research this year further validates these findings, confirming that AI can not only improve productivity, but in many cases also help shrink both high- and low-skilled workers
capacity gaps. Chapter Highlights (continued)
Table of Contents Chapter 4 Preview 218 This chapter begins with an overview of the most promising AI in 2024
Loud economic events, which are organized by the Steering Committee of the Artificial Intelligence Index
Authoritative selection.
4.1 Timeline of major events in the field of artificial intelligence in 2024 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 219 Chapter 4: The Economy
Timeline of big events in the field of artificial intelligence in 2024
January 16, 2024
February 21, 2024
February 29, 2024
March 21, 2024
Figure 2.1.6 on March 21, 2024
Source: Inflection, 2025Synopsys acquires Ansys for $35 billion
Chip-to-system-level full-stack design solutions
There are reports that OpenAI's annualized revenue is in 2023 
It surpassed $2 billion in December.
Humanoid robotics startup Figure AI won with 2.6 billion
$675 million in U.S. dollar valuation.
Microsoft hired Inflection, including co-founders 
The majority of AI's employees, and paid $650 million to license Inflection's AI models.
CoreWeave, an AI cloud infrastructure start-up 
Secured $1.1 billion in financing at a valuation of $19 billion. Date, Event, Type, Image
acquisition
Valuation milestones
Investment/Financing
acquisition
Investment/Financing
Figure 4.1.2
Source: Inc, 2024
Figure 4.1.4 Source: Reuters, 2024
Figure 4.1.5
Source: Fortune, 2024
Figure 4.1.3 Source: SiliconAngle, Artificial Intelligence 20242025
Chapter 4 of the Index Report: Economy
Timeline of big events in the field of artificial intelligence in 2024
June 11, 2024
June 14, 2024
August 2, 2024 July 22, 2024
Figure 4.1.8 on August 5, 2024
Source: Reuters, 2024 Figure 4.1.7
Source: TechCrunch, 2024
Tempus AI, a precision medicine artificial intelligence company, has been successful
City, which raised $410.7 million and exceeded $6 billion at Mistral, a French open-source AI model startup 
AI raised $640 million at a $6 billion valuation.
Cohere, an artificial intelligence company focused on enterprise applications
Startup, closing $500 million funding round at a $5.5 billion valuation.
Google acquires Character.AI for about $2.5 billion
shareholder shares, and licensing the startup's AI technology. The acquisition includes the introduction of Character.AI's co-founders and research team members.
Groq, an artificial intelligence chip focused on fast inference
The startup, which raised $640 million in its latest funding round, valuing the company at $2.8 billion.
Table of Contents Chapter 4 Preview 220 Investment/Financecapital
Investment/Financing
Investment/Financing
Investment/Financing
acquisition
Investment/Financing
Figure 4.1.9
Source: Crunchbase, 2024
Figure 4.1.10 Source: The Verge, 2024
Figure 4.1.11
Source: GroqGroq, 1 May 20242024Data Label Startup Scale AI Raises $1 Billion,
The valuation reached $13.8 billion.
Figure 4.1.6
Source: Reuters, 2024
August 12, 2024
On September 5, 2024, AMD acquired Europe's largest private company for approximately $665 million
Silo AI, a human artificial intelligence lab.
Safe Superintelligence (SSI) gets 1 billion
U.S. dollar financing. Figure 4.1.12
Source: AMD, 2024
Figure 4.1.13
Source: TechCrunch, Artificial Intelligence 20242025
Chapter 4 of the Index Report: Economy
Timeline of big events in the field of artificial intelligence in 2024
Table of Contents Chapter IV Preview 221
September 12, 2024
September 20, 2024
October 2, 2024
October 14, 2024
On October 16, 2024, Salesforce launched Agent-
force, which is an autonomous AI agent suite for business operations.
Microsoft announced a partnership with Constellation Energy
a $1.6 billion agreement to restart the Three Mile Island nuclear reactor to power an AI data center.
Google has announced an agreement with Kairos Power that will start with
The company has developed several small modular reactors (SMRs) to purchase nuclear energy.
Amazon has announced a partnership with Energy Northwest and X-energy
Partnered with Dominion Energy to launch a small modular reactor (SMR) development nuclear energy program. OpenAI, with a valuation of $157 billion,
$6.6 billion raised. acquisition
Investment/Financing
Product launches/integrations
Partners
Investment/Financing
Partners
Partner Figure 4.1.14
Source: Salesforce, 2024
Figure 4.1.15 Source: National Public Radio, 2024
Figure 4.1.16
Source: Axios, 2024
Figure 4.1.17
Source: Google, 2024
Figure 4.1.18
Source: Amazon, 2024
Artificial intelligence in 2025
Chapter 4 of the Index Report: Economy
Timeline of big events in the field of artificial intelligence in 2024
Table of Contents Chapter 4 Preview November 22, 2222024 October 17, 2024Google's NotebookLM removed the "experimental" label
and has millions of users and more than 80,000 organizations.
Anthropic expands partnership with AWS, Amazon reinvests
$4 billion, bringing the total investment to $8 billion. Figure 4.1.19
Source: Google, 2024
Figure 4.1.20
Source: Anthropic, 2024
December 17, 2024
December 18, 2024
December 23, 2024
December 30, 2024 Artificial intelligence data analytics company Databricks in the most
$10 billion was raised in the new funding round, valuing the company at $62 billion.
Startups focused on AI-powered search products 
Perplexity AI raised $500 million at a $9 billion valuation.
Nvidia acquires Israeli startup for $700 million 
Run:AI, to enhance its GPU optimization capabilities in computing power-hungry environments. xAI announced the closing of a $6 billion funding round, with a cumulative total of fundraising
$12 billion, with a valuation of more than $40 billion. Product launches/integrations
Partners
Investment/Financing
Investment/Financing
Investment/Financing
Acquisition Figure 4.1.21
Source: TechCrunch, 2024
Figure 4.1.22
Source: Journal of Artificial Intelligence, 2024
Figure 4.1.23
Source: Forbes, 2024
Figure 4.1.24
Source: TechCrunch, 2024
Artificial intelligence in 2025
Chapter 4 of the Index Report: Economy
4.2 Job Position
Table of Contents Chapter 4 Preview 2234.2 Jobs
AI workforce needs
This section uses data provided by Lightcast to analyze the labor market's impact on labor
The need for intelligence-related skills. Lightcast has been analyzing since 2010
Hundreds of millions of job postings from more than 51,000 websites and filter out jobs that require AI skills.
Global AI Workforce Demand
Figures 4.2.1 and 4.2.2 show the percentage of jobs that require AI skills. In 2024, Singapore (3.2%), Luxembourg (2%), and China
Hong Kong (1.9%) leads the way in this indicator. In 2023, AI-related jobs accounted for 1.4% of job postings in the U.S., rising to 1.8% by 2024. From 2023 to 2024, the proportion of jobs in demand for AI skills has increased in most countries.
2014-2024 AI Job Postings by Selected Geographic Region (% of All Job Vacancies) (Part 1)
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.12014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.00%1.00%2.00%3.00%4.00%5.00%
3.27%, Singapore
1.99%, Luxembourg 1.89%, Hong Kong 1.79%, United States 1.72%, United Arab Emirates 1.41%, Canada 1.37%, Switzerland 1.31%, Belgium 1.31%, Sweden 1.26%, United Kingdom 1.25%, Netherlands AI job postings (% of all job postings) AI in 2025
Index Report
Table of Contents Chapter 4 Preview 2242014-2024 AI Job Vacancies by Selected Geographic Region (% of All Job Vacancies) (Part 2)
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.2 Ratio of AI job postings (proportion of all job postings)
2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.00%1.00%2.00%3.00%4.00%5.00%
1.24%, Spain
1.15%, Germany 1.14%, Australia 1.10%, France 1.06%, Austria 0.87%, Italy 0.73%, Mexico 0.65%, Chile 0.55%, New Zealand
0.13%, Croatia Chapter IV: Economy
4.2 Jobs 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview 2252014-2024 AI Job Vacancies by Technology Cluster (% of All Job Vacancies)
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.3 1 AI job vacancies (as a percentage of all job postings) by skill cluster and specialized skills, U.S. AI labor demand
Figure 4.2.3 shows the hottest in the U.S. labor market since 2010
's artificial intelligence skills. Artificial intelligence accounts for 0.9% of the demand, followed by machines
learning (also 0.9%) and natural language processing (0.2%). Since last year, most of the AI-related skill clusters tracked by Lightcast have seen market share growth, with the exception of autonomous driving and robotics. Generative AI saw the largest increase, with a nearly fourfold increase.
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.00%0.20%0.40%0.60%0.80%1.00%
0.94%, artificial intelligence
0.92%, machine learning
0.23%, natural language processing 
0.22%, Generative AI 0.16%, Neural Networks 0.13%, Autonomous Driving 0.09%, Visual Image Recognition 0.07%, Robotics 0.02%, AI Ethics, Governance and Regulations 
1. A job posting can list a variety of AI skills. Chapter 4: Economy
4.2 Jobs 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview 2262012-2014 vs. 2024 Top 10 Professional Skills in U.S. AI Job Recruitment Comparison
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.4 Figure 4.2.4 compares the most in-demand AI job openings in 2024
10 professional skills and demand between 2012 and 2014. 2 from absolutely
The demand for each specialized skill has increased over the past decade, with Python's significant growth highlighting its position as the AI programming language of choice
Bit.
2. The decision to choose 2012-2014 as the point of comparison was due to the scarcity of job/skills data in previous years. For this reason, Lightcast uses data from 2012-2014 and uses a large sample size as a benchmark from 10 years ago. Figure 4.2.4 will be 2012 to 2014 
The total number of job postings that require specific skills in the year is tied with the total number in 2024. Chapter 4: Economy
4.2 Job Position
Number of Artificial Intelligence Job VacanciesPython ( Programming Languages )
computer science
data analysis
SQL ( Programming Language )
Data science
automation
project management
Amazon Web Services
Agile development methodology
System scalability architecture 19, 88620, 3305, 37154, 03522, 15711, 86151, 30441, 84283, 82631, 782
86,990 (+337%)88,141 (+334%)100,881 (+1,778%)101,127 (+87%)102,210 (+361%)110,620 (+833%)119,441 (+133%)128,938 (+208%)193,341 (+131%)199,213 (+527%)
0 50,000 100,000 150,000 200,0002024
2012-142025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview In 2272024, the number of jobs in U.S. job postings mentioning generative AI skills more than tripled from the previous year (Figure 4.2.5). Figure 4.2.6 shows the year 2024 and
The percentage of AI job postings published in 2023 that mention specific generative AI skills.
Generative AI skills in 2023 vs. 2024 U.S. AI job postings
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Percentage of U.S. AI job postings with generative AI skills in 2023 and 2024
Source: Lightcast, 2024| Chart: Artificial Intelligence Index Report 2025 Figure 4.2.5
Figure 4.2.6 Chapter 4: Economy
4.2 Job Position
Artificial intelligence, number of job openings, generative AI 
Large language models
ChatGPT
Prompt engineering
Generative adversarial networks
Text-to-speech (TTS) 
Retrieval enhancement generation
Microsoft Copilot variation
Autoencoder
Multimodal Model 15,741
4,956
1,3933,047
1321,323
642,021
400
4466,635 (+323%)
19,562 (+295%)
6,263 (+350%)5,664 (+86% )
2,834 (+2,047%)2,213 (+67%)
1,496 (+2,238%)1,045 (-48%)
756 (+89%)
733 (+1,566% )
0 6,000 12,000 18,000 24,000 30,000 36,000 42,000 48,000 54,000 60,000 66,000 72,000 78,0002024
2023
Generative AI 
Large language models
ChatGPT
Prompt engineering 
Text-to-speech (TTS)
Generative adversarial networks 
Retrieval enhancement generation 
Variable autoencoder
Microsoft Copilot
Multimodal model52.23%
16.45%
4.62%10.11%
0.44%4.39%
0.21%6.71%
1.33%
0.15%60.48% (+16% )
17 .76%  (+8%)
5.68% (+23%)5.14% (-49%)
2.57% (+487%)2.01% (-54%)
1.36%  (+539%)0.95% (-86% )
0.69% (-48%)
0.67% (+356% )
0% 10% 20% 30% 40% 50% 60%2024
Artificial intelligence in 20232025
Index Report
Table of Contents Chapter 4 Preview 228 Information
Professional, scientific and technical services
Finance and insurance
manufacturing
utility
Educational services
Corporate and business management
Mining, quarrying, and oil and gas extraction
Public Administration 
Real Estate & Rental
Wholesale and retail trade
Agriculture, forestry, fishing, and hunting
Transportation and warehousing
Waste Management and Administrative Support Services: 2023 vs. 2024 U.S. AI job openings by industry as a percentage of total job postings
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.7 3 AI labor demand by industry in the United States
Figure 4.2.7 shows the U.S. industry sector for people from 2023 to 2024
The proportion of jobs in demand for intelligent skills. Compared to 2023, 2024 is almost the same
The proportion of jobs in demand for AI skills has increased in all sectors, except in public administration. In 2024, the proportion of jobs in demand for AI skills increased in almost all industry sectors compared to 2023, with the exception of public administration.
3. The industry classification in Figure 4.2.7 is based on two-digit NAICS codes. For more information about the Bureau of Labor Statistics' supra-industry classification and NAICS classification, see the following references. Artificial Intelligence Job Recruitment (% of All Job Vacancies) Chapter 4: The Economy
4.2 Job Position
0.41%0.61%0.87%0.57%0.84%0.85%1.76%1.11%1.69%1.79%1.39%2.88%3.24%4.00%5.19%
0.48% (+15.65%)0.82% (+35.81%)1.07% (+22.26%)1.16% (+101.95%)1.20% (+43.41%)1.21% (+41.95%)1.29% (- 26.93%)1.87% (+67 .82%)1.92% (+13.57%)2.05% (+14.98%)2.15% (+55.08%)3.75% (+ 30.21%)3.76% (+16.15%)5.25% (+31.20%)9.33% (+79.56%)
0% 1% 2% 3% 4% 5% 6% 7% 8% 9% 10% 11%2024
Artificial intelligence in 20232025
Index Report
Table of Contents Chapter 4 Preview 229 Chapter 4: The Economy
4.2 Job Position
Number of AI job postings by state in the United States in 2024
Source: Lightcast, 2024 | Chart: 2025 Artificial Intelligence Index Report
Percentage of AI job postings in U.S. states as a percentage of total state job postings in 2024
Source: Lightcast, 2024 | Chart: The 2025 AI Index reports on AI labor demand by state in the United States  
Figure 4.2.8 shows the number of AI job openings in each state in the United States. Top
The three states are California (103,375) and Texas (57,785).
New York (37,944). Figure 4.2.9 shows the percentage of AI-related job postings in each state for the total number of jobs in the state
Percentage of published volume. According to this indicator, the top three states are Washington, D.C. (
4.4%), Delaware (3.4%), and Washington (3.3%).
Figure 4.2.8
Figure 4.2.9 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 230 Chapter 4: The Economy
4.2 Job Position
Percentage of AI job postings by state in the U.S. in 2024
Source: Lightcast, 2024 | Chart: 2025 Artificial Intelligence Index Report
Percentage of AI jobs in selected U.S. states as a percentage of total job postings in the state, 2010-2024
Source: Lightcast, 2024 | Chart: Chart 4.2.10 of the 2025 AI Index Report
Figure 4.2.11 Figure 4.2.10 shows which states in the United States are available for AI jobs
Releases account for the largest proportion in the country. In 2024, 15.7% in the United States 
of AI was published in California, followed by Texas (8.8%) and New York (5.8%).
Figure 4.2.11 illustrates four jobs with a large number of AI jobs
Hiring information trends in states – Washington, California, New York and Texas. From 2023 to 2024, all four states saw a significant increase in the share of AI-related job postings in total job postings.
Percentage of jobs posted in the field of artificial intelligence by state in the United States
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240.00%0.50%1.00%1.50%2.00%2.50%3.00%3.27%, Washington
2.67%, California
2.19%, New York
1.86%, the percentage of selected states in Texas that posted AI jobs nationwide from 2010 to 2024
Source: Lightcast, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.12 Figure 4.2.12 shows that AI-related jobs have come to the fore over time
Distribution of the four states. In 2024, all four states reversed years of labor
Trends in the proportion of intelligence-related jobs. AI job postings – The changes are particularly noticeable in California, where job postings have decreased since 2020. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 231 Chapter 4: The Economy
4.2 Job Position
Percentage of AI job openings in the United States
2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 20240%5%10%15%20%25%
15.70%, California
8.77%, Texas
5.76%, New York
4.72%, Washington State's relative hiring rate for AI by geographic region year-over-year in 2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.13 5 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 232 Chapter 4: The Economy
4.2 Job Position
AI Recruitment
The recruitment data provided in the AI Index is based on the economy of LinkedIn (LinkedIn).
The Economic Graph reflects the work of the platform's more than 1 billion members
Skill situation. As a result, data can be influenced by how members choose to use the platform, which may vary depending on occupation, social and regional culture, and the overall usability and accessibility of the website. The AI Index notes that Hungary, Indonesia, India, and South Korea have a low percentage of LinkedIn coverage in the sample, so special caution should be exercised when interpreting the situation in these countries.
Figure 4.2.13 reports the relative recruitment rate of AI by geographic region
Year-on-year ratio. The overall hiring rate is calculated by dividing the number of LinkedIn members who added new employers by the total number of LinkedIn members in the region during the same time period. Conversely, the relative AI talent acquisition rate refers to the year-over-year change in AI hiring compared to the overall hiring rate in the same geographic region. 4 Thus, Figure 4.2.13 illustrates AI talent
Regions with the highest hiring activity – AI talent recruitment growth in these regions is significantly outpacing overall hiring growth. In 2024, the countries with the most significant year-on-year growth in the relative recruitment rate of AI talent are: India (33.4%), Brazil (30.8%), and Saudi Arabia (28.7%). This means that, in the case of India, the ratio of the number of AI talent hires to the overall number of hires in 2024 increased by 33.4 percentage points year-on-year.
Figure 4.2.14 shows the year-over-year growth of AI hiring by region over the past five years.
Starting in 2024, South American countries such as Argentina, Brazil, and Chile will see a significant increase in AI recruitment rates. Other countries that have seen similar growth recently include Canada, India, South Africa and the United States.
4. LinkedIn calculates the AI hiring rate for a geographic region on a monthly basis, divides it by the overall hiring rate for that region, calculates the annual change in that ratio, and then takes a moving average over the past 12 months.
5. For brevity, the visualization includes only the top 15 countries for this indicator. Artificial intelligence relative recruitment rate year-on-year ratio23.60%24.02%24.24%24.58%24.73%24.88%24.97%26.13%26.39%26.98%27 .31%28.21%28.71%30.83%33.39%
0% 5% 10% 15% 20% 25% 30% 35% India
Brazil
Slovenia, Saudi Arabia
Romania
Finland
Argentina, Canada, Singapore, United Arab Emirates
United States
Ireland
South Africa
Mexico
Latvia Artificial Intelligence Relative Recruitment YoY by Geographical Region 2018-2024
Source: LinkedIn, 2024| Chart: Artificial Intelligence Index 2025 Report Artificial Intelligence 2025
Index Report
Table of Contents Chapter 4 Preview 233 Chapter 4: The Economy
4.2 Job Position
Figure 4.2.14 Relative Recruitment Rate of AI Year-on-Year Ratio: 2018 2021 20240%, 50%, 100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240%50%100%
2018 2021 20240% 50% 100% Argentina Australia Austria Belgium
Brazil, Canada, Chile, Costa Rica
Croatia, Cyprus, Czech Republic, Denmark
Estonia, Finland, Finland, Germany
Greece, Hong Kong Hungary, India
Indonesia, Ireland, Israel, Italy
Latvia, Lithuania, Luxembourg, Mexico
Netherlands, New Zealand, Norway, Poland
Portugal, Romania, Saudi Arabia, Singapore
Slovenia, South Africa, South Korea, Spain
Sweden, Sweden, Turkey, United Arab Emirates
United Kingdom United States Uruguay 26.39% 16.78% 16.23% 10.53%
30.83% 26.12% 22. 18% 17 .61%
7 .62% 6.86% 11.29% 20.47%
17 .40% 26.98%5.75% 9.10%
14.52% 20.83% 22.34% 33.39%
16.61% 24.58% 14.28% 19.78%
23.59% 12.20% 9.15%24.02%
8.57% 12.72% 13.33% 13.05%
19.67% 27 .31% 28.71% 24.97%
28.21% 24.24% 13.21% 18.22%
19.12% 18.43% 20.36% 24.88%
13.78% 24.73% 13.22% Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 234 Chapter 4: Economy
4.2 Job Position
Relative penetration of AI skills by geographic region, 2015-2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.15 AI Skills Penetration
Figures 4.2.15 and 4.2.16 highlight the relative penetration of AI skills
Rate. This indicator is designed to measure the strength of AI skills in a particular country, industry, or gender
Degree. The penetration rate of AI skills indicates the prevalence of AI skills in various occupations
and degree, or the intensity of LinkedIn members' use of AI skills at work. For example, the top 50 skills for an engineer's career are calculated based on how often they appear on LinkedIn member profiles. For example, if 4 of the skills an engineer has belong to the AI skill group, the prevalence of AI skills among engineers is estimated to be 8% (4/50). Between 2015 and 2024, AI skills adoption is the highest
The countries are the United States (2.6) and India (2.5). This was followed by the United Kingdom (1.4), Germany (1.3) and Brazil (1.3). As a result, the relative penetration of AI skills in the U.S. is 2.6 times higher than the global average in the same group of occupations.
0.870.900.920.940.951.001.041.101.231.301.311.321.402.512.63
0.00 0.50 1.00 1.50 2.00 2.50 US
India, Great Britain
Germany
Brazil
Canada
France
Spain
Indonesia
globe
Australia
Turkey
Netherlands
Italy, Israel
Artificial Intelligence Relative Skills Penetration Rate Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 235 Chapter 4: The Economy
4.2 Job Position
Relative penetration of AI skills by gender, 2015-2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.16Figure 4.2.16 Breakdown of AI skills by gender in different countries or regions
Permeability. A country has a female penetration rate of 1.5, which means LinkedIn women in that country
Members are 1.5 times more likely to have AI skills than the global average for all countries. In all sample countries, with the exception of Saudi Arabia, men had a higher penetration rate of AI skills than women. Among all sample countries, India (1.9) and the United States
(1.7) and Canada (1.0) reported the highest relative penetration of women's AI skills.
India
United States
Canada
United Kingdom, Germany, France, Brazil
Israel, Spain
Netherlands
Australia
Italy, Turkey, Singapore
Saudi Arabia
The relative AI skill penetration rate is 0.610.640.660.670.680.720.750.790.830.830.890.900.971.711.91
0.590.770.960.910.890.981.130.891.301.251.341.291.302.392.38
0.00 0.50 1.00 1.50 2.00 2.50 male
Female Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 236 Chapter 4: The Economy
AI Talent by Geographic Region, 2016 vs. 2024
Proportion of change in concentration
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Israel
Singapore
Luxembourg
Estonia
Switzerland
Finland
Ireland
Germany, Netherlands
 Korea
Lithuania
Poland
Canada, Hungary
Sweden, India
Costa Rica
Portugal
Cyprus
Brazil
Estonia
Turkey
Croatia
Denmark 
Indonesia
Iceland 
Uruguay 
Argentina
4.2 jobs in Canada UAE
Artificial intelligence talents
Figures 4.2.17 and 4.2.18 classify AI talent by country. If collared
Members have explicitly added AI skills, engaged in, or worked on in their profiles
It's over
AI jobs, then they are considered AI talents. Artificial intelligence
The number of capable talents is calculated as the concentration of talents, that is, the number of AI talents among the members
Proportion. Please note that talent concentration metrics may be affected by LinkedIn in these countries
home coverage of the impact, so caution should be used.
AI Talent Concentration by Geographic Region, 2024
Source: LinkedIn, 2024| Chart: The AI Index 2025 report Figure 4.2.17 shows the concentration of AI talent in different geographic regions.
In 2024, the countries with the highest concentration of AI talent include Israel (2.0%), Singapore
Canada (1.6%) and Luxembourg (1.4%). Figure 4.2.18 shows the percentage change in AI talent concentration in selected countries since 2016. During this period, the AI talent pool in several major economies has increased substantially. The largest increases were in India (252%), Costa Rica (240%) and Portugal (237%).
There are also significant gender differences in the distribution of AI talent. in the analytical sample
In all countries, with the exception of India and Saudi Arabia, the concentration of male AI talent is higher than that of women (Figure 4.2.19). Israel reported the highest concentration of female AI talent in 2024 at 1.6%. Artificial intelligence talent concentration 1.98%
1.64%
1.44%
1.17%
1.16%
1.13%
1.11%
1.09%
1.07%
1.06%
1.06%
0.94%
0.93%
0.92%
0.90%
0.00% 0.50% 1.00% 1.50% 2.00%166%168%170%171%173%191%192%192%198%207%217%219%237%240%252%
0% 40% 80% 120% 160% 200% 240% 280%
Figure 4.2.18 Figure 4.2.17 Proportion of AI Talent Concentration Change AI Talent Concentration Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 237 Chapter 4: The Economy
4.2 Job Position
Concentration of AI talent by gender and geographic region, 2016-2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.19 Artificial Intelligence Talent Gathering 2016 2020 20240.00%0.20%0.40%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.20%0.40%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.20%0.40%0.60%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%1.00%2.00%
2016 2020 20240.00%1.00%2.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%1.00%2.00%3.00%
2016 2020 20240.00%0.20%0.40%0.60%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%1.00%2.00%
2016 2020 20240.00%0.20%0.40%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%
2016 2020 20240.00%0.20%0.40%0.60%
2016 2020 20240.00%1.00%2.00%
2016 2020 20240.00%0.20%0.40%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%1.50%
2016 2020 20240.00%1.00%2.00%
2016 2020 20240.00%0.20%0.40%
2016 2020 20240.00%0.20%0.40%0.60%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.50%1.00%
2016 2020 20240.00%0.20%0.40%0.18%0.45%
0.52%1.00%
0.48%1.07%
0.39%0.95%
0.11%0.37%
0.61%1.15%
0.17%0.49%
0.45%0.85%
0.46%0.83%
0.59%1.27%
0.47%1.14%
0.44%1.07%
0.81%1.69%
0.75%1.71%
0.53%1.06%
0.65%1.38%
0.62%1.38%
0.52%1.05% 0.92%
0.89%0.75%1.40%
1.60%2.88%
0.29%0.55%
0.46%0.95%
0.74%1.47%
0.96%1.86%
0.18%0.39%
0.72%1.38%
0.46%0.81%
0.44%0.86%
0.59%1.30%
0.36%0.88%
0.47%0.75%
0.60%
0.40% 1.35%1.91%
0.24%0.40%
0.37%0.86%
0.58%1.21%
0.70%1.55%0.33%0.42%
0.55%0.59%
0.56%1.08%
0.51%0.99%
0.15%, 0.45%, Argentina, Australia, Austria, Belgium
Brazil, Canada, Chile, Costa Rica
Croatia, Cyprus, Czech Republic, Denmark
Estonia, Finland, Finland, Germany
Greece, Hong Kong, India, Ireland
Israel, Italy, Latvia, Lithuania
Luxembourg, Mexico, Netherlands, New Zealand
Norway, Poland, Poland, Romania
Saudi Arabia, Singapore, South Africa, Spain
Sweden, Sweden, Turkey, United Arab Emirates
United Kingdom, United States, Uruguay
man
Female Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 238 Chapter 4: The Economy
4.2 WorkPost
Global AI talent distribution from 2016 to 2024
Source: LinkedIn, 2024| Chart: The 2025 AI Index report LinkedIn also tracks the gender distribution of AI talent (Figure 4.2.20). It is estimated that in 2024, 69.5% of AI professionals on the platform will be men, and 30.5% 
for women. This ratio has remained stable over time.
LinkedIn's data on AI talent can also be broken down by country. In each of the countries in the sample, a higher proportion of men than women held AI positions (Figure 4.2.21).
New Zealand and Romania have the most balanced gender distribution, while Brazil and Chile have the least balanced gender distribution. Figure 4.2.20 Distribution of AI talent
2016 2017 2018 2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%70%80%
30.54%, 69.46% female, male artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 239 Chapter 4: The Economy
4.2 Job Position
Proportion of AI talent distribution by gender and geography, 2016-2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.21 AI Talent Representatives 2016 2020 20240% 50% 100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%
2016 2020 20240%50%100%28.64%71.36%
31.39%68.61%
24.34%75.66%
24.13%75.87%
22.89%77 .11%
32.22%67 .78%
22.89%77 .11%
31.35%68.65%
34.92%65.08%
27 .16%72.84%
26.35%73.66%
25.72%74.28%
32.90%67 .10%
35.66%64.34%
31.05%68.95%
23.77%76.23%
26.95%73.05%
31.77%68.23%
29.92%70.08%
31.69%68.31%
25.84%74.16%
34.05%65.94%
38.54%61.46%
33.37%66.63%
27 .58%72.42%
25.95%74.05%
28.32%71.68%
34.25%65.75%
27 .39%72.61%
30.79%69.21%
27 .49%72.51%
41.00%59.00%
30.98%69.02%
37 .09%62.91%
35.29%64.71%
27 .79%72.21%
28.62%71.38%
25.06%74.94%
28.76%71.24%
29.39%70.61%
29.50%70.50%
33.68%66.32%
26.50%, 73.50%, Argentina, Australia, Austria, Belgium
Brazil, Canada, Chile, Costa Rica
Croatia, Cyprus, Czech Republic, Denmark
Estonia, Finland, Finland, Germany
Greece, Hong Kong, India, Ireland
Israel, Italy, Latvia, Lithuania
Luxembourg, Mexico, Netherlands, New Zealand
Norway, Poland, Poland, Romania
Saudi Arabia, Singapore, South Africa, Spain
Sweden, Sweden, Turkey, United Arab Emirates
United Kingdom, United States, Uruguay
man
Net migration of female AI talent (per 10,000 LinkedIn members) Luxembourg
Cyprus
UAE
Switzerland
Ireland
Germany
Austria
Saudi Arabia
Australia
Finland
Singapore
Denmark
USA, Hong Kong, Poland, 2025, Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview 240 Chapter 4: The Economy
4.2 Job Position
Net migration of AI talent per 10,000 members of LinkedIn by geographic region in 2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.22 LinkedIn's data reflects the flow of AI talent due to migration trends
Circumstance. 6 Net inflows are defined as the number of arrivals minus the number of departures in a given time period
Sum. If the net migration score for AI talent is positive, it indicates entry into the place
There are more people in the district than there are people leaving. A negative number means that more talent is leaving the region than it is entering. Figure 4.2.22 shows the net inflow of AI talent per 10,000 LinkedIn members by geographic region. The regions with the highest migration per capita of AI talent are Luxembourg (8.9), Cyprus (4.7), and the United Arab Emirates (4.1).
Figure 4.2.23 illustrates the evolution of AI talent mobility data over time.
In recent years, countries such as Israel, the Netherlands, and Canada have shown a downward trend in the net flow of AI talent, indicating that the number of AI talent flowing to these countries has decreased. Countries with increasing talent flows include the United Arab Emirates, Saudi Arabia and Luxembourg.
6) The number of LinkedIn members varies significantly between countries, making it difficult to interpret the absolute change in membership migration from one country to another. In order to fairly compare migration traffic between countries, migration traffic is normalized for the target country. For example, if A 
If country is of interest, all absolute net flows to and from country A (both source and destination) are normalized based on the number of LinkedIn members in country A at the end of each year and multiplied by 10,000. As such, the indicator represents the relative picture of talent migration between all other countries and country A. 0.950.971.071.141.261.301.481.612.092.132.173.154.134.678.92
0.00 0.50 1.00 1.50 2.00 2.50 3.00 3.50 4.00 4.50 5.00 5.50 6.00 6.50 7 .00 7 .50 8.00 8.50 9.00Net migration of AI talent per 10,000 LinkedIn members by geographic region, 2019-2024
Source: LinkedIn, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.23 7 Net migration of AI talent (per 10,000 LinkedIn members) AI in 2025
Index Report
Table of Contents Chapter 4 Preview 241 Chapter 4: The Economy
4.2 Job Position
7. An asterisk indicates that the Y-axis annotation of one country is different from the Y-axis annotation of other countries. 2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 1012
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 1012
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 202404812
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 20240246
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 10123
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 2− 101
2020 2022 2024− 101
2020 2022 2024− 2− 101
2020 2022 2024− 101
2020 2022 2024− 1012
2020 2022 2024− 202
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 10123
2020 2022 202404812
2020 2022 2024− 101
2020 2022 2024− 10123
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 10123
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101234
2020 2022 2024− 101
2020 2022 20240246
2020 2022 2024− 101
2020 2022 2024− 101
2020 2022 2024− 101- 0.221.482.090.63
- 0.090.95- 0.19 - 0.28
0.01 4.670.701.14
0.131.30
0.342.13
- 0.250.97
- 1.150.51
- 1.55- 0.072.17
- 2.10
- 0.100.66
0.568.92
- 0.100.92
- 0.230.55
0.95
0.420.061.61
1.26 0.36
- 0.22 - 0.36
0.94
0.413.15
- 0.49
4.130.551.07
- 0.05 Argentina, Australia, Austria, Belgium
Brazil, Canada*, Chile, Costa Rica
Croatia, Cyprus*, Czech Republic, Denmark 12
Estonia* Finland France Germany * 3
Greece, Hong Kong, Hungary*, Iceland
Italy Latvia Lithuania* Luxembourg*
Mexico, Netherlands*, New Zealand, Norway, 3, India*, Indonesia, Ireland*, Israel, Israel
Poland, Poland, Romania, Saudi Arabia
Singapore* Slovenia, South Africa, South Korea
Spain, Sweden, Switzerland*, Turkey, Turkey 
United Arab Emirates* United Kingdom United States Uruguay 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Pre242 Chapter 4: The Economy
4.2 Job Position
Focus:
Measure the convergence of AI and the economy
A score for more than 4 million real-world AI interactions
It provides a comprehensive empirical basis for the integration of artificial intelligence in various economic fields
Occupy. A recent study by Anthropic was conducted through the U.S. Department of Labor's O*NET
The Occupational Classification Framework, which analyzes patterns in the use of its AI models, reveals which industries and functions are leveraging AI technologies. Specifically, the Anthropic team did this by analyzing the user's relationship with Claude. The AI model's conversations identify the tasks and occupations that use AI most frequently. The analysis shows that while all industries use the current one to some extent
Artificial intelligence technology, but the dominant field is still the technology and creative industries. As shown in Figure 4.2.24, computer and math-related occupations dominate, accounting for 37.2% of all AI interactions. This was followed by arts, design, entertainment, sports, and media occupations at 10.3 percent, while educational guidance and library occupations also showed higher application rates. The responsibility for risk mitigation lies with the model provider or the user.
Claude uses the data to compare the distribution of occupations with the distribution of the U.S. labor force
Source: Handa et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.230.30% 0.10%0.80% 0.90%0.90% 6.40%1.40% 10.30%1.60% 2.10%1.70% 4.50%2.00% 0.50%2.30% 0.40%2.90% 0.10%3.40% 37.20%3.90% 0.70%4.10% 0.40%4.70% 0.30%5.80% 9.30%5.80% 2.90%6.10% 2.60%6.60% 5.90%6.90% 4.50%8.70% 0.50%8.80% 2.30%9.10% 0.30%12.20% 7.90%
0% 10% 20% 30% 40%
Claude usage vs. U.S. labor force distribution Claude conversation percentage
Percentage of U.S. workers for office and administrative support
Transportation and material handling
Sales and related 
Food preparation and service related
Management, commercial and financial operations
 Medical practitioners and technicians
produce
Educational guidance and library
Medical support
Construction and excavation
Installation, maintenance and repair
Computing and Mathematics
Building & Ground Cleaning & Maintenance
Protective services
 Personal Care & Services
 Construction & Engineering
Community & Social Services
Art, Design, Entertainment, Sports and Media
Life, Physics and Social Sciences
law
Artificial Intelligence in Agriculture, Fisheries and Forestry 2025
Index Report
Table of Contents Chapter 4 Preview 243 Chapter 4: The Economy
4.2 Job Position
Percentage of Claude Talk Highlights :
Measuring the Convergence of AI and the Economy (continued)
There is a gap between the patterns of AI use and the level of wages and the skills required
Obvious correlation. Figure 4.2.25 shows that AI usage rates are in the high wage quarter
It peaks in single-digit occupations, but declines significantly at the extremes of wages. Jobs that require a lot of preparation (typically at the bachelor's level) have 50% higher AI usage than their baseline workforce representation, while jobs that require little and a lot of preparation show lower adoption rates.
Median Annual Wage (in thousands) Claude occupation usage by median annual salary
Source: Handa et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 4.2.250 50 100 150 2000%1%2%3%4%5%6%Computer programmer
Software development, application
Bioinformatics, Technician
Lecturer Copywriter
Obstetricians and gynecologists Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 244 Chapter 4: Economy
4.2 Job Position
Focus:
Measuring the Convergence of AI and the Economy (continued)
Anthropic's research found that about 36% of occupations were at least quarry
One of the related tasks used in artificial intelligence (Figure 4.2.26) suggests that humans
There is also a great penetration of industrial intelligence outside the field of technology. However, deep integration is still rare: only about 4% of occupations use AI in more than 75% of tasks, suggesting that full automation across occupational categories has not yet been achieved.
The depth of use of AI by organizations
Source: Handa et al., 2025
Figure 4.2.26
The minimum proportion of tasks to be used
Occupations account for about 36% of occupations
At least 25% of the tasks are used
About 11% of occupations have at least 50% of the tasks used
About 4% of occupations have at least 75% of tasks using AI in 2025
Index Report
Table of Contents Chapter 4 Preview 245 Chapter 4: The Economy
4.2 Job Position
Focus:
Measuring the Convergence of AI and the Economy (continued)
The analysis reveals how AI is being used within an organization. See Figure 4.2.27 
shows that 57% of AI interactions exhibit an augmentation pattern (augmented human performance
force ), while 43% exhibit an automated mode. This difference suggests that current AI applications tend to complement rather than replace human workers. The study found that the presence of cognitive skills such as critical thinking and writing was high, while the presence of physical and managerial skills was low in AI interactions (Figure 4.2.28).
Percentage of Claude conversations by task execution type
Source: Handa et al., 2025|Chart: AI Index Report 2025
Figure 4.2.27 Minimum scale of tasks to be used
Claude talks about the percentage expansion
Automation31.33% 23.27%
14.80% 27 .75%
0% 10% 20% 30% 40% 50% 60% Verify Task iteration Learn Feedback Loop Instruction
skill
Figure 4.2.28
Critical Thinking,
Active listening,
Reading comprehension, 
writing
systems analysis 
programming
Complex Problem Solving,
teaching
Troubleshooting, Social Awareness, Service Orientation, Technical Design,
Judgment & Decision-Making, 
mathematics 
Operational Analysis,
science
Oral Expression, Coordination, Persuasion, Systematic Assessment, Learning Strategies, 
Quality Control Analysis, Financial Resource Management,
Time Management, Active Learning,
Human Resource Management, 
Monitoring Capabilities, Operational Monitoring, Equipment Selection, Negotiation Skills,
Installation 
Equipment Maintenance, 
Material resource management, 
Operation & Control,
Maintenance
Percentage of total records (%) Distribution of career skills demonstrated by Claude in the conversation
Source: Handa et al., Total Investment 2025 (in billions) Chapter 4: Economy
4.3 Investments
  AI
 An agent is designed to operate in a specific environment to achieve a purpose
The subject autonomous or semi-autonomous system is a challenge for AI research
Exciting frontier field. These agents have a wide range of potential applications, from:
Assist with academic research, arrange conferences to facilitate online shopping and vacation pre-production
order,
And so on . As many recent company press releases indicate
Agents have become a growing concern in the field of artificial intelligence technology
Title.
Global corporate investment in AI by investment activity, 2013-2024
Sources; Quid, 2024| Chart: 2025 Artificial Intelligence Index Report 4.3 Investment
Corporate investment
Figure 4.3.1 illustrates trends in global enterprise AI investment from 2013 to 2024, including:
Mergers and acquisitions, minority stakes, private investments and public offerings.
In 2024, the total investment will increase to $252.3 billion, an increase of 25.5% from 2023. Among them private
Investment increased most significantly, up 44.5% year-on-year, and M&A transactions increased by 12.1%. Over the past decade, people
The scale of investment related to industrial intelligence has increased nearly thirteen times.
Figure 4.3.120.0637 .3225.7243.1 58.1873.79145.4
113.01
104.34150.7988.19
24.6821.8936.4339.83175.36
121.39
82.2692.19
14.5719.0425.4333.8253.7279.62103.27221.87360.73
253.25
201252.33
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024050100150200250300350 mergers/acquisitions
Minority private investment in public listing of artificial intelligence in 2025
Index Report
Table of Contents Chapter 1 Preview 246Total Investment (in billions of dollars) Global Private Investment in Artificial Intelligence 2013-2024
Source: Quid, 2024 | Chart: Artificial Intelligence Index 2025 Report Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 1 Preview 247 Startup Events
This section analyzes the investments that have received more than $1.5 million since 2013
Private investment trends in AI start-ups. Global trends
From 2023 to 2024, global private AI investment has grown 
44.5%, the first year-over-year increase since 2021 (Figure 4.3.2).
Despite recent volatility, global private AI investment has grown significantly over the past decade.
150.79
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024020406080100120140
Figure 4.3.2 Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 1 Preview 248 Total Investment (in USD billions) Global private investment in generative AI, 2019-2024
Source: Quid, 2024 | Chart: The AI Index 2025 reports that funding for generative AI continues to grow significantly (Figure 4.3.3).
In 2024, the sector attracted US$33.9 billion in investment, an increase of 18.7% from 2023 and more than 8.5 times the amount invested in 2022. In addition, in 2024, generate
AI accounts for more than one-fifth of all AI-related private investment.
Figure 4.3.333.94
2019 2020 2021 2022 2023 202405101520253035 Chapter 4: The Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 1 Preview 249Number of companies Number of companies Number of new AI companies in the world that received financing from 2013 to 2024
Source: Quid, 2024 | Chart: 2025 Artificial Intelligence Index Report
Number of new generative AI companies globally receiving financing, 2019-2024
Source: Quid, 2024 | Chart: The 2025 AI Index reports that the number of newly invested AI companies jumped to 2,049 in 2024 
home, an increase of 8.4% from the previous year (Figure 4.3.4). In addition, the number of new generative AI companies receiving funding increased in 2024, with a total of 214 startups
access to financing, compared to 179 in 2023 and only 31 in 2019 (Figure 4.3.5).
Figure 4.3.4
Figure 4.3.52,049
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 202405001,0001,5002,000
214
2019 2020 2021 2022 2023 2024050100150200 Chapter 4: The Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 250 Number of Companies
Number of companies: Average size of global private investment activity in AI, 2013-2024
Source: Quid, 2024 | Chart: 2025 Artificial Intelligence Index Report
Global AI private investment activity by size of funds in 2023 and 2024
Source: Quid, 2024 | Table: AI Index 2025 Report Figure 4.3.6 shows the average size of private investment in AI, how it is calculated
It is the total amount of private investment in AI divided by the private investment event in AI each year
Total. From 2023 to 2024, the average size increases significantly, from $31.6 million to $45.4 million. Figure 4.3.7 illustrates AI financing events by size. In 2024, AI private investment events will increase in categories with more than $100 million raised, while decreasing or remaining stable in smaller categories. In 2024, there will be 15 AI private investment events involving more than $1 billion in fundraising.
Figure 4.3.745.43
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024051015202530354045
The size of the funding
9
9
134
200
2,945
680
3,977
2023 
15
20
143
196
2,945
207
3,526
 2024 
The total price is more than 1 billion
500 million - 1 billion 100 million - 550 million - 100 million below 50 million undisclosed Figure 4.3.6 Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 251 Number of Companies Global Private Investment in AI by Geographic Region in 2024
Source: Quid, 2024 | Chart: Regional comparison of the 2025 AI Index Report by funding size
The United States once again ranks first in the world in terms of total private investment in artificial intelligence
One. In 2024, the United States will invest a total of 1,091 private investments in AI
US$100 million, 11.7 times that of China (US$9.3 billion) and 24.1 times that of the United Kingdom (US$4.5 billion) (Figure 4.3.8). Other countries to watch in the top 15 in 2024 include Sweden ($4.3 billion), Austria ($1.5 billion), and the Netherlands
($1.1 billion) and Italy ($900 million).
Figure 4.3.8 Total Investment (in billions of US dollars) 0.860.931.091.161.331.361.511.771.972.622.894.344.529.29109.08
0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115l United States
China, United Kingdom
Sweden
Canada
France
Germany
UAE
Austria
Israel
South Korea, India, Netherlands
Japan
Chapter 4 of Italy: The Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 252Number of Companies: Global Private Investment in Artificial Intelligence by Geographic Region, 2013-2024 (Sum)
Source: Quid, 2024 | Chart: The 2025 AI Index reports the ranking of countries when aggregating data on private AI investments since 2013
Unchanged: The United States topped the list with $47.09 billion in investment, followed by China
It followed with $11.93 billion, followed by the United Kingdom in third place with $2.82 billion (Figure 4.3.9).
Other countries that have attracted significant AI investment over the past decade include Israel ($15 billion), Singapore ($7.3 billion), and Sweden ($7.3 billion). past
Other countries that have attracted significant AI investment over the decade include Israel ($15 billion), Singapore ($7.3 billion), and Sweden ($7.3 billion).
Figure 4.3.90.860.931.091.161.331.361.511.771.972.622.894.344.529.29109.08
0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 105 110 115 United States
China, United Kingdom
Canada, Israel
Germany, India, France
Korea
Singapore
Sweden
Japan
Australia
Switzerland
UAE
Total Investment (in billions of dollars) Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 253 Total Investment (in USD billion) Global Private Investment in AI by Geographic Region, 2013-2024
Source: Quid, 2024 | Chart: The AI Index Report 2025 Figure 4.3.10 shows the evolution of private investment in AI by region, Table
The gap in private investment between the United States and other regions is widening. Since 2023
Since then, private investment in AI in China has fallen by 1.9%, while in Europe it has increased by 60%. At the same time, the U.S. has achieved a significant growth of 50.7% over the same period and 78.3% since 2022.
Figure 4.3.102013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024020406080100109.08, United States
19.42, Europe
9.29, China Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 254 Total Investment (in USD billion) Global Private Investment in Generative AI by Geographic Region, 2019-2024
Source: Quid, 2024 | Chart: The 2025 AI Index Report analyzes AI across regions when analyzing generative AI-related investments
The gap between people and investment is particularly pronounced. For example, in 2023, the United States is developing generative AI
Investment in this sector is about US$21.8 billion, more than the total investment in China and Europe (Figure 4.3.11). By 2024, this gap widens further to $25.4 billion.
By 2024, this gap widens further to $25.4 billion.
Figure 4.3.112019 2020 2021 2022 2023 2024051015202530
29.04, United States
2.11, China
1.49, Europe Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview Number of Newly Funded AI Companies by Geographic Region in 2552024
Source: Quid, 2024 | Chart: Comparison of newly funded AI companies by region in the 2025 AI Index report 
This section analyzes the number of new AI companies that have received investment in different geographic regions
Measure. In line with the trend of private investment, the U.S. received 1,073 new investments in AI companies
It topped the list among regions, followed by the United Kingdom with 116 and China with 98 (Figure 4.3.12). The U.S. topped the region with 1,073 new AI companies, followed by the U.K. with 116 and China with 98 (Figure 4.3.12).
Figure 4.3.12 Number of companies 182223243639425152596774981161,073
0 100 200 300 400 500 600 700 800 900 1,000 1,100 United States
United Kingdom, China, India, Germany, France, South Korea
Canada
Japan
Singapore, Israel
Netherlands
Australia
Switzerland
Spain Chapter 4: The Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 2562013-2024 Number of Newly Financed AI Companies by Geographic Region (Sum)
Source: Quid, 2024 | Chart: The 2025 AI Index Report's aggregate data since 2013 shows a similar trend. In the past decade, the U.S. has raised about 4.3 times as many new AI companies as China and 7.9 as the U.K 
times (Figure 4.3.13).
Figure 4.3.13: Number of companies in the United States
China, United Kingdom
Israel, Canada
France, India, Germany, Japan, South Korea
Singapore
Australia
Switzerland
Spain
Netherlands
1161171541782392703883944344684814928851,6056,956
0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,500 5,000 5,500 6,000 6,500 7 ,000 Chapter 4: The Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 257 Number of Firms Number of Newly Funded AI Companies by Geographic Region, 2013-2024
Source: Quid, 2024 | Chart: Chart 4.3.14 of the 2025 AI Index Report shows the number of newly funded AI companies in a specific geographic area
highlights the long-term trend of the U.S. leading Europe and China over the past decade. Since 2022, there have been new AI companies in both the United States and Europe
The number of divisions increased significantly, while China experienced an annual decline for the second year in a row.
Figure 4.3.141,143, United States
447, Europe
109, China
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 202402004006008001,0001,200Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview of Global Private Investment in AI by Focus Area in 2582023 vs. 2024)
Source: Quid, 2024 | Chart: 2025 AI Index Report Focus area analysis
Quid also breaks down private AI investments by focus area. Figure 4.3.15 
Compares global private AI investment by focus in 2024 versus 2023
The distribution of domains. In 2024, the focus areas that will attract the most investment will be AI infrastructure/research/governance ($37.3 billion); data management and processing ($16.6 billion); and Health Care ($11 billion). Fundamentals of Artificial Intelligence
Prominence in the facilities, research, and governance sectors reflects massive investments in companies that specialize in developing AI applications, such as OpenAI, Anthropic, and xAI.
AI Infrastructure/Research/Governance
Data management and processing
Healthcare
AV
Fintech
manufacturing
semiconductor
NLP, Customer Support Cybersecurity, Data Protection
Robotic drones
Energy, Oil & Gas Marketing, Digital Advertising
Business Operations
 Semantic search
supply chain
Insurtech
AR/VR
Retail education technology
Quantum computing
Internet of Things
Agricultural technology
Content Creation/Translation
Creative, musical, video content
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 382024
2023
Figure 4.3.15 Total Investment (in billions of dollars)
Figure 4.3.16 shows the long-term trend of investment in AI focus areas. As mentioned earlier, investment in most focus areas has increased over the last year. For NLP, customer support
Holdings, while still significant, peaked in 2021 and have declined since then. Chapter 4: Economy
4.3 Invest in AI by 2025
Index Report
Table of Contents Chapter 4 Preview 2592018-2024 Global Private Investment in AI by Focus Area
Source: Quid, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 4.3.162018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 20240102030
2018 2020 2022 2024010203037 .27
1.359.43
0.81
1.52 0.76 0.753.73
16.59
2.580.97 2.02
6.88
1.36 0.846.58
1.6010.80
4.180.96
1.173.291.435.53
1.40 Artificial Intelligence Infrastructure/Research/Management AR/VR Audiovisual Agricultural Technology
Business Operations Content Creation/Translation Creative, Music, Video Content Cybersecurity, Data Protection
Data management and processing drones educational technology energy, oil and gas
Fintech, InsurTech, Internet of Things manufacturing
Marketing, Digital Advertising, Medical & Healthcare NLP, Customer Support Quantum Computing
Retail, Robotics, Semantic Search, Semiconductors
Total supply chain investment (in billions of dollars) This section explores the practical application of AI by enterprises
Trends in the use of the industry, how companies integrate artificial intelligence, is considered to have the most
specific AI technologies, and the impact of the use of AI on financial performance. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 260% of respondents, 2017-2024, who said their organization uses AI in at least one function
Source: McKinsey & Company survey, 2024 | Chart: Artificial Intelligence Index 2025 reports 4.4 corporate activity
Industry usage
This section combines McKinsey's publication on the State of Artificial Intelligence
Insights as well as data from previous releases. The 2024 McKinsey analysis is based on two surveys,
The survey was conducted among 2,854 respondents from different regions, industries, company sizes, functional areas and years of service.
Harness AI capabilities
Business applications of AI have increased dramatically after stagnation from 2017 to 2023
Figure 4.4.1 adds. According to a recent McKinsey report, 78% of respondents said their business
The use of AI in at least one business function has begun, a significant increase from 55% in 2023 (Figure 4.4.1). The use of generative AI, first addressed in the survey, has more than doubled, with 71% of respondents saying their organization uses the technology regularly in at least one business function in 2024, compared to just 33% in 2023.  
2017 2018 2019 2020 2021 2022 2023 20240%10%20%30%40%50%60%70%80%
78%, artificial intelligence
71%, GenAI Chapter 4: Economy
4.4 Corporate activities 2025 Artificial intelligence
Index Report
Table of Contents Chapter 4 previews the use of AI across industries and functions in 2612024
Source: McKinsey & Company survey, 2024 | Chart: The 2025 AI Index report Figure 4.4.2 shows the use of AI by industry and AI function in 2024. The highest usage rate is information technology in the technology industry (48%), which:
This was followed by product and/or service development in the technology sector (47%) and marketing and sales in the technology sector (47%).
Figure 4.4.2 8 Chapter 4: Economy
4.4 Corporate Activities
Type of industry
Percentage of respondents using AI by function (%)High-end manufacturing
Business / Legal / Professional Services
Consumer Goods & Retail
Energy & Materials
Financial services
Medical / Pharmaceutical / Medical Products
Media & Telecommunications
Technology industry
Human Resources Information Technology (IT) Manufacturing Marketing & Sales Product and/or Service Development Risk / Legal / Compliance Service Operations Software Engineering Strategy & Corporate Finance Supply Chain / Inventory Management
8. Among them, high-end manufacturing includes respondents from industries such as advanced electronics, aerospace and defense, automotive and assembly, and semiconductors. Energy & Materials included respondents in the agriculture, chemical, power & gas, metals & mining, oil & gas, and paper, forest products, and packaging industries. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 2622024 AI Analytics Cost Reduction and Revenue Increase by Function)
Source: McKinsey & Company survey, 2024 | Chart: The 2025 AI Index reports that organizations report cost reductions and revenue increases after they start using AI
Plus, but most often at a lower level (Figure 4.4.3). Respondents reported most often
The areas where AI use is delivering cost savings are service operations (49%), supply chain and inventory management (43%), and software engineering (41%). In terms of income growth, people
The functions that most benefited from AI applications included marketing and sales (71%), supply chain and inventory management (63%), and service operations (57%).
Figure 4.4.3 Chapter 4: Economy
4.4 Corporate Activities
28%
9% 20%
8%8% 21%
8% 11%
11% 29%
16% 28%
11% 22%
17% 20%
9% 15%34% 
34% 
37% 
23% 
43% 
49% 
37% 
41% 
25% 23% 44%
10% 16% 30%
10% 14% 39%
12% 10% 35%
11% 14% 19% 71%
 56%
 63%
 57%
 44% features
Percentage of respondents: Marketing & Sales
Risk, Legal, and Compliance
human resources
Product or service development
Supply chain and inventory management
Service business
Information Technology Software Engineering
Other Agency Functions Decrease <10 Decrease 10-19 Decrease ≥20 Increase >10 Increase 6-10 Increase ≤5 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 previews the use of AI by organizations worldwide in 2632023 versus 2024
Source: McKinsey & Company survey, 2024 | Chart: The AI Index 2025 reportFigure 4.4.4 illustrates the use of AI by region in organizations around the world
Condition. In 2024, respondents across all regions reported a higher rate of AI usage than in 2023
years have improved. The annual growth rate of AI adoption is in Greater China
Most notably, organizations reported a 27 percentage point increase in usage. North America retains the lead in AI adoption (82%), but only marginally. The use of AI in Europe has also increased significantly, up 23 percentage points from 2023 to 80%.
Figure 4.4.4 Total Investment (in billions of dollars) Chapter 4: Economy
4.4 Corporate Activities
78%
72%
80%
82%
75%
77%55%
58%
57%
61%
48%
49%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%2024
2023 All Regions
Asia pacific
Europe
North America
Greater China (including Hong Kong, Taiwan, Macau)
Developing markets
(including India, Central/South America,
Middle East and North Africa)
Percentage of respondents: Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 previews the most common generative AI use cases by function in 2642024
Source: McKinsey & Company survey, 2024 | Chart: The 2025 AI Index reports on the deployment of generative AI capabilities
How can enterprises deploy generative AI capabilities? Figure 4.4.5 shows the report
Respondents who use generative AI for specific functions are among the total number of respondents
Proportion. Respondents are likely to say they have deployed AI for a variety of purposes. The most common application was marketing strategy content enablement (27%), followed by knowledge management (19%), personalization (19%), and design development (14%). Most of the top use cases reported are for the marketing and sales functions. A supplemental survey of executives in developed markets found that only 1% of companies describe their promotion of generative AI as "mature." Overall, most companies are still in the early stages of extracting value from AI at scale.
Figure 4.4.5 Chapter 4: Economy
4.4 Corporate Activities
12%
11%14%
11%13%19%27%
11%13%19%
0% 5% 10% 15% 20% 25%
Percentage of respondents: Marketing strategy content support (i.e., drafting, presenting ideas.)
and introduction of relevant knowledge to create a marketing strategy)
knowledge management
Personalization (e.g., personalized creatives.)
Large-scale content generation)
Design and development
Code creation (i.e. using code helpers, leveraging nature.)
Language-to-code conversion, debugging,
Test Development)
 Sales follow-up interaction automation
Integrate genetic AI into the workflow of human representatives
(e.g., during a person-to-person phone conversation.)
for real-time reply suggestions)
Lead identification and prioritization
Accelerate the early simulation/testing phase (i.e. pass gen 
AI's compositing and writing capabilities, redesigned and accelerated
Targeted customer research or interviews)
Scientific literature and research review service business
R&D / Product Development Marketing & Sales Software Engineering Other Corporate Functions 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 previews the cost reduction and revenue increase in generative AI use by function in 2652024
Source: McKinsey & Company survey, 2024 | Chart: The 2025 AI Index report Figure 4.4.6 shows the percentage of respondents who reported how their organizations are performing across business functions
The proportion of costs that fall and revenues increase with generative AI. Overall
Respondents reported cost reductions and revenue increases across business functions after using generative AI, with the majority of respondents reporting low levels. The most common areas of cost savings reported by respondents included supply chain and inventory management (61%), service operations (58%), and human resources and strategy and corporate finance (56%). in income
In terms of growth, the functions most commonly reported the benefits of generative AI include Strategy & Corporate Finance (70%), Supply Chain & Inventory Management (67%), and
Marketing & Sales (66%).
Figure 4.4.6 Chapter 4: Economy
4.4 Corporate Activities
function
Percentage of respondents: Marketing & Sales
Risk, Legal, and Compliance
human resources
Product or service development
Supply chain and inventory management
Service business
Information Technology Software Engineering
Other Corporate Functions 10% 11% 26%
13% 9% 29%
10% 14% 32%
19% 7% 17%
7% 15% 39%
7% 11% 39%
10% 12% 21%
13% 16% 23%
15% 6% 35%
19% 8% 16%47% 
51% 
56%  
43% 
61% 
58% 
56%  52%  44% 
44% 8% 24% 34%
12% 15% 25%
19% 15% 32%
18% 14% 31%
12% 13% 31%
11% 12% 47% 66%
 51%
 67%
 63%
 70% 57% decrease <10 decrease 10-19 decrease ≥20 increase >10 increase 6-10 increase ≤5 artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Previews Cost Reductions and Revenue Increases in the Use of Generative AI by Function in 2662024
Source: McKinsey & Company survey, 2024 | Chart: The AI Index 2025 reportFigure 4.4.7 illustrates the use of generative AI by enterprises in different regions of the world
Differences in circumstances. In all regions, 2024 will be in at least one business function
The percentage of businesses using generative AI reached 71%, more than doubling from 33% in 2023. This percentage is only 7 percentage points lower than the proportion that reported using any form of AI (78%).  This is shown in Figure 4.4.1. The gap between overall AI usage and generative AI usage has narrowed dramatically from 22 percentage points in 2023 to 7 percentage points in 2024, indicating that the use of generative AI capabilities is accelerating. North America (74%), Europe (73%), and Chinese mainland (73%) lead the way in the use of generative AI.
Figure 4.4.7 9 Chapter 4: Economy
4.4 Corporate Activities
All regions
Asia pacific
Europe
North America
Greater China (including Hong Kong, Taiwan, Macau)
Developing markets
(including India, Central/South America,
Middle East and North Africa)
Percentage of respondents: 71%
67%
73%
74%
73%
68%33%
30%
31%
40%
31%
33%
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%2024
2023
9. The diagram highlights the application of AI in at least one business function. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 267 Chats per Customer Support Worker per Hour The Effect of Artificial Intelligence on Customer Service Representatives
Source: Brynjolfsson et al., 2023| Chart:: Artificial Intelligence Index Report 2024
The impact of artificial intelligence on scientific innovation
Source: Toner-Rodgers et al., 2025| Chart: The 2025 AI Index reports on the impact of AI on the workforce
Over the past six years, AI has become increasingly integrated into the economy, triggering a rise in people's lives
There is a strong interest in the potential of production efficiency. While the early adoption of AI shows promise,
But quantifying the impact of AI remains challenging, and it wasn't until 2023 that the first wave of rigorous research emerged. In 2024, a large number of empirical studies have established a clear pattern of the impact of AI on the workplace across multiple domains and contexts. This section analyzes productivity impact data from five major academic studies that together represent the first large-scale empirical survey of the impact of AI on the workplace. The studies, which covered more than 200,000 professionals across a wide range of industries and sectors, revealed productivity gains ranging from 10% to 45%, with the impact of technology, customer support, and creative tasks being particularly significant. theseA variety of methods, including natural experiments, randomized controlled trials, and large-scale surveys, were used to measure the impact of AI in different organizational settings.
Productivity trends
April 2023, Erik Brynjolfsson, Danielle Li, and Daniel 
Rock published about the impact of artificial intelligence (especially generative AI) on production
A study of the efficiency impact. This is also one of the most representative studies in this field.
10
The study analyzed data from 5,179 customer service representatives to examine the phased introduction of generative AI-powered conversational assistants. The researchers found that the adoption of AI led to a 14.2% increase in the number of problems solved per hour (Figure 4.4.8). In addition, the study also found that productivity gains were seen quickly after the introduction of AI, and that employees exposed to AI remained more productive during AI system failures.
Other recently published studies have also confirmed Brynjolfsson's findings. Microsoft
A workplace study by the company identified a productivity improvement benchmark for common workplace tasks, with a 10-13% increase in Chinese editing and an 11% reduction in email processing time. Professional roles are more profitable, with security professionals seeing a 23% reduction in completion time and a 7% increase in accuracy; The sales team's response time has improved 
10. The paper was published in 2023 as NBER Working Paper 31161 and subsequently in the Quarterly Journal of Economics in 2025. 39%, with a 25% improvement in accuracy.
In terms of scientific research, Aiden Toner-Rodgers' study on 1018 
scientists surveyed and found that scientists who used AI found 44.1% more material discoveries, 39.4% more patent applications, and 17.2% more prototypes than those who didn't (Figure 4.4.9)
Figure 4.4.8
Figure 4.4.9 Chapter 4: Economy
4.4 Corporate Activities
2.97
2.60
0.000.501.001.502.002.503.00
44.10%
39.40%
17 .20%
0% 10% 20% 30% 40% 50% use artificial intelligence
New Materials, Product Prototypes, Innovation Indicators, Patents, Artificial Intelligence, 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 4 Preview 268 Productivity Equilibrium Effect of Artificial Intelligence In the field of software development, two important studies provide insights into the impact of artificial intelligence
Additional evidence. A field experiment with 4,867 developers found that people
Artificial assistance increased task completion rates by an average of 26.08%. Another natural experiment with 187489 developers reinforced this finding; The experiment showed a 12.4% increase in core programming activities, while a 24.9% reduction in time spent on project management tasks.
Equilibrium effect
Multiple studies have revealed a consistent pattern: artificial intelligence has a significant impact on workplace performance
There is an equalization effect (Figure 4.4.10). The latest research in the field of software development shows that the primary
Developers saw a 21%-40% increase in productivity, while veteran developers saw a relatively limited increase of 7%-16%. This pattern has been validated in other independent studies – the productivity gains of low-skilled programmers (14%-27%) are significantly higher than those of high-skilled programmers (5%-10%). In addition, their analysis shows that AI has increased the exploration of new technologies
21.8% and a potential salary increase of $1,683 per developer per year, demonstrating that AI tools are not only more productive but also actively promote skill development. This study supports earlier findings from 2023 and 2024 that AI-driven productivity gains vary based on employees' initial skill levels.
However, some studies suggest that the impact of AI may be in the opposite direction.
A study by Toner-Rodgers found that while the output of high-performing scientists nearly doubled, the bottom third of scientists benefited little from the introduction of AI. The study further highlights that the key factor influencing the impact of AI is not previous achievements, but the ability to effectively evaluate AI-generated recommendations. This suggests that AI tools can be a powerful amplification for those who can effectively utilize them, regardless of experience level. Understanding how AI affects different workers in different tasks will be an important focus of current research.
Figure 4.4.10 Chapter 4: Economy
4.4 Corporate Activities
Brynjolfsson et al., 2023
Dell'Acqua et al., 2023Cui et al., 2024Hoffman et al., 2024 Customer Support Consulting, Software Engineering, Software Engineering, 34%, 42.96%, 21-40%, 12-27%, No Difference from Zero, 16.5%, 7-16%, 5-10%, Research Tasks: Productivity improvement for low-skilled workers Productivity improvement for high-skilled workers, Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 269 Percent of Respondents Use AI to Improve Productivity Distribution
Source: Necula et al., 2024| Chart: 2025 AI Index Report Application and Integration
Studies have shown that the improvement of production efficiency is fully integrated with artificial intelligence and systems
There is a significant correlation between implementations. Romanian researchers targeted 233 employees
According to the survey, 72% of companies with high AI integration have a significant increase in productivity, compared to 3.4% for companies with a low level of integration. The analysis data shows that the productivity improvement of respondents shows a clear gradient distribution: 46.8% of respondents achieved a 0-20% increase, 26.2% achieved a 20-40% increase, and 18.4% achieved a 40-60% improvement. Smaller minority groups saw even greater improvements, with 7.7% of respondents achieving a 60-80% increase and 0.9% achieving a significant increase of 80-100% (Figure 4.4.11).
Impact on the workforce
The introduction of AI tools has dramatically changed the mode of task assignment with team groups
Weave structure. Microsoft workplace research shows that artificial intelligence and automation technology make employees feel better
The mental load was reduced by 45%, and the score on the cognitive load scale decreased from the baseline value of 55 to 30 points. At the same time, the gap in the accuracy rate of non-native English speakers narrowed by 84.6%, and the coverage of key information in professional reports increased by 49%. These improvements are particularly evident in deep user groups, which use AI tools at least a few times a week, with 29% of members saving more than 30 minutes a day. Harvard Business School research confirms that the application of AI technology has significantly reduced the cost of collaboration. The data shows that the average number of team members required for a project has decreased by 79.3%. This finding shows that AI not only optimizes individual work efficiency, but also reshapes the basic paradigm of team collaboration.
These changes are fundamentally reshaping the role of the profession. Toner-Rodg-
The ERS study found that there has been a dramatic shift in the allocation of time spent by scientists: the proportion of work time spent on idea generation has fallen from 39 percent to 16 percent, while the proportion of judgment tasks has risen from 23 percent to 40 percent. As with previous technological advances, the debate about AI often revolves around automation versus augmentation, i.e., whether AI will replace or augment human work. Although about AI-driven labor
Specific data on force changes are still limited, but research is revealing how people perceive their impact on employment. Survey data from Romania shows that there is a lot of interest in artificial intelligence in the size of the workforce
43% of organizations expect the size of their workforce to be
Decreased, 30% expected little change, 15% expected to increase, and 12% were uncertain about the long-term impact. According to a McKinsey survey of executives, 31% of respondents expect AI to reduce the size of the workforce, while only 19% expect it to increase (Figure 4.4.12). Despite claims that generative AI will increase the productivity of software engineers, the findings suggest that the number of software engineers is expected to increase, consistent with the Jevons paradox. Notably, the proportion of predicted labor force reductions is lower than last year, suggesting that business leaders are increasingly less convinced that AI will reduce the organizational workforce (Figure 4.4.13).
Figure 4.4.11 Improving Productivity Chapter 4: Economy
4.4 Corporate Activities
46.78%
26.18%
18.45%
7 .73%
0.86%
0 – 20% 20 – 40% 40 – 60% 60 – 80% 80 – 100% 0% 10% 20% 30% 40% 50% Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 270 The expected impact of generative AI on the enterprise workforce in the next 3 years (2024).
Source: McKinsey & Company survey, 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.4.12 Percentage of Respondents Chapter 4: Economy
4.4 Corporate Activities
The overall situation
Service business
Marketing and sales
Supply chain/inventory management
manufacturing
human resources
Software
Product and/or service development
Strategy and Corporate Finance
Risk, Legal, and Compliance
Information Technology 8%
 15%
 10%
 10%
 8%
 8%
 8%
 7%
 7%
 6%
 5% 9%
 19% 17%
 17% 15%
 14%
 13%
 10% 10%
 9%
 7% 14%
 24% 18%
 18% 16%
 14% 11%
 11% 10%
 10% 9% 38%
 38%
 33%
 29% 26%
 25% 25%
 21% 20% 19%
 15% 8%
 18%
 17%
 17% 16% 15%
 13% 11% 7% 7%
 6% 6%
 15% 11%
 10%
 8% 8%
 7%
 5% 5% 4% 4% 5%
 10% 10%
 10%
 9% 8% 8% 6%
 4% 12%
 15%
 15%
 14% 13% 12%
 11%
 11%
 10%
 9% 9%
0% 20% 40% 60% 80% 100% reduction >20
Increase 3-10 less 11-20 increase 11-20 decrease 3-10 increase > 20 little or no change I don't know Figure 4.4.13 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 271 Changes in the number of employees
Proportion of employees expected to reskill, vs. expected impact of AI on the workforce over the next 3 years (2023 vs. 2024).
Source: McKinsey & Company survey, 2023-2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 4.3.9 Chapter 4: Economy
4.4 Corporate Activities
Percentage of respondents 8%
 5%
 10%
 31%
 14%
 10%
 8%
 14% 3%
 4%
 8%
 30%
 25%
 10%
 8%
 12%
0% 10% 20% 30% 40% 50% 46%
 17%
 14%
 12%
 11% 38%
 18%
 17%
 20%
 8%
0% 10% 20% 30% 40% 50%Don’t know≤ 5%6– 10%11– 20%>20%
2024
2023 increase >20
>20%
Increase 11-20
Increase by 3-10
11-20%
Little or no change
Reduce by 3-10
6-10%
Reduce by 11-20
≤5%
Reduce >20
I don't know
Don't know about 4.5 bot deployment
General trends
The next section includes data on the installation and operation of industrial robots, which are defined as "one
A kind of automatically controlled, reprogrammable multi-purpose manipulator, programmable three or more axes, can be fixed in situ or
mobile, for industrial automation applications ».
Figure 4.5.1 shows the total number of industrial robots installed worldwide by year. In 2023, industrial robots
Installations fell slightly to 541,000 units, down 2.2% from 2022. This is the first year-over-year decline since 2019. Robots equipped with AI software technology are deployed as artificial intelligence
A window into the practical application of ready-to-use infrastructure. This section is based on sections
Data from the International Federation of Robotics (IFR). IFR is a non-profit organization dedicated to advancing the robotics industry. The organization publishes it annually
The World Robotics Report tracks global robot installation trends. Artificial intelligence in 112025
Index Report
Table of Contents Chapter 4 Preview 272Number of Industrial Robots Installed (in thousands) Chapter 4: Economy
4.5 Deploy the bot
Number of industrial robots installed worldwide from 2012-2023
Source: McKinsey & Company survey, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 4.5.1541
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230100200300400500
11. Due to the timing of IFRS reporting, the latest data is from 2023. IFRS re-examines data collected in previous years and occasionally updates data if more accurate data becomes available. As a result, some of the data in this year's report can beYes
This is a slight difference from previous years. Number of industrial robots (thousands) Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 273 Chapter 4: The Economy
4.5 Deploy the bot
2012-2023 global industrial robot operation holdings
Source: International Federation of Robotics (IFR), 2024| Chart: The 2025 Artificial Intelligence Index reports that by 2023, the global number of industrial robots will increase from 3.904 million in 2022 to 4.282 million units (Figure 4.5.2). Since 2012, industrial robots
Both installs and usage are growing steadily.
Figure 4.5.24, 282
2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 202305001,0001,5002,0002,5003,0003,5004,0004,500 Number of installed industrial robots (thousand units) 2025 Artificial intelligence
Index Report
Table of Contents Chapter 4 Preview 274 Chapter 4: Economy
4.5 Deploy the bot
Figure 4.5.3 Industrial robots: traditional robots and collaborative robots
There is an essential difference between traditional industrial robots and collaborative robots: the former is used for:
Replace manual operations, which are designed for human-robot collaboration. 12 Robotics
The industry has shown a growing enthusiasm for collaborative robot research and development.
Because it has four cores
Advantages – operational safety, work flexibility, system scalability and stacking
Generational learning ability. Figure 4.5.3 illustrates the number of industrial robot installations by type worldwide
Statistics. According to the data, the proportion of collaborative robots in the number of new industrial robot installations has increased significantly: only 2.8% in 2017, and has increased to 10.5% in 2023, an increase of 7.7 percentage points.
4258 57389405
366 363484495484400424
387 389526553541
2017 2018 2019 2020 2021 2022 20230100200300400500 traditions
collaboration
12. For more details on the definition of collaborative robots by the International Federation of Robotics, please visit: Number of Industrial Robots Installed Worldwide by Type, 2017-2023
Source: International Federation of Robotics (IFR), 2024| Chart: Artificial Intelligence Index 2025 Report Artificial Intelligence 2025
Index Report
Table of Contents Chapter 4 Preview 275 Chapter 4: The Economy
4.5 Deploy the bot
Number of Industrial Robot Installations by Geography in 2023
Source: International Federation of Robotics (IFR), 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.5.4 China
Japan, the United States, South Korea, Germany
Italy
India, France
Mexico, Spain
Taiwan, China
Turkey, Canada
United Kingdom, Thailand
3.603.804.304.404.405.105.806.408.5010.4028.4031.4037 .6046.10276.30
0 30 60 90 120 150 180 210 240 270
The number of installed industrial robots (in thousands) is broken down by geographical region
The installation data of industrial robots in various countries can reflect the impact of different economies on machines
The importance of the application of human technology. The 2023 annual statistics show that China is ranked with 276,300
The number of industrial robots installed in Taiwan is the highest in the world, with 6 times that of Japan (46,100 units) and 7.3 times that of the United States (37,600 units) (Figure 4.5.4). South Korea followed with Germany with 31,400 and 28,400 installations, respectively. Number of industrial robots installed (thousands) Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 276 Chapter 4: Economy
4.5 Deploy the bot
Number of newly installed industrial robots in the top 5 countries in 2021-2023
Source: International Federation of Robotics (IFR), 2024| Chart: 2025 Artificial Intelligence Index ReportSince overtaking Japan in 2013 to become the world's largest market for industrial robot applications, China has continued to expand its lead. The data shows that the number of industrial robots installed in China is
The share of the global total increased significantly from 20.8% in 2013 to 51.1% in 2023 (Figure 4.5.5).
Figure 4.5.52011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022 202350100150200250300
276, China
46, Japan
38, United States 31, South Korea 28, Number of industrial robots installed in Germany (thousands) Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 277 Chapter 4: The Economy
4.5 Deploy the bot
2016-2023 China vs. Rest of the World Number of Industrial Robot Installations
Source: International Federation of Robotics (IFR), 2024| Chart: 2025 Artificial Intelligence Index Report Since 2021, China's annual industrial robot installations have continued to exceed the rest of the world combined. Although this lead in 2023 is narrower than in 2022 (Figure
4.5.6), but the slowdown in year-on-year growth has not shaken China's absolute dominance in the global industrial robot application market.
Figure 4.5.62016 2017 2018 2019 2020 2021 2022 2023050100150200250300
276, China
265, Artificial Intelligence in the Rest of the World 2025
Index Report
Table of Contents Chapter 4 Preview 278 Chapter 4: The Economy
4.5 Deploy the bot
Annual growth rate of industrial robot installations by region in 2022 vs. 2023
Source: International Federation of Robotics (IFR), 2024| Chart: 2025 Artificial Intelligence Index Report
Figure 4.5.7- 43%-13%-9%-9%-5%-5%-3%-1%7%9%15%31%37%51%59%
− 40% − 30% − 20% − 10% 0% 10% 20% 30% 40% 50% 60% India
United Kingdom
Canada, Spain, Turkey
Thailand, Germany, South Korea
Mexico
United States, China
Italy
Japan, France
Taiwan region of China
The annual growth rate of installed industrial robots is reported by the International Federation of Robotics that between 2022 and 2023 is the only one in the world
Seven countries saw year-on-year growth in the number of industrial robot installations (Figure 4.5.7). thereinto
India topped the list with a growth rate of 59 percent, followed by the United Kingdom (51 percent) and Canada (37 percent). At the same time, China's Taiwan region saw a significant decline of 43%, France fell by 13%, and Japan and Italy both recorded negative growth of 9%. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 4 Preview 279 Chapter 4: The Economy
4.5 Deploy the bot
Figure 4.5.8 Number of Service Robots Installed (in thousands) Country-level data for service robots
Another important category of robots is service robots. According to the International Organization for Standardization
(ISO), a service robot is defined as "performing a useful task for a human or device, and
Robot systems that do not include industrial automation applications". Such robots can be applied to:
Medical environment and professional cleaning and other scenarios. 132023 annual data shows that all application categories except medical robots
The number of service robots installed increased compared to 2022 (Figure 4.5.8). Among them, the installation of service robots in the agricultural field increased to 2.5 times, and the installation of hotel services reached 2.2 times, showing a significant upward trend. Number of Industrial Robots (in thousands): Global Service Robot Installations by Application in 2022 vs. 2023
Source: International Federation of Robotics (IFR), 2024| Chart: 2025 Artificial Intelligence Index Report
agriculture
Reception services
Medical and health care
'Professionally cleaned
Transportation and logistics 8679258
1131265420
0 10 20 30 40 50 60 70 80 90 100 1102023
2022
12. A more detailed definition can be found here. Artificial intelligence in 2025
Index Report
Chapter 5:
Science & Medicine 2025 Artificial Intelligence
Index Report
Table of Contents Chapter V Preview 281 Overview 282
Chapter Highlights 283
5.1 Important medical and biological AI milestones 285
Protein Sequence Optimization 285
Aviary 286
AlphaProteo 287
Human Brain Atlas 287
Artificial Intelligence Virtual Lab 288
GluFormer 289
Evolutionary Scale Modeling v3  
(ESM3) 289
AlphaFold 3 290
5.2 Central Law 291
Protein sequence analysis 291
AI-Driven Protein Sequence Models 291
Public Database for Protein Sciences 293
Research & Publication Trends 294
AI-driven protein science
Paper Statistics 294
Image and Multimodal Artificial Intelligence for Scientific Discovery 295
5.3 Clinical diagnosis and treatment: the field of imaging 296
Data: Sources, Types, and Needs 296
Advanced Modeling Methods 298
5.4 Clinical diagnosis and treatment: non-imaging field 300
Clinical knowledge 300
MedQA 300
Focus: Artificial Intelligence Doctors and Cost-Effective Considerations 301
Medical Large Language Model Performance Evaluation 302
Overview 302 Application of large language models in clinical diagnostic reasoning 304
 Focus: The Impact of Large Language Models on Diagnostic Inference 304
Managerial Reasoning and Patient Care Decisions 304
Focus: GPT-4 assists in clinical management tasks
Evaluation of effectiveness  
 305
Ambient AI voice assistant 306
Deploy, Implement, and Remove 308
FDA Approval 308 for AI-Powered Medical Devices
Success Story: Stanford Medical System 308
 Peripheral Arterial Disease Screening 309
Social Determinants of Health 310
Extracted from electronic health records and clinical records
SDoH 310
Integration of AI Applications and SDoH in the Healthcare Field 311
Synthetic Data 311
Clinical Risk Prediction 311
Drug Discovery 312
Data Generation Platform 312
Electronic Health Record System 313
Clinical decision support
315
5.5 Ethical considerations 317
Meta-analysis 317
5.6 Basic models of artificial intelligence in the field of science 320
Highlights: The iconic model released 320
Access to Public Data Chapter 5: Science & Medicine 282Index Report 20252025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5:
Science and Medicine
overview
This chapter explores the major trends in AI-driven science and medicine, reflecting the technology in these areas
Growing influence. This chapter begins with an overview of the important milestones for AI in 2024 and then analyzes
The application of artificial intelligence in the important field of scientific progress of protein folding. This chapter then explores the role of AI in clinical care, including imaging and non-imaging applications. This includes reviewing the clinical knowledge capabilities in new language models, the diagnostic and clinical management capabilities of AI systems, the practical application of AI in medicine, the application of synthetic data, and the social determinants of health. Finally, the chapter concludes with a discussion of ethical trends in AI medical research. This chapter was prepared by RAISE Health (Responsible AI for Safe and Equitable Health), a collaboration between Stanford University School of Medicine and the Stanford Institute for Human-Centered Artificial Intelligence (HAI). Since its launch in 2023, RAISE Health has been committed to driving innovation in responsible AI in biomedical research, education, and patient care, with a focus on ensuring that these technologies benefit everyone.
Promoting collaborative research and knowledge sharing is at the core of RAISE Health's mission. As part of this commitment,
RAISE Health has partnered with the AI Index Steering Committee to expand the group's focus to key developments in science and medicine. In 2024, this collaboration will result in a first-class chapter on science and medicine, highlighting significant advances in AI at Stanford University and beyond. Building on this, members of the RAISE Health Faculty Research Council, Stanford University School of Medicine faculty, postdoctoral fellows, and undergraduate students from the School of Medicine and the School of Engineering contributed to the 2025 chapter. Index Report 2025
1. More advanced large-scale protein sequencing models are available. In 2024, multiple high-performance large-scale protein sequencing models, including ESM3 and AlphaFold 3, will be launched one after another
Go out. Over time, the scale of these models has expanded significantly, resulting in an increase in protein prediction accuracy.
2. Artificial intelligence continues to drive the rapid development of scientific discovery. The role of artificial intelligence in scientific progress is expanding. The year 2022-2023 will only be an AI I-driven research outburst
Breaking the initial phase, while 2024 will see more breakthrough advances, including Aviary, which trains large language model agents to perform biological tasks, as wellDramatically enhance wildfire prediction
Force of FireSat.
3. The clinical knowledge level of mainstream large language models continues to improve. OpenAI's recently released o1 set a new record of 96.0% in the MedQA benchmark, compared to 2023
The best results announced increased by 5.8%. Since the end of 2022, the test has seen a cumulative 28.4% improvement in performance. As an important benchmark for assessing clinical knowledge, MedQA can:
Being able to approach performance saturation bodes well for more challenging assessments. This points to the need for a more challenging assessment system.
4. AI outperforms doctors in critical clinical tasks. A new study has found that when it comes to diagnosing complex clinical cases, with or without artificial intelligence
Yes, GPT-4 alone can outperform doctors. Other recent studies have shown that AI has surpassed doctors in cancer detection and identifying patients at high mortality risk. However, some of the beginnings
The research shows that the collaborative diagnosis and treatment of artificial intelligence and clinicians can produce optimal results, and this finding deserves to be further studied as a key area.
5. The number of AI-powered medical devices approved by the U.S. Food and Drug Administration (FDA) has skyrocketed. The U.S. Food and Drug Administration approved the first AI-powered medicine in 1995
Therapeutic equipment. As of 2015, only 6 such devices were approved, but that number has surged to 223 by 2023. 6. Synthetic data shows great potential in the medical field. Research published in 2024 suggests that AI-generated synthetic data can help models better identify healthy societies
Determinants, enhance privacy-preserving clinical risk predictions, and facilitate the discovery of new drug compounds. The latest research in 2024 shows that AI-generated synthetic data can be effectively improved
The ability of the model to identify the social determinants of health optimizes the clinical risk prediction of privacy protection and promotes the discovery of new drug compounds. Chapter HighlightsChapter 5:
Science & Medicine 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview 283 Chapter Highlights (continued)Chapter 5:
Science and Medicine
7. The literature on the ethics of medical artificial intelligence is increasing year by year. From 2020 to 2024, the number of papers on the ethics of medical AI has almost quadrupled, from 2020
288 to 1031 in 2024.
8. The basic model enters the medical field. In 2024, a large wave of large-scale medical foundation models will be released, ranging from general-purpose multimodal models such as Med-Gemini to specialty-specific ones
Dedicated models such as EchoCLIP, Vision FM (Ophthalmology) and ChexAgent (Radiology). 9. The public protein database is constantly expanding. Since 2021, there has been a significant increase in the number of entries in major public protein science databases, including UniProt (Growth
31%), PDB (up 23%) and AlphaFold (up 585%). This expansion has important implications for scientific discovery. 10. Won two Nobel Prizes for AI research. In 2024, AI-driven research received top honors, and two AI-related breakthroughs were awarded Nobel Prizes
Prize. Google DeepMind's Demis · Demis Hassabis and John John Jumper with AlphaFold for his expertise in protein folding
He was awarded the Nobel Prize in Chemistry for his pioneering work. At the same time, John John Hopfield and Jeffrey Geoffrey Hinton for his work in the neural network
He was awarded the Nobel Prize in Physics for his foundational contributions. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview 284 This chapter section focuses on the 2024 program created by RAISE Health Labor
The Intelligence Index Working Group and the Artificial Intelligence Index Steering Committee were elected to work with
Major medical and biological breakthroughs related to artificial intelligence.
5.1 Important medical and bio-AI milestones
Protein sequence optimization
Large language models optimize protein sequences
1. Evolutionary algorithms (EAs) simulate key aspects of biological evolution in computer programs to solve complex problems, especially those that do not have an exact rate or a completely satisfactory solution, by finding approximate answers.
Figure 5.1.1 Single-objective optimization results for fitness optimization
Source: Wang et al., 2024 Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
Large language models have recently unexpectedly demonstrated new biological capabilities for protein sequence optimization
Force. Traditional protein engineering requires extensive laboratory research to optimize sequences for extraction
The latest study has found that unfine-tuned large language models have shown amazing results on this task – a hidden capability validated in an adapted version of Llama-3.1-8B-Instruct.
The researchers used directed evolution to confirm that the protein generated by the large language model
Plasma sequences outperform traditional algorithms in both synthetic and experimental adaptability scenarios (Fig. 5.1.1). In this study, the goal is to maximize the fitness value (higher scores represent better performance), and the adaptation scores of the proposed method are compared with the default evolutionary algorithm (EA).
1 result
This optimization capability is not only applicable to single-target tasks, but can also be extended to constrained and multi-objective scenarios with limited budgets. This breakthrough discovery reveals the emerging characteristics of cutting-edge large language models, indicating that their impact on the scientific field will continue to deepen as general-purpose models continue to evolve. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview 285 large language models and language agents perform in task solving in the Aviary environment
Source: Narayanan et al., 2024| Chart: 2025 Artificial Intelligence Index Report
GSM8K hotpotQA SeqQA LitQA2 Protein Stability 0.000.200.400.600.801.00Claude 3.5 Sonnet Claude 3.5 Sonnet agent Claude 3.5 Sonnet agent pass @16
GPT-4o EI agent Llama 3.1 8B EI agent Llama 3.1 8B EI agent majority v ote @32
Task pass rate
Figure 5.1.22025 Artificial intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
Aviary
Large language model agent training for biological tasks
As artificial intelligence systems play an increasingly important role in scientific research applications, such as:
How to design a language model that can invoke tools for complex inference tasks becomes the key
Challenge. The Aviary research platform proposes a structured training framework specifically for three challenging bioscience tasks: DNA manipulation (for molecular cloning), scientific question answering (through searching the scientific literature), and protein stability engineering. Figure 5.1.2 compares the performance data of different models in Aviary's experimental environment, and the results show that the model integrated in the Aviary agent framework performs better in almost all tasks than the Claude 3.5 Sonnet baseline model that is not connected to the experimental environment. This study confirms: (1) Although general-purpose large language models are competent for most scientific research
tasks, but models that are fine-tuned with domain expert knowledge tend to yield better results; (2) AI-driven research processes can be achieved not only by expanding model specifications
Modeling and acceleration can be achieved through interaction with external tools – a capability that is now collectively referred to as "agentic AI" in the academic community.
286Figure 5.1.3 AlphaProteo successfully generated the binder
Source: Google DeepMind 2024
Figure 5.1.4 Three-dimensional brain map image
Source: Google Research 2024 AlphaProteo
AI-driven development of novel high-affinity protein binders
AlphaProteo is a new design-focused development developed by Google DeepMind
Models of high-affinity protein binders that are able to attach specifically
to the target molecule. As shown in Figure 5.1.3, the model has successfully predicted and constructed binding protein structures for seven target proteins. On multiple targets, including VEGF-A proteins associated with cancer and diabetes, AlphaProteo enabled the world's first protein-binding design. The tool has been tested to significantly outperform existing best practices for binders on seven target proteins – some of which the research team evaluated to be up to 300 times more effective than current binders. For the viral protein BHRF1, the design binder has a successful binding rate of up to 88% in DeepMind wet lab testing. Based on data from the tested targets, the binding strength of the binder designed by AlphaProteo is approximately 10 times stronger than that of existing top-of-the-line design methods, marking a major breakthrough in the field of bioengineering. At present, the model has been applied in drug discovery, diagnostic technology and biotechnology.
Atlas of the Human Brain
Synaptic reconstruction of microregions of the human brain 
A team of researchers from Google's Connectomics project has been working on the synaptic layer
It reconstructed a one-cubic-millimeter region of the human brain – what Wired magazine called "the most detailed atlas of brain connections to date." The sample was taken from the left anterior temporal lobe region that was removed during surgery in a patient with epilepsy and imaged using a multibeam scanning electron microscope. The researchers recorded about 57,000 cells — including neurons, glial cells and blood vessels — and 150 million synapses — through more than 5,000 ultrathin sections, each 30 nanometers thick. Figure 5.1.4 shows the results of the reconstruction: excitatory neurons on the left and inhibitory neurons on the right. To handle this massive dataset, the team developed several machine learning tools, such as a flood-filled network for neuronal reconstruction without manual delineation, SegCLR (for cell type recognition), and TensorStore (for cube management). The dataset is available to the public via Neuroglancer, a web-based exploration tool, and its annotation refinement extension CAVE. This project is an important step forward in understanding neural circuits and is expected to provide key insights for the treatment of neurological diseases in the future. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
287 Artificial Intelligence Virtual Lab
Artificial Intelligence Virtual Labs Drive Breakthroughs in Biomedical Research
The role of AI in scientific research is shifting from a passive tool to an active one
Collaborator. A recently released study from Stanford University proposes a virtual AI 
A lab where multiple specialized AI scientists (essentially large language models) work together to conduct research in the form of agents. The role of AI in scientific research is shifting from a passive tool to an active collaborator. A recently published study from Stanford University proposes a virtual AI lab in which multiple specialized AI scientists, essentially large language models, work together as agents with each other. Structured after the Computational Biology Laboratory, the virtual lab consists of a Principal Investigator (PI), a scientifically reviewed AI system, and three subject experts specializing in immunology, computational biology, and machine learning (Figure 5.1.5). The Principal Investigator model is responsible for creating these experts and guiding the research process. Protein design tools such as AlphaFold and Rosetta were used in the study. But the real significance of this study lies not only in the concrete results, but also in the fact that it demonstrates that a lab driven entirely by large language models can also produce meaningful scientific discoveries. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
AI-based laboratory workflows
Source: FreeThinkFreeThink2025
Figure 5.1.5
288 Figure 5.1.6
Figure 5.1.7 Comparison of GluFormer with glycemic management indicators
Source: Lutsker et al., Artificial Intelligence 20242025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
GluFormer
AI-assisted continuous glucose monitoring
GluFormer is developed by the NVIDIA Tel Aviv Institute, the Weizmann Institute and the Institute
A basic model jointly developed by other institutions enables continuous glucose monitoring data
Analyze and predict long-term health trends. The model was trained on more than 10 million blood glucose records from nearly 11,000 individuals, most of whom did not have diabetes. It is able to predict the trajectory of health changes up to four years in advance, such as identifying people at risk of developing diabetes or worsening blood sugar control, even before symptoms appear. In a 12-year study involving 580 adults, GluFormer successfully predicted 66% of new-onset diabetes cases and accurately identified 69% of deaths in a high-risk group of cardiovascular-related deaths. The model's predictions have been replicated in 19 independent populations across five countriesValidated in this study, the total sample was 6,044 people, covering a wide range of health conditions. GluFormer generally outperforms existing standard measures based on glucose monitoring, such as glycemic management metrics
(GMI) (Figure 5.1.6). In the short and long term, models such as GluFormer are promising
Shift diabetes treatment from reactive to proactive prevention and drive earlier clinical intervention.
Evolutionary Scale Modeling v3 (ESM3)
Simulating evolutionary processes to generate novel proteins
The ESM3 model introduced by EvolutionaryScale is a breakthrough
Sexual studies aimed at generating novel proteins by mimicking biological evolutionary processes. The model was trained on 2.78 billion protein sequences with 98 billion parameters. Like many AI models, ESM3 is available in small, medium, and large versions, and is available through APIs or partner platforms. One of ESM3's hallmarks is the design of a new type of green fluorescent protein, esmGFP, which the company estimates would take about 500 million years to evolve in nature. This result was done under the guidance of human reasoning. Figure 5.1.7 illustrates the performance of ESM3 models at different scales to generate proteins under the cue of atomic structure coordination. The results show that the larger the model size, the greater the number of tasks completed. ESM3 is open source and data-driven, enabling collaborative research in the fields of synthetic biology and protein engineering, with applications including drug discovery, materials science, and environmental engineering. Evaluation of the ESM3 model in a protein generation task based on atomic coordinate cues
The percentage of tasks that have been completed
Model source: ESM3, 2024| Chart: 2025 Artificial Intelligence Index Report
Comparison of 289AlphaFold 3 with baseline method in protein-ligand docking
Figure 5.1.858.1067.2068.2077.30
73.1084.40
59.7070.10 70.5079.5080.5093.20
Vina Vina + Conf. Ensemble Gnina Gnina + Conf. Ensemble AF3 AF3 Pocket Specﬁed020406080100 RMSD < 2 and PB-valid RMSD < 2
Method%RMSD< 2ÅSource: ESM3, 2024| Chart: Artificial Intelligence Index 2025 Report Artificial Intelligence 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.1 Important medical and bio-AI milestones
AlphaFold 3
Predict the structure and interactions of all living molecules
AlphaFold 3 from Google in partnership with Isomorphic Lab is 
The latest advancement in the AlphaFold series, its function has gone beyond protein structure prediction to can
More accurately simulate interactions between proteins and key biomolecules, including DNA, RNA, small molecule ligands, and antibodies. Figure 5.1.8 illustrates the performance of AlphaFold 3 in predicting protein-small molecule ligand binding accuracy and compares it to other leading docking tools such as Vina and Gnina. In the figure, the Angstroms-Root Mean Square Deviation (RMSD) in the prediction results is less than 2Å, which is an important indicator to evaluate the docking accuracy.
2 3 Performance of AlphaFold 3
It is comparable to previous state-of-the-art methods, and performs particularly well where the binding site has been pre-set, i.e., the docking algorithm obtains prior information about the specific region of the protein that the small molecule (ligand) is expected to bind. By modeling the interactions between small molecules and proteins, AlphaFold 3 is able to accelerate the drug discovery process, which has important implications for disease research. In addition, the open-source nature of AlphaFold 3 gives researchers around the world greater power and freedom.
2902. A docking tool like Vina is a computational procedure for molecular docking, which is a process of predicting how a small molecule, such as a drug, will interact with a target protein. These tools can help scientists simulate and visualize how molecules bond with the active sites of proteins
This is crucial in drug discovery. 3. The chart: Two bar charts with different shades are used to represent different accuracy criteria for molecular docking prediction. The light colored bar indicates the percentage of docking results with a mean deviation (RMSD) of less than 2 Å, which means that the predicted pose is structurally accurate. The darker bar applies a stricter criterion, showing the proportion of predicted results that not only have RMSD values within 2 Å, but are also correctly positioned (PB-valid) within the binding pocket. This distinction highlights the difference between general docking accuracy and more precise and biologically relevant binding predictions. Artificial intelligence has profoundly revolutionized many areas of science, among which proteins
Science is one of the most affected disciplines. Understanding protein sequences is
The foundation of biological research, which has far-reaching implications for drug discovery, synthetic biology, and disease research. Recent breakthroughs in artificial intelligence technology have enabled scientists to analyze and predict protein function, structure, and interactions with unprecedented precision. As the field evolves, these technological advancements will have a significant impact on healthcare, biotechnology, and regulatory systems. This session will highlight key developments in AI-driven protein analysis over the past year, focusing on public databases, evolving research trends, and emerging policy considerations.
Emerging Structural Prediction Results, CASP15
Source: EvolutionaryScale, 2024
Figure 5.2.1 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview 5.2 The Central Law
Protein sequence analysis
AI-driven protein sequence models
Over the past year, AI has made significant progress in protein sequence analysis. large-scale
Machine learning models have improved our ability to predict protein properties, advancing structural biology and molecules
The research process of the project. As mentioned earlier, several representative protein sequence modeling systems, including AlphaFold, ESM2, and ESM3, have been published.
The ESM3 model fuses multimodal inputs, including sequence, structure, and interaction data, which are much larger
The parameter size also improves the representativeness and prediction accuracy of the model. As the size of the ESM family of models expands, the protein prediction performance continues to improve. For example, ESM C, a next-generation model released in 2024, demonstrated higher prediction accuracy in the Structural Prediction Authority Assessment (CASP15) (Figure 5.2.1).
291 Chapter 5 : Science and Medicine
5.2 Central Law 292 Figure 5.2.22025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.2 Central Rule
Other significant advances, such as ProGen, a generative AI model,
The ability to design functional protein sequences has been demonstrated, highlighting the AI-assisted
The potential of protein engineering. At the same time, models based on the Transformer architecture, such as ProtT5, leverage deep learning techniques to make predictions from only the sequence data
Protein function and interactions have advanced the development of computational biology. Figure 5.2.2 illustrates multiple models of key protein sequences and their parameter scales by publication time. As shown above, the research trend is moving towards very large models with ever-expanding training datasets. These AI-driven approaches are reshaping protein science, reducing reliance on costly and time-consuming experimental methods and making the exploration of protein function and design more efficient.
Protein sequence model size 2020-2024
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Number of parameters (unit: billion)
Model (sorted by release date) 293 dataset Release Date Description
Protein Database (PDB)
PFAM 19951971 is the first open digital resource in the life sciences, a database of experimentally resolved protein structures.
A comprehensive database of protein families that provides annotation and multi-sequence alignments based on hidden Markov models.
STRING 2000 PROVIDES AN IMPORTANT RESOURCE FOR INFORMATION ON PROTEIN-PROTEIN INTERACTIONS AND THEIR EVOLUTIONARY RELATIONSHIPS.
UniProt 2002 remains the gold standard for protein sequence and functional annotation, and AI-assisted redaction improves its accuracy.
PDBbind 2004 is a subset of PDBbind, which contains protein-biomolecule complexes such as protein-ligand, protein-protein, protein-nucleic acid, etc.
An important resource for structural biology in the AlphaFold Database 2021, which now integrates AI models to predict missing experimental data. Key Protein Science Database
Source: Artificial Intelligence Index 2025
Figure 5.2.3
2019 2020 2021 2022 2023 2024 2025100K1M10M100MUniProt AlphaFold DB Number of Entity Entries (logarithmic scale)
Figure 5.2.4 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.2 Central Rule
Public Database of Protein Science
Expansion of public databases for artificial intelligence applications in protein science
played a key role. Finely curated large-scale datasets enable AI models to be trained on diverse biological sequences, enhancing them
Predictive power. Figure 5.2.3 lists several key protein science databases
and the date of its release.
Over time, multiple protein science public databases have been indexed
The number of projects is also growing (see Figure 5.2.4). Proteins generated by artificial intelligence
These databases are constantly enriched with qualitative data, making them an indispensable tool for research and industry. However, maintaining data quality and preventing bias in AI models remains an ongoing challenge. Growth of public protein science databases, 2019-2025
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report Research & Paper Publication Trends 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.2 Central Rule
294 Papers Statistics for AI-Driven Protein Science
The application of artificial intelligence in protein science research is rapidly expanding, which has shifted from:
Over the past year, PubMed and bioRxiv have been on the number of AI-driven studies
This can be seen in the uptrend. The research covers a number of key areas. With the development of machine learning, protein structure prediction has become more efficient, providing deeper structural insights. AI models are now able to infer biochemical functions from raw sequences more accurately, improving functional prediction capabilities. In addition, researchers are developing AI models that can predict protein-drug interactions, and can even design new drugs that target specific proteins directly from scratch. These two tasks are important for the drug to be issued
Now and development is crucial. In addition, artificial intelligence with novel features generates eggs
White matter is emerging, especially in enzyme engineering and therapeutic applications
It marks an important step forward in the design of synthetic proteins. Figure 5.2.5 shows
AI-driven research in the field of protein science in 2024 is available throughout life
The field of life science
in the percentage of. The most studied topic is functional prediction (accounted for 
8.4%), followed by protein structure prediction (7.6%) and protein-drug phase
Interactions (3.0%).
7.60%
Figure 5.2.50% 1% 2% 3% 4% 5% 6% 7% 8% Synthetic protein design, protein-drug interaction, protein structure prediction, function prediction
Statistics on AI-Driven Papers in Biological Sciences (% of Total) Research Field: Proportion of AI-driven research in Protein Sciences in Life Sciences in 2024
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report 2952025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.2 Central Rule
Images and multimodal AI facilitate scientific discovery
Cryo-electron microscopy, high-throughput fluorescence microscopy, and whole-section imaging
, enabling scientists to observe and analyze at the atomic and subcellular levels with extreme precision
and tissue-level structures, thus revealing new insights into complex biological processes. To achieve this, researchers interpret and contextualize findings in images based on existing scientific knowledge to link observations to biological functions and disease associations. With the rise of high-throughput microscopy, research focuses increasingly on the intersection of visual models, visual-linguistic models, and, more recently, fundamental models of visual-omics. The number of basic models under different imaging techniques is increasing year by year (Figure 5.2.6). In the case of optical imaging, for example, the number of relevant models will increase from 4 in 2023 to 8 in 2024. In 2023, no models have been released for electron microscopy and fluorescence microscopy, but in 2024, four models will be available in each of these fields. Overall, with the accumulation and disclosure of data, the number of basic models in the field of microscopy is continuing to rise.Number of base models under different microscopy techniques, 2023–2024
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 5.2.6 Number of Base ModelsFluorescence Microscopy Electron Microscopy Artificial intelligence in medical imaging in light microscopy is rapidly evolving and expanding to new data
modality and attempts to answer increasingly complex clinical questions. Currently, the U.S. Food and Drug Administration
More than 80% of machine learning software approved by the FDA is for medical image analysis. Currently, AI is primarily used in two-dimensional (2D) image environments, where traditional image processing architectures such as convolutional neural networks (CNNs) and Transformer can be used effectively. However, despite several success stories in the field, many AI applications in medical imaging still rely heavily on limited training datasets.
In histopathology, for example, staining a patient's biopsy sample is one of the following
Routine, but only a very small part of it is digitized and made public. Fewer datasets contain the paired annotations or omics data needed to accomplish complex classification tasks. Currently publicly available histopathology datasets typically do not exceed 10,000 patient samples. One of the most comprehensive data resources is the Cancer Genome Atlas (TCGA), which includes a total of 11,125 patient samples with clinical annotation, genome sequencing, and protein expression data covering 32 cancer types. As a result, many histopathology AI models have less than 1,000 samples trained on data, especially when models are labeled with genomic or proteomic data. Limited training samples will lead to an increased risk of overfitting and reduce the generalization ability of the model.
Figure 5.3.1 illustrates patients in the U.S. states used to train clinical machine learning algorithms
Cohort distribution. The data suggests that most of the patient data used to train deep learning algorithms is concentrated in California, Massachusetts, and New York, raising concerns about the limitations of dataset coverage.
2965.3 Clinical diagnosis and treatment: imaging
Data: source, type, and demand
Figure 5.3.1 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.3 Clinical diagnosis and treatment: imaging
Cohort distribution of patients used to train clinical machine learning algorithms by state in the United States, 2015–2019
Source: Kaushal et al., 2020 | Chart: Artificial Intelligence Index Report 2025 297 Figure 5.3.Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.3 Clinical diagnosis and treatment: imaging
The number of tokens in the dataset used for medical versus non-medical language and image model training
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 reports that these data limitations are more pronounced in the field of three-dimensional (3D) medical imaging.
Although AI has traditionally focused primarily on two-dimensional modalities, such as chest X-rays, groups
Pathological sections and fundus photography, but in recent years, their applications have expanded to include 3D imaging modalities, including computed tomography (CT), magnetic resonance imaging (MRI), and 3D histopathological analysis. 3D analysis provides richer data, enabling AI models to learn patterns from volumetric structures and complex surfaces that are often imperceptible in 2D slices. Although a range of promising methods have been developed for analyzing 3D medical images, data limitations and practical needs remain. The 3D datasets that are currently publicly available are still very limited. Among them, the scale is larger
These include the UK Biobank (about 100,000 MRI scans) and the cancer imaging archive TCIA (about 50,000 studies). Although 3D samples are routinely collected in histopathology, 3D imaging has not become standard practice, resulting in a lack of publicly accessible 3D histopathology datasets. In addition, the problem of standardization is still prominent, mainly due to variability in the pathology image acquisition process. Differences in instrument setup, staining methods, and protocols between institutions can introduce batch effects, which are further exacerbated by limited training data. Training high-precision AI models requires a lot of data: convolutional neural networks
CNNs typically perform well with about 10,000 annotated images, but Transformer models require orders of magnitude higher amounts of data. While datasets such as MIMIC-CXR (377,000 images) and CheXpert Plus (approximately 226,000 orthotopic radiology images with radiology reports and patient metadata) are important, they are still much smaller than ImageNet (approximately 14 million images). Data integrity and bias remain key challenges.
Figure 5.3.2 illustrates the training of different mainstream medical language models and image models
Data tokens and compare them with generic text and image models. For example, GatorTron is a large clinical language model for unstructured patient information extraction from electronic health records, with a training corpus of 82 billion tokens; In comparison, Llama 3 is trained at 15 trillion words, which is about 182 times more than the former. In terms of image models, RadImageNet is an open radiology deep learning research dataset containing the equivalent of 16 million image tokens; And OpenAI's early image generator DALL· E has about 6 billion words to train, which is 375 times more than the former.  
80B20T
GatorTron Llama 3100B1T10T
20M6B
RadImageNet DALL-E100M1B number of tokens (logarithmic scale)
Number of Tokens (Logarithmic Scale) Medical Non-Medical 298 Modeling Methods Representative Model Publishing Advantages Challenges
1. RoentGen (2022)
2. RNA-CDM (2023)3. XReal (2024) diffusion model
Large visual-language models
（LVLMs）1. CheXagent (2024)
2. Merlin (2024)3. Med-Gemini (2024)4. PathChat (2024)5. TITAN (2024)6. PRISM (2025)7. BiomedParse (2025)
Pure 2D vision base model
1. CTransPath (2022)2. Virchow (2024)3. UNI (2024)4. MedSAM(2024)
Multiscale/slice-level models
1. HIPT (2022)2. MEGT (2023)3. MG-Trans (2023)4. HIGT (2023)5.Prov-GigaPath (2024)
Figure 5.3.3 Advanced Modeling Methods
Figure 5.3.3 illustrates the mainstream clinical imaging modeling methods, the key model releases under each approach, and the main challenges faced by each. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.3 Clinical diagnosis and treatment: imaging
Longitudinal imaging data is important for modeling disease progression, but it is still important
Obviously insufficient. For example, the ADNI project (Alzheimer's Disease Neuroimaging Project) covers
Approximately 2,000 participants and studies spanning more than 15 years are typical of this type of study. However, scalable multimodal longitudinal datasets are still very rare. Filling these gaps requires a combination of privacy-focused data sharing strategies
(e.g., federal learning), synthetic data generation techniques, and better annotation strategies. In order to train and validate robust AI models for medical imaging, it is necessary to build larger, more comprehensive, and multi-cohort source training datasets. Improving the availability of high-quality, labeled data is expected to improve model performance. At the same time, improving validation practices will also increase confidence in the model and facilitate its smoother application in clinical practice.
Medical Image Modeling Methods and Representative Artificial Intelligence Models
Source: Artificial Intelligence Index 2025
Generation is used for training, privacy-preserving, and pathology-specific enhancement
Strong synthetic medical images that outperform GAN models in terms of stability and diversity
Fusion of medical images and text for better diagnosis,
Segmentation and automatic report generation to expand multimodal capabilities
Layered transformers are added with graph neural networks
Strong whole-slice image analysis to improve diagnostic accuracy and interpretability can be used for pan-cancer detection, biomarker prediction and imaging
Segmentation to reduce annotation burden, dataset bias, hallucinatory artifacts, and diagnostic uncertainty
Data is scarce, and the environment is full of resources
Insufficient processing capacity and high computing requirements
Scalability, computational efficiency, and dataset variation
There are challenges in the opposite sex: weak generalization ability and cross-modal adaptation
Limited capacity 299 Figure 5.3.4 Medical specialties Representative release model
Echocardiography 1. EchoCLIP (2024)
Oncology 1. MUSK (2025)
Ophthalmology 1. RETFound (2023)
2. VisionFM (2024)
Pathology 1. CTransPath (2022)2. CHIEF (2024)3. Prov-GigaPath (2024)4. PathChat (2024)5. TITAN (2024)6. Virchow (2024)7. UNI (2024)
Radiology
1. RoentGen (2022)2. CheXagent (2024)3. Merlin (2024)4. PRISM (2025) 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.3 Clinical diagnosis and treatment: imaging
In recent years, the application of basic models in the field of medical imaging has grown significantly. Figure 5.3.4 classifies representative models by medical specialty. It is worth noting that pathology
The number of newly released models has increased significantly, making it one of the areas with the highest concentration.
Medical specialties and representative artificial intelligence models
Source: 2025 Artificial Intelligence Index 3005.4 Clinical diagnosis and treatment: non-imaging field
Clinical knowledge 2025 Artificial intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
This section examines the role of large language models and recent artificial intelligence models in key medical knowledge
Recognize performance in benchmarks.
MedQA
To evaluate the clinical knowledge performance of an AI model, it is necessary to measure its medical expertise
Flat, especially knowledge that can be applied to clinical scenarios.
MedQA is a comprehensive dataset launched in 2020
The Medical Exam, which contains more than 60,000 clinical questions, is designed to challenge doctors. Artificial intelligence has improved significantly on MedQA benchmarks. Microsoft
A recent test of the model O1 with OpenAI's research team achieved a new optimal score of 96.0%, an improvement of 5.8 percentage points from the record set in 2023 (Figure 5.4.1). Since the end of 2022, the benchmark has improved by a cumulative 28.4 percentage points. As with other general knowledge benchmarks described in Chapter 2, MedQA may be approaching saturation, which means that more challenging assessment systems need to be developed.
2021 2022 2023 20240%20%40%60%80%100%MedQA test accuracy 91.10%, depth fine-tuning 96.00%, no fine-tuning used
Figure 5.4.1 MedQA: Test accuracy
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report 3012025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Focus:
Artificial intelligence doctors and cost-benefit considerations
Some researchers have pointed out that the evaluation of large language models in the medical field should not be relied on alone 
MedQA, benchmarks should be used that cover a broader sub-area of medicine. though 
MedQA has some value, but when used alone, it may not reflect the complexity of real-world clinical applications. In contrast, the use of multiple benchmarks resulted in greater clinical relevance and a more robust assessment of model performance.
In 2024, the University of California, Santa Cruz, the University of Edinburgh and the United States
The National Institutes of Health has collaborated on a more extensive study to test AI-powered medical systems. The study evaluated five leading large language models, including the newly developed O1 model with "chain inference" capabilities. The rest of the models include GPT-3.5, Llama 3-8B, GPT-4, and the purpose-built medical model Meditron-70B. The models were tested on 19 medical datasets, with tasks ranging from concept recognition, text summarization, knowledge-based question answering, clinical decision support, and medical computing. Figure 5.4.2 shows the average performance of the five large language models across all datasets. The results show that the clinical knowledge capabilities of large language models are continuously improving, especially for new models with real-time inference capabilities such as O1. Despite significant progress, challenges remain, including hallucinations and inconsistencies in multilingualism.
Previous research (cited in last year's AI Index.)) table
Clearly, prompting strategies like Medprompt can significantly improve the performance of large language models in medical benchmarks without additional fine-tuning. OpenAI's newly released O1 model draws on some of the insights from the above strategy to enhance model performance by introducing a runtime inference mechanism before generating a final answer. The researchers found that even without the use of specialized prompt engineering techniques, O1 outperformed the GPT-4 series of models combined with Medprompt in medical tasks. However, their analysis also highlights the trade-off between accuracy and cost that o1 faces: while it scores 5.8 percentage points higher on the MedQA benchmark than GPT-4 Turbo using Medprompt, it costs about 1.5 times more in terms of computational resources. As shown in Figure 5.4.3, there is a clear trade-off between cost and accuracy in this benchmark. This phenomenon presents a key consideration for healthcare practitioners deploying generative AI capabilities in clinical scenarios: they must balance performance gains with computational costs.
GPT-3.5
Meditron-70B
GPT-4
Llama3-8B
o1
2022 2023 20240%20%40%60%80%100%
Figure 5.4.2
Figure 5.4.3 Enhanced Pareto Frontier: Accuracy vs. Cost
Source: Nori et al., 2024 Performance of selected large language models on medical datasets
Source: Xie et al., 2024| Chart: 2025 Artificial Intelligence Index Report
The average accuracy rate is 302 for the performance evaluation of medical large language models
Overview of Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
In recent years, there has been a sharp rise in interest in evaluating the performance of large language models in medical tasks. A search for the term "large language model" in the PubMed database yielded a total of 1,566 searches 
of these, of which 1,210 were published in 2024 alone (Figure 5.4.4).
Figure 5.4.4 Number of papers on large language models included in PubMed in 2019–2024
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Number of papers 303 Figure 5.4.5 4
4. Tasks marked with an asterisk (*) are natural language processing (NLP) or natural language understanding (NLU) tasks. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
A systematic review conducted in early 2024 identified more than 500 reviews
This article focuses on evaluating the performance of natural language processing (NLP) in medical tasks
and focus on the area of medical decision support (Figure 5.4.5).  Most studies evaluating the performance of medical NLP systems have focused on two types of tasks: medical knowledge enhancement tasks (419 papers) and diagnostic assistance tasks (178 papers).
Medical tasks, NLP and NLU tasks, and dimensions assessed in 519 studies
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Accuracy, Comprehensiveness, Factuality, Robustness, Fairness, Bias, and Bias
Hazard Assessment Calibration & Uncertainty Deployment Metrics
Enhance medical knowledge
to make a diagnosis
Communicate information to patients
Make treatment recommendations
Communicate with patients
Medical Coordination and Planning
Triage patients
Conduct a literature review
Synthesize research data, generate medical reports, conduct medical research, provide asynchronous care, manage clinical knowledge, record clinical notes, generate referral recommendations, and optimize surgical operations
Biomedical Data Mining
Generate a billing code
Prescription
Q&A Task(*)Text Classification(*)Information Extraction(*)Summary Generation(*)Conversation Interaction(*)
Translation(*) Task Category 304 Focus: Application of large language models in clinical diagnostic reasoning
Diagnostic errors have led to a large number of patient harms, and many institutions are exploring AI as a tool to improve the diagnostic process.
Figure 5.4.6 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Managerial reasoning and patient care decisions 
In addition to the diagnosis itself, the physician must also deal with treatment options, risks, and treatment
Multidimensional decision-making tasks, such as benefit trade-offs and patient preferences, are collectively referred to as "management reasoning". Researchers are exploring large slangs
Whether the speech model can improve these complex, context-dependent reasoning skills. The impact of large language models on diagnostic inference
In 2024, a single-blind, randomized controlled trial tested the treatment
In complex clinical cases, the auxiliary effect of GPT-4 is compared with traditional medical resources
contrast. The study, which involved 50 licensed physicians in the U.S., assessed the question of whether AI-assisted decision-making could improve the accuracy and efficiency of doctors' diagnoses. The results of the study showed that the overall performance of physicians with the assistance of GPT-4 was not significantly better than that of the group of physicians who relied solely on traditional tools. In fact, 76% of AI-assisted doctors used the accuracy of their diagnosis, compared to 74% of those who used traditional tools, a slight improvement. However, in a secondary analysis, the researchers found that the GPT-4 model alone outperformed all physician populations, achieving a 92% diagnostic reasoning score, 1 6 percentage points higher than the physician population without AI (Figure 5.4.6). While AI models excel in standalone tasks, integrating them into real-world clinical workflows presents challenges. In terms of time efficiency, there was no significant difference in the time it took for physicians to complete a case between groups, suggesting that the introduction of large language models in clinical workflows still did not bring efficiency benefits.
Even if the AI model performs well in independent tests, just let
The use of large language models by physicians is not enough to improve their performance. This phenomenon is also seen in other AI and human collaboration scenarios, suggesting that true collaboration between model performance and clinical professionals requires redesigning workflows, improving user training, and human-computer interfaces.
Performance of large language models in clinical diagnosis
Source: Goh et al., 2024| Chart: 2025 AI Index Report Score
Use GPT-4 Physician + GPT-4 Physician + Conventional Resources Only 305 Figure 5.4.7 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Focus:
Evaluation of the effect of GPT-4 in assisting clinical management tasks
A prospective, randomized, controlled trial between 2024 and 2025
The auxiliary effect of GPT-4 in complex clinical management decision-making was evaluated. study
A total of 92 practicing physicians were involved, half of whom used GPT-4 to assist and combine standard resources, and the other half relied solely on traditional medical references. The results are displayed
: Physicians using GPT-4 outperformed the control group on average in task performance 
6.5 percentage points (see Figure 5.4.7). Interestingly, the performance of using GPT-4 alone was comparable to that of the GPT-4-assisted physician group, suggesting that near-autonomous AI management support may be feasible in certain well-defined scenarios. However, the introduction of AI assistance also comes with trade-offs: doctors using GPT-4 take slightly longer on each case. Researchers attribute this to deeper thinking and analysis by physicians in the decision-making process. Overall, generative AI can lead to substantial improvements in clinical decision-making, but its impact may be more about the quality of decision-making than simply improving efficiency.
Performance of large language models in clinical diagnosis
Source: Goh et al., 2024| Chart: 2025 AI Index Report Score
GPT-4 Physician + GPT-4 Physician+ only
Only the general resource Panel A is the cumulative number of independent physicians with AI voice assistant enabled
Panel B is the cumulative number of AI voice assistant services
306 environment-based artificial intelligence voice assistant
Figure 5.4.8 Source: Tierney et al., Artificial Intelligence 20242025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Clinical documentation has long been a major source of burden and burnout for physicians
One. Ambient speech recording technology is rapidly evolving and will incorporate large language models
Integrate into the doctor-patient communication process. The first related study, published in the journal NEJM Catalyst, describes the deployment of environmentally-based AI voice assistant technology in Kaiser Permanente Northern California by the end of 2023. This technology has been adopted by thousands of clinicians before the end of the pilot (Figure 5.4.8). This was followed by a second study, published in the journal JAMIA, on the experience of piloting the technology at Intermountain Health. It's important to note that both studies are evaluating earlier versions of technology that have not yet been fully automated or integrated with electronic health record systems (EHRs). Cumulative usage of environment-based AI voice assistant tools from October 16 to December 24, 2023
Between launch on October 16 and December 24, 2023, there were a total of 3,442 independent registered physician and staff users 
Enable the AI voice assistant (see Panel A); A total of 303,266 physician-patient interactions (see Panel B) were recorded, all of which had voice assistant enabled and each session lasted at least 2 minutes.
2023 Cumulative Number of Doctor Users (Person)
In 2023, the cumulative number of doctor users (person) is 307
Figure 5.4.9 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Researchers at Stanford University conducted a two-phase study to evaluate
The effect of environment-based AI voice assistant technology. The study is based on previous work
On this basis, a full-process integrated and automated artificial intelligence medical document system was tested. The study showed that the system achieved significant improvements in both objective indicators (e.g., time required for paperwork) and subjective indicators (e.g., doctors' work experience). Technology adoption was good, with an average adoption rate of 55% among participating physicians. The AI voice assistant has brought significant efficiency gains, saving doctors an average of about 30 seconds per record and reducing the overall electronic health record (EHR) operation time by about 20 minutes per day (Figure 5.4.9). In addition, physicians generally reported significant reductions in work load and burnout, with an average reduction of 35% and 26%, respectively. These results suggest that AI-powered voice assistant technology can effectively improve physicians' workflow and well-being, saving time and alleviating onerous administrative burdens.
According to reports, investment in environment-based voice assistant technology will be received by 2024
Nearly $300 million. While current applications of the technology are focused on clinical documentation, optimists in the research and industry expect that it will be fully deployed in the future, covering both outpatient and inpatient scenarios, and ultimately automating processes such as order issuance, billing and coding, and real-time clinical decision support. The impact of AI records on physicians' use of electronic health records (EHRs).
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Change in average daily documentation time (minutes)
Change in Average After-Hours Recording Time Per Day (min)
Change in average total daily time of electronic health record (minutes) 308 1 1 1 1 1 1 5 2 2 3 3 6 6 18 26 64 80 114 129 160 223
 0  0 0  0 0  0 0  01995
1996
1997
1998
1999
2000
2001
2002
2003
2004
2005
2006
2007
2008
2009
2010
2011
2012
2013
2014
2015
2016
2017
2018
2019
2020
2021
2022
2023050100150200 the number of AI-powered medical devices
Figure 5.4.10 Deployment, Implementation, and Removal
FDA Approval for Artificial Intelligence Medical Devices for Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
The use of AI in clinical settings has increased exponentially over the past decade
long, especially in the U.S. Food and Drug Administration (FDA)-approved artificial intelligence
The number of medical devices has proliferated. The FDA first approved a medical treatment with artificial intelligence capabilities in 1995
Equipment. For almost 20 years since then, the number of approvals has remained in the single digits each year. Until 2015, a total of 6 AI medical devices were approved that year. Since then, the number of annual approvals has grown exponentially, peaking at 223 in 2023 (Figure 5.4.10).
Case Study: Stanford Health Care
Successful deployment of generative AI functions in clinical practice is requiredtorr
A system framework to ensure fairness, practicality and reliability. Stanford Medical
The system uses its internally developed FURM framework (Fair, Useful, Reliable, Measurable) when evaluating and deploying generative AI capabilities. Of the 6 AI use cases evaluated, 2 have been successfully deployed: (1) peripheral arterial disease (PAD) screening; (2) Documentation and coding improvements for inpatients. This section will detail the application of peripheral artery disease screening. Number of AI-powered medical devices approved by the FDA from 1995-2023
Source: FDA, 2024| Chart: 2025 Artificial Intelligence Index Report 309
Figure 5.4.11 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Suggested models and workflows for integrating PAD screening into clinical practice
Source: Callahan et al., 2024 Peripheral Arterial Disease Screening
Peripheral arterial disease is a chronic vascular disease that is often overlooked in the early stages.
This can lead to serious complications such as severe limb ischemia or even amputation. For ascension early
Stanford Medical System has developed and deployed an AI-enabled PAD classification model to optimize the screening process and improve patient care.
The main objectives of this screening tool are: to achieve earlier in the primary care population
stage of diagnosis so that medical or surgical intervention can be taken before the condition worsens. By identifying high-risk patients, the model can also help optimize resource allocation, ensuring that those most in need of intervention receive immediate follow-up and treatment.
To achieve seamless integration with clinical workflows, the AI tool is:
Designed to automatically assess the risk of peripheral arterial disease (PAD) and to label high-risk individuals for further evaluation. Once the condition is confirmed, the patient will be referred to the Department of Vascular Surgery for consultation. Figure 5.4.11 illustrates the recommended model and operational path for integrating PAD screening into the clinical workflow, including key aspects such as risk assessment, referral process, and patient follow-up.
After completing the pilot phase, the AI tool moves on to Phase 2
(Stage 2) and has been fully deployed in the Stanford Medical System. The model is expected to affect approximately 1,400 patients per year. In addition to the significant clinical benefits, the project has proven to be financially sustainable and can function without external funding. By increasing early detection rates, reducing the risk of serious complications, and improving patient outcomes, this AI-driven strategy is gradually reshaping the standard treatment pathway for peripheral arterial disease. 310 Social Determinants of Health: Artificial Intelligence 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Large language models and AI-based clinical decision support (CDS) systems
Changing medical practice is being driven, but there are differences in adoption across different specialties
Different. Some specialties are quick to embrace these tools, while others are cautious. this section
Research and innovation are reviewed, with emphasis on the importance of the evidence base. One of the core areas is Social Determinants of Health (SDoH), such as socioeconomic status and living environment. In 2024, Artificial
Advances in intelligence are focused on SDoH to improve patient care and advance health equity. Extraction of SDoH from electronic health records and clinical records
Fine-tuned multi-label classifiers (such as the Flan-T5 XL) are instrumental in identifying clinical pens
In terms of SDoH information, it outperformed the ChatGPT series of models and was less sensitive to demographic descriptions. Such models exhibit lower bias when introducing race, ethnicity, or gender variables. Figure 5.4.12 illustrates the performance of multiple models to identify SDoH on the Radiation Therapy (RT) test set. Newer generation models, such as Flan-T5-XXL, perform best with the addition of synthetic and annotated data (SDoH tag sentences). Overall, the expansion of the model scale and the optimization of data fusion have significantly improved the SDoH recognition ability.
Extracting SDoH data from electronic health records can help physicians identify patients
social needs (e.g., housing instability or food shortages). Such research highlights the potential of large language models to improve SDoH record quality, resource allocation efficiency, and health equity, while also emphasizing the importance of reducing bias and enhancing synthetic data methods. Multiple models identify the manifestation of SDoH in radiation therapy tasks
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 5.4.12 Macro average F1 value
BERT-base
Model (using the gold number
According to + synthetic data)
BERT-base
Model (gold only.)
data)
Flan-T5-base
Model (gold only.)
data)
Flan-T5-base
Model (using the gold number
According to + synthetic data)
Flan-T5-large
Model (gold only.)
data)
Flan-T5-large
Model (using the gold number
According to + synthetic data)
Flan-T5-XL
Model (gold only.)
data)
Flan-T5-XXL
Model (gold only.)
data)
Flan-T5-XL
Model (using the gold number
According to + synthetic data)
Flan-T5-XXL
Model (using the gold number
According to + Synthetic Data) 311 Integration of AI applications in the medical field with SDoH
Figure 5.4.13
5. A regular smoker is someone who has smoked at least 100 cigarettes in their lifetime. Figure 5.4.14Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Synthetic data
Synthetic data is improving privacy-preserving analytics, clinical modeling, and artificial intelligence
Able to train and revolutionize the field of healthcare. It optimizes the workflow and is able to simulate
rare cases, and support innovative practices driven by artificial intelligence. However, as noted in the first chapter of this year's AI Index, concerns about its scalability have prompted us to be cautious in our adoption process.
Clinical risk prediction
Recent studies have verified the role of synthetic data in the prediction of clinical risks in privacy protection
Value. A recent study validated the effectiveness of synthetic data in privacy-preserving clinical risk prediction. The researchers used three generative models, ADSGAN, PATEGAN, and DPGAN, to model the lung cancer risk of ever-smokers in the UK Biobank.
5 Figure 5.4.14
The comparison results of principal component analysis (PCA) eigenvalues are presented, which shows that the data distribution generated by ADSGAN and PATEGAN is highly consistent with the real data, which can support reliable clustering and feature selection. These findings suggest that synthetic datasets can retain the authenticity of statistical features without relying on real and identifiable patient information, support exploratory analysis, and can be used to develop predictive models.
Principal component analysis
SourceSource: Qian et al., 2024 Figure 5.4.13 highlights various medical specialties and illustrates how AI can incorporate social determinants of health into various fields.
Specialty Field: Latest Research Integrated Description
Oncology Stasy et al., 2024
Cardiology Snowdon et al., 2023
Quer et al., 2024
Psychiatry Stade et al., 2024 AI tools are being used to incorporate SDoH into cancer treatment plans, such as considering patient accessibility and social support
to help oncologists develop individualized and feasible treatment strategies
Artificial intelligence models for cardiology have begun to incorporate SDoH to improve risk assessment for diseases such as hypertension and heart failure
degree to optimize treatment management.
Large language models are used to analyze SDoH data at the community level, helping to identify areas where social risk factors are concentrated, thus
Prioritize the deployment of mental health intervention resources.
Number of principal components Number of clusters
 (a) Principal component analysis and (b) are eigenvalues for K-means cluster analysis
Bayesian Information Guidelines 312 Drug Discovery
Data generation platform
Figure 5.4.15
Figure 5.4.16
6. The tortuosity refers to the degree of tortuosity of the path compared to the shortest possible straight-line distance between two points. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
A recent study published in the journal Nature, mentions:
came up with a generative AI approach for using drugs in
In vitro formulation optimization and particle engineering modeling are realized in R&D. The method reduces the reliance on large-scale physical experiments by generating analytical-ready digital drug formulations through an image generator guided by critical quality attributes (CQAs). The research team verified the effectiveness of the method by predicting the percolation threshold of microcrystalline cellulose (MCC) in oral tablets. Figure 5.4.15 Comparing the results of the tortuosity calculation of the real tablet volume (green squares) with the results of the artificial intelligence synthetic volume (red circles).
contrasted.
6 The results of the two are highly consistent and the results are synthetic
Data shows great potential in simulating drug properties.
It can improve the efficiency and modeling capabilities of AI-driven drug discovery.
The platform is ideal for displaying, standardizing, and automating synthetic numbers
The creation of data is essential. The newly published study shows that the proposed Synthetic Tabular Neural Generator (STNG) framework not only enables large-scale synthetic data generation and validation, but also significantly enhances the effectiveness of AI applications in the medical field. Figure 5.4.16 evaluates the effectiveness of different synthetic data generation methods by comparing the area under the curve (AUC) values of the real and synthetic heart disease datasets. In most cases, there is a high degree of agreement between the real and synthetic datasets, demonstrating the ability of synthetic data to accurately model complex health conditions. Advances in synthetic data generation methods can improve data fidelity while reducing privacy risks. Area under the curve used to assess the synthetic cardiology dataset
Source: Rashidi et al., 2024 Percolation Threshold Prediction and Validation Based on AI-Generated Synthetic Structures
Source: Hornick et al., Artificial Intelligence for 2024313 Electronic Health Record Systems 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Integrating AI into electronic health record (EHR) systems can be simplified
Manage processes, enhance clinical decision support, and improve the quality of patient care for mitigation
Burden on the healthcare system. Currently, the EHR market is dominated by several major players, including: Epic, Oracle Health (formerly Cerner), Meditech, and TruBridge (formerly CPSI). These vendors' AI tools are expected to be widely used in their ecosystems due to their market share. As of 2021, the adoption rate of any type of EHR system in U.S. hospitals is close to 90%, with about 80% of certified EHR systems being adopted. One was developed by the American Hospital Association, 
A 2023 IT survey conducted by AHA found that most hospitals that use machine learning or predictive models in their electronic health record (EHR) systems rely heavily on inpatient solutions from a major vendor (Figure 5.4.17). Among them, Epic, Cerner, and Meditech have the highest adoption rates. Epic, Cerner, and CPSI serve hospitals that primarily use vendor-developed models, while users from Meditech and others are more likely to use third-party or hospital-built solutions (see Figure 5.4.18).
Figure 5.4.17 710
 295
 60
 4  5 22 450
 190  183
 8  8 35 160 190  191
 144
 31 244
Epic Cerner Meditech CPSI/Evident Altera Other0100200300400500600700 Machine Learning Models (ML) Other non-ML predictive models are not/inconclusive
Application of the Supplier Hospital Quantity Prediction Model in Major Inpatient Electronic Health Record Providers
Source: AHA Survey, 2024 | Chart: 2025 AI Index Report314 95%
 84%
 30% 75%
 8% 41% 53%
 46% 71%
 42% 46% 68%
 52%
 33% 81%
 33% 54%
 23%
 5%  4% 2% 17%
 0% 9%
 0% 1%  1% 8%
 0% 7%
Epic Cerner Meditech CPSI/Evident Altera Other0%20%40%60%80%100%Self-built models Third-Party Developers Hospital self-development Public Domain Don't Know (ML Development)
Percentage of provider hospitals
Figure 5.4.182025 Artificial Intelligence
Index Newspapertell
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Sources of predictive model development for electronic health record (EHR) vendors
Source: AHA Survey, 2024 | Chart: 2025 Artificial Intelligence Index Report
Integrate AI systems into electronic health record (EHR) platforms, yes:
We want to streamline clinical workflows while improving the integration of healthcare providers and patients
Experience. However, it remains uncertain whether such AI-equipped health information technologies can actually benefit under-resourced populations. These groups often face higher barriers to technology adoption. For example, people living in rural areas are often constrained by structural constraints such as limited network bandwidth, weak healthcare information technology infrastructure, and limited functionality of EHR systems. These factors are the basic supporting conditions for the realization of AI-driven medical systems. In addition, there is still a need to further evaluate whether existing AI tools are equally applicable to EHR systems with weak functional foundations. Today, many healthcare environments still rely on EHR platforms with simplified functionality. Therefore, if we want to truly realize the equitable deployment of AI in healthcare, we must face up to the structural differences caused by the adaptability of technologies and the uneven underlying conditions. 315 Clinical Decision Support
Figure 5.4.192014-2024 Number of clinical trials mentioning artificial intelligence
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report Artificial Intelligence 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Artificial intelligence is revolutionizing the diagnosis, prediction, and management of diseases in healthcare practitioners
and an increasing emphasis on rigorous evaluation of AI systems through clinical trials
Estimate. The development and evolution of artificial intelligence technology in clinical decision support systems (CDS) reflects the gradual shift from passive intervention during the pandemic to data-based proactive clinical decision-making, and the number of related clinical trials is also increasing year by year. As shown in Figure 5.4.19, the number of clinical trials involving AI technologies is showing a steady growth trend. 3162021–Number of clinical trials with AI content by region, 2024
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report Artificial Intelligence 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.4 Clinical diagnosis and treatment: non-imaging field
Figure 5.4.20 Number of Clinical Trials
Germany, Canada, Canada, France, Spain, United Kingdom, Turkey, Italy, United States China: The novel coronavirus pneumonia epidemic has accelerated the use of artificial intelligence in triage, resource allocation, and prognosis
The application of this technology in the field of testing highlights the application of this technology in real-time clinical decision support systems (CDS)
potential. In the post-pandemic era, the application of AI has expanded from emergency response to chronic disease management, diagnosis and treatment process optimization, and workflow integration. For example, the CERTAIN study demonstrated that AI-driven real-time surgical assistance can significantly improve the diagnostic accuracy of gastrointestinal surgery. As of 2023, the application of AI in CDS has been extended to the field of medication safety and workflow optimization, such as the Study on the Prevention of Medication Errors in Pharmaceutical Practice, which uses AI to enable real-time drug error monitoring. The number of AI-driven clinical trials has surged globally, with China (105 trials), the United States (97), and Italy (42) rounding out the top three in 2024 (Figure 5.4.20). As discussed in the previous sections, AI is used in medical research and clinical diagnosis
The increasing application of therapy brings both hope and challenge. Artificial intelligence
Energy systems rely heavily on large amounts of data during training, and the collection, use, and sharing of this data – especially in high-risk areas such as healthcare – can raise multiple ethical issues.
317 288 397 523 674 1,031
2020 2021 2022 2023 202402004006008001,000 AI Ethics Papers Statistics 2020-2024 Artificial Intelligence Ethics Medical Outcomes Statistics
Source: RAISE Health, 2025| Chart: Artificial Intelligence Index 2025 Report 5.5 Ethical Considerations
Meta-analysis
Figure 5.5.2
Figure 5.5.1 Artificial intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.5 Ethical Considerations
In this section, the AI Index team examines thousands of medical ethics
The study conducted a meta-review to systematically sort out the field
Development status. Figure 5.5.1 illustrates the methodological framework adopted by the research team. The data shows that over the past five years, the focus on the ethics of medical AI has increased year by year, and the number of related publications has quadrupled between 2020 and 2024 (Figure 5.5.2). 318 Bias Privacy Fairness Transparency Trust Security Accessibility Stakeholders Fairness Security Security 0% 5% 10% 15% 20% 25% 30% 2024 2023 2022 2021 2020
Ethical Issues: Statistical Percentage of Papers on Medical Ethics in Artificial IntelligenceTop 10 Most Discussed Ethical Issues in Medical Ethics Papers, 2020-2024
Source: RAISE Health, 2025| Chart: 2025 Artificial Intelligence Index Report
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 042
0 1 2 1 0 0 086
159
31 0 0
OpenAI GPT Series
(GPT-3, ChatGPT,
GPT-3.5, GPT-4,
GPT-4-Turbo)OpenAI Vision
(DALL-E, SORA) Google
(LaMDA, PaLM,
Gemini)Meta
(BART, OPT,
LLaMA)Anthropic
(Claude) Mistral Cohere xAI
(Grok)01020304050607080902024 2023 2022 2021 2020
Artificial intelligence tools, artificial intelligence medical ethics papers, artificial intelligence tools discussed in medical ethics papers 2020-2024
Source: RAISE Health, 2025| Chart: Chart 5.5.3 of the 2025 AI Index Report
Figure 5.5.4 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.5 Ethical Considerations
The focus on the application of AI in medical ethics papers has evolved over time. Figure 5.5.3 illustrates the ethics discussed in AI medical papers from 2020 to 2024
Distribution of issues. According to the 2024 data, bias and privacy are the top ethical concerns, followed by fairness. It is worth noting that privacy issues have been hotly discussed in 2020
is higher than the issue of bias, but this trend has shifted significantly in subsequent studies.
In terms of AI tools, the medical ethics literature has given high attention to OpenAI's GPT series, such as ChatGPT (Figure 5.5.4). This phenomenon reflects
Over the past few years, large language models have been gaining traction in the field of medical ethics. 319Source: RAISE Health, 2025 Chart: The 2025 AI Index reports the number of NIH grants for research on AI ethics in healthcare for fiscal years 2020-2024
Source: RAISE Health, 2025| Chart: The 2025 AI Index reports the amount of NIH research funding on AI ethics in healthcare for fiscal years 2020-2024
Figure 5.5.5 Figure 5.5.6 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.5 Ethical Considerations
Figure 5.5.5 and Figure 5.5.6 show the U.S. National Health Study by fiscal year, respectively
The number and total amount of funding funded by the Institute of Medicine (NIH) for medical AI ethics projects.
The data shows that between 2023 and 2024, the number of projects will surge from 25 to 337 (Figure 5.5.5). During the same period, the total amount of funding soared from $16 million to $276 million, a nearly 17-fold increase in just one year. NIH grant amount
NIH Grant Amount (in millions of dollars)
Fiscal Year Fiscal YearThis year, a number of basic models have been developed in various fields of science. Some models are in
On the basis of large language models, fine-tuning is carried out for specific domain literature; Others do
Train from scratch with specialized data, such as time series or meteorological data. Subsequently, these basic models are further fine-tuned for specific scientific tasks or application scenarios.
320 Focus:
Iconic Model Release: 5.6 Artificial Intelligence Foundation Model in Science 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.6 Basic models of artificial intelligence in the field of science
Artificial intelligence has advanced several scientific fields such as physics, chemistry, and earth sciences
Significant progress. The table below summarizes some of the most iconic models in these fields
and new resources to track those progress. This analysis is the first attempt of the AI Index project, which will continue to expand and deepen the coverage of AI-driven scientific progress in a wider range of disciplines in the future.
Release Date Model Name Domain Technical Significance Image
In 2024
Feb. 6: Crystal Large Language Model Materials Science
Figure 5.6.1
Source: Gruver et al., 2024
In 2024
Feb. 14 LlaSMol Chemistry
Figure 5.6.2
Source: Yu et al., 2024 Researchers Based on the LLaMA-2 70B model,
Fine-tuning atomic-level data encoded as text to generate stable materials with nearly twice the metastable generation rate of leading diffusion models (49% vs. 28%), while still being physically plausible. The method supports flexible applications such as unconditional generation, structure completion, and text-guided design, and enhances the perception of symmetry by expanding the model size
To cope with the inefficiency of large language models in chemical tasks
performance, the researchers introduced SMolInstruct, a high-quality dataset with more than 3 million samples covering 14 tasks; Based on this dataset, the LlaSMol model series was developed. Among them, the Mistral-based LlaSMol significantly outperformed GPT-4 and Claude 3 Opus in multiple tasks, and was close to the performance of the task-specific model on the premise of adjusting only 0.58% of the parameters, showing the powerful ability of domain-specific instruction fine-tuning. 3212024 years 
April 23 ORBIT Geosciences
Figure 5.6.3
Source: Wang et al., 2024
In 2024
May 20 Aurora Geosciences
Figure 5.6.4
Source: Bodnar et al., 2024
In 2024 
NeuralGCM weather forecast for July 22
Figure 5.6.5
Source: Kochkov et al., 2024 Highlights:
Iconic Model Released (Continued) Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.6 Basic models of artificial intelligence in the field of science
Oak Ridge National Laboratory Releases ORBIT Model,
This is the largest AI model in climate science to date, with 113 billion parameters, which is 1,000 times larger than previous models. The model was trained using a novel parallel computing technique and tested on the Frontier supercomputer, with sustained performance of up to 1.6 exaFLOPS, marking a new level of AI-driven Earth system prediction.
Aurora is a large-scale base model with a number of trainings
More than 1 million hours of Earth system records are available. It provides state-of-the-art prediction capabilities in areas such as air quality, wave conditions, cyclone trajectories, and high-resolution weather, surpassing traditional systems at very low computational costs, and can be fine-tuned across domains with minimal resources, making it an important step towards inclusive AI-based earth system prediction.
The study launched NeuralGCM, a differentiable
A hybrid model that combines a physics-based solver with a machine learning component is capable of simulating both weather and climate. In short- and medium-term forecasts, the model performs as well as or better than current leading machine learning and physical models, accurately tracking long-term climate indicators, capturing complex phenomena such as tropical cyclones, and achieving significant computational savings. 322 Focus:
Iconic Model Released (continued)
In 2024 
August 18th
Figure 5.6.6
Source: Hellert et al., 2024
In 2024 
FireSat fire prediction for September 16th
Figure 5.6.7 
Source: Google, 2024
In 2024 
GenCast weather forecast for December 4th
Figure 5.6.8
Source: Google, 2024
In 2024 
December 9 AlphaQubit Quantum Computing
Figure 5.6.9
Source: Google, Artificial Intelligence 20242025
Index Report
Table of Contents Chapter 5 Preview Chapter 5: Science and Medicine
5.6 Basic models of artificial intelligence in the field of science
Physics due to itsTerminology & Complex Concepts, Physics Texts
Natural language processing is challenging. PhysBERT is the first text-embedded model designed specifically for physics, significantly outperforming general-purpose models for physics tasks. The model was trained on 1.2 million arXiv papers, and by supervising data fine-tuning, it significantly improved the performance in information retrieval and subdomain adaptation tasks.
FireSat, released by Google, is a satellite-based forest
The forest fire detection system uses artificial intelligence to identify fire points as small as 5×5 meters within 20 minutes of starting a fire. The system does this by analyzing real-time imagery and environmental data. Jointly developed by Gu Ge in partnership with the Earth Fire Alliance and Muon Space, the project not only strengthens disaster response capabilities, but also advances global wildfire research.
GenCast by Google DeepMind is
An AI-driven weather model, based on a diffusion approach, provides extremely accurate 15-day weather forecasts that outperform existing legacy systems such as ENS on almost all indicators. GenCast generates predictions in minutes for a wide range of applications in disaster response, renewable energy, and agriculture.
At the end of 2024, Google DeepMind will work with
Google Quantum AI has jointly released AlphaQubit, an AI decoder with state-of-the-art quantum error correction capabilities. The subsequent introduction of Willow marks a major breakthrough in the field as the first quantum chip to achieve exponential error suppression and correction below the surface code threshold. Willow also completed a baseline task that took only five minutes, and the task took more than ten septillion years on the world's fastest supercomputer, well over the age of the universe Chapter 6:
Policy 2025 Artificial Intelligence
Index Report 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VI Preview 324 Chapter VI: Policies
Get an overview of public data
Chapter Highlights
6.1 Global AI Policy Highlights 2024 6.2 AI and Policy Making
Global Record of AI Legislation
overview
By Geography
Focus: An in-depth look at global AI legislation
U.S. Legislative Records
Federal level
At the state level
Highlights: An overview of U.S. state-level AI legislative cases
Focus: Policy development on anti-deepfake technology
Frequency of AI mentions in global legislative discussions
overview
The U.S. Congressional Committee referred to the situation
U.S. Regulations
overview
Classification by institution 
Focus: In-Depth Observation of the Code of Federal Regulations 325
326
327336
33633633733833933934034234333453453483493493493493516.3 Public investment in artificial intelligence
Total Public Investment in Artificial Intelligence (AI) by Institution and Functional Area Allocation of Public Spending on Artificial Intelligence (AI) by Focus: An Analysis of U.S. AI Research Grants
Artificial intelligence in 3523533603622025
Index Report
Table of Contents Chapter 6 Preview 325 Chapter 6:
policy
overview
The rapid development of artificial intelligence technology has attracted great attention from policymakers around the world, and countries have introduced artificial intelligence one after another
Intelligence-related policies. In recent years, a number of countries and political entities, represented by the United States and the European Union, have successively introduced important prisons
Regulatory Regulations. The latest developments show that several governments have announced large-scale investments in AI infrastructure. This policy wave reflects the growing international consensus on "dual-track governance" of AI, which is to regulate risks while unleashing the potential for change.
This chapter systematically reviews the global AI governance landscape: first, presents the timeline of key policy events in 2024,
Then, it analyzes the progress of global and U.S. legislation, quantifies the heat of AI issues in legislative discussions, and interprets the AI governance path of U.S. regulators. Finally, it concludes with an analysis of public investment in AI in the United States, most of which is collected independently by the AI index team. Artificial intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 3261. U.S. states are leading the AI legislative process, while progress at the federal level has been relatively slow. In 2016, only one state-level AI-related law was passed, and by 2023
year, increased to 49 items. In the last year alone, that number has more than doubled to 131. While there has also been an increase in proposed AI bills at the federal level, the number of passes remains
Rarely.
2. Governments around the world are stepping up investment in AI infrastructure. Canada announced a $2.4 billion AI infrastructure package, while China set up
$47.5 billion semiconductor industry fund. France has pledged $117 billion in AI infrastructure, India has pledged $1.25 billion, and Saudi Arabia's "Beyond Meter."
This includes a $100 billion investment in artificial intelligence.
3. Globally, the mention of AI in the legislative process is on the rise. In 75 countries, there was an increase in the number of mentions of AI in the legislative process in 2024
21.3%, an increase from 1,557 in 2023 to 1,889. Since 2016, the total number of AI mentions has grown more than 9-fold. On a global scale, artificial intelligence is safe
Accelerate expansion and collaboration across research institutes.
4. In 2024, countries will successively establish international AI security research institutions. The first institutions were spearheaded by the US and UK following the conclusion of the inaugural AI Security Summit in November 2023
Set up. With the Seoul AI Summit in May 2024, Japan, France, Germany, Italy, Singapore, South Korea, Australia, Canada, and the European Union will be held
They have also pledged to establish relevant institutions.
5. The number of AI-related federal regulations in the U.S. has skyrocketed. In 2024, the U.S. introduced 59 AI-related regulations, more than double the 25 in 2023. These regulations come:
Since 42 agencies, double the 21 agencies that introduced regulations in 2023.
6. U.S. states strengthen deepfake regulatory legislation. By 2024, only five states, California, Michigan, Washington, Texas and Minnesota, have enacted laws to be elected
Deepfakes are regulated. In 2024, 15 states, including Oregon, New Mexico, and New York, introduced similar measures. In addition, by 2024, there are already 24
The state passed regulations against deepfakes. Chapter HighlightsChapter 6:
This section of the policy provides an overview of the policy selected by the AI Index Steering Committee
The most important AI-related policies in the world in 2024
Event.
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 327Singapore plans to invest US$1 billion in AI over 5 years
(then) Deputy Prime Minister and Finance Minister Lawrence Wong at the pre-meeting on 16 February 2024
The report announced that the government will allocate more than $1 billion over the next five years to cover expenses
Supporting AI computing, talent training and industry development. February 21, 2024
Source: The Straits Times, 2024
European Parliament passes Artificial Intelligence Act
Three months after reaching a preliminary agreement, the European Parliament officially adopted a milestone
Significance of the Artificial Intelligence Act. The bill is the world's first comprehensive regulatory framework for AI, with provisions such as transparency and reporting obligations, risk-based regulatory mechanisms, and prohibitions on social scoring, manipulation, and biometric classification based on "sensitive features". Most of the provisions will come into force in 2026 after a two-year implementation period. As the law adopts stricter regulatory measures, it is more restrictive than other regions, which has aroused widespread concern and controversy in the industry. March 13, 2024
Source: Time, 2023 Abu Dhabi established a 100 billion dollar artificial intelligence investment company
In March 2024, Abu Dhabi launched the MGX Fund, a state-owned investment fund 
Management Limited, which focuses on artificial intelligence technology and has a target asset size of US$100 billion. The move is in line with the UAE's strategic goal of positioning itself as a global leader in AI technology innovation. March 11, 2024
Source: Bloomberg, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 328 India Withdraws Plans to Impose Compulsory Approval for New AI Models
Government approval is required before technology companies can launch new AI models
Less than a month later, India faced a backlash from entrepreneurs and investors
Yes, the revised Corporate Self-Regulatory Guidelines have been issued recently. The new rules require companies to indicate to users whether their AI models have not been adequately tested or have reliability issues. India's Ministry of Electronics and Information Technology continues to stress that AI models must not undermine electoral fairness or promote bias and discrimination. March 15, 2024
Source: TechCrunch, 2024
The French government fined Google €250 million for its use of copyrighted information
The French competition regulatory authority, the Autorité de la 
Concurrence fined Google 250 million euros for training its artificial intelligence chatbot Bard (now Gemini) using French news content without notifying media outlets. The regulator noted that this action violated EU IP rules and prevented news publishers and news agencies from negotiating fair pricing on content use. Google has accepted the penalty decision and proposed a series of corrective actions to address the content scraping issue. March 20, 2024
Source: NBC News 2024 India Launches IndiaAI Mission with an investment of 1.25 billion
Dollar
In March 2024, India officially launched the India AI Mission Program to strengthen
its artificial intelligence ecosystem. The $1.25 billion initiative will be approved by the public
The private partnership model achieves three major goals: building computing infrastructure with more than 10,000 GPUs, developing a national non-personal data platform, and supporting local AI models and deep tech start-ups. The plan also emphasizes the development of ethical AI governance frameworks and the promotion of technology inclusion through the expansion of AI labs in non-central cities. March 17, 2024
Source: Nature 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 329 The United Nations General Assembly adopts a resolution to promote "safe, reliable, and trustworthy" artificial intelligence
With the support of more than 120 member states, the United Nations General Assembly adopted a law to be approved by the United States
Leading "historic" resolution (although the resolution is not legally binding.)
force) to promote the use of "safe and trusted" AI systems. The Assembly called on all parties to ensure that the use of AI systems is in accordance with human rights law and to recognize the role that these systems can play in accelerating the achievement of the UN Sustainable Development Goals. The resolution was supported by more than 120 countries, including China, and unanimously adopted by the 193 member states of the United Nations, without a vote. March 21, 2024
Source: UN News, 2024
The UK's Institute for AI Safety has launched an open-source tool for assessing the safety of AI models
The institute has released a set of tools called Inspect to evaluate human labor
The capabilities of intelligent models in multiple domains, including core knowledge, reasoning ability, and autonomy. According to the institute, this is the first AI security test platform to be led by a government-backed organization and publicly released in the form of an open-source license for the benefit of industry, research institutions and academia. May 11, 2024
Source: TechCrunch, Canada commits $2.4 billion in 2024 to secure its position as a leader in AI
Canada's 2024 federal budget proposes a $2.4 billion package of measures,
to "ensure Canada's edge in AI" in the context of increasing competition in the development and adoption of AI globally. Funding will be used for a range of initiatives, including strengthening the capacity and infrastructure of researchers and developers, supporting AI start-ups, helping small and medium-sized enterprises (SMEs) increase productivity through AI, supporting AI-affected workers, and establishing a new Canadian AI Safety Institute. April 7, 2024
Source: International Center for Innovation in Governance, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 330 UK and South Korea jointly host AI Security Summit in Seoul
During the AI Summit in Seoul, the participating countries shared their insights based on the Bligh
Chilly Declaration. The declaration was made the year before in the UK Artificial Intelligence Ann
Signed during the Summit, it emphasizes the ethics and responsible development of AI. On the basis of the results of the UK summit, countries have subsequently established or announced the establishment of AI security research institutes. In Seoul, countries went one step further by signing a letter of intent to build a collaborative network of agencies that underscores the importance of advancing global cooperation to improve AI security. May 2024 21st
Source: Center for Strategic and International Studies, 2024
The European Commission establishes the Office of Artificial Intelligence
Three years after the Artificial Intelligence Act was introduced, the European Commission unveiled its core enforcement
The Office of Artificial Intelligence (AI Office). The Office will play a key role in the implementation of the Act, including the implementation of regulatory standards for general AI models, the coordination of the development of guidelines of practice, and the imposition of penalties for violations. With more than 140 employees, the organization is made up of five divisions that are responsible for different AI-related goals, including promoting social well-being through AI and driving excellence in AI and robotics. May 28, 2024
Source: Center for Strategic and International Studies, 2024 country establishes the largest ever state-backed investment fund to promote semiconductors
Industrial development
China has launched a $47.5 billion fund to boost semiconductors
Capacity. The establishment of the fund marks China's "National Integrated Circuit Industry Investment Fund"
(abbreviated as the "Big Fund") The launch of the third phase. Since 2014, the fund has passed the gate
Key investment to support the development of the two leading chip manufacturing enterprises in China. The initiative is in the United States
Proposed in the context of tighter export controls on key technologies such as semiconductors, which are the basis for hardware components such as GPUs on which AI systems are trained. May 27, 2024
Source: Reuters, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 331 The National Institute of Standards and Technology (NIST) publishes a framework to help institutions identify and mitigate
Addressing the risks of generative AI
The National Institute of Standards and Technology (NIST) has published a voluntary framework for
It is designed to help organizations identify the unique risks posed by generative AI and identify the unique risks posed by generative AI
Mitigating these risks proposes a series of recommended measures. The framework is an extension of the NIST AI Risk Management Framework, which was released in 2023. Suggested measures include identifying an organization's AI risk tolerance and corresponding risk management needs, clarifying the division of responsibilities for managing AI risks, and regularly engaging non-developer experts in the risk assessment and update process. The release of the framework was preceded by a document on adversarial machine learning, which systematically describes the classification of attack types, the potential impact of such attacks, and related mitigation strategies. June 26, 2024
Source: FedScoop, 2024
The UK withdraws £1.3 billion commitment to technology and artificial intelligence infrastructure
The British Labour government has scrapped the £1.3 billion promised by its predecessor for technology and people
Funding for the AI project, calling these commitments "underfunded". The projects, which were originally announced in 2023, include £500 million for the AI Research Resource to fund computing infrastructure, and £800 million for the University of Edinburgh to build exascale supercomputing. August 2, 2024
Source: BBC, 2024 U.S. State Department Releases Guidance on Artificial Intelligence and Human Rights Risk Management
The U.S. Department of State designed the Artificial Intelligence and Human Rights Risk Management Archive for countries
Governments, businesses and civil society provide guidance on integrating AI risk management with human rights safeguards. Based on NIST's AI risk management framework, the dossier proposes four key functions – Governance, Mapping, Assessment & Management – to assess and mitigate AI-related risks, from bias to monitoring misuse. By bridging AI governance with human rights protection, the archive provides a suitable tool for the responsible development and deployment of AI globally. July 25, 2024
Source: U.S. Department of State, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 332 The White House Establishes Artificial Intelligence Data Center Infrastructure Working Group
The White House convened a meeting to invite federal officials and tech executives to join in
Discuss the issue of securing the energy source of a robust data center infrastructure, and such infrastructure
Shi is essential to support the operation of AI models. Companies in attendance included OpenAI, Anthropic, Amazon Web Services (AWS), Nvidia and Google's parent company Alphabet. In a press release, the White House emphasized that advancing the development of AI in the United States is critical to national security and helps ensure the safety, security, and trustworthiness of AI systems. The newly formed AI Data Center Infrastructure Working Group will be tasked with identifying construction opportunities and working with relevant agencies to prioritize the development of AI data centers. September 13, 2024
Source: FedScoop, 2024
The United Nations adopts the Global Digital Compact to ensure an inclusive and secure digital future
At the Summit for the Future, UN member states adopted the Global Digital Compact (Global 
Digital Compact) aims to build an inclusive, open, sustainable, just, safe and secure digital future for all. The Compact emphasizes the following objectives: bridging the digital divide, expanding inclusive outcomes from the digital economy, fostering a digital space that respects human rights, promoting equitable data governance, and strengthening international governance of AI. The principles underlying the compact are centered on international law and human rights, and seek to accelerate the achievement of the Sustainable Development Goals through the power of digital technologies. September 22, 2024
Source: United Nations, 2024 California Governor Signs Three Bills on Artificial Intelligence and Election Communication
On the eve of the 2024 San Francisco mayoral election, California Governor Gavin Newsom
Announced the signing of three bills aimed at combating deepfake election content. AB 2655, AB 2839 and AB 2355, respectively, these bills require large online platforms to remove or label digitally falsified election content for a specific period of time; extend the time window to prohibit the dissemination of misleading AI-generated election content; and mandate that all election ads that use AI-generated or modified content must be accompanied by appropriate disclosure instructions. September 17, 2024
Source: Wall Street Journal, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter VI Preview 333 California Governor Vetoes Expansive AI Legislation
California Governor Gavin Newsom vetoed a California AI safety law
Table. The bill was expected to set a precedent for AI regulation across the country, Inca
The state is home to a number of leading AI businesses. The bill would require security testing of cutting-edge AI models before they are publicly released, and give state attorneys general the power to prosecute businesses for AI-related harms. Proponents see the bill as a necessary step towards ensuring AI security and accountability, while critics argue that the bill is too restrictive and could inhibit the development of AI, especially the open-source AI ecosystem. Given California's status as the world's fifth-largest economy, the impact of the bill could extend beyond state borders, resembling the "Brussels effect" and shaping AI governance at the national and international levels. Newsom defended its veto, saying the bill imposes excessively high standards. September 29, 2024
Source: Financial Times, 2024
Saudi Arabia Announces 'Beyond Project'
In November 2024, Saudi Arabia announced the launch of the Beyond Project 
Transcendence, a $100 billion AI initiative that aims to establish the country as a global tech hub. The plan is led by Saudi Arabia's sovereign wealth fund, the Public Investment Fund (PIF), and has a partnership agreement with Google's parent company Alphabet to invest between $5 billion and $10 billion to develop Arabic AI models. The move aligns well with Saudi Arabia's Vision 2030, which aims to diversify the economy, wean itself off oil, and make AI an important pillar of future development. November 8, 2024
Source: Telecommunications Review, 2024 U.S. Judge Halts California's New Artificial Intelligence Act for Involving Kamala A. Harris's Deep
degree of fake video
Just two weeks after California's new AI law was signed, it was enacted by a federal law
The official is temporarily suspended. In the ruling, Judge Mendez noted that the law has a positive impact on "have
The vague definition of "harm" images could pose a threat to constitutionally protected freedom of expression. The law was previously used to prosecute an X platform user who posted a video about Vice President Kamala A. Harris's deepfake video. October 2, 2024
Source: Los Angeles Times, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 334 The European Office for Artificial Intelligence publishes the first draft of the Code of Practice for Artificial General Intelligence
The European Office for Artificial Intelligence has published four copies of the Guidelines of Practice for Artificial General Intelligence
The first copy in the first draft. The guidelines were developed by four working groups of independent experts, with a focus on to:
Following: Transparency & Copyright, Risk Identification & Assessment, Risk Mitigation, and Internal Governance. Once formalized, the Code will serve as a complementary mechanism to the AI Act, allowing AI model providers to demonstrate compliance through the Code before the final standard is published. November 14, 2024
Source: European Union, 2024
The U.S. has tightened export controls on semiconductor manufacturing equipment and software in China
The U.S. Department of Commerce's Bureau of Industry and Security has announced new export control measures further
Limit China's ability to manufacture advanced semiconductors. The new rules include export restrictions on 24 categories of semiconductor manufacturing equipment, 3 categories of software tools, and additional restrictions. The U.S. Secretary of Commerce stressed that such measures are critical to maintaining U.S. national security. December 2, 2024
Source: CNBC, 2024U.S. Launches International AI Safety Network with Global Partners
In November 2024, the U.S. Department of Commerce and the Department of State co-hosted the "National
The first meeting of the International Network of AI Safety Institutes. The initiative aims to strengthen global coordination and cooperation on safe AI innovation, with a focus on managing synthetic content risks, testing foundational models, and conducting risk assessments of advanced AI systems. The United States holds the first rotating presidency of Australia, Canada, the European Union, France, Japan, Kenya, the Republic of Korea, Singapore and the United Kingdom. The network has secured more than $11 million in global research funding commitments to support its follow-up efforts. November 25, 2024
Source: Associated Press, 2024
Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 335 UN Security Council Discusses the Use of AI in Conflict and Calls for a Global Framework
On December 19, 2024, the United Nations Security Council convened a meeting dedicated to artificial
The challenges posed by intelligence in the military environment. United Nations Secretary-General António Murphy Gut
Reis stressed that the rapid development of AI is outpacing the adaptability of existing governance frameworks and could weaken human control over weapons systems. He called for the creation of an "international guardrail"
(international guardrails) to ensure the safety and inclusiveness of AI
Use. The discussion comes against the backdrop of ongoing reports on the widespread use of autonomous drones and robotic weapon systems in the war in Ukraine. December 19, 2024
Source: Berkeley Political Review, 2016, Chapter 6: Policy and Management
6.1 Global AI Policy Highlights 2024 AI AI in 2025
Index Report
Table of Contents Chapter 6 Preview 3366.2 Artificial Intelligence and Policy Making
Global Record of AI Legislation
overview
The AI Index analyzes 114 country packages between 2016 and 2024
Legislation containing the term "artificial intelligence". 1 Of these, 39 countries have developed at least one of the following
Laws related to artificial intelligence (Figure 6.2.1). 2 Overall, these countries have adopted
204 laws related to artificial intelligence. Figure 6.2.2 shows the number of AI-related laws enacted each year since 2016. Artificial intelligence adopted in 2024
A total of 40 laws were enacted, up from 30 in 2023, making it the second highest number of laws after 2022. Since 2016, the number of AI-related laws has grown from 1 to 40.
Distribution of the number of AI-related laws passed by country from 2016 to 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
0
1–5
6–10
11–15
16–30
No data available Chapter 6: Policy and Governance
6.2 Artificial Intelligence and Policy Making
1. Due to the large size proposedThe bill may include multiple chapters related to artificial intelligence, so the analysis may be underestimating the number of laws actually passed. For example, the National Defense Authorization Act was introduced as a single comprehensive bill, but it included a series of smaller bills that were part of these laws
The case was originally presented separately and later merged into a single synthesis. 2. Due to limited access to legislative databases in some countries, the AI Index has reduced the sample of countries analysed this year, so the number of AI-related laws reported this year may be lower than reported in previous years. In addition, Hong Kong and Macau, although not officially recognized as sovereign states, are included in the statistics, covering 116 countries and territories in the overall analysis. Figure 6.2.1 Artificial intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 3373, For brevity, Figures 6.2.3 and 6.2.4 show data for the top 15 geographic regions by count. The full country totals will be available in the Summer 2025 update of the Global AI Vibrancy Tool. For immediate access, please contact the AI Index team. Number of AI-related laws passed in selected regions in 2024
Source: AI Index 2025 | Chart: The 2025 AI Index report is broken down by geography
Figure 6.2.3 illustrates the AI enacted in the world's top 15 regions by 2024
Number of relevant laws. Russia leads the way with 7 laws, followed by Belgium and Portugal with 5 each
laws followed. Figure 6.2.4 shows the total number of AI-related laws enacted globally since 2016, with the United States topping the list with 27 laws and Portugal and Russia tied for second place with 20 laws each.
 3
Number of AI-related laws passed by selected regions (combined) 2016-2024
Source: AI Index 2025 | Chart: Number of AI-related bills passed by the 2025 AI Index report
2016 2017 2018 2019 2020 2021 2022 2023 2024051015202530354045
402016-2024 Number of AI-related laws passed in 116 selected regions
Source: Artificial Intelligence Index, 2025| Chart: 2025 Artificial Intelligence Index Report
Number of AI-related bills passed in Russia
Belgium, Portugal
Hong Kong, USA
Latvia
South Korea, Great Britain
Australia
Austrian Bahamas
Barbados
China, France, Germany 7
5
5
4
2
2
2
2
1
1
1
1
1
1
1
0 1 2 3 4 5 6 7
The number of AI-related bills passed in the United States
Portugal
Russia, Belgium
Korea
Spain, Italy
Great Britain, France
Austria, Philippines
China, Germany, Japan
Andorra 27
20
20
18
13
11
10
10
9
7
6
4
4
4
3
0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 Chapter VI: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.2
Figure 6.2.3 Figure 6.2.4 Highlights:
Global AI Legislation Takes an In-Depth Look at AI in 2025
Index Report
Table of Contents Chapter 6 Preview 338 This section provides a detailed analysis of some of the AI-related laws passed in 2024. Figure 6.2.5 selects legal cases from five countries, covering multiple areas of AI governance.
country
Austria
Belgium
France
Latvia
Name of the Russian Act Summary of contents
Federal Law Amendment: Amendments to the Communications Regulation
The Act and the Telecommunications Act of 2021 establish an "Artificial Intelligence Service Center" to support, advise and coordinate with the media
AI governance in the fields of sports, telecommunications and postal services. The law establishes an AI Advisory Committee to monitor AI trends, provide policy advice to governments, and help shape national AI policy. The service center operates an information portal for AI projects, specifically covering publicly funded projects and providing guidance on AI governance, cybersecurity, and compliance. To support these activities, the bill allocates 700,000 euros per year, which will be adjusted for inflation.
This bill establishes a federal AI steering committee to inform the government on AI policy
and serve as the main liaison mechanism for AI governance. The committee is made up of representatives of ministries and public institutions and meets regularly to coordinate the implementation of Belgian AI policy.
This Act establishes the Audiovisual and Digital Communication Regulatory Authority (ARCOM) by merging the former "Vision".
Listen to the High Committee (CSA) and the High Agency for the Dissemination and Copyright Protection of Works on the Web (HADOPI). The law strengthens measures to combat online piracy and strengthens the regulation of digital platforms to safeguard digital access to cultural content. The amendments expand ARCOM's mandate to use AI tools to regulate digital platforms, particularly in the area of identifying copyright infringement and combating piracy.
This amendment regulates the use of artificial intelligence in political advertising and requires payment for campaign materials
, explicit disclosure of AI-generated content. At the same time, it is forbidden to use automated systems with false or anonymous social media accounts in election campaigns.
This Act establishes a framework for the processing and sharing of anonymized personal data in support of government duties
The development of artificial intelligence in energy. The bill regulates AI-driven decision-making, sets security standards for biometric data, and restricts foreign access to sensitive AI-related datasets. Royal Decree on the Establishment of the Steering Committee on Artificial Intelligence
No. 2021-1382 of 25 October 2021
Law: On the Regulation and Protection of Access to Cultural Works in the Digital Age (2024 by No. 2024-449).
Amendment to the Act)
4
Election Propaganda Act Amendments
"On the amendment of the Federal Law on Personal Data" and
"Establishment of a Law on Specific Regulatory Experiments for the Promotion of the Development and Implementation of Artificial Intelligence Technologies in the Federal City of Moscow, a Constituent Body of the Russian Federation" and amendments to Articles 6 and 10 of the Law on Personal Data Chapter VI: Policy and Regulation
6.2 Artificial Intelligence and Policy Making
4. Law No. 2024-449, adopted in 2024, amends the original Law No. 2021-1382 promulgated in 2021 to extend its scope of application to the field of artificial intelligence and officially authorizes ARCOM to use artificial intelligence technology. Figure 6.2.5 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 339 Of all the proposed AI bills, the percentage that actually passed is still low. this
The active trend of quasi-legislation, reflecting the interest of policymakers in AI technologies (in particular
generative AI) capabilities and responses to the rise in public interest. 6
The number of AI-related bills introduced and the number of laws passed in the U.S. Congress from 2016 to 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of AI-related bills
2016 2017 2018 2019 2020 2021 2022 2023 20240306090120150180210
4, Passage 221, Recommendation Chapter VI: Policy and Management
6.2 Artificial Intelligence and Policy Making
U.S. Legislative Records
Federal level
Figure 6.2.6 illustrates the passage and proposal by the U.S. Congress between 2016 and 2024
and revealed a significant increase in the number of proposals.  
5 In 2023, the U.S. Congress introduced 171 AI-related bills, compared to 2024
This number has increased to 221 in the year, almost tripling since 2022. however
5. The "passed" bill in the figure means that it has been passed by the Senate and the House of Representatives.
6. This section covers only congressional legislation and excludes policies enacted by the executive branch (e.g., President Trump's "Stargate" statement) and federal regulators (e.g., the FTC's new rules on AI-generated comments and social media bots). Figure 6.2.6 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 340 state level
The AI Index also tracks US state legislation in the field of AI
Circumstance. Figure 6.2.7 shows the number of AI-related bills passed by state in 2024
California led the way with 22, followed by Utah (12) and Maryland (8). Figure 6.2.8 shows the cumulative number of AI legislation passed by state between 2016 and 2024, with California also leading the way (42), followed by Maryland, Virginia, and Utah with 17 each.
Number of AI-related Bills Passed by U.S. State (Total), 2016-2024
Source: Artificial Intelligence Index 2025 | Chart: The 2025 AI Index reports the number of AI-related bills passed in select U.S. states in 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
22
12
8
6
5
5
5
4
4
4
4
4
4
4
3
0 2 4 6 8 10 12 14 16 18 20 22i California
Utah 
Maryland 
Virginia 
Illinois
New Hampshire
New york
 Alabama
 Arizona 
Colorado 
Florida Massachusetts 
Mississippi
 Tennessee
Idaho
Number of AI-related bills passed Chapter VI: Policy and Governance
6.2 Artificial Intelligence and Policy Making
Figure 6.2.7
Figure 6.2.8 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 341Since 2016, there has been a significant increase in the number of AI-related laws passed at the state level in the United States. In 2016, only one was passed, and in 2023 it will grow to 49. And in the past one
During the year, this number more than doubled to 131 (Figure 6.2.9).
Number of AI-related bills passed by U.S. states from 2016-2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of AI-related bills passed
2016 2017 2018 2019 2020 2021 2022 2023 2024020406080100120140
131 Chapter VI: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.9 Key points:
An Overview of U.S. State-Level AI Legislative Cases on Artificial Intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 342 states
Alabama
California
Colorado
Massachusetts
New York Act Name Content Summary
"Election-related Elections; Provision for the dissemination of material misleading media
This bill prohibits the dissemination of AI-generated information designed to mislead voters in the 90 days leading up to an election
or deceptive media that harms candidates. In the absence of a clear disclaimer, the offender may be sentenced to a misdemeanor; Repeat offenders can be sentenced to felony offenses. News reports, satirical content and media with disclaimers are exempt from civil action.
The bill requires large AI providers to provide AI detection tools free of charge, and:
Include a clear and permanent attribution of the source in AI-generated content. Each violation is punishable by a fine of $5,000, enforced by the Attorney General or local law enforcement agency.
This bill imposes requirements for the transparent and fair use of high-risk AI systems. exploitation
Deployers must prevent algorithmic discrimination, protect users' right to appeal AI decisions, and conduct regular impact assessments.
The bill allocates $1.26 billion for information technology, cybersecurity, and broadband infrastructure across the state
Modernization of infrastructure. $25 million of that will be spent on integrating artificial intelligence and machine learning into state government systems to improve automation, efficiency and safety.
The Act requires social media companies to disclose their platforms in a clear and accessible manner
Terms of Service and submit a report of the terms to the State Attorney General. Failure to comply will result in penalties. California Transparency in Artificial Intelligence Act
Artificial Intelligence Consumer Protection Act
7
On Meeting the Future of Information Technology in Massachusetts
Bill of Demand》
Amendments to the General Commercial Law relating to social media
Title VI of the Act on Disclosure Requirements for Terms of Service: Policy and Governance
6.2 Artificial Intelligence and Policy Making
This section features a selection of AI-related legal cases passed in 2024 in several U.S. states, including California and New York, as well as Allah
States with relatively small positions in the industry, such as Bama and Colorado, reflect a diverse focus on AI governance at the state level (Figure 6.2.10).
Figure 6.2.102025 Artificial intelligence
Index Report
Table of Contents Chapter 6 Preview 343 U.S. states are passing legislation to combat deepfakes
The performance was particularly positive. Deepfakes refer to synthetic media generated by artificial intelligence
The ability to tamper with or replace a person's image in video, audio, or images, often resulting in realistic but deceptive content. As discussed in Chapter 3 of this year's AI Index, deepfakes could be used to manipulate election results or generate indecent images. Public Citizen, a nonprofit organization, maintains a database that tracks AI deepfake regulations, covering both election-related abuse and intimate image abuse. Figure 6.2.11 illustrates the number of anti-deepfake laws passed by U.S. states over time, including regulations related to elections and intimate imagery.
8
Figure 6.2.12 highlights the timing of states adopting election-related AI deepfake regulations: by 2024, five states have passed such laws: California, Washington, Texas, Michigan, and Minnesota; In 2024, 12 more states, including Oregon, New Mexico and New York, will introduce similar regulations.
State-level regulations against intimate deepfakes are far greater than those for election abuse
More common. A total of 25 states have enacted coverage for all individualsand five other states have passed regulations that apply only to minors (Figure 6.2.13). Wyoming and Ohio are currently the only two states that have not implemented any form of intimate deepfake regulations. Focus:
Policy development on anti-deepfake technology
Statistics on the number of anti-deepfake laws passed by U.S. states from 2019–2024
Source: Public Citizen, 2025| Chart: 2025 Artificial Intelligence Index Report
8. Because the effective date of anti-deepfake laws in some states is not fully verified, Figure 6.2.11 only counts bills that have been confirmed to have been passed.
Number of state-level laws enacted
2019 2020 2021 2022 2023 202405101520253035
20, Electoral Domain36, Chapter 6: Policy and Management in the Intimate Image Domain
6.2 Artificial Intelligence and Policy Making
Figure 6.2.11 Key points:
Policy development on anti-deepfake technology (continued) Artificial intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 344State regulations and their status for AI-generated election-based deepfakes by state in the U.S. as of 2024
Source: Public Citizen, 2025 | Chart: 2025 Artificial Intelligence Index Report
As of 2024, state regulations and their status for AI-generated, intimate imagery deepfakes by state in the United States
Source: Public Citizen, 2025 | Chart: 2025 Artificial Intelligence Index Report
Enacted by 2024
No relevant legislation has been enacted in the 2024 legislative review
Enacted (Covering the entire population)
Enacted (Minors Only) Legislation Under Consideration (Covering the Entire Population) Legislation Under Consideration (Covering Minors Only) No relevant law Chapter VI: Policy and Governance
6.2 Artificial Intelligence and Policy Making
Figure 6.2.12
Figure 6.2.13Artificial intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 345 Another indicator of legislative attention is mentioned in the minutes of government and parliamentary meetings
The number of times "artificial intelligence". The AI Index analyzes the period from 2016 to 2024
Records of legislative meetings in 73 countries and regions, counting the number of meetings containing the keyword "artificial intelligence".
9 Overview
Figure 6.2.14 illustrates the use of "artificial intelligence" in the global legislative process between 2016 and 2024
The number of annual mentions of the word "can". In 2023, it will be 1,557 times, and in 2024, it will increase to 1,889 times, an increase of 21.3%. Since 2016, that number has grown more than ninefold.  
Statistics on the frequency of AI mentions in 75 regional legislative sessions from 2016–2024
Source: AI Index 2025 | Chart: Frequency of AI mentions in global legislative discussions reported by the AI Index 2025
Number of mentions
2016 2017 2018 2019 2020 2021 2022 2023 202402004006008001,0001,2001,4001,6001,8001,889
9. See the Appendix for the full list of countries analyzed. The goal of the AI Index research group is to review government and parliamentary processes around the world, but not all countries have publicly accessible databases. This year, the index has slightly adjusted its tracking methodology, resulting in a slight departure from previous totals.
More specifically, the number of mentions is counted on a sessional basis, so multiple mentions of the AI Index in the same legislative session count as one. The full methodology is detailed in the Appendix. In addition, the AI Index Index tracks mentions in Macau and Hong Kong. Although they are not officially countries, their mention is also included in the statistics in Figure 6.2.14. In total, the index tracks AI mentions across 75 geographic regions. Chapter 6: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.14Artificial intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview In 3462024, the country with the most mentions of AI in the legislative process was Spain (314 times), followed by Ireland (145 times) and Australia (123 times). In been
Of the 75 countries and territories analysed, 57 mentioned AI in at least one legislative process.
A similar trend emerges when the number of legislative mentions is aggregated from 2016 to 2024 (Figure 6.2.16). Spain is in first place with 1,200 times, followed by a close second
It was the United Kingdom (710) and Ireland (659). Number of mentions of AI in national legislative processes in 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of references to AI in national legislative processes, 2016-2024 (combined)
Source: AI Index 2025 | Chart: Artificial Intelligence Index Report 20250
1–55
56–120
121–250
251–315
No data available 
0
1–220
221–440
441–660
661–890
891–1,200
No data available Chapter 6: Policy and Governance
6.2 Artificial Intelligence and Policy Making
Figure 6.2.15
Figure 6.2.162025 Artificial Intelligence
Index Report
Table of Contents Chapter 6 Preview 347Figure 6.2.17 Based on data from some countries, a comparison of artificial intelligence in parliament
The frequency of references to the number of AI-related laws passed. Overall
The high level of interest in AI in parliament is positively correlated with the number of AI legislation. However, in some countries, such as Belgium, Portugal and Russia, there is a clear deviation between the frequency of discussion and the actual legislation, suggesting that parliamentary concerns do not necessarily translate directly into legislative outcomes.
The number of references to AI in national legislative processes from 2016 to 2024 compared to the number of AI-related bills passed
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
The number of AI-related bills that have passed into law
Artificial intelligence mentions: US
Portugal
Russia
Belgium
Spain
Italy, South Korea, United Kingdom
France
Hong Kong, Japan
Brazil, Canada
Iceland, India
0 100 200 300 400 500 600 700 800 900 1,000 1,100 1,2000510152025
Germany
Liechtenste Den, Barbados
Andorra, Latvia, China
Philippines
Slovenia
Panama Australia Chapter 6: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.17Artificial intelligence in 2025
Index Report
Table of Contents Chapter VI Preview 348 U.S. Congressional Committee Mentions
The U.S. House of Representatives and Senate committees have raised artificial intelligence in their reports
and the situation is another indicator of Congress's interest in AI. These commissions
The Council is usually responsible for legislative, policy affairs, investigations, and internal affairs. Figure 6.2.18 records the frequency of references to AI in the reports of various congressional committees in the United States between 2001 and 2024. The 118th session of the National Assembly (2023–2024) reached a record high of 136 mentions, an increase of 83.8% from the 117th session.
Statistics on the number of AI mentions in the reports of the in-session committees of each session of the U.S. Congress from 2001-2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Number of mentions
020406080100120140
136
107th
(2001-02) 108th
(2003-04) 109th session
(2005-06) No. 110
(2007-08) 111th
(2009-10) 112th
(2011-12) No. 113
(2013-14) 114th
(2015-16) 115th
(2017-18) 116th
(2019-20) 118th edition
(2023-24) 117th edition
 (2021-22) Chapter 6: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.18 Number of AI-related regulations
2016 2017 2018 2019 2020 2021 2022 2023 Artificial Intelligence 20240102030405060592025
Index Report
Table of Contents Chapter VI Preview 349 U.S. Regulations
The rise of artificial intelligence has raised a lot of concern among regulators – these federal
Institutions are responsible for regulating specific areas of the economy and directing the enforcement of laws. This section explores
The discussion is about the regulation of artificial intelligence in the United States. Unlike legislation, which establishes the legal framework of the country, regulatory regulations are detailed instructions drawn up by the executive authorities to implement legislative provisions. In the United States, representative regulatory agencies include: Environmental Protection Agency (EPA), Food and Drug Administration (FDA), and Federal Communications Commission (FCC). Understanding the AI regulatory landscape is an important part of understanding AI policymaking, as the specific content of legislation is often reflected in regulatory action. This section analyzes the AI-related regulations issued by U.S. regulators between 2016 and 2024, covering the total number of regulations, topics, scope of application, regulatory intent, and sponsors. To collect relevant data, the AI Index research team searched the Federal Register for the keyword "artificial intelligence". The Federal Register is a comprehensive database of documents from nearly every department of the U.S. government, bringing together information from more than 436 federal agencies.
overview
Over the past six years, the number of AI-related regulations has risen dramatically. Especially in the past
The growth trend was particularly pronounced in the last year (Figure 6.2.19). In 2024, the United States will be a total
Issued 59 AI-related regulations, up from 25 in 2023 and more than tripled.
Classification by institution
Figure 6.2.20 illustrates the number of U.S. federal regulators since 2016
Number of AI-related regulations issued.
10 2024, U.S. Health & Public
The Department of Public Services issued the most AI regulations (14 in total), followed by the Center for Medicare & Medicaid Services (7) and the Department of Commerce (7). The number of sources for AI regulations is also at an all-time high – 42, up from 21 in 2023 and 17 in 2022. This trend reflects the fact that AI is receiving widespread attention from a growing number of regulators in the United States. Number of AI-related regulations in the U.S. between 2016 and 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
10. Regulatory regulations can be jointly initiated by multiple agencies, so the total number of institutions in Figure 6.2.20 is not exactly the same as the total number of regulations in Figure 6.2.19. The term "agency" in Figure 6.2.20 follows the standard usage of the Federal Register. Chapter 6: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.192025 Artificial Intelligence
Index Report
Table of Contents Chapter 6 Preview 3502016–Number of AI-related regulations issued by U.S. federal agencies in 2024
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Chapter 6: Policy and Management
6.2 Artificial Intelligence and Policy Making
Figure 6.2.20 Key points:
U.S. Code of Federal Regulations Takes a Deep Dive at Artificial Intelligence in 2025
Chapter 6 of the Index Report: Policy and Governance
6.3 Public investment in AI
Table of Contents Chapter 6 Preview 351This section highlights some of the AI-related regulations passed by the U.S. federal government in 2024 in the form of "rules" and "administrative mandates" (Figure 6.2.21).
institution
Executive Office of the President
Bureau of Industry and Security
Consumer Financial Protection Bureau
Federal Election Commission
Ministry of Finance's Office of Investment Security Regulation Name Summary of the contents
Preventing 'Countries of Concern' from Accessing Sensitive U.S. Personal Data
and data related to the U.S. government (Preventing 
Access to Americans' Bulk Sensitive Personal Data and United States Gov-ernment–Related Data by Countries of Concern) This Executive Order classifies the national security threat posed by the use of artificial intelligence by "countries of concern" as a significant risk. Specifically, the order warns that foreign hostile forces may use large amounts of sensitive personal data and data about the U.S. government to train artificial intelligence algorithms to perform espionage, cyber operations, and manipulation of public opinion. To address such risks, the order proposes a series of data protection measures, including restricting or prohibiting data transactions with these countries and strengthening the security of network infrastructure.
This rule amends the U.S. Export Administration Regulations to tighten exports of semiconductor manufacturing equipment and supercomputers
, especially in relation to China. The rules add further restrictions on semiconductor manufacturing, update existing provisions, and introduce a "red flags" regime to identify potential risks of illegal exports. The move is intended to deter China from circumventing existing restrictions and limiting its ability to develop advanced computing and artificial intelligence systems that pose a threat to U.S. national security.
This circular makes it clear that employers must not rely on background without compliance when making employment decisions
Profiles, algorithmic scoring, or third-party reports. This reaffirms core obligations under the Fair Credit Reporting Act (FCRA), particularly with respect to AI-driven systemsIf the employee's consent is obtained, the terms such as consumer reports can be invoked. Through the circular, the regulator sets clear boundaries on the use of algorithmic scoring in recruitment and hiring.
The explanatory rule addresses the context of the increasing amount of AI-generated content, and the Federal Election Act
(Federal Election Campaign Act, FECA). The rules reaffirm FECA
It is "technology neutral" and the regulatory focus is not specifically on the misuse of AI, but on individuals or organizations
Whether or not they have engaged in election-related misrepresentation.
This final rule implements Executive Order 14105, which requires U.S. citizens to notify the Treasury Department of their transactions with entities in "countries of concern" that engage in sensitive technology areas, and prohibits transactions in certain circumstances. The order, issued in 2023, covers high-risk technology areas including artificial intelligence, semiconductors, and quantum computing. The U.S. government believes that investments in these areas could enhance the ability of hostile countries to pose a threat to U.S. national security. Supplementation and Consideration of the Rules for Foreign-Produced Direct Products
Foreign-Produced Direct Product Rule Additions, and Refinements to Control for Advanced Computing and Semicon-ductor Manufacturing Items
Consumer Financial Protection Notice 2024–06: Used for:
Consumer Financial Protection Circular 2024–06: Background Dossiers and Algorithmic Scores for Hiring, Pro-motion, and Other Employment Deci-sions
Explanatory Rules on Misrepresentation of Electoral Authority
(Fraudulent Misrepresentation of Cam-paign Authority)
"On the U.S. Security of Certain Countries in the "Countries of Concern".
Provisions Pertaining to U.S. Investments in Certain National Security Technologies and Products in Countries of Concern
Figure 6.2.Artificial intelligence in 202025
Index Report
Table of Contents Chapter 6 Preview 352As AI continues to drive innovation in key areas such as healthcare, transportation, and defense
New, public funding has become a key pillar for countries to achieve their AI strategies. finish
Understanding governments' investments in AI research and development is critical to understanding the broader geopolitical AI landscape, but tracking these investments remains a major challenge. Although national budgets may list items of expenditure related to AI, these budget allocations are not always directly reflected in actual expenditures. In addition, AI investments are often nested within broader science or technology initiatives, making it difficult to accurately identify AI-specific allocations.
To solve this problem, the AI Index uses natural language processing (NLP)
The technology analyzes publicly available tender and contract documents in various countries to identify AI-related government spending.
12. This way of analyzing the bidding documents can be more straightforward
It also reflects investment trends and better shows how the government allocates resources over time. Since the AI Index only analyses countries that publicly disclose contract and tender data, some countries are therefore not included in the analysis.
13 This section also separately analyzes the in:
The total amount of research grant expenditures in the field of artificial intelligence.
The AI Index report specifically reminds that the figures of government spending published in this section are based on
Caution is required in making cross-border direct comparisons. While this analysis includes data on multi-government contracts, it only includes data on research funding expenditures at the federal level in the United States. This data asymmetry stems from the complexity and difficulty of obtaining comparable funding data from other countries and regions, such as the European Union and China. In the United States, for example, research funding accounts for an important proportion of government AI index spending. In 2023, according to the AI Index, the U.S. government's AI Index-related public contracts are estimated to be worth about $830 million, while AI Index-related research funding is as high as $4.5 billion during the same period. Given the current limitations of cross-country data availability and consistency, it is still premature to conduct a comparative analysis of public spending on AI indices across countries. This study aims to take the first step towards establishing a more comprehensive global data coverage. The AI Index Report will continue this work and welcomes collaboration from researchers, institutions and governments interested in improving the scope and quality of data. 6.3 Public Investment in Artificial Intelligence11 Chapter 6: Policy and Management
6.3 Public investment in AI
11. The analysis of this section was conducted by Lapo Santarlasci.
12. The Appendix details all the methods behind this analytical method. The lag in the report may result in incomplete data for 2024, with the latest analysis being for the end of 2023. 13. Due to data access limitations, this analysis does not cover major government-funded regions such as the EU (at the overall level) and China. The AI Index promises to expand the scope of research in future editions to include these and other regions. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 353Figure 6.3.1 summarizes the number of AI-related contracts and their value in each country
Cardiac data. 14 From 2013 to 2023, the U.S. was a public investor in artificial intelligence
It ranked first in the world, with a total of 2,678 independent AI contracts signed, with a total amount
Approximately US$ 5.2 billion (Figures 6.3.1 and 6.3.2). In Europe, the UK, Germany and France have the highest total value of AI contracts, together accounting for 56% of public AI investment in Europe. In Europe, the UK, Germany and France have the highest total value of AI contracts, together accounting for 56% of public AI investment in Europe. Total public investment in AI
Total spending on AI-related public contracts in selected countries from 2013 to 2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
United States
Great Britain, Germany, France
Spain, Belgium
Denmark, Finland, Poland, Greece
Romania
Italy
Czech Republic
Hungary Ireland 5,233.10
568.48
278.07
190.10
99.71
83.54
74.40
71.25
55.92
50.02
46.37
44.30
40.71
36.56
29.42
0 500 1,000 1,500 2,000 2,500 3,000 3,500 4,000 4,500 5,000 5,500
Spending on AI-related public contracts (in millions of dollars) Chapter 6: Policy and Management
6.3 Public investment in AI
14. The results and figures provided are subject to the percentage of missing values for the specific matching bid sample: 0.16% for the NAICS code and 26.8% for the dollar value. It is important to note that Northern Ireland's bids are not included in the sample, as their offices do not offer API services or bulk download options to
Conduct large-scale data collection. Figure 6.3.1 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 3542013-2023 Total number of AI-related contracts in selected countries
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
The median value of AI-related public contracts in selected countries from 2013 to 2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Switzerland
Turkey
Luxembourg, Ireland
Denmark
Italy, Belgium, Austria
Finland
Malta
Norway
Portugal
Estonia, Latvia
Greece
The median value of AI-related public contracts (in millions of dollars) is 3.05
2.81
1.42
1.15
1.07
1.03
1.01
0.92
0.67
0.65
0.63
0.60
0.57
0.56
0.55
0.00 0.50 1.00 1.50 2.00 2.50 3.00 United States, United Kingdom, Germany, France, Poland
Spain
Czech Republic
Finland
Bulgaria, Romania
Hungary, Italy
Denmark
Belgium
Greece
The number of contracts related to artificial intelligence is 2,678
555
409
139
136
121
75
69
49
48
40
38
32
29
28
0 200 400 600 800 1,000 1,200 1,400 1,600 1,800 2,000 2,200 2,400 2,600 Chapter 6: Policy and Management
6.3 Public investment in AI
Figure 6.3.2
Figure 6.3.3 Artificial Intelligence in 2025
Chapter 6 of the Index Report: Policy and Governance
6.3 Public investment in AI
Table of Contents Chapter 6 Preview 355Which countries have invested the most in AI over the past decade? The United States topped the list with $1.58 million per 100,000 inhabitants, followed by Finland ($1.3 million) and Denmark (
$1.3 million) (Figure 6.3.4).
2013-2023 Amount of AI-related public contract spending per 100,000 inhabitants in selected countries (total)
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
United States
Finland, Denmark, United Kingdom
Belgium, Luxembourg, Ireland
Greece, Norway
Czech Republic
Hungary Lithuania
Germany
Slovenia
Austria
1.58 per 100,000 inhabitants on AI-related public contracts (in millions of dollars).
1.29
1.27
0.84
0.72
0.60
0.56
0.48
0.47
0.38
0.38
0.38
0.33
0.33
0.32
0.00 0.30 0.60 0.90 1.20 1.50
Figure 6.3.4 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 356Figure 6.3.5 shows public investment in AI in 2023.
The U.S. spent $831 million on AI contracts, far more than any other country, the U.K
It came in second with $263 million. While Germany, Spain and the United Kingdom remain the largest investors in Europe, countries that have historically ranked lower are also in the top 10. This change suggests that the distribution of AI funding in Europe tends to be more balanced.
The amount of contracts for AI-related public spending in selected countries in 2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
830.98
262.59
49.59
49.55
36.89
31.13
26.08
22.98
18.44
16.84
10.48
10.14
8.35
5.78
4.77
0 50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 United States
United Kingdom
Spain
Germany, Greece
Romania
Ireland
Poland, France
Hungary, Italy, Austria, Belgium
Czech Republic
Sweden
Spending on AI-related public contracts per 100,000 inhabitants (in millions of dollars) Chapter VI: Policy and Management
6.3 Public investment in AI
Figure 6.3.5 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 357Figure 6.3.6 shows the United States and Europe, two key areas for AI investment
Trends in public AI investment over the past decade. The data shows that people in both regions
Spending related to industrial intelligence has increased significantly. Of particular note is that total AI investment in Europe in 2023 will increase by about 67 times compared to 2013, while in the United States it will increase by about 15 times. Europe experienced a particularly significant jump in 2017 and 2019: 400% year-on-year growth in 2017 and another 200% in 2019. It is worth mentioning that 2019 was also the year when the number of national AI strategy releases reached a peak worldwide. This continued upward trend is a clear indication of the financial importance and willingness of governments to invest in AI.
Amount of AI-related public contract spending in the U.S. and Europe from 2013-2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
AI-related public contract expenditures (in millions of dollars)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 202302004006008001000
581.38, Europe 830.98, U.S. Chapter 6: Policy and Management
6.3 Public investment in AI
Figure 6.3.6 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 358Figure 6.3.7 shows the difference between the United States and Europe in terms of public spending on AI
Variation. The data shows that this gap continued to widen until 2020, but has begun to gradually narrow in the past three years, indicating that European countries are gradually catching up with the United States in artificial intelligence
on the pace of public spending.
Difference in spending on AI-related public contracts between the United States and Europe, 2013-2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
AI-related public contract expenditures (in millions of dollars)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230100200300400500600700800
249.60 Chapter VI: Policy and Management
6.3 Public investment in AI
Figure 6.3.7 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 359 Figure 6.3.8 shows the five major European countries from 2013 to 2023 – than
AI-related public spending figures for Nesbits, France, Germany, Spain, and the United Kingdom
Investment has been shown to show a steady growth trend, accompanied by cyclical peaks. Among them, Germany achieved significant growth in 2019 after the release of its national AI strategy in November 2018. The UK, on the other hand, saw two sharp increases in public investment in AI in 2021 and 2023, closely linked to the national strategy proposed by its AI Commission, which was established in 2019 to advise governments and provide high-level guidance on the AI ecosystem. In contrast, Belgium, France and Spain saw modest but steady growth.
The amount spent on AI-related public contracts in the five major European countries from 2013 to 2023
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
AI-related public contract expenditures (in millions of dollars)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023050100150200250300
8.35, Belgium 18.44, France 49.55, Germany 49.59, Spain 262. 77 , United Kingdom Chapter VI: Policy and Governance
6.3 Public investment in AI
Figure 6.3.8 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 360 The distribution pattern of investment in AI public tenders between the United States and Europe is obvious
This difference stems from the disagreement between the two sides on strategic priorities and institutional structures
Same. As Figure 6.3.9 shows, the vast majority of AI-related contracts in the U.S. have been signed by the Department of Defense since 2013, consistent with the agency's longstanding central role in the U.S. technology innovation system. In 2023, the Department of Defense will account for 75.04% of AI-related public contracts in the United States. The Department of Veterans Affairs ranked second, accounting for 6.83%; The Ministry of Finance ranked third, accounting for 5.34%.
The Department of Veterans Affairs' investments in artificial intelligence are primarily focused on healthcare
and rehabilitation-related applications, including AI-based assisted diagnosis, research and development of robotic prosthetics, and construction of mental health support systems. These applications reflect the division's continued investment in driving smart healthcare services. Distribution of public spending on AI by institution and functional area
Public Expenditure on AI-related Research Grants by Institution, 2013-2023 (% of Total)
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
Spending on AI-related public contracts (% of total)
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%10%20%30%40%50%60%70%80%
0.03%, State Department 0.05%, Department of Education 0.32%, General Services Administration 0.69%, NASA 0.80%, Department of Transportation 0.97%, Department of Justice 1.57%, Other 2.08%, Department of Commerce 2.30%, Department of Homeland Security 3.98%, Department of Health and Human Services 5.34%, Department of Treasury 6.83%, Department of Veterans Affairs 75.04%, Department of Defense Chapter VI: Policy and Management
6.3 Public investment in AI
Figure 6.3.9 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 361 In Europe, investments in artificial intelligence realized through public tenders are presented with those of the United States
Significantly different modes. This is due to the lack of fiscal spending that is as centralized as in the United States
Data, the AI Index uses a methodology to classify funding entities by main functional categories to analyze the structure of public investment in AI in Europe. As Figure 6.3.10 shows, AI investment in Europe is more evenly distributed across different functional categories. Among them, the top three funding areas in 2023 are: general public services, education, and healthcare, which together accounted for about 84% of the total AI-related public investment in Europe that year. In the same year, defense-related spending accounted for only 0.84% of all AI public tender investment, a percentage in stark contrast to the United States. In the United States, defense is the absolute main recipient of AI funding.
Expenditure by European governments on AI-related public contracts (% of total expenditure), 2013-2023, by Funding Institution
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230%10%20%30%40%50%60%70%80%
0.84%, Defence 0.87%, Economic and Financial Affairs 1.63%, Local Authorities 5.35%, Government 7.43%, Health 7.58%, Other 12.26%, Education 64.05%, General Public Services for AI-related Public Contract Spending (% of Total) Chapter VI: Policy and Management
6.3 Public investment in AI
Figure 6.3.10 Figure 6.3.11 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 362 Public funding is an important channel for governments to support AI projects and related programs
One of the ways. With such grants, public institutions can invest directly in multiple types of AI
It can be used in projects such as improving the interpretation of X-ray angiography and building AI-driven unmanned aerial systems for automated soil monitoring. developing explainable machine learning tools, etc. Governments can support AI-focused research projects by providing research grants to agencies such as the National Science Foundation (NSF) or the Department of Health and Human Services (HHS), which includes the National Institutes of Health (NIH). In this section, the AI Index analyzes data on U.S. government grants in AI-related programs. In line with the previous article, the AI index is also used
Natural language processing (NLP) methods are used to identify AI-related grant projects.
15 
Figure 6.3.11 illustrates AI-related allocations in the United States from 2013 to 2023
aggregate data on expenditures. During this period, the U.S. federal government has cumulatively allocated approximately $19.7 billion to AI-related research projects. Figure 6.3.12 illustrates trends in U.S. AI funding over time.
Between 2013 and 2023, total funding for AI research in the United States increased nearly 19-fold, from an initial $230 million to $4.5 billion. Between 2014 and 2020, grants grew at an average annual rate of about 40%. The rapid expansion of this grant is closely related to the continued evolution of AI technology over the past decade. Especially in the core areas of deep learning, natural language processing, and computer vision
Against the backdrop of key progress in the field, the public sector has an increasing demand for the deployment of AI in specific application scenarios, which in turn has promoted the government to continue to increase investment in related research projects. Focus:
Analysis of U.S. Artificial Intelligence Research Grants
Public Expenditure on AI-related Research Grants by Institution, 2013-2023 (% of Total)
Source: AI Index 2025 | Chart: 2025 AI Index Report Statistics on AI-related Grants in the United States from 2013 to 2023
Source: AI Index 2025 | Table: Artificial Intelligence Index Report 2025
Figure 6.3.124.49
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230.000.501.001.502.002.503.003.504.004.50Public Expenditure on AI-related Research Grants (in billions of dollars)
18,399
19,748.44
247 .53
1,073.34
5,967 .69
Value Statistics on the amount of funding
Number of funded projects
Total Amount (US$ millions) Median (US$ thousands) Average amount (US$ thousands) Funding per capita (US$ thousands/100,000 people) Chapter 6: Policy and Management
6.3 Public investment in AI
15. The full principle of this method is shown in the Appendix. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 6 Preview 363 Figure 6.3.13 shows the United States between 2013 and 2023 in relation to artificial intelligence
Distribution of allocations among funding agencies. The Department of Health and Human Services received the highest percentage of funding at 43.6 percent, followed by the National Science Foundation
Yes, accounting for 27.9%, and the Ministry of Commerce ranked third, accounting for 5.4%. Focus:
Analysis of U.S. Artificial Intelligence Research Funding (continued)
Public Expenditure on AI-related Research Grants by Institution, 2013-2023 (% of Total)
Source: AI Index 2025 | Chart: 2025 Artificial Intelligence Index Report
43.57%
27 .91%
16.06%
5.38%
2.62%
1.87%
1.47%
1.12%
0% 5% 10% 15% 20% 25% 30% 35% 40% 45% Department of Health and Human Services
National Science Foundation
Other agencies
Commerce
Defense
Agriculture
Energy
National Aeronautics and Space Administration
Public Expenditure on AI-related Research Grants (% of Total) Funding Institutions Chapter VI: Policy and Management
6.3 Public investment in AI
Figure 6.3.13 Artificial Intelligence in 2025
Index Report
Chapter 7:
Education 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VII Preview 378 Chapter VII: Education
Get an overview of public data
Chapter Highlights
7.1 Background7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
United States
          Basic computer science education
          Advanced computer science education
          Educational standards and policy guidance
          Teacher's perspective
Global status quo
          Popularity
          Policy guidance
7.3 Computer Science and Artificial Intelligence Education at Higher Education
Degree awarded
          United States
          globe
          Guiding Policy
7.4 Looking to the future 366367
368369
369369373376377379379380
382
382382388392
Artificial intelligence in 3932025
Index Report
Table of Contents Chapter 7 Preview 378 Chapter 7:
educate
overview
The impact of AI on work through generative AI – improving efficiency and automating tasks –
It has entered the public eye, and at the same time, it has also promoted the innovation of personalized learning in the field of education. However, although this technology has a bright future,
But there are hidden risks: from the "illusion problem" that generates false output, to the reinforcement of social biases and the weakening of critical thinking. As the size of the AI education market is expected to grow dramatically, the ethical issues raised by the misuse of technology are becoming increasingly prominent, and the fact that AI tools have falsely accused marginalized students of cheating is a reminder of the urgency of responsible technology development and deployment.
Addressing these challenges requires both technological literacy and the ability to critically examine societal impacts. Develop AI professionals
Beginning with K-12 basic and higher education, students must be responsible users and developers. AI education cannot exist in isolation – it must work in tandem with the broader computer science (CS) education system. This chapter examines the current state of global AI and computer science education, the disparities in educational opportunities, and the policy frameworks that shape the role of AI in education.
This chapter is sponsored by the Kapoor Foundation, the Computer Science Teachers Association (CSTA), and the Public Interest University Consortium
(PIT-UN) and the Artificial Intelligence Index. The Kapoor Foundation is committed to the intersection of racial equity and technological innovation
The mission is achieved by building equitable and inclusive computing education pathways, advancing policies that mitigate technology harm and promote equal opportunity, and deploying capital to support responsible and ethical technology solutions. The Association of Teachers of Computer Science is a global membership organization that unites, supports, and empowers educators to improve the quality, accessibility, and inclusion of computer science education. The Public Interest Technical Universities Alliance (PIT-UN) promotes cooperation between universities to jointly build public interest technology fields and cultivate a new generation of technical talents who care about the public interest. Artificial intelligence in 2025
Index Report
Table of Contents Chapter VII Preview 3781. The popularity and number of elective students in high school computer science (CS) courses in the United States have increased slightly compared with the previous academic year, but the education gap still exists. Student's ginseng
The situation varies by state, race and ethnicity, school size, geographic location, income, gender, and disability.
2. Computer science teachers in the U.S. want to teach artificial intelligence, but don't think they have the ability to do so. Although 81% of computer science teachers agree that humans should be usedSmart apps
and the basic knowledge of artificial intelligence into the basic curriculum system of computer science, but less than half of the high school computer science teachers believe that they have the ability to teach artificial intelligence
Professional competence.
3. Two-thirds of the world's countries offer or plan to offer K-12 computer science education. Since 2019, this proportion has doubled, with Africa and Latino
Progress has been most pronounced in the Americas. However, due to the lack of electricity supply in schools, students in African countries have the least access to computer science education.
4. Between 2022 and 2023, the number of graduates in the United States who earned a master's degree in artificial intelligence nearly doubled. Despite the fact that artificial intelligence is in the bachelor's degree and doctoral degree off
The increase in interest will be slower, but the surge in master's degrees may be a harbinger of this trend at all degree levels. 5. The United States continues to be a global leader in producing information, technology, and communications technology (ICT) graduates. Spain, Brazil and the United Kingdom followed the United States as the next level of completion
The country with the highest number of graduates, while Turkey has the most balanced ratio of men and women. Chapter HighlightsChapter 7:
Education 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 7 Preview 3787.1 Background
In order to deeply grasp the current development trend of artificial intelligence education, it is necessary to understand the education sector
Artificial intelligence applications, artificial intelligence literacy education, and artificial intelligence professional education
These three are clearly defined (Figure 7.1.1). The application of artificial intelligence in the field of education mainly refers to the practical application of artificial intelligence technology in the teaching process. AI literacy education focuses on cultivating basic cognitive abilities of AI technology, including understanding its operating mechanism, mastering how to use it, and recognizing potential risks. Artificial intelligence professional education not only includes the above literacy requirements, but also aims to cultivate students' professional and technical abilities required to develop AI systems, such as data analysis capabilities that support AI technology, and key skills such as data bias identification and correction. The data indicators used in this chapter are mainly aimed at the field of AI professional education. Chapter 7: Education
7.1 Background
Artificial Intelligence Applications in Education Artificial Intelligence Literacy Education Artificial Intelligence Professional Education
In teaching and learning
a basic understanding of artificial intelligence using artificial intelligence tools,
including how it works,
How to use and how to use risky AI literacy 
+ 
The technical skills needed to build AI
Figure 7.1.1 The world is building a resilient and diverse workforce
Serious challenges, especially in infrastructure, access to resources, and curriculum
There are large disparities in participation, and these disparities further exacerbate the unequal starting point of K–12 students in their journey towards a technology-driven future. Although it is difficult to accurately estimate the actual scale of the problem due to the lack of standardization in data collection and indicator setting, this section still focuses on the earliest stages of computing technology education, and examines the current status of computer science and AI education at K-12 levels in light of the available global data. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 378 Basic Computer Science Education
Over the past decade, education advocates have urged policy
Makers passed legislation to improve computer science education
Spread. This series of efforts has paid off: in the 2017–2018 school year, only 35% of U.S. high schools offered computer science courses; By the 2023–2024 school year, the ratio has risen to 60%. However, overall data at the national level can still mask differences between different states. For example, all high schools in Arkansas and Maryland (100%) offer computer science courses, while Montana has a coverage rate of only 31% (Figure 7.2.1) Percentage of state-state public high schools offering computer science foundation courses in 2024 (% of total high schools in the state)
Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 Artificial Intelligence Index Report
1. Since artificial intelligence has traditionally belonged to the subfield of computer science, this chapter cites computer science education data when there is a lack of specific data on artificial intelligence. Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.17.2 Computer Science in K-12 vs 
     Artificial Intelligence Education
United States
Before discussing the popularity and quality of AI education in the United States, it is necessary to review its aspects
Historical Evolution in Computer Science Education. Since 2016, President President Ma launched "Computer Science for All
Since the Education initiative, the federal government has invested billions of dollars to ensure that all K–12 students have access to computer science learning opportunities to prepare them to become creators of the digital economy and responsible citizens in a techno-society society. The funding focuses on supporting professional teacher training, the optimization of teaching resources, and the establishment of regional cooperation mechanisms to expand the coverage of computer science education. The National Science Foundation (NSF) is also leading the development and implementation of two new courses, Exploring Computer Science and AP Principles of Computer Science, to engage a broader student body in computing education. At the same time, the tech industry and philanthropic organizations have co-funded nationwide projects that have brought computer science education to millions of students. 12025 Artificial Intelligence
Index Report
Table of Contents Chapter VII Preview 378 There are still significant gaps in equitable access to computer science education
Populations are marginalized. For the 2023–2024 academic year, courses will be covered by a select group of students
Still insufficient: including students who qualify for free or reduced-price lunch (FRL), students in small schools, students in urban and rural areas, and Native American students (Figures 7.2.2 to 7.2.5).
Schools offering computer science fundamentals courses by size in 2024
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
Schools offering computer science fundamentals courses by number of free and waived lunch students in 2024
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: The 2025 Artificial Intelligence Index reports on schools offering computer science foundation courses by geographic region in 2024
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
43.12%76.40%91.18%
0%20%40%60%80%100%
Percentage of small schools
Medium Percentage of large schools
Percentage of students enjoying free and reduced lunch65.01%67.00%
60.00%
50.03%
<25% 25– 49% 50– 75% >75% 0% 20% 40% 60% 80% 100% Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.2
Figure 7.2.4 Figure 7.2.3 Urban Suburban Rural 58.15%70.13%
56.05%
0%20%40%60%80%100%School Percentage 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 7 Preview 3782025 Artificial Intelligence Index Report
Table of Contents Chapter VII Preview 371In addition, based on student participation data from 41 states,
The actual electives for computer science courses are also not
Foot. In the 2020–2021 school year, only 5.1 percent of high school students participated in computer science courses; By the 2023–2024 school year, the share has risen only slightly to 6.4 percent. Differences in participation between states are equally significant—for example, 26 percent of high school students in South Carolina participate in computer science courses, compared to only 2 percent in Florida, Arizona, and Idaho (Figure 7.2.6) for learning computer science fundamentals courses by race/ethnicity in 2024
Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 Artificial Intelligence Index Report
High school computer science enrollment as a percentage of the total number of students in 2024
Source: Code.org, CSTA, and ECEP Alliance, 2024 | Chart: 2025 Artificial Intelligence Index Report66.34%79.74% 80.39%82.46% 82.98% 83.27%91.55%
0%20%40%60%80%100%
Native Americans Black Hispanic / Hispanic White Two or more races Native Hawaiian Percentage of Asian students Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.5
Figure 7.2.6 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 372 Computer Science Course Participation Data by Race and Ethnicity, Promotion
The work did raise some degree for African-Americans, Native Americans/Alaska
Participation of Indigenous and white students approaches or exceeds their share of the population nationally (Figure 7.2.7). However, the incomplete data, especially for the nine states, also reminds us to be cautious about interpreting the overall trend. Female student participation in computer science courses is significantly lower than their proportion of the K–12 population. In addition, Latino and Pacific Islander students, students with Individualized Education Plans (IEPs), FRL students, and English Learners all showed a trend of under-participation nationally (Figures 7.2.7 vs. 7.2.8).
2024 Computer Science Public High School Enrollment by Race/Ethnicity vs. National Demographics
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
Asian
Black / African American
Hispanic / Latino / Latino / Latinos
Native American / Alaska
Native Hawaiian/Pacific Islander
Two or more races
Whites
The ratio of computer science enrollment to the national population is 2.60
1.13
0.69
1.00
0.75
0.80
1.00
0 1 2 3 Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.7 Advanced Computer Science Education
In order to improve students' abilities in the field of artificial intelligence, only basic courses are offered
Not enough, but also to make sure that they have access to the more advanced course content. Despite the current AP meter
The Computer Science A (AP CS A) course does not explicitly cover artificial intelligence, but the AP CS Principles (AP CS P) course has begun to incorporate related topics. Therefore, AP CS P has the potential to provide a wider group of students with initial exposure to AI-related knowledge. While the total number of students taking AP CS exams continues to grow (Figure 7.2.9), there is still an imbalance in the participation of groups in terms of the racial and ethnic composition of the overall student population (Figures 7.2.10 and 7.2.11). Specifically, Asian American students, white male students, and multiracial students are significantly overrepresented in AP CS exams, while other student groups are significantly under-represented (Figure 7.2.12).
2. The 504 Plan, as defined in Section 504 of the Rehabilitation Act of 1973, guarantees equal opportunities for students with disabilities in an educational setting; The IEP (Individualized Education Plan) is a legally tailored educational program for students with special needs in accordance with the Disability Education Act. 2024 Computer Science Public High School Enrollment by Subgroup vs. National Demographics
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
0.72
0.64
0.65
1.33
0.67
0.00 0.50 1.00 1.50 Financial difficulties
English Language Learners
girl
Students in the 504 program
Students with an individual education plan
Ratio of Computer Science Enrollment to National Demographics 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VII Preview 373 Chapter VII: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.8 Artificial intelligence in 2025
Index Report
Table of Contents Chapter VII Preview 3742007-2023 Number of People Taking the AP Computer Science Exam
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
AP Computer Science Exam Attendance by Race/Ethnicity, 2007-2023
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report 19.39 19.83 20.96 19.39 21.1424.7829.5537 .3346.3454.3899.87130.90158.56179.19 181.04201.61243.18
2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023050100150200250 Number of people who took the AP Computer Science exam (thousands)
2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023010,00020,00030,00040,00050,00060,00070,00080,00090,000
0,Other 321, Native Hawaiian/Pacific Islander801, Native American/Alaskan 11,238, Two or More Races 16,351,43,083, Hispanic/Hispanic/Latino 69,695, 91,216, White
Asian
Black/African American Chapter VII: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.9
Figure 7.2.10: Number of AP Computer Science Exams Taken, 2025 Artificial Intelligence
Index Report
Table of Contents Chapter 7 Preview 3752007-2023 Number of Students Taking AP Computer Science Exams by Race/Ethnicity (% of Total Students Responding)
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: 2025 Artificial Intelligence Index Report
AP Computer Science Exam Participation Rate by Race/Ethnicity in 2023 vs. National Demographics
Source: Code.org, CSTA, and ECEP Alliance, 2024 Chart: Artificial Intelligence Index Report 2025 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230% 10% 20% 30% 40% 50% 60%
0.00%, Other 0.10%, Native Hawaiian/Pacific Islander 0.30%, Native American/Alaskan 4.60%, Two or More Races 6.70%, 17.70%, 28.70%, 37.50%, White
Asian
Hispanic/Hispanic/Latino
Black/African-American
The ratio of the number of people taking the AP computer science exam to the national population is 0 1 2 3 4 5 6 7 8 male
Female Asian
Black/African-American
Hispanic/Hispanic/Latino/Hispanic
Native American/Alaska
Native Hawaiian/Pacific Islander
Two or more races
Chapter 7 for Whites: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.11
Figure 7.2.12 Artificial Intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 376 Educational Standards and Policy Guidance
To date, U.S. policy guidance at the federal level has focused primarily on "education."
AI in education, not "AI in education." 
education） 。 In 2023 and 2024, the U.S. Department of Education's Office of Educational Technology released a series of reports on the use of AI in education. One is for edtech developers, and the other two are for educators, education administrators, and policymakers. The latest report, published in October 2024, aims to provide policy recommendations for K–12 schools on the safe and effective implementation of AI.
As of January 2025, 26 U.S. states have issued information on "In Education
Artificial Intelligence Applications". While there is a great deal of overlap in the content of computer science and AI education, and teachers often cross-cover both in their actual teaching, the computer science curriculum standards at levels K–12 have very limited content that addresses AI. In the Computer Science Curriculum Standards for Levels K–12, published by the Computer Science Teachers Association (CSTA) in 2017, there are only two standards in the upper upper grades of high school that explicitly require students to have knowledge of artificial intelligence. However, the standard still provides support for the fundamentals and skills of AI education, covering topics such as perception, data structures, and algorithms. The computer science curriculum standards adopted in the United States at K–12 levels cover an average of 97% of the same sub-concepts in the CSTA standards, showing a high degree of consistency in teaching content at the national level. Of the 44 states that have adopted K–12 CS standards, 33 have set AI-related curriculum standards. These standards are typically brief, conform to the CSTA framework, and focus primarily on the high school level (Figure 7.2.13).
3 Where, Colorado (2024), Florida
(2024), Ohio (2022), and Virginia (2024).
more detailed AI curriculum standards covering all stages of K–12 have been promulgated; The state of Arkansas has established independent standards for AI and machine learning courses at the high school level.
U.S. states adopt AI-specific K-12 stage computer science standards
Source: CSTA and IACE, 2024 | Chart: 2025 Artificial Intelligence Index Report
Computer science curriculum standards with a lot of AI-specific content
Computer Science Curriculum Standards with a Small Amount of Artificial Intelligence Curriculum Standards The Computer Science Curriculum Standards without AI Specifics do not have a Computer Science Curriculum Standards Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.13
3. This project is funded by the National Science Foundation (NSF) of the United States, and the grant number is 2311746. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 377 Teacher's Perspective
In order to explore the cognition and reality of computer science teachers in artificial intelligence education
The State of Computer Science Teacher Survey collected 2,901 preschool students nationwide
Data for 12th grade computer science teachers (33% of respondents were elementary school teachers, 36% were middle school teachers, and 51% were high school teachers).
4 5
As AI education becomes more important in the future of workforce development, the assessment is now
The readiness of the teacher community has become particularly critical. While 81% of computer science teachers believe that AI should be included in the basic computer science education system, only 46% of high school teachers, 44% of middle school teachers, and 34% of elementary school teachers say they have the ability to teach AI (Figure 7.2.14).
When asked what is actually taught, more than two-thirds of middle and high schools are in high school
Computer science teachers indicated that they actively included AI content in their classrooms, compared to 65% of primary school teachers, despite the fact that they were not explicitly stated in the curriculum standards (Figure 7.2.15). In addition, more teachers said they covered a wide range of topics related to AI, such as algorithms, computing systems, computational thinking, and programming.
Concepts of artificial intelligence taught in computer science classrooms by grade level
Source: State of Computer Science Faculty Survey, 2024| Chart: Percentage of teachers who believe they are capable of imparting AI in the 2025 AI Index report, broken down by grade level
Source: State of Computer Science Faculty Survey, 2024| Chart: 2025 Artificial Intelligence Index Report
34%44%46%
Elementary school Middle school High school0%10%20%30%40%50%% of teachers
Concept 84%
65%82%90%
51%56%89% 88%
75%86%93%
61%73%94%92%
72%85%96%
74%87%96%
0%20%40%60%80%100%Elementary School High School Percentage of Middle School Teachers
Algorithms Artificial Intelligence
(AI) computing systems
(e.g., hardware/software) data and analysis Computer Impact & Ethics Programming Computers
Synovate Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.14
Figure 7.2.15
4. This project is funded by the National Science Foundation (NSF) with grant number 2118453. Any opinions, findings, conclusions, or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. As some questions allow respondents to select more than one option, due to:
The total number of responses to this survey may not be 100%. 5. The percentages in the graph do not add up to 100% because if the respondent teaches more than one, there are multiple options to choose from. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 378 Of the 2,245 teachers who teach AI content in their classrooms, most spend less than five hours per class on the topic. Elementary school teachers devote the most time
Feminently, 70% teach only 1 to 2 hours (Figure 7.2.16).
When talking about the main benefits of AI in the classroom, teachers generally agree that it is
It helps to improve teaching efficiency, realize individualized teaching, and improve students' academic support mechanisms
system and prepare students for the future. However, when asked about the potential risks, teachers
The top concerns include the misuse of AI (particularly with regard to academic integrity), the erosion of student learning and engagement by technology, the over-reliance on AI, the risk of AI generating false information and replication bias, and ethical issues such as student privacy. In order for students to be able to use AI responsibly, the teacher community itself also:
Upskilling is required. According to a 2024 survey of 364 computer science teachers, 88% of respondents said they urgently needed more AI-related professional development resources. Specifically, teachers believe that they urgently need to improve their literacy in the field of AI, including understanding the working mechanism, use and ethical impact of AI. Breakdown by grade level of time students spend learning AI in computer science classes
Source: State of Computer Science Faculty Survey, 2024| Chart: 2025 Artificial Intelligence Index Report
70%
22%
6%
2%48%
33%
13%
5%42%
35%
17%
6%
1– 2 hours, 3– 5 hours, 6– 19 hours, 20+ hours0%, 20%, 40%, 60%, 80%, 100%, elementary, middle, high school, percentage of teachers
Time Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.162025 Artificial Intelligence
Index Report
Table of Contents Chapter 7 Preview 379 Global Status
As of now, countries that have explicitly included AI education in their national curricula are still available
minorities (e.g. Ghana, South Korea and the Netherlands); Most countries are strong at the level of education strategy
The importance of AI education has been remediated, but no specific implementation plan has been proposed. Since AI education has historically been integrated into computer science (CS) or information and communication technology (ICT) education systems, the prevalence of CS and/or ICT education is used as a surrogate indicator for the development of AI education in this analysis. However, similar to the challenges of tracking the development of computer science education in the United States, there is a need to be cautious in interpreting global education indicators, as computer science (CS) and information and communication technology (ICT) education are often confused with digital literacy or computer literacy education.  
6. Popularity
By 2024, about two-thirds of the world's countries have implemented or planned to do so
Computer science education (Figure 7.2.17). About 30% of these countries have made computer science education compulsory at the primary and/or secondary levels, and Europe has the highest number of countries implementing such policies. Over the past five years, all continents of the world have made varying degrees of progress in promoting computer science education, with particularly significant growth in Africa and Latin America (Figure 7.2.18). Despite this, students in African countries continue to be among the most difficult to access computer science education opportunities globally. The main reason for this is a lack of infrastructure: as of 2023, only 34% of primary schools in sub-Saharan Africa have access to electricity, a reality that not only limits students' basic computer skills, but also further hinders the implementation of computer science and artificial intelligence curricula.
Compulsory courses are required in both primary and secondary schools
Compulsory for primary or secondary schools only Elective for all regions Some schools/regions offer interdisciplinary integrated teaching programs, no computer science courses are offered, and the prevalence of computer science education by country in 2024 is available
Source: Raspberry Pi Center for Computing Education and Research, 2024| Chart: Chapter 7 of the 2025 AI Index Report: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.17
6. Digital literacy refers to "the ability to use ICTs to find, assess, create and deliver information, requiring both cognitive and technical skills"; Computer literacy refers to "the ability to operate in general, such as computers and productivity software". Artificial intelligence in 2025
Index Report
Table of Contents Chapter 7 Preview 380Globally, tracking progress in AI education is challenging due to the lack of a standardized data collection mechanism. The language barrier and the lag in updating the implementation status of each country are further increased
It is more difficult to accurately monitor across borders.
Policy guidance
atGlobally, countries are pushing for the development of "AI education standards".
The pace of progress has lagged significantly behind the development of "AI in education" policymaking. end
In November 2024, a total of 10 countries have issued guidance documents related to AI education: Australia, Belgium, Canada, Japan, New Zealand, South Korea, Ukraine, the United Kingdom, the United States, and Uruguay. This trajectory is not surprising, with a decade of discussions around the development of policies and guidelines on AI in education. As early as 2015, UNESCO's Member States pledged to advance science and technology at the global level to ensure "inclusive and equitable quality education and promote lifelong learning opportunities for all" (SDG 4). Subsequently, in 2019, UNESCO published the Beijing Consensus: AI and Education, which aims to provide concrete recommendations to guide countries towards achieving equitable access to quality education for all by 2030 (see Education 2030 Agenda for details). Within this framework, there are four guidance on the policy and implementation aspects of education in K-12 that explicitly address AI. Change in access to computer science education by continent, 2019 vs. 2024
Source: Raspberry Pi Center for Computing Education and Research, 2024| Chart: 2025 Artificial Intelligence Index Report
9.40%
24.50%
63.49%
29.54%49.05% (+39.65 pp)
57 .89% (+33.39 pp)
88.88% (+25.39 pp)
70.45% (+40.91 pp)
0% 20% 40% 60% 80% 100% Africa
Asia
Europe
2019
2024
Percentage of countries providing computer science education Latin America and the Caribbean Continent Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.182025 Artificial Intelligence
Index Report
Table of Contents Chapter 7 Preview 381 Similar to the AI4K12 initiative, international organizations are also actively building AI education
Curriculum frameworks for adoption and localization. AI4K12 proposes "Five
The Five Big Ideas in AI have become an important framework for organizing AI education at the K–12 level (Figure 7.2.19). In 2023, UNESCO launched an AI Competency Framework for students and teachers. The student framework covers four core competencies: human-centered values, AI ethics, AI technologies and applications, and AI system design. In each competency, students need to go through a cognitive progression of "understanding, applying, and creating". At EU level, most member states have adopted the DigComp 2.2 framework as an important guide to improving citizens' digital competencies and promoting the holistic development of students' digital literacy in conjunction with computer science learning objectives. The latest version of DigComp 2.2 already includes recommendations on the knowledge, skills, and attitudes needed to interact with AI, although it does not explicitly include guidance for teaching citizens to build AI systems. The AI4K12 guidelines revolve around five major ideas in the field of artificial intelligence
Source: AI4K12, 2024
Chapter 7: Education
7.2 Computer Science and Artificial Intelligence Education at K-12 Levels
Figure 7.2.19 7
7. Note: Figure 7.2.19 introduces the "Five Cores", which are as follows:1. Perception, a computer perceives the world through sensors. 2. Representation and Reasoning, where the agent maintains representations of the world and makes use of these
Characterize for inference. 3. Learning, a computer can learn from data. 4. Natural Interaction: Agents need multiple kinds of knowledge to interact with humans naturally. 5. Societal Impact: AI may impact society in a positive or negative way. Artificial intelligence will play a role in the structure of the U.S. workforce and the future of the economy
The role is not yet fully understood, but the impact is expected to be far-reaching. while
Previously, technology workers have become an important part of the U.S. economy, with 9.6 million people working in technical positions across the country. While the job substitution caused by automation is a concern, the demand for AI-related jobs – such as database management and data infrastructure solutions – is expected to continue to grow. Therefore, there must be a concerted global effort to ensure that higher education institutions have the capacity to train the workforce of the future and to further expand the computing technology talent training system. Artificial intelligence in 2025
Index Report
Table of Contents Chapter VII Preview 382 United States
In this section, we will discuss computer science and artificial intelligence education at the higher education level in the United States
Trend data, mainly from the National Center for Education Statistics (NCES). Noteworthy
The Subject Classification Standards (CIP) were developed by the Center for the U.S. Department of Education and are used to classify academic programs in a unified manner. Since 2016, AI-related courses have been included in CIP Code 11.0102, which covers "courses with symbolic reasoning, knowledge representation and simulation at its core, with an emphasis on simulating the processes and abilities of human learning and reasoning through computers and software, as well as computational modeling of human motion control and action." The course content includes computational theory, cybernetics, human factors engineering, natural language processing, as well as engineering technology and related knowledge in specific application areas."
Although the number of associate's degree holders in computer science has remained roughly unchanged over the past decade
Some community colleges have taken the lead in exploring AI education, offering relevant certificate programs, as well as associate and bachelor's degree programs in AI and related fields (Figure Degree Awarding).
7.3.2） 。 Representative institutions include Maricopa, Houston Community College, Miami Dade College, and several members of the Bay Area Community College Consortium.
Over the past decade, the number of graduates of bachelor's degrees in computing has increased by 22%
(Figure 7.3.1). In 2023, the top five high schools with the highest number of bachelor's degree graduates in computer science
Western Governors University, University of California, Berkeley, Southern New Hampshire University, University of Texas at Dallas, and University of Michigan are.
8 Although the growth of AI at the bachelor's level will take time to be realized (due to its academic length
Typically four years), the rapid expansion of the field of AI is already evident at the master's level: the number of computer science master's graduates increased by 26% between 2022 and 2023, with a cumulative increase of 83% over the past decade. 7.3 Computer Science and Artificial Intelligence Education at Higher Education
8. Western Governors University and Southern New Hampshire University are primarily online educational institutions. Chapter 7: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter 7 Preview 3832013-2023 Number of Computer Science Graduates at the Higher Education Level in the United States
Source: National Center for Education Statistics Integrated Data System for Higher Education, 2013-2023 | Chart: 2025 Artificial Intelligence Index Report
Although women's overall tertiary education graduation rates are higher than men's, degree completion rate data show that women are still underrepresented in computer science (Figure).
7.3.2） 。 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023010,00020,00030,00040,00050,00060,00070,00080,00090,000
2,54020,72552,10787 ,435Number of new computer science graduatesBachelor's degree
Associate's degree
Ph.D. Number of Artificial Intelligence Graduates
23% 22%32%
24%77% 78%68%
76%
0%20%40%60%80%100%Male Female
Associate's Bachelor's Degree Master's Ph.D. Gender-Neutral Computer Science Graduates in the U.S. at Higher Education Level
Source: National Center for Education Statistics Integrated Data System for Higher Education, 2013-2023 | Chart: Chart 7.3.1 of the 2025 AI Index Report
Figure 7.3.2 Chapter 7: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter 7 Preview 384 The percentage of African-American students in computer-related subjects is: at the undergraduate level
8%, 8% at the master's level, and 7% at the doctoral level (Figure 7.3.3). Latino students in
The proportion is 13% at the undergraduate level, 8% at the master's level, and 4% at the doctoral level. By comparison, white students make up 46 percent of students at the undergraduate level and more than half (52 percent) at the doctoral level. Asian-American students show a significant over-representation trend in computer science majors at the tertiary level, accounting for 23%, 28%, and 17% of undergraduate, master's, and doctoral levels, respectively.
The majority of students in computer-related graduate programs come from the United States and foreign countries
home, this proportion has continued to rise over the past few years. In 2023, non-residents of the country
It accounts for 67% of master's degree graduates and 60% of doctoral degree graduates. Between 2022 and 2023, the number of international master's students in computer science more than tripled, from 15,811 to 34,850 (source: IPEDS). Students from India and China make up the vast majority of this graduate group, accounting for 93% (95,130) of the international computer science master's degree and 60% (13,070) of the international CS PhD students, respectively (Figures 7.3.4 and 7.3.5). At the same time, the number of U.S. colleges and universities offering AI-specific bachelor's degree programs nearly doubled between 2022 and 2023; There has also been a significant increase in the number of institutions offering dedicated master's programmes in AI (Figure 7.3.6). U.S. Computer Science by Race/Ethnicity vs. All Higher Education Graduates in 2023 (U.S. Residents Only)
Source: National Center for Education Statistics Post-Secondary Integrated Data System, 2013-2023 | Chart: 2025 Artificial Intelligence Index Report
 12%
 12%
 10%
 8%
 12%
 8%
 10%
 7% 27%
 20%
 18%
 13%
 13%
 8%
 10%
 4% 4%
 4%
 4%
 4%
 3%
 3%
 3%
 3% 6%
 13%
 9%
 23%
 8%
 28%
 12%
 17% 47%
 44%
 56%
 46%
 57%
 40%
 58%
 52% 4%
 6%
 3%
 5%
 6%
 12%
 6%
 15%
0% 20% 40% 60% 80% 100% CSCSCSCS Native American/Alaska Black Hispanic NHPI Two or more Asian White Unknown
Percentage of tertiary education graduates all
Associate's degree
bachelor
Master
Dr. All
all
all
Figure 7.3.3 Chapter 7: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter 7 Preview 3852022 Number of International Computer Science Master's Students at U.S. Colleges and Universities
Sources: U.S. National Science Board; National Science Foundation, 2023| Chart: 2025 Artificial Intelligence Index Report
International Ph.D. students in computer science at U.S. colleges and universities in 2022
Sources: U.S. National Science Board; National Science Foundation, 2023| Chart: 2025 AI Index Report 3.140.060.070.080.090.100.140.140.180.230.230.260.290.480.530.860.880.991.1813.1972.02
0 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 India
China
Taiwan, China 
Nepal
 Bangladesh, Nigeria 
Korea
Pakistan
Vietnam 
Saudi Arabia
Turkey, Canada
 Ghana, Brazil 
Iran
Colombia
Japan, Great Britain, France
Mexico
Other locations
Number of International Computer Science Master's Students (1,000)
1,060304040505050801301601901902202402503703806609802,7605,130
0 300 600 900 1,200 1,500 1,800 2,100 2,400 2,700 3,000 3,300 3,600 3,900 4,200 4,500 4,800 5,100
International Number of PhD Students in Computer Science: China, India
Bangladesh
Iran, South Korea
Saudi Arabia
Nepal
Pakistan
Taiwan, China
Nigeria
Vietnam 
Turkey 
Canada
Sri Lanka
Brazil, Ghana, Egypt
Colombia
Italy, Mexico
Other Locations Map 7.3.4
Figure 7.3.5 Chapter VII:educate
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter 7 Preview 3862013-2023 Number of Colleges and Universities in the United States Offering Bachelor's and Master's Degrees in Artificial Intelligence
Source: National Center for Education Statistics Post-Secondary Integrated Data System, 2013-2023 | Chart: 2025 Artificial Intelligence Index Report
The number of students who earned a master's degree in artificial intelligence between 2022 and 2023
There was a significant increase (Figure 7.3.7). Carnegie Mellon University as the year of artificial intelligence
The number of graduates from universities with the largest number of graduates has doubled within a year; Penn State, meanwhile, welcomed its first class of AI graduates in 2022 (Figure 7.3.8). Prior to that, Carnegie Mellon University was one of the few universities to offer a degree program dedicated to artificial intelligence. 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023051015202530354045
19, 45 bachelor's, master's degree institutions, number of fresh AI graduates
2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 20230200400600800
104, Bachelor's 935, Master's Figure 7.3.6
Figure 7.3.7 U.S. Bachelor's and Master's Degree Graduates in Artificial Intelligence from 2013-2023
Source: National Center for Education Statistics Post-Secondary Integrated Data System, 2013-2023 | Chart: Chapter 7 of the 2025 AI Index Report: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter 7 Preview 387 Higher Education Institutions with the Most Graduates in Artificial Intelligence by Degree Type in 2023 9
Source: Integrated Data System for Post-Secondary Education, National Center for Education Statistics, 2023.
Bachelor's degree in Artificial Intelligence
Carnegie Mellon University, Fuller Sell University, Concordia University of Wisconsin, Concordia University of Wisconsin, Polytechnic University, Pennsylvania State University, Main Campus Artificial Intelligence Master's Program Graduates, Carnegie Mellon University, University of Pennsylvania, University of North Texas, University of Pennsylvania, University of North Texas, San Jose State University, Ph.D. Program in Artificial Intelligence, Carnegie Mellon University, Congressional Technical University, University of Pittsburgh, University of Pittsburgh, Pittsburgh Campus 32
1916107
178
98765552
28
41
Figure 7.3.8
9. This list only includes universities that use CIP codes for AI majors, not universities that use general CS codes. However, it is likely that many students studying AI across the globe are enrolled in the broader CS. Chapter 7: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Index Report
Table of Contents Chapter VII Preview 388 Global
Globally, there is no single dataset that can be applied to all countries
The state of higher education in artificial intelligence or computer science is unified and standardized
Plan. However, the Organisation for Economic Co-operation and Development (OECD) has consolidated data from its member countries and a number of non-member countries to provide a somewhat comparative basis.
10 The International Standard Classification of Education Statistics (ISCED) is used for the study
The classification system is also the benchmark for the OECD to assess global education progress. Information and Communication Technology (ICT) covers research areas such as "informatics, information and communication technology and computer science", and its core content covers a series of emerging technologies, involving the processing and transmission of digital information, including computers, computer networks (such as the Internet), microelectronics, multimedia, software and programming.
In this data set, the United States continues to be in ICT-related areas
A global leader with more graduates at the associate's, bachelor's, master's and doctoral levels than any other country (see Figures 7.3.9 to 7.3.12). In particular, at the associate, master's, and doctoral levels, the U.S. has twice as many graduates as the second-place country; At the bachelor's level, the U.S. also has nearly twice as many graduates as the second-place country.
Number of recent graduates of short-cycle higher education in ICT by country, 2022
Source: OECD, 2022 Chart: 2025 Artificial Intelligence Index Report
1,2731,8892,1572,8852,9463,7206,9837 ,2499,42510,82012,85216,27516,46417 ,76438,746
0 3,000 6,000 9,000 12,000 15,000 18,000 21,000 24,000 27 ,000 30,000 33,000 36,000 39,000l United States
Spain
Turkey, Canada
Colombia
France, England
Australia
Korea
Mexico
Chile and Sweden
Israel, New Zealand, Austria
Number of new ICT short-cycle tertiary education graduates
Figure 7.3.9
10. While the dataset provides insight into some countries, it ignores some countries with large numbers of ICT graduates. India, China and African countries were excluded, highlighting the need for standardized global data collection to ensure that those in computer education were taken seriously
This includes countries that have made significant investments and represent a large proportion of the majority of the world's countries. There is also a significant lag in the collection and reporting of global education data; Therefore, the most recent year for which data is available is 2022. Chapter 7: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education Level Artificial Intelligence 2025
Chapter 7 of the Index Report: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education
Table of Contents Chapter 7 Preview of the new ICT undergraduate graduates by country in 3892022
Source: OECD, 2022 Chart: 2025 Artificial Intelligence Index Report
Number of new graduates of the Master in Information and Communication Technology by country in 2022
Source: OECD, 2022 Chart: 2025 Artificial Intelligence Index Report
2,2002,4032,4522,9102,9823,2143,3733,7284,0444,1649,71612,50013,94021,68855,706
0 4,000 8,000 12,000 16,000 20,000 24,000 28,000 32,000 36,000 40,000 44,000 48,000 52,000 56,000 United States
United Kingdom, France, Germany
Australia
Poland
Canada, Ireland, Mexico, Spain
Colombia
South Korea, Netherlands
Italy
Romania Figure 7.3.10
Figure 7.3.115,0906,0236,2566,65010,47212,81713,05313,05414,58419,60320,43521,36532,73861,760116,401
0 8,000 16,000 24,000 32,000 40,000 48,000 56,000 64,000 72,000 80,000 88,000 96,000 104,000 112,000 120,000 United States
Brazil
Mexico
Germany, Great Britain, South Korea
Australia
Peru
Canada
Poland, France
Spain
Romania
Turkey
Chile
Number of ICT graduates in the current year
Number of ICT Master's Graduates 2025 Artificial Intelligence
Chapter 7 of the Index Report: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education
Table of Contents Chapter 7 Preview 390 Gender balance remains a major challenge in AI-related disciplines worldwide
(Figure 7.3.13). Globally, women are highly relevant in ICT
The average proportion of graduates from education is about a quarter, and this is true at the associate, bachelor's, and doctoral levels. In contrast, the proportion of women at the master's level is slightly higher, about one-third. Among countries, Turkey is particularly strong in terms of gender balance, with women accounting for at least half of graduates at the associate's, bachelor's, master's and doctoral levels. New ICT PhD graduates by country in 2022
Source: OECD, 2022 Chart: 2025 Artificial Intelligence Index Report
1201221401421441942473093744256177331,0081,1562,759
0 150 300 450 600 750 900 1,050 1,200 1,350 1,500 1,650 1,800 1,950 2,100 2,250 2,400 2,550 2,700 2,850 United States
Great Britain, Germany, France, South Korea
Australia
Brazil
Canada, Spain, Italy, Mexico
Switzerland, Finland, Sweden, the Netherlands
Number of newly graduated ICT PhD graduates
Figure 7.3.1222025 Artificial Intelligence
Chapter 7 of the Index Report: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education
Table of Contents Chapter 7 Preview of the percentage of ICT higher education graduates by country in 3912022 as a percentage of recent graduates from higher education
Source: OECD, 2022 Chart: 2025 Artificial Intelligence Index Report
Percentage of female post-secondary graduates in ICT 24% 23% 33% 34%
SC B M PhD0%50%100%
10%19% 21%13%
SC B M PhD0%50%100%
10% 14% 17%
NA
SC B M PhD0%50%100%
NA15% 19% 19%
SC B M PhD0%50%100%
NA35% 40%25%
SC B M PhD0%50%100%
29%22%31%24%
SC B M PhD0%50%100%
13% 12%22%
NA
SC B M PhD0%50%100%
25%18%28%38%
SC B M PhD0%50%100%
31%21% 18%
NA
SC B M PhD0%50%100%
NA26% 25%
NA
SC B M PhD0%50%100%
NA16% 19% 18%
SC B M PhD0%50%100%
10%19%35%
NA
SC B M PhD0%50%100%
NA24%45%38%
SC B M PhD0%50%100%
NA25% 30%21%
SC B M PhD0%50%100%
14% 17% 22% 26%
SC B M PhD0%50%100%
NA21% 24% 20%
SC B M PhD0%50%100%
NA30%42%
22%
SC B M PhD0%50%100%
12%18% 18% 17%
SC B M PhD0%50%100%
NA28%
9%NA
SC B M PhD0%50%100%
37%27%36% 35%
SC B M PhD0%50%100%
56%
32%18%28%
SC B M PhD0%50%100%
17% 17%25% 28%
SC B M PhD0%50%100%
26%32%23%15%
SC B M PhD0%50%100%
20% 21%28%
NA
SC B M PhD0%50%100%
NA16%34%
NA
SC B M PhD0%50%100%
13% 17%42%
23%
SC B M PhD0%50%100%
27% 27%33% 33%
SC B M PhD0%50%100%
13% 15%29%14%
SC B M PhD0%50%100%
36%29% 34% 35%
SC B M PhD0%50%100%
27% 23%29%43%
SC B M PhD0%50%100%
NA31%
NA NA
SC B M PhD0%50%100%
NA23% 19%12%
SC B M PhD0%50%100%
6%20%37%
11%
SC B M PhD0%50%100%
NA33%42%35%
SC B M PhD0%50%100%
NA18% 17%11%
SC B M PhD0%50%100%
13%21% 23%15%
SC B M PhD0%50%100%
12% 14%22% 23%
SC B M PhD0%50%100%
30%36% 41%33%
SC B M PhD0%50%100%
NA11%17% 19%
SC B M PhD0%50%100%
55% 50% 51% 53%
SC B M PhD0%50%100%
24%18%31% 28%
SC B M PhD0%50%100%
24% 24%35%26%
SC B M PhD0%50%100% Short Term (SC) 
Bachelor's (B), Master's (M), Ph.D., Australia, Austria, Belgium, Brazil
Bulgaria, Canada, Chile, Colombia
CostaRica, Croatia, Czech Republic, Denmark
Estonia, Finland, France, Germany
Greece, Hungary, Iceland, Ireland
Israel, Italy, South Korea, Latvia
Lithuania, Luxembourg, Mexico, Netherlands
New Zealand, Norway, Peru, Poland
Portugal
Spain, Romania, Slovakia, Slovenia
Sweden
United Kingdom, United States, Switzerland, Turkey
Figure 7.3.13Artificial intelligence in 2025
Chapter 7 of the Index Report: Education
7.3 Computer Science and Artificial Intelligence Education at Higher Education
Table of Contents Chapter VII Preview 392 Guiding Policies
Currently, AI policy and guidance at the university level is mainly focused on students
Norms of conduct for the use of AI in assignments, and for AI education itself
Guidance is usually developed internally by individual faculties, mainly computing faculties.
The use of AI on college campuses has become extremely common, both for students and for the better
Teachers are highly reliant on them: 86% of students use AI in their learning and 61% of teachers use AI in their teaching. However, there is still a lack of clarity and standardization of guidelines around the use of AI within universities. By early 2025, only 39% of higher education institutions have an "acceptable use policy" related to AI, although this is an increase of 16 percentage points from 2024. Among large universities with more than 10,000 students, the proportion of relevant policies is significantly higher than that of smaller universities with fewer than 5,000 students. While AI has the most significant impact on teaching and learning policies, virtually almost all types of university policies are affected by AI technologies, including technology procurement processes
(e.g. whether the school can use resources to procure AI tools), intellectual property rights and copyrights
Compliance with laws, whether it is permissible to use artificial intelligence to create malware or viruses, etc. In many policy areas such as cybersecurity, data privacy, online teaching, and data analysis, the application and control of AI have triggered a systemic chain reaction.
In addition to the 2019 Beijing Consensus: AI and Education, which is K–12
In addition to the guidance provided, UNESCO has published a comprehensive guidance policy for K–12 and higher education with the aim of using AI to advance the global goals set out in the Education 2030 Agenda. The report proposes five implementation and policy recommendations specifically for AI education at the tertiary level. Artificial intelligence in 2025
Chapter 7 of the Index Report: Education
7.4 Looking Ahead
Table of Contents Chapter 7 Preview 3937.4 Looking to the Future
Equitable AI education ecosystems are consciously designed to be instrumental in future technologies
The responsible development and deployment of technological innovation plays a crucial role. Current artificial intelligence
The rapidly expanding institutional environment has led to a range of undesirable consequences, including disinformation and misleading information campaigns that manipulate national political processes, the development of AI-enabled weapons, and the infringement of copyrighted intellectual property rights. These phenomena highlight the urgent need to prioritize a more robust and responsible approach to building AI. To achieve this, the holistic approach to AI education must be reimagined to recognize AI competencies as the core competencies that students will have to navigate a technology-driven future. These capabilities should encompass not only the development of the technology itself, but also an ethical perspective that proactively identifies, analyses and questions the societal impact of AI. At present, there are infrastructure, policy frameworks and implementation mechanisms based on computer science, which provide a realistic path for the systematic integration of AI education. However, as AI technology continues to evolve, the transformation of the education system is urgent. This is the only way to ensure that the builders of future technologies are fully aware of the risks that AI can pose, and have the ability to effectively mitigate their negative impacts. Higher education institutions around the world should continue to promote the construction of AI education channels, and conduct phased effectiveness monitoring in the process. At the same time, it is necessary to formulate corresponding policies to expand the equity of curriculum access, and implement practical strategies to improve teachers' professional competence and promote students' extensive participation, so as to achieve the equitable popularization and capacity building of AI core literacy in the education system. Artificial intelligence in 2025
Index Report
Chapter 8:
Public opinion
Text & Analytics 2025 Artificial Intelligence from Emily Capstick
Index Report
Table of Contents Chapter 8 Preview 395 Get an overview of public data
Chapter Highlights
8.1 Public Opinion
Global Public Perspectives Artificial Intelligence Products and ServicesArtificial Intelligence and EmploymentArtificial Intelligence and People's LivelihoodFocus: Autonomous Vehicles
8.2 Perspectives of U.S. Policymakers396
397
399
399399405407409
410 Chapter VIII: Public Opinion 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VIII Preview 396 Overview
As AI becomes more and more permeated at all levels of society, it is becoming more common to understand public attitudes towards the technology
Significant. Insights into how people perceive AI can not only help predict its possible social impacts.
It can also reveal differences in adoption and acceptance across countries and demographic groups. Preliminary data shows that public anxiety about AI is on the rise, with much more pessimism in some regions than others. It remains to be seen whether this trend will continue as technology continues to evolve.
This chapter will explore the public's perception of AI from multiple dimensions such as global, national, demographic, and ethnic.
The data used comes from a number of research sources, including Ipsos' long-term survey that continues to track global attitudes towards AI, the American Automobile Association's poll on autonomous vehicles, and the latest research on the views of local policymakers in the U.S. on AI. Chapter 8:
Public Opinion 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VIII Preview 3971. There is cautious optimism about AI products and services around the world. Surveyed in 18 of the 26 countries that Ipsos (Ipsos) continues to track from 2022-2024
The proportion of respondents who agree that "the benefits outweigh the disadvantages" of AI products and services is on the rise. Globally, the proportion of individuals who believe that the benefits of AI products and services outweigh the harms from:
52% in 2022 rises to 55% in 2024.
2. Awareness of the expected impact of AI on everyday life continues to rise. Around the world, two-thirds of people now believe that AI-powered products and services will be in the future3
Significant changes in daily life within 5 years – a 6 percentage point increase from 2022. With the exception of Malaysia, Poland and India, the rest of the countries have been recognized since 2022
Awareness increased, with Canada (up 17%) and Germany (up 15%) seeing the most significant increases.
3. Skepticism about the ethical behavior of AI companies is increasing, while trust in AI fairness is declining. Globally, people are protecting AI companies
Confidence in people's data from
 50% in 2023 drops to 47% in 2024. Similarly, fewer and fewer people today believe that AI systems are impartial and non-discriminatory.
4. Regional differences in AI optimism remain. For the first time, the 2023 AI Index notes that regional differences in AI optimism remain. In China (
83%), Indonesia (80%), and Thailand (77%), where the vast majority of people believe that the benefits of AI-driven products and services outweigh the harms, while in Canada (40%), the United States (
39%) and the Netherlands (36%), with only a minority holding this view.
5. Americans still have a distrust of self-driving cars. According to the latest survey data from the American Automobile Association (AAA), 61%
of Americans are afraid of self-driving cars, with only 13% of respondents saying they trust the technology. This is despite the fact that this percentage is lower than the peak of 68% in 2023
down, but still higher than the 2021 level of 54%.
6. Local policymakers in the U.S. are generally supportive of regulating AI. In 2023, 73.7% of local policymakers in the U.S. (covering town, city, and county governments) support the pair
The implementation of AI supervision has increased significantly from 55.7% in 2022. Democrats (79.2%) significantly higher than Republicans (55.5%), but both parties show significant growth compared to 2022. Chapter HighlightsChapter 8:
Public Opinion 2025 Artificial Intelligence
Index Report
Table of Contents Chapter VIII Preview 3988. Workers expect AI to reshape the employment structure, but they are relatively less concerned about job substitution. Globally, 60%
of respondents believe that AI will be used in
Change the way individuals work in the next five years. However, a small percentage of respondents (36%) believe that AI will replace their jobs in the next five years.
9. There is a clear disagreement among local policymakers in the United States on AI policy priorities. Although local government policymakers in the United States generally support AI regulation, they are better at specific policies
There are significant differences in the first matters. The policies with the highest support ratings include stricter data privacy regulations (80.4%), retraining programs for the unemployed (76.2%), and artificial intelligence applications
Regulatory (72.5%). However, support for policies such as a ban on facial recognition (34.2%), subsidies for wage reductions (32.9%), and a universal basic income (24.6%) for law enforcement has dropped significantly.
10. AI is seen as a tool for efficiency and a booster for entertainment experiences, but its economic impact remains questionable. Global perceptions of the impact of AI vary. 55% of
People believe that AI will save time, with 51% expecting it to provide better entertainment options, but fewer are confident in its health or economic benefits. Only 38% do
36% believe that AI will improve the national economy, 31% believe that AI will have a positive impact on the job market, and 37% believe that AI will improve their productivity. Chapter 8:
Public opinion
Chapter Highlights (continued) 
7. Optimism about AI has risen sharply among the countries that have previously held the strongest skepticism about AI. Globally, there is a lot of interest in AI products and
Optimism in services has improved, with the largest increase in optimism in the previously most skeptical countries.
In 2022, the United Kingdom (38%), Germany (37%), the United States (35%), Canada
Large (32%) and France (31%) are the countries least inclined to believe that the benefits of AI outweigh the disadvantages. Since then, these countries have seen an 8% increase in optimism about AI,  
10%, 4%, 8% and 10%. Artificial intelligence in 2025
Chapter 8 of the Index Report: Public Opinion
8.1 Public Opinion
Table of Contents Chapter VIII Preview 3998.1 Public Opinions
Global Public Perspectives
This section is conducted by Ipsos in 2022, 2023 and 2024
to explore the differences in global public perceptions of AI. The results show that different
There are significant differences in perceptions and attitudes towards AI between countries and population groups.
Artificial intelligence products and services
In 2024, Ipsos launched a study on the global public perception of artificial intelligence
degree of investigation. The survey was conducted among 23,685 adults in 32 countries
Talk done. 1 Figure 8.1.1 shows the proportion of respondents who agree with a particular statement.
Between 2022 and 2024, public perception of AI has remained relatively stable overall. In 2024, 67% of respondents reported a good understanding of AI, and 66% expect AI to profoundly transform their daily lives in the next three to five years. The proportion of people who believe that the benefits of AI-driven products and services outweigh the disadvantages are
52% in 2022 rose slightly to 55% in 2024.
However, Figure 8.1.1 also sheds light on growing concerns. past year
The percentage of respondents who believe AI companies will protect their personal data has declined
3 percentage points, with a 2 percentage point decrease in the percentage of respondents who believe that AI does not discriminate or bias against any group.
Global Public Perception of Products and Services Using AI (% of Total), 2022-2024
Source: Ipsos, 2022-2024 | Chart: 2025 Artificial Intelligence Index Report
Percentage of respondents who agreed: 67%
52%
50%
66%
55%
45%
54%
47%
50%67%
51%
49%
66%
54%
56%
50%
52%64%
50%
49%
60%
52%
39%
0% 10% 20% 30% 40% 50% 60% 70%2024
2023
2022
Figure 8.1.1 is clear to me
What is artificial intelligence
I know what types of products and services use AI
In the last three to five years, products that have used artificial intelligence and
Service has profoundly changed my daily life
Products and services that use AI will be available in the next three to five
This year has profoundly changed my daily life
The benefits of products and services that use AI outweigh the disadvantages
I believe that people do not discriminate or favor any group
I believe that AI does not discriminate or favor
Any group
I believe that companies that use AI will protect
My Profile
I'm unsettling with products and services that use artificial intelligence
1. Please refer to the appendix for details on the survey methodology. The survey is conducted in 2024 April-May. Artificial intelligence in 2025
Index Report
Table of Contents Chapter 8 Preview 400According to an Ipsos survey, there is a poor perception of the pros and cons of AI among different countries
Distinctive. Overall, respondents in Asia and Latin America are more likely to perceive people
The benefits of AI outweigh the disadvantages, such as China (83%), Mexico (70%) and India
(62%) of respondents have a positive view of AI. In contrast, Europe and the United Kingdom
Speak-speaking countries are more cautious, such as the United Kingdom (46%), Australia (44%), and Canada
(40%) vs. 39% of respondents in the U.S. believe the benefits of AI outweigh the disadvantages
Significantly low. It is worth noting that among the countries that were previously more skeptical in 2022,
Public sentiment is gradually improving. Ipsos' 2022 and 2024 comparisons of 26 countries show that 18 of them have seen an increase in the proportion of countries with a positive attitude towards AI. In 2022, France (31%), Canada (32%), and the United States
(35%), Germany (37%), Australia (37%) and the United Kingdom (38%) were the least available
One of the countries that are bullish on AI, and by 2024, the proportion of these countries has increased.
Percentage of the public by country that perceives the benefits of AI as outweighing the harms, 2022-2024
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 8.1.2
Argentina
Australia
Belgium
Brazil
Canada
Chile
China
Colombia
France, Germany, Great Britain
Hungary
India
Indonesia
Ireland, Italy
Japan
Malaysia
Mexico
Netherlands
New Zealand
Peru, Poland
Romania
Russia
Saudi Arabia
Singapore
South Africa, South Korea
Spain
Sweden, Switzerland, Thailand
Turkey
United States
Percentage of respondents (%) Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 401 Figure 8.1.3 further illustrates the public's interest in AI products and services in various countries
Cognitive, trust, and emotional responses. In all countries, Chinese respondents were interested in labor
Intelligence has the highest levels of awareness, trust, and excitement: 81% know which products or services use AI, 80% are excited about these products, 76% trust that AI will not bias the group, and 86% expect AI to profoundly change their lives within three to five years. In contrast, only 58% of U.S. respondents believe AI will significantly impact their lives in the next three to five years, and only 34% are excited about AI products.
Concerns about the privacy of personal data are most pronounced in Japan and Canada, and yes
Concerns about AI discrimination are highest in Sweden and Belgium.
Public perception and attitudes towards AI products in various countries in 2024
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
Figure 8.1.3 I have a good idea of what artificial intelligence is
understanding
I know what types of products kimonos
Artificial intelligence is used
In the last three to five years, the use of people
The products and services of industrial intelligence have been deep
Tick changed my daily life
In the next three to five years, Products and services that use artificial intelligence will be profound
Change my daily life
I believe that artificial intelligence will not be useful for any
The group exhibits discrimination or prejudice
I believe in companies that use artificial intelligence
will protect my personal data
Products and services that use artificial intelligence
Gets me excited
Products and services that use artificial intelligence
It makes me feel uneasy
globe
Argentina
Australia
Belgium
Brazil
Canada
Chile
China
Colombia
France, Germany
United Kingdom
Hungary
India
Indonesia
Ireland
Italy
Japan
Malaysia
Mexico
Netherlands
New Zealand
Peru, Poland
Romania
Russia
Saudi Arabia
Singapore
South Africa
Korea
Spain
Sweden
Switzerland
Thailand
Turkey
United States
Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 402Figure 8.1.4 Revealing the "excitement" of respondents in different countries about AI
The relationship with "feelings of anxiety". The results show that English-speaking countries (e.g., the United Kingdom, the United States, Canada
Australia, Australia and New Zealand) are significantly more anxious about AI than in other countries, while excitement is generally low. Comparatively speaking, Asian countries. For example, respondents in China, South Korea and Indonesia showed higher levels of excitement and lower levels of anxiety. Japan is the most cautious exception to AI in the region.
The distribution of public attitudes towards AI products in 2024 is crossed
Source: Ipsos, 2024| Chart: 2025 Artificial Intelligence Index Report
1
globe
China, Thailand, Peru, Turkey, Singapore
South Korea, Colombia, Brazil, Spain
Poland, New Zealand, Ireland
Netherlands, Switzerland, United States
Belgium
Japan, Canada
Sweden
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%0%10%20%30%40%50%60%70%80%90%00%
britannia  
Hungary
Argentina, France, Mexico, India
South Africa, Chile
Excitement (percentage of respondents who agreed) Anxiety (percentage of respondents who agreed)
Figure 8.1.4 Chapter 8: Public Perspectives
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 403 Ipsos surveyed most countries for two consecutive years, making cross-year comparisons
It is possible. Figure 8.1.5 shows the year-over-year change in various AI-related issues
Trend. Overall, the AI Index observed a slight uptick in concerns about the use of AI, with positive responses dropping by an average of 0.6%. This is largely due to a 3% drop in trust in whether companies using AI will protect personal data and a 2% drop in trust in whether AI will not discriminate or favor any group.
2  
Brazil and Malaysia saw the most significant declines in awareness, trust and enthusiasm for AI. In both countries, the negative trend stems from a sharp decline in the proportion of respondents who trust AI companies to protect their personal data.
South Africa and Ireland are in terms of awareness, trust and enthusiasm for AI
The most significant average increase was presented. Ireland's positive trend appears to stem from a good user experience, with the country having the highest percentage of respondents in the world who say their daily lives are profoundly influenced by AI products and services.
Changing global public attitudes towards AI in 2023–2024
Source: Ipsos, 2022-2024 | Chart: 2025 Artificial Intelligence Index Report
I have a good idea of what AI is
understanding
I know what types of products kimonos
Artificial intelligence is used
In the last three to five years, the use of people
The products and services of industrial intelligence have been deep
Tick changed my daily life
In the next three to five years, Products and services that use artificial intelligence will be profound
Change my daily life
I believe that artificial intelligence will not be useful for any
The group exhibits discrimination or prejudice
I believe in companies that use artificial intelligence
will protect my personal data
Products and services that use artificial intelligence
Gets me excited
Products and services that use artificial intelligence
It makes me feel uneasy
globe
Argentina
Australia
Belgium
Brazil
Canada
Chile
China
Colombia
France, Germany
United Kingdom
Hungary
India
Indonesia
Ireland
Italy
Japan
Malaysia
Mexico
Netherlands
New Zealand
Peru, Poland
Romania
Russia
Saudi Arabia
Singapore
South Africa
Korea
Spain
Sweden
Switzerland
Thailand
Turkey
United States
Figure 8.1.5
2. The global average response to the question "Products and services that use artificial intelligence make me nervous" is not included, as it is the only question where a positive score produces a normative negative outcome. Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 404Figure 8.1.6 Compares the 2022 and 2024 Ipsos (Ipsos) surveys
data, highlighting the change in public attitudes since the launch of ChatGPT. globe
Within 6%, the share of people who believe that AI-driven products and services will profoundly change everyday life in the next 3-5 years has risen. With the exception of India, Malaysia and Poland, all countries have seen an increase in awareness since 2022, with Canada (17%) and Germany (15%) seeing the most significant increases.
Comparison of the changes in the public's perception of "artificial intelligence will profoundly change lives" in 2022 and 2024
Source: Ipsos, 2022-2024 | Chart: 2025 Artificial Intelligence Index Report
I have a good idea of what AI is
understanding
I know what types of products kimonos
Artificial intelligence is used
In the last three to five years, the use of people
The products and services of industrial intelligence have been deep
Tick changed my daily life
In the next three to five years, products and services that use AI will be profound
Change my daily life
Products and services that use artificial intelligence
It makes me feel uneasy
globe
Argentina
Australia
Belgium
Brazil
Canada
Chile
China
Colombia
France, Germany
United Kingdom
Hungary
India
Indonesia
Ireland
Italy
Japan
Malaysia
Mexico
Netherlands
New Zealand
Peru, Poland
Romania
Russia
Saudi Arabia
Singapore
South Africa
Korea
Spain
Sweden
Switzerland
Thailand
Turkey
United States
Figure 8.1.6 Chapter 8: Public Perspectives
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 405 Artificial Intelligence and Employment
The 2024 Ipsos survey has added several new questions to explore the public's perception of artificial intelligence
Perceptions that can influence the current job. Figure 8.1.7 illustrates the global public's interest in AI
Expectations of how work will be changed or replaced by existing positions. Overall, 60% of respondents believe that AI is "likely" to change the way they work in the next five years, and another 36% believe that AI is "likely" to replace their current position at the same time, i.e. one in three people. Since the 2023 version does not distinguish between "very likely" and "somewhat likely", there are certain limitations to the year-to-year comparison. However, when the 2024 data is summed up by total "likelihood" and compared to 2023, the overall sentiment does not change much. In 2023, 57% of respondents believe that AI will change the way they work, and 36% believe that it may replace current jobs, almost in line with 2024.
2024 Global Perception of the Impact of AI on Current Jobs
Source: Ipsos, 2024| Chart: 2025 Artificial Intelligence Index Report
Percentage of respondents 21%
 11% 39%
 25% 8%
 8% 22%
 33% 10%
 23%
0% 20% 40% 60% 80% 100% Quite Likely Somewhat Probably Not Knowing Unlikely Completely Impossible
In the next 5 years
Artificial intelligence will change the way you work
Next 5 years
Artificial intelligence will replace your current job
Figure 8.1.7 Chapter 8: Public Perspectives
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 406 on whether AI will change what people currently do in the next five years
There are significant differences between different generational groups (see Figure 8.1.8). The younger generation
(e.g. Gen Z and Millennials) Older than older groups (e.g. Gen X and Baby Boomers)
More inclined to think that AI will change the way they work. Specifically,
In 2024, 67% of Gen Zers agree that AI may impact their current jobs, compared to just 49% of Baby Boomers. From 2023 to 2024, the proportion of people across all generations who believe that AI will change the way we work has increased. Notably, among the new 3% of respondents, millennials and baby boomers saw the largest increases, perhaps indicating a growing awareness of the impact of AI across generations.
Percentage of the global public agreeing that "AI will change the way we work in the next five years" in 2023 and 2024 (by generation)
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
67%
64%
55%
49%66%
61%
53%
46%
0% 10% 20% 30% 40% 50% 60% 70%2024
Gen Z 2023
Millennials
Generation X
Baby boomers
(% of respondents)
Figure 8.1.8 Chapter 8: Public View
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 407 Artificial Intelligence and People's Livelihood
The Ipsos survey also explores the impact that respondents will have on all aspects of their lives in artificial intelligence
on issues that affect the economy, recreation and health.
According to Figure 8.1.9, 55% of global respondents believe that AI will be reduced
The time required to become a task, 51% believe that AI will improve their entertainment options.
On the economic and job market fronts, respondents are more cautious, with only 36% and 31% respectively believing that AI will have a positive impact in these areas.
Figure 8.1.9 also shows that the perception of AI in different countries "will improve their economies
There is a significant difference in the proportion of people who are confident. Asian countries are the most optimistic, with 72% of respondents in China expressing positive expectations, followed by Indonesia (54%). In contrast, in the Netherlands, the United States, Belgium, Sweden and Canada, the proportion of people who believe that AI will improve the economy is lower 25%。
In addition, in each country, respondents believe that AI will improve the economy
With optimism, they tend to be more positive in other areas as well. For example, those who believe that AI will improve their own economies also generally believe that AI will save time and improve health.
On a global average, 38% of respondents believe that AI will improve health
Healthy. Mexico has the highest level of optimism at 56 percent. Japan has the lowest at 19%.
Global public perception of the impact of AI on the economy, entertainment, health, and more in 2024
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
Artificial intelligence will improve the economic situation of our country
Artificial intelligence will improve job market performance
Artificial intelligence will improve my work
Artificial intelligence will reduce the amount of time I need to complete my transactions
time
Artificial intelligence will improve my entertainment options
(e.g. TV/video content, movies, audio.)
Music, Books)
Artificial intelligence will improve my health
globe
Argentina
Australia
Belgium
Brazil
Canada
Chile
China
Colombia
France, Germany
United Kingdom
Hungary
India
Indonesia
Ireland
Italy
Japan
Malaysia
Mexico
Netherlands
New Zealand
Peru, Poland
Romania
Russia
Saudi Arabia
Singapore
South Africa
Korea
Spain
Sweden
Switzerland
Thailand
Turkey
United States
Figure 8.1.9
Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 408 Figure 8.1.10 and Figure 8.1.11 A correlation analysis of the preceding data is carried out in order to
Explore the degree of correlation between different question feedbacks. The study found that respondents were very likely to respond to "
There is a strong correlation between the belief that AI will improve the job market and the belief that AI will benefit one's job. Some countries, such as Poland, are less optimistic on both fronts, with only 17% and 21% agreeing, respectively. In contrast, Chinese respondents are more positive, with 44% believing that AI will boost the job market and 62% believing that AI will improve their own work conditions.
Similarly, among those surveyed they believe that AI will shorten the time it takes to complete tasks
of the country, people are also more inclined to believe that AI will improve their personal work conditions.
2024 Global Perception of Artificial Intelligence Improving Job Market Potential and Individual Jobs
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
2024 Global Perception of the Potential of AI to Improve Completion of Working Hours vs. Individual Work
Source: Ipsos, 2024 | Chart: 2025 Artificial Intelligence Index Report
Individual Work (% of Respondents) Personal Work (% of Respondents) Job Market (% of Respondents) China
Indonesia
Thailand South Africa
Singapore, India, Mexico, Peru
Malaysia
Argentina
Japan, Brazil, Colombia
Turkey, Chile
Switzerland, Ireland
Hungary, Belgium, Sweden
Canada
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%0%10%20%30%40%50%60%70%80%90%100%
United States
New Zealand  
Great Britain Australia
Italy
Netherlands, Germany, Spain
South Korea, France
Poland Global
Time taken to complete work (% of respondents) Global Thailand
Singapore, India, Peru
Malaysia
Argentina, Turkey
South Korea, Poland, Chile
Switzerland, Ireland
Hungary, New Zealand  
Japan, Netherlands
Canada
0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100%0%10%20%30%40%50%60%70%80%90%100%
 
Great Britain Australia
Italy
Germany, Spain, France
Sweden
Belgium China
Indonesia
Mexico
Colombia United States, Figure 8.1.10
Figure 8.1.11 Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter 8 Preview 409 Key Points :
Self-driving cars
As discussed in Chapter 2 on technical performance, self-driving technology is both capable and practical
Significant progress has been made in international deployment. With Waymo and Zoox and other companies
To develop, understanding the public's attitude towards autonomous driving technology has become increasingly critical.
Every year, the American Automobile Association (AAA) conducts a survey on public perception of self-driving cars
Examine. The latest survey was conducted in January 2025 and covered about 97% of U.S. households. Figure 8.1.12 shows that 61% of Americans say they are afraid of the technology, even though autonomous vehicles are gradually moving onto public roads. Only 13% of respondents said they trust self-driving cars. Although the "sense of fear" is slightly lower than the peak in 2023 (68%), it is still higher than the 54% in 2021. supported this view, up significantly from 55.7% in 2022. The release of ChatGPT appears to be a key factor driving policymakers to pivot to pro-regulation. Democrats have higher support for AI regulation (79.2%) than Republicans (55.5%), but both parties have seen a significant increase in support on this issue since 2022.
U.S. drivers' attitudes toward autonomous vehicles, 2021-2025
Source: AAA, 2025 Chart: 2025 Artificial Intelligence Index Report
Percentage of respondents are afraid of trusting and unsure
 54%  55% 68%  66% 61% 32%  30% 23%  25%
 26% 14%  15% 9%  9% 13%
2021 2022 2023 2024 20250%20%40%60%80%100%
Figure 8.1.12 Chapter 8: Public Opinion
8.1 Public Opinion Artificial Intelligence 2025
Index Report
Table of Contents Chapter VIII Preview 4108.2 Perspectives of U.S. Policymakers
When assessing public attitudes towards AI, it is not enough to look at public opinion
It is also important to pay attention to the views of key stakeholders, especially policymakers, as a result
for them to play a central role in AI regulation and policymaking. In 2022 and 2023, a joint research team from Uppsala University, the University of Oxford, Harvard University, and Syracuse University conducted a study involving local policymakers in the United States
(including municipal, township, and county levels). The study collected a total of about
Responses from 1,000 local officials, spanning exactly before and after the release of ChatGPT, allow researchers to compare changes in policymakers' attitudes. Figure 8.2.1 shows the extent to which local policymakers agree with the statement that governments should regulate AI. In 2023, 73.7% of U.S. local policymakers support this view, up significantly from 55.7% in 2022. The release of ChatGPT appears to be a key factor driving policymakers to pivot to pro-regulation. Democrats have higher support for AI regulation (79.2%) than Republicans (55.5%), but both parties have seen a significant increase in support of the issue since 2022.
The extent to which U.S. local officials support government regulation of AI, broken down by party and year
Source: Hatz et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Percentage of respondents all
2023
2022
Democrats, Republicans
Democrats in 2023
Democrats in 2022, Republicans in 2023, Republicans in 2022 agree Disagree and neither agree nor disagree
 64.50%
 73.70%
 55.70%
 79.20%
 55.50%
 84.40%
 74.60%
 67 .90%
 42.70% 19.10%
 14.40%
 23.60%
 15.10%
 21.60%
 11.60%
 18.30%
 15.50%
 28.00% 16.40%
 12.00%
 20.70%
 5.70%
 22.90%
 7 .10%
 16.60%
 29.40%
0% 20% 40% 60% 80% 100%
Figure 8.2.1 Chapter 8: Public Opinion
8.2 Opinions of U.S. policymakers on AI in 2025
Index Report
Table of Contents Chapter VIII Preview 411 Whereas, most local policymakers support some form of AI monitoring
Tube, what policies do they specifically prefer? The data shows (Figure 8.2.2) that support is the highest
The highest is the strengthening of data privacy regulations (80.4%). In addition, 76.2% of respondents supported retraining programs for unemployed persons and 72.5% supported the implementation of regulations on the use of artificial intelligence. In contrast, support for redistributive measures is significantly lower: only 33.9% support wage subsidies to offset income declines, and 24.6% support UBI.
U.S. local officials see AI policy options as positive for 2025–2050
Source: Hatz et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Strengthen data privacy regulation
Retraining programs for the unemployed
Regulate AI deployments
Strengthen anti-monopoly supervision
Regulate the use of artificial intelligence in parole and sentencing
Conduct bias audits on the use of AI in recruitment and promotion
Strengthen social safety nets
Impose federal regulation on the use of AI by local governments
Subsidies for semiconductor and AI hardware
Increase corporate income tax
Tax robots
Immigration reform for AI developers
Law enforcement agencies are prohibited from using facial recognition technology
Wage subsidies are provided to mitigate the decline in income
Implementation of Universal Basic Income (UBI)
Percentage of respondents 80.40%
 76.20%
 72.50%
 57 .70%
 54.70%
 51.70%
 46.40%
 45.60%
 44.40%
 42.90%
 42.40%
 39.10%
 34.20%
 33.90%
 24.60% 9.50%
 14.00%
 14.50%
 24.50%
 20.20%
 18.30%
 24.60%
 22.80%
 27 .40%
 30.50%
 22.30%
 34.10%
 26.00%
 27 .00%
 17 .10% 10.10%
 9.80%
 13.00%
 17 .80%
 25.10%
 30.00%
 29.00%
 31.70%
 28.20%
 26.60%
 35.30%
 26.80%
 39.80%
 39.00%
 58.30%
0% 20% 40% 60% 80% 100% agree Disagree Neither agree nor disagree
Figure 8.2.2 Chapter 8: Public Opinion
8.2 Opinions of U.S. policymakers on AI in 2025
Index Report
Table of Contents Chapter VIII Preview 412Although most local officials support AI regulation, only a few argue
You need to take action in the short term (see Figure 8.2.3). In 2023, only
34.3% of respondents believe they will need to make a decision in the next few years, while 56.5% believe it is unlikely. However, this proportion has increased from 2022: from 32.2% to 36.6%. This change reflects the impact of important AI developments such as ChatGPT on the attitudes of policymakers.
Likelihood of U.S. local officials making decisions on AI-related policies, categorized by party affiliation and year
Source: Hatz et al., 2025| Chart: 2025 Artificial Intelligence Index Report
All may be unlikely to know
2023
2022
Democrats, Republicans
Democrats in 2023
Democrats in 2022, Republicans in 2023, Republicans in 2022
Percentage of respondents 34.30%
 36.60%
 32.20%
 35.50%
 33.60%
 40.50%
 31.10%
 34.10%
 33.00% 9.20%
 9.10%
 9.20%
 8.90%
 8.80%
 8.10%
 9.70%
 8.40%
 9.10% 56.50%
 54.30%
 58.60%
 55.60%
 57 .70%
 51.40%
 59.20%
 57 .40%
 57 .90%
0% 20% 40% 60% 80% 100%
Figure 8.2.3 Chapter 8: Public Opinion
8.2 Opinions of U.S. policymakers on AI in 2025
Index Report
Table of Contents Chapter 8 Preview 413 Only 29.8% of locally elected officials believe they have enough information to develop AI policy (Figure 8.2.4). Although from 2022 to 2023, democracy
Confidence levels among party and Republican officials have improved, but overall levels remain relatively low.
 29.80%
 31.30%
 28.50%
 26.80%
 31.50%
 29.50%
 24.40%
 31.80%
 31.20% 17 .90%
 14.90%
 20.80%
 15.10%
 19.80%
 11.00%
 18.80%
 17 .60%
 22. 10% 52.30%
 53.80%
 50.80%
 58.10%
 48.70%
 59.50%
 56.90%
 50.70%
 46.70%
0% 20% 40% 60% 80% 100% all agree Disagree Neither agree nor disagree
2023
2022
Democrats, Republicans
Democrats in 2023
Democrats in 2022, Republicans in 2023, Republicans in 2022
Percentage of respondents: The degree to which U.S. local officials, disaggregated by party and year, agree that they have adequate information to develop AI policies
Source: Hatz et al., 2025| Chart: 2025 Artificial Intelligence Index Report
Figure 8.2.4 Chapter 8: Public View
8.2 Opinions of U.S. policymakers on AI in 2025
Index Report
Addendum 2025 Artificial Intelligence
Index Report
Table of Contents Appendix 415 Appendix
Chapter I
Chapter 2 Chapter 3 Chapter 4 Chapter 5 Chapter 6 Chapter 7 Chapter 8 Research and DevelopmentTechnological PerformanceResponsible Artificial IntelligenceEconomyScience and MedicinePolicy and GovernanceEducationPublic Perspectives
416
420
427
431441451
Artificial intelligence in 4544552025
Index Report Appendix
Chapter 1: Research and Development
Table of Contents Appendix 416 Chapter I: Research and Development
Thanks
Thanks to Angelo Salatino for the AI essay score
Class contributions, Machine Learning Inference Cost Analysis led by Ben Cottier, AI Patent Analysis led by Lapo Santarlasci, and Environmental Impact Analysis of AI Models led by Andrew Shi.
Artificial Intelligence Publication Analysis
For this analysis, the AI Index uses OpenAlex, an open scholarly database with more than 260 million research papers, as the primary source. OpenAlex uses its own knowledge organization system to classify papers, which is called OpenAlex Topics – a classification system of about 4,500 topics that combines Scopus codes and CWTS classifications. The system uses a deep learning model that takes into account titles, abstracts, journal names, and citation networks for classification. To more precisely identify AI-related topics, the AI Index analyzes the statistics of computer science papers identified by OpenAlex and refines the classification using computer science ontologies and CSO classifiers.
The Computer Science Ontology (CSO) is a large-scale, auto-generated research domain
Domain ontology, which is derived from 16 million papers using the Klink-2 algorithm. It features a hierarchical structure with thousands of subtopics that can be mapped to specific terms to a broader field of study with precision. Compared to general academic databases such as OpenAlex, Scopus, and Web of Science, CSO provides a more detailed and granular representation of the field of study. It has been widely used for academic data exploration, analysis, modeling, and expert identification and recommendation. Version 3.4.1 used in this analysis includes about 15,000 topics and 166,000 relationships in the field of computer science. This version, released on January 17, 2025, introduces more than 150 new research topics in AI, bringing the total number of AI-related topics to 2,369, with 12,620 hierarchical relationships in the field of AI alone. To analyze research trends, the AI Index uses the CSO classifier – an unsupervised method for automatically classifying research papers based on CSO topics. The classifier uses a three-stage process to process paper titles and abstracts: the grammar module detects direct mentions of CSO topics; The semantic module uses word embeddings to identify related concepts; The post-processing module merges results, filters out irrelevant topics, and adds a wider range of categories for more granular classification. In this analysis, the AI Index expands on the CSO classifier, specifically AI and its subtopics. Since its initial release, the classifier has gained increasing attention for its versatility. For example, Springer Nature uses it to routinely classify proceedings books and improve metadata quality. In addition to scholarly publishing, it has been successfully applied to research software, YouTube videos, press releases, job advertisements, and the classification of IT museum collections.
Accurately classify research papers into conference proceedings or journal proceedings
Important. OpenAlex's metadata fields—type, cross-reference type, and source type—sometimes conflict. To address these inconsistencies, the AI Index maps OpenAlex records to DBLP, a leading statistical database of computer science papers. Known for its high-quality metadata, DBLP is constantly adding new paper statistics through a rigorous, semi-automated curation process and currently indexes 3.6 million conference papers and 3 million journal papers. The initial match between OpenAlex and DBLP was made using DOI. For the remaining unmatched papers, the AI index uses a combination of title and year of publication. To simplify this process, AI Index has built a headline index to optimize search and ensure efficient mapping across datasets.
AI paper statistics are aggregated based on multiple parameters to provide comprehensive analysis.
The statistics of the papers were divided by year taking into account the publication date of the latest version of the 2025 artificial intelligence
Index Report
Table of Contents Appendix 417 Group. In addition, the AI Index team also sorted the authors by geographic region or world
Banking Regions are grouped. This means that if a paper is co-authored by researchers from different countries, the paper may be counted multiple times, once for each country. If the author's affiliation is missing, these paper statistics will be mapped as "unknown". In addition, if there is an author's affiliation, the department is linked to the paper statistics through the author's affiliation, which may result in a publication being counted by multiple departments. If citation data is available, citation counts are included; Publications without citation data are classified as "unknown".
Statistical analysis of top 100 papers
The AI Index provides a comprehensive analysis of influential AI paper publication statistics by collecting and analyzing citation data from multiple sources, including OpenAlex, Google Scholar, and Semantic Scholar. Initially collected from OpenAlex were the 150 most cited papers per publication year, and after careful review, the list was refined into a 100-paper count.
This method attributes the paper statistics to all countries and regions represented by the author's affiliation, which means that a paper can be counted multiple times. For example, a paper co-authored by an American and Chinese person is counted once in each country. This approach can result in overlapping totals in the summary statistics. Whether in journals, conferences, or repositories such as arXiv, the year of publication is based on the most recent version. In order to maintain accuracy, organizational affiliations are verified and standardized, and countries are assigned according to the location of headquarters.
The full list of the top 100 AI publication statistics can be found here.
Artificial Intelligence Patent Analysis
The AI Index uses a hybrid taxonomy that combines keyword-based text analysis with the base
Combined with the recognition of classification codes, it identifies patents related to artificial intelligence. Patent document data comes from PATSTAT Global, which is a tool developed by the European Patent Office
(EPO). 1 Patents are based on the earliest documented authorized publications
of publishers are owned by various countries.
Use the deep-translator tool, Google Translate engine, and Meta NLLB-200 
The machine translation model translates patent abstracts and titles that were originally published in a language other than English. After translation, the patent text is processed using natural language processing (NLP) technology. These techniques include removing pauses and special characters, preserving discourse (POS) markup for key grammatical categories, lowercase conversion, lexicalization, and <NUM> marker substitution of numeric amounts.
Patents related to artificial intelligence are made through the use of regular expressions (regex) search criteria
questions and abstracts in the relevant terms. The AI-specific keyword dictionary was developed through a structured, multi-step process that incorporates keywords generated by AI models and is extended with established AI dictionaries such as those in Yamashita et al. (2021), and also refined with synonym recognition based on Word2Vec. Further validation was carried out using B E R T o p i c topic modeling and DeBERTA-based zero-shot classification, and manual checks were employed to reduce false positives. In addition to keyword-based classification, AI-related patents were identified using the International Patent Classification (IPC) and Cooperative Patent Classification (CPC) codes. A collated list of AI-related codes was compiled through AI model analysis, regex-based searches, and previous studies, including classifications from Pairolero et al. (2023) and WIPO (2024). The final dataset was constructed by merging the results of the two methods, taking into account both coverage and accuracy.
Epoch Signature Model Analysis
Epoch AI, an AI prediction research group, maintains a dataset that includes landmark AI and machine learning models, as well as appendices about these appendices
Chapter 1: Research and Development
1. Despite this aggregation procedure, there are occasional duplicates in the marginal case where applications in the same DOCDB family have the same earliest filing date. When the AI Index is analyzed, duplicate values related to summary variables, such as by year, are removed. Artificial intelligence in 2025
Index Report
Table of Contents Appendix 418 Information about model creators and paper statistics, such as author lists, citations,
The type of AI task completed and the amount of computation used in training. The nationality of the authors of these papers has an important impact on AI geopolitical predictions. As various research institutes and technology companies begin to produce advanced machine learning, the global distribution of AI development is likely to shift or concentrate in certain locations, which in turn will affect the geopolitical landscape, as AI is expected to become an important part of economic and military power in the near future.
In order to track the distribution of AI research contributions in each country in terms of landmark papers
In this case, the Epoch era dataset is encoded as follows:
1. The dataset was intercepted in March 2025. These include papers on milestone models, which were screened based on inclusion criteria such as importance, relevance, and uniqueness as described in the "Calculating Trends" dataset document. 2. The author's country is subject to the affiliation indicated in the paper. In the case of international organizations, the author is attributed to the country where the organization's headquarters are located, unless a more specific location is indicated. 3. All landmark paper statistics are aggregated over a time period (e.g., monthly or annual) and a compilation of countries' contributions is made to determine the extent to which each country contributed to landmark AI research in each time period.
4. Compare the contributions of different countries over time to identify any trends.
Training cost analysis
To create the cost estimation dataset, Epoch Database filtered the models released in the era of large-scale machine learning 2 that ranked in the top 10 in terms of training computation at the time of publication. This results in the largest scale machine learning. Transformer models are added to this set of models for further context. appendix
Chapter 1: Research and Development
2. According to Compute Trends Across Three Eras of Machine Learning (Epoch, 2022), the selected deadline is September 1, 2015.
3. Historical prices are from archived snapshots of Amazon Web Services, Microsoft Azure, and Google Cloud Platform price catalogs, which can be viewed through the Internet Archive Wayback Machine. 4. The selected rental rate is the latest published price of the hardware and cloud provider used by the model developer, calculated based on the three-year commitment rental rate, minus the training time and two months after the published date. If that price is not available, use the most similar price—either the same hardware and vendor for different dates, or the same hardware for different cloud vendors. If there is no three-year commitment tenancy rate, the average discount based on the experience of a given cloud vendor is extrapolated from other tenancy rates. If you don't have the exact type of hardware, such as Nvidia A100 SXM4 40GB, then use a generic type, such as Nvidia A100. For the selected machine learning, its training time, type, quantity, and hardware usage are all available
Determined from publications, press releases, or technical reports, as applicable. The cloud rental prices for the computing hardware used by these models are collected from the online history archives of the cloud provider's website.
3  
The cost of training is estimated based on the type of hardware, volume, and time by combining the hourly cloud fee (at the time of training)
4 times the number of hardware hours. However, there are developers
Hardware is purchased instead of renting cloud computing, and cloud computing prices vary by vendor and rental commitment, so the true cost to developers can vary.
There are various encounters in estimating the training cost of these modelsChallenge. Normally,
The developer will not disclose the training time or the hardware used. In other cases, the cloud computing price of the hardware is not available. A survey of training cost trends is described in more detail in another report by Epoch AI.
The scale of participation in the AI conference
The AI Index reached out to the organizers of various AI academic conferences in 2024 to ask them for information on the total attendance. For meetings where the total attendance was published online, the AI Index used the total number of people reported by these reports without contacting the conference organizers.
GitHub
Identify AI project GitHub collaboration with researchers from Harvard Business School, Microsoft Research, and Microsoft AI Pro Bono Lab to identify public AI repositories following the methods of Gonzalez, Zimmerman, and Nagappan (2020) and Dohmke, Iansiti, and Richards (2023), using hashtags related to AI/ML generative AI, respectively,  and other relevant concerns identified by snowball sampling on 2025 artificial intelligence
Index Report
Table of Contents Appendix 419 keywords, such as "machine learning", "deep learning", and "artificial intelligence". GitHub passed
The dataset is further enriched by repositories that rely on Python's PyTorch, TensorFlow, OpenAI, Transform-ers, XGBoost, scikit-learn, and SciPy libraries.
Map AI projects to geographic regions
Public AI projects map to geographic areas via IP address geolocation to determine the model location of the project owner each year. Each project owner is assigned a location based on their IP address when they interact with GitHub. If the project owner changes locations within a year, the location of the project will be determined by the pattern location of the owner who samples each day during the year. In addition, even if the project owner does not perform any activities, the last known location of the project owner is carried forward on a daily basis. If the project owner has an activity in the U.S. and then no activity is carried out for six days, then the project owner will be considered to be in the U.S. for those seven days.
Environmental impact analysis
The AI Index estimates the carbon emissions of training language and vision models using a calculator proposed in 2019. The analysis focuses on emissions from the training phase and excludes emissions from hardware production, idle infrastructure, and deployment. The study examines four types of models: industrial language models, academic language models, industrial vision models, and academic vision models.
The accuracy of the calculator has been verified against published emission values. Calculator to lose
This includes hardware type, graphics processor hours, provider, and compute region. For newer hardware, such as the H100 graphics processor (released in 2022), the A100 SXM4 80GB is used as an alternative in computing. Provider selection is based on known partnerships (e.g., Google models use GCP, OpenAI uses Azure), and compute regions are determined by where the team is located.
Particular consideration was given to models trained on custom hardware, such as the Jean Zay supercomputer used by BLOOM in France. In these cases, the calculation of private infrastructure
Carbon efficiency (kg/kWh) and offset percentages are included.
A total of 50 models were evaluated in the study: 34 industry language models (2018-24 
8 industry vision models (2019-23), 4 academic language models
(2020-23) and 4 Academic Vision Models (2011-22) and selected
Models that have a particular influence in their respective fields. appendix
Chapter 1: Research and Development of Artificial Intelligence in 2025
Index Report
Table of Contents Appendix 420 Appendix
Chapter 2: Technical Performance
Chapter 2: Technical Performance
Thanks
Artificial Intelligence Index would like to thank Andrew Shi (responsible for generating Midjourney and Pika video production samples) and Armin Hamrah (who tasked with combing through the timeline of major technological advances in artificial intelligence).
Benchmarks
In this chapter, the AI Index reports on benchmarks, acknowledging the importance of benchmarks in tracking AI technological advancements. As a standard practice, indexes derive benchmark scores from leaderboards, public repositories such as Papers With Code and RankedAGI, as well as company papers, blog posts, and product launches. The index operates on the premise that the scores reported by companies are accurate and truthful. The baseline scores in this section are current as of mid-February 2025. However, since the release of the AI Index, it is possible that newer models have been released to surpass the current state-of-the-art scores.
1. ARC-AGI Artificial General Intelligence: Data on ARC-AGI taken from the February 2025 ARC-AGI paper and OpenAI video. To learn more about ARC-AGI, read the original article. 2. Arena-Hard-Auto: The data for Arena-Hard-Auto is from the LMSYS leaderboard in February 2025. To learn more about Arena-Hard-Auto, read the original article. 3. Bench2Drive: Data on Bench2Drive taken from the February 2025 Bench2Drive paper To learn more about Bench2Drive, read the original article. 4. Berkeley Function Calls: Data about Berkeley function calls is taken from
In February 2025, the Berkeley function called leaderboard. To learn more about Berkeley function calls, read the original book. 5. BigCodeBench: Data about BigCodeBench is taken from the February 2025 BigCodeBench leaderboard. To learn more about BigCodeBench, read the original. 6. Chatbot Arena: Data on Chatbot Aren is taken from the Chatbot Arena Leaderboard as of February 2025. To learn more about Chatbot Arena, read the original article. 7. FrontierMath: The data about FrontierMath comes from the FrontierMath paper and OpenAI video. To learn more about FrontierMath, read the original article. The visuals are complemented by benchmark data for the o 3 model of O p e n A I from a YouTube video announcing the launch of the model in December 2025. 8.GAIA: Data on GAIA are taken from the GAIA leaderboard in February 2025. To learn more about GAIA, read the original article. 9. GPQA: The data on GPQA comes from the 2025 2GPQA paper and OpenAI video. To learn more about GPQA, read the original article. 10. GSM8K: Data on GSM8K taken from the February 2025 issue of GSM8K Papers With Code leaderboard. To learn more about GSM8K, read the original article. 11. HELMET: DATA ON HELMET (HOW TO EFFECTIVELY AND THOROUGHLY EVALUATE LONG CONTEXT MODELS) IS TAKEN FROM THE FEBRUARY 2025 HELMET PAPER. To learn more about HELMET, read the original article. 12. HLE: Data on HLE is taken from the February 2025 HLE paper. To learn more about HLE, read the original article. 13. HumanEval: Data on HumanEval from the February 2025 issue of HumanEval Papers With Code leaderboard. To learn more about HumanEval, read the original article. 14. LRS2: Oxford-BBC Lip Reading Sentences 2025 Artificial Intelligence
Index Report
Table of Contents Data for Appendix 42115.2 (LRS2) were taken from 2 0 2 5 February LRS2 Papers With 
Code leaderboard。 To learn more about LRS2, read the original article.
16. MATH: Data on MATH is taken from MATH in February 2025 
Papers With Code leaderboard and o3-mini model launch. To learn more about MATH, read the original article.
17. MixEval: Data on MixEval is taken from February 2025
MixEval leaderboard。 To learn more about MixEval, read the original article.
18. MLU: Data on MLU is taken from the February 2025 MMLU 
Papers With Code leaderboard To learn more about MLU, read the original article.
19. MMLU-Pro: Data on MMLU-Pro is taken from 20252
Month MMLU-Pro leaderboard. To learn more about MMLU-Pro, read the original article.
20. MMMU: Data on MMMU is taken from February 2025
MMMU leaderboard。 To learn more about MMMU, read the original article.
21. MTEB: Data fetch for the Massive Text Embedding Baseline (MTEB).
As of February 2025 MTEB leaderboard. To learn more about MTEB, read the original article.
22. MVBench: Data on MVBench is taken from February 2025 
MVBench leaderboard To learn more about MVBench, read the original article.
23. PlanBench: Data on PlanBench is taken from 20252
PlanBench paper. To learn more about PlanBench, read the original article.
24. RE-Bench: Data for RE-Bench is taken from February 2025
RE-  Bench paper。 To learn more about RE-Bench, read the original article.
25. RLBench: Data on RLBench is from February 2025
The RLBench Papers With Code leaderboard. To learn more about RLBench, read the original article.
26. Ruler data on Ruler is taken from the February 2025 Ruler Database
Source library. To learn more about Ruler, read the original article. 27. SWE-bench: Data on SWE-bench is taken from 2025
SWE-benchleaderboard in February. To learn more about SWE-
For more information on bench, please read the original article.
28. VAB: Data on the VisualAgentBench (VAB) taken from the February 2025 VAB leaderboard. To learn more about VAB, read the original article. 29. VCR: Data on VCR taken from the VCRleaderboard of February 2 0 2 5. To learn more about VCR, read the original article. 30. WildBench: Data about WildBench taken from the February 2025 WildBench leaderboard To learn more about WildBench, read the original article. appendix
Chapter 2: Technical Performance 2025 Artificial Intelligence
Index Report
Table of Contents Appendix 422 Cited Works
Akter, S. N., Yu, Z., Muhamed, A., Ou, T., Bäuerle, A., Cabrera, Á. A., Dholakia, K ., Xiong, C., & Neubig, G. (2023). A n In-Depth Look 
at Gemini’s Language Abilities (arXiv:2312.11444). arXiv. https://doi.org/10.48550/arXiv.2312.11444
Bairi, R., Sonwane, A., Kanade, A., C, V. D., Iyer, A., Parthasarathy, S., Rajamani, S., Ashok, B., & Shet, S. (2023). CodePlan: Reposi-
tory-Level Coding Using LLMs and Planning  (arXiv:230 9.12499). arXiv. https://doi.org/10.48550/arXiv.2309.12499
Bauza, 
M., Chen, J. E., Dalibard, V., Gileadi, N., Hafner, R., Martins, M. F., Moore, J., Pevceviciute, R., Laurens, A., Rao, D., Zambelli, 
M., Riedmiller, 
M., Scholz, J., Bousmalis, K., Nori, F., & Heess, N. (2024). DemoStart: Demonstration-Led Auto-Curriculum Applied 
to Sim-to-Real With Multi-ﬁngered Robots (arXiv:2409.06613). arXiv. https://doi.org/10.48550/arXiv.2409.06613
Bommasani, R., Kapoor, S., Klyman, K., Longpre, S., Ramaswami, A., Zhang, D., Schaake, M., Ho, D. E., Narayanan, A., & Liang, P. 
(2024 ). “Considerations for Governing Open Foundation Models.” Science, 386(6718), 151–53. https://doi.org/10.1126/-
science.adp1848
Brohan, A., Brown, N., Carbajal, J., Chebotar, Y., Chen, X., Choromanski, K., ... & Zitkovich, B. (2023). RT-2: Vision-LanguageAc-
tion Models Transfer Web Knowledge to Robotic Control.  (arXiv:2307.15818). arXiv. https://arxiv.org/abs/2307.15818
Budagam, D., 
Kumar, A., Khoshnoodi, M., KJ, S., Jain, V., & Chadha, A. (2024). Hierarchical Prompting Taxonomy: A Universal 
Evaluation Framework 
for Large Language Models Aligned With Human Cognitive Principles (arXiv:2406.12644; Version 4). arXiv. 
https://doi.org/10.48550/arXiv.2406.12644
Cao, Z., Long, M., Wang, J., & Yu, P. S. (2017). HashNet: Deep Learning to Hash by Continuation (arXiv:1702.00758). arXiv. 
https://doi.org/10.48550/arXiv.1702.00758
Chen, M., Tworek, J., Jun, H., Yuan, Q., Pinto, H. P. de O., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., 
Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., … Zaremba, W. (2021). Evaluating Large Lan-
guage Models Trained on Code  (arXiv:2107.03374). arXiv. https://doi.org/10.48550/arXiv.2107.03374
Chiang, W.-L., 
Zheng, L., Sheng, Y., Angelopoulos, A. N., Li, T., Li, D., Zhang, H., Zhu, B., Jordan, M., Gonzalez, J. E., & Stoica, I. 
(2024). Chatbot Arena: An O pen Platform for Evaluating LLMs b y Human Pref erence (arXiv :2403.04132). arXiv. https://doio-
rg/10.48550/a rXiv.2403.0413 2
Chollet, F., Knoop, M., Kamradt, G., & Landers, B. (2025). ARC Prize 2024: Technical Report  (arXiv:2412.04604). arXiv. https://doi.  
org/10.48550/arXiv.2412.04604
Chung, J. S., Senior, A., Vinyals , O., & Zisser man, A. (2017).“ Lip Re ading Sentences  in the Wild .” 2017 IEEE Conference o n Com-
puter Vision and Pattern Recognition (CVPR), 3444–53. https://doi.org/10.1109/CVPR.2017.367附录
第二章：技术性能2025年人工智能
指数报告
Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano, R., Hesse, C., & 
Schulman, J. (2021). Training Veriﬁers to Solve Math Word Problems (arXiv:2110.14168). arXiv. https://doi.org/10.48550/arX-
iv.2110.14168 
Driess, D., Xia, F., Sajjadi, M. S. M., Lynch, C., Chowdhery, A., Ichter, B., Wahid, A., Tompson, J., Vuong, Q., Yu, T., Huang, W., 
Chebotar, Y., Sermanet, P., Duckworth, D., Levine, S., Vanhoucke, V., Hausman, K., Toussaint, M., Greﬀ, K., … Florence, P. (2023). 
PaLM-E: An Embo died Multimodal Language Model (arXiv:230 3.03378). arXiv. https://doi.org/10.48550/arXiv.2303.03378
Fang, H., Grotz, M., Pumacay, W., Wang, Y. R., Fox, D., Krishna, R., & Duan, J. (2025). SAM2Act: Integrating Visual Foundation 
Model With a Memory Architecture for Robotic Manipulation (arXiv:2501.18564). arXiv. https://doi.org/10.48550/arXiv.2501.18564
Fattorini, L., Maslej, N., Perrault, R., Parli, 
V., Etchemendy, J., Shoham, Y., & Ligett, K. (2024). The Global AI Vibrancy Tool (arX-
iv:2412.04486 ). arXiv. https://doi.org/10.48550/arXiv.2412.04486
Glazer, 
E., Erdil, E., Besiroglu, T., Chicharro, D., Chen, E., Gunning, A., Olsson, C. F., Denain, J.-S., Ho, A., Santos, E. de O., Jär-
viniemi, O., 
Barnett, M., Sandler, R., Vrzala, M., Sevilla, J., Ren, Q., Pratt, E., Levine, L., Barkley, G., … Wildon, M. (2024). Frontier-
Math: A 
Benchmark for Evaluating Advanced Mathematical Reasoning in AI  (arXiv:2411.04872). arXiv. https://-
doi.org/10.4855 0/arXiv.2411.048 72
Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., & Steinhardt, J. (2021). Measuring Massive Multitask Language 
Understanding (arXiv:2009.03 300). arXiv. https://doi.org/10.48550/arXiv.2009.03300
Hendrycks, D., Burns, C., Kadavath, S., Arora, A., Basart, S., 
Tang, E., Song, D., & Steinhardt, J. (2021). Measuring Mathematical 
Problem Solving With the MATH Dataset (arXiv:2103.03874). arXiv. https://doi.org/10.48550/arXiv.2103.03874
Hsieh, C.-P., Sun, S., Kriman, S., Acharya, S., Rekesh, D., Jia, F., Zhang, Y., & Ginsburg, B. (2024). RULER: What’s the Real Context 
Size of Your Long-Context Language Models? (arXiv:240 4.06654) . arXiv. https://doi.org/10.48550/arXiv.2404.06654
Huang, Q., Vora, J., Liang, P., & Leskovec, J. (2024). MLAgentBench: Evaluating Language Agents on Machine Learning Experi-
mentation (arXiv:2310.03302) . arXiv. https://doi.org/10.48550/arXiv.2310.03302
Islam, P., Ka nnappan, A., Kie la, D., Qian, R., S cherrer, N., & Vidgen, B. (2023) . Finance Bench: A New Benchmark for Financia l 
Question Answering (arXiv:2311 .11944). arXiv. https://doi.org/10.48550/arXiv.2311.11944
James, S., Ma, Z., Arrojo , D. R., & Davison, A. J. (2019). RLBench: The Robot Learning Benchmark & Learning Environment  (arX-
iv:1909.1227 1; Version 1). arXiv. https://doi.org/10.48550/arXiv.1909.12271
Jia, X., Yang, Z., Li, Q., Zhang, Z., & Yan, J. (2024). Bench2Drive: Towards Multi-ability Benchmarking of Closed-Loop 
End-to-End Autonomous Driving (arXiv:2406.03877). arXiv. https://doi.org/10.48550/arXiv.2406.03877
目录 附录 423附录
第二章：技术性能2025年人工智能
指数报告
Jimenez, C. E., Yang, J., Wettig, A., Yao, S., Pei, K., Press, O., & Narasimhan, K. (2024). SWE-bench: Can Language Models Re-
solve Real-World GitHub Issues? (arXiv:2310.06770). arXiv. https://doi.org/10.48550/arXiv.2310.06770
Jones, C. R., & Bergen, B. K. (2 024). People Cannot Distinguish GPT-4 From a Human in a Turing Test  (arXiv:2405.08007). arXiv. 
https://doi.org/10.48550/arXiv.2405.08007 
Karnchanach ari, N., Geromichalos, D., Tan, K. S., Li, N., Eriksen, C., Yaghoubi, S., Meh-d ipour, N., Bernasconi, G., Fong, W. K., 
Guo, Y., & Caesar, H. (2024). Towards Learning-Based Planning: The nuPlan Benchmark for Real-World Autonomous Driving  
(arXiv:2403.04133). arXiv. https://doi.org/10.48550/arXiv.2403.04133
Kusupati, A., Bhatt, G., Rege, A., Wallingford, M., Sinha, A., Ramanujan, V., Howard-Snyde r, W., Chen, K., Kakade, S., Jain, P.,& 
Farhadi, A. (20 24). Matryoshka  Representatio n Learning (arXiv:2205.13147). arXiv. https://doi.org/10.48550/arXiv.2205.13147
Leal, I., Choromanski, K., Jain, D., Dubey, A., Varley, J., Ryoo, M., Lu, Y., Liu, F., Sindhwani, V., Vuong, Q., Sarlos, T., Oslund, K., 
Hausman, 
K., & Rao, K. (2023). SARA-RT: Scaling Up Robotics Transformers With Self-Adaptive Robust Attention (arX-
iv:2312.01990 ). arXiv. https://doi.org/10.48550/arXiv.2312.01990
Li, K., Wang, Y., He, Y., Li, Y., Wang, Y., Liu, Y., Wang
, Z., Xu, J., Chen, G., Luo, P., Wang, L., & Qiao, Y. (2024). M VBench: A Com-
prehensive Multi-modal Video Understanding Benchmark  (arXiv:2311.17005). arXiv. https://doi.org/10.48550/arXiv.2311.17005
Li, T., Chiang, W.-L., Frick, E., Dunlap, L., Wu, T., Zhu, B., Gonzalez, J. E., & Stoica, I.  (2024). From Crowdsourced Data to High-
Quality Benchmarks: Arena-Hard and BenchBuilder Pipeline  (arXiv:240 6.11939). arXiv. https://doi.org/10.48550/arXiv.2406.11939
Li, 
X., Mata, C., Park, J., Kahatapitiya, K., Jang, Y. S., Shang, J., Ranasinghe, K., Burgert, R., Cai, M., Lee, Y. J., & Ryoo, M. S. 
(2025). LLaRA: Supercharging Robot Learning Data for Vision-Language Policy (arXiv:2406.20095). arXiv. https://-
doi.org/10.4855 0/arXiv.2406.20095
Liu, 
X., Yu, H., Zhang, H., Xu, Y. , Lei, X., Lai, H., Gu, Y., Ding, H., Men, K., Yang, K., Zhang, S., Deng, X., Zeng, A., Du, Z., Zhang, C., 
Shen, S., Zhang, T., Su, Y., Sun, H., … Tang, J. (2023). AgentBench: Evaluating LLMs as Agents (arXiv:2308.03688). arXiv. 
https://doi.org/10.48550/arXiv.2308.03688
Liu, X., Zhang, T., Gu, Y., Iong, I. L., Xu, Y., Song, X., Zhang, S., Lai, H., Liu, X., Zhao, H., Sun, J., Yang, X., Yang, Y., Qi, Z., Yao, S., 
Sun, X., Cheng, S., Zheng,  Q., Yu, H., … Tang, J. (2024). VisualAge ntBench: To wards Large Multimodal Models as Visual Founda-
tion Agents (arXiv:2408.06327 ). arXiv. https://doi.org/10.48550/arXiv.2408.06327
Mialon, G., Fourrier, C., Swift, C., Wolf, T ., LeCun, Y., & Scialom, T. (2023). GAIA: A Benchmark for General AI Assistants 
(arXiv:2311.1 2983). arXiv. https://doi.org/10.48550/arXiv.2311.12983
Mitchell, M. (2 024). “The Turing Test and Our Shifting Concep-t ions of Intelligence.” Science, 385(6710), eadq9356. https://
www.science.o rg/doi/10.1126/science.adq9356
Muennighoﬀ, N., Tazi, N., Magne, L., & Reimers, N. (2023). MTEB: Massive Text Embedding Benchmark (arXiv:2210.07316). arXiv. 
https://doi.org/10.48550/arXiv.2210.07316
目录 附录 424附录
第二章：技术性能2025年人工智能
指数报告
Ni, J., Xue, F., Yue, X., Deng, Y., Shah, M., Jai n, K., Neubig, G., & You, Y. (2024). MixEval: Deriving Wisdom of the Crowd From LLM 
Benchmark Mixtures (arXiv:2406.06565). arXiv. https://doi.org/10.48550/arXiv.2406.06565
O’Neill, A., Rehman, A., Gupta, A., Maddukuri, A., Gupta, A., Padalkar, A., Lee, A., Pooley, A., Gupta, A., Mandlekar, A., Jain, A., Tung, 
A., Bewley, 
A., Herzog, A., Irpan, A., Khazatsky, A., Rai, A., Gupta, A., … Lin, Z. (2024). Open X-Embodiment: Robotic Learning 
Datasets and RT-X Models  (arXiv:2310.08864) . arXiv. https://doi.org/10.48550/arXiv.2310.08864
Phan, L., Gatti, A., Han, Z., Li, N., Hu, J., Zhang, H., Zhang, C. B. C., Shaaban, M., Ling, J., Shi, S., Choi, M., Agrawal, A., Chopra, A., 
Khoja, A., 
Kim, R., Ren, R., Hausenloy, J., Zhang, O., Mazeika, M., … Hendrycks, D. (2025). Humanity’ s Last Exam  (arX-
iv:2501.14249 ). arXiv. https://doi.org/10.48550/arXiv.2501.14249
Rein, D., Hou, B. L., Stickland, A. C., Petty, J., Pang, R
. Y., Dirani, J., Michael, J., & Bowman, S. R. (2023). GPQA: A Graduate-Level 
Google-Proof Q&A Benchmark (arXiv:2311.12022) . arXiv. https://doi.org/10.48550/arXiv.2311.12022
Reuel, A., Hardy, A., Smith, C., Lamparth, M., Hardy, M., & Kochenderfer, M. J. (2024). BetterBench: Assessing AI Benchmarks, 
Uncovering Issues, and Establishing Best Practices  (arXiv:2411.12990). arXiv. https://doi.org/10.48550/arXiv.2411.12990
Turing, A. M. (2009). Computing Machinery and Intelligence. In Epstein, R., Roberts, G., & Beber, G., eds., Parsing the Turing Test: 
Philosophical and Methodological Issues in the Quest for the Th
inking Computer (23–65). Springer Netherlands. https://-
doi.org/10.1007 /978-1-4020-6710-5_3
Valmeekam, K., Stechly, K., & Kambhampati, S. (2024). LLMs Still Can’ t Plan; Can LRMs? A Preliminary Evaluation of OpenAI’ s o1 
on PlanBench  (arXiv:24 09.13373). arXiv. https://doi.org/10.48550/arXiv.2409.13373
Wijk, H., 
Lin, T., Becker, J., Jawhar, S., Parikh, N., Broadley, T., Chan, L., Chen, M., Clymer, J., Dhyani, J., Ericheva, E., Garcia, K., 
Goodrich, 
B., Jurkovic, N., Kinniment, M., Lajko, A., Nix, S., Sato, L., Saunders, W., … Barnes, E. (2024). RE-Bench: Evaluating 
Frontier AI 
R&D Capabilities of Language Model Agents Against Human Experts (arXiv:2411.15114). arXiv. https://-
doi.org/10.4855 0/arXiv.2411.151 14
Xia, Z., Li, J., Lin, Z., Wang, X., Wang, Y., & Yang, M.-H. (2024). OpenAD: Open-Wo rld Autonomous Driving Benchmark for 3D 
Object Detection  (arXiv:2411.17761). arXiv. https://doi.org/10.48550/arXiv.2411.17761
Xu, C., Guan, S., Greene, D., & Kechadi, M.-T. (2024). Benchmark Data Contamination of Large Language Models: A Survey 
(arXiv:2406.04244) . arXiv. https://doi.org/10.48550/arXiv.2406.04244
Yang, X., Sun, K., Xin, H., Sun, Y., Bhalla, N., Chen, X., Choudhary, S., Gui, R. D., Jiang, Z. W., Jiang, Z., Kong, L., Moran, B., 
Wang, J., Xu, Y. E., Yan, A., Yang, C., Yuan, E., Zha, H., Tang, N., … Dong, X. L. (2024). CRAG—Comprehensive RAG Benchmark  
(arXiv:2406.0 4744). arXiv. https://doi.org/10.48550/arXiv.2406.04744
Yen, H., Gao, T., Hou, M., Ding, K., Fleischer, D., Izsak, P., Wasserblat, M., & Chen, D. (2025). HELMET: How to Evaluate LongCon-
text Language Models Eﬀectively and Thoroughly (arXiv:2410.02694). arXiv. https://doi.org/10.48550/arXiv.2410.02694
目录 附录 425附录
第二章：技术性能2025年人工智能
指数报告
Yue, X., Ni, Y., Zhang, K., Zheng, T., Liu, R., Zhang, G., Stevens, S., Jiang, D., Ren, W., Sun, Y., Wei, C., Yu, B., Yuan, R., Sun, R., Yin, 
M., Zheng, 
B., Yang, Z., Liu, Y., Huang, W., … Chen, W. (2024). MMMU: A Massive Multi-discipline Multimodal Understanding and 
Reasoning Benchmark for Expert AGI (arXiv:2311.16502). arXiv. https://doi.org/10.48550/arXiv.2311.16502 
Zellers, R., Bisk, Y., Far-h adi, A., & Choi, Y. (2019). From Recognition to Cognition: Visual Commonsense Reasoning  
(arXiv:1811.10830). arXiv. https://-d oi.org/10.48550/arXiv.1811.10830
Zhang, H., Da, J., Lee, D., Robinson, V., Wu, C., Song, W., Zhao, T., Raja, P., Zhuang, C., Slack, D., Lyu, Q., Hendryx, S., Kaplan, 
R., Lunati, M., & Yue, S. (2024). A Careful Examination of Large Language Model Performance on Grade School Arithmetic  
(arXiv:2405.0 0332). arXiv. https://doi.org/10.48550/arXiv.2405.00332
目录 附录 426附录
第二章：技术性能2025年人工智能
指数报告附录
第三章：  负责任的人工智能
目录 附录 427第三章： 负责任的人工智能
致谢
人工智能指数谨此致谢Andrew Shi在负责任的人工智能相关
会议报告分析方面所做的工作。 人工智能指数承认 "全球负责任的人工智能状况 "分析是与埃森哲合作进行的。 人工智能指数特别强调了埃森哲Chief Responsible AI Oﬃcer ，Arnab Chakraborty，以及埃森哲研究团队（包括Patrick Connolly、Jakub Wiatrak、Dikshita Venkatesh和Shekhar Tewari）在数据收集和分析方面做出的贡献。 人工智能指数谨此致谢麦肯锡团队（特别是 Medha Bankhwal、Emily Capstick、Katherine Ottenbreit、Brittany Presten、Roger Roberts 和 Cayla Volandes）在负责任的人工智能生态系统调查中的合作。
会议材料分析
关于负责任的人工智能相关会议论文的分析，人工智能指数研究了以下会议中负责任的人工智能相关的数量：AAAI, AIES,FAccT, ICML,ICLR, 和 NeurIPS。 具体来说，团队从会议网站或会议投稿库中搜索包含相关关键字的论文，这些关键字表明这些论文可能属于特定的负责任的人工智能类别。 然后，由一个人工团队对论文进行人工验证，以确认其分类。 一篇论文有可能属于多个负责任的人工智能类别。
搜索的关键词包括
公平与偏见：algorithmic fairness, bias detection, bias mitiga-
tion, discrimination, equity in AI, ethical algorithm design, fair data practices, fair ML, fairness and bias, group fairness, individual fairness, justice, nondiscrimination, representational fairness, unfair, unfairness.隐私和数据管理：anonymity, conﬁdentiality,data breach, data ethics, data governance, data integrity, data privacy, data protection, data transparency, diﬀerential privacy, inferencepri-vacy, machine unlearning, privacy by design, privacy-preserv-ing, secure data storage, trustworthy data curation.
安全：adversarial attack, adversarial learning, AI incident, 
attacks, audits, cybersecurity, ethical hacking, forensic analysis, fraud detection, red teaming, safety, security, security ethics, threat detection, vulnerability assessment.
透明度和可解释性： algorithmic transparency, audit, auditing, 
causal reasoning, causality, explainability, explainable AI, 
explainable models, human-understandable decisions, inter-pretability, interpretable models, model explainability, outcome explanation, transparency, xAI.
埃森哲全球负责任的人工智能状况
调查
斯坦福大学的研究人员与埃森哲公司合作进行第二次 "全球负
责任的人工智能状况 "调查。 调查收集了来自 20 个国家和 19 个行业的 1,500 家企业的回复，每家企业的总收入至少为 5 亿美元。 调查于 2025 年 1 月至 2 月进行。 负责任的人工智能全球状况调查的目的是了解采用 RAI 原则和实践所面临的挑战，并对组织和运营 RAI 活动的 10 个方面进行长期比较。
调查共涉及 10 个 RAI 维度：可靠性、隐私和数据管理、公平
和非歧视、透明度和可解释性、人际互动、社会和环境福祉、问责制、领导力/原则/文化、合法性和合规性以及组织管理。 有关该方法的详细信息，请访问这里 。 2025年人工智能
指数报告
目录 附录 428附录
第三章： 负责任的人工智能
麦肯锡负责任的人工智能调查
麦肯锡公司最近对 38 个国家的  750 多位领导者进行了调查，
深入了解了企业  RAI 的现状。 这些领导者代表了从技术到医疗
保健等各行各业， 包括法律、 数据 / 人工智能、 工程、 风险和财
务领域的专业人士。 麦肯锡  RAI 成熟度模型是一个负责任的人
工智能框架， 包含  RAI 的四个维度——战略、 风险管理、 数据和
技术以及运营模式——以及 21 个子维度。 RAI  成熟度分为四
个等级， 从开发基础 RAI 实践到全面、 积极的计划。 2025年人工智能
指数报告
引用作品
Alanazi, S., & Asif, S . (2024). “Exploring Deepfake Technology: Creation, Consequences and Countermeasures.” Human- Intelli-
gent Systems Integration , 6(1), 49–60. https://doi.org/10.1007/s42454-024-00054-8
Bai, X., Wan g, A., Sucholutsky, I., & Grifths, T. L. (2024). Measuring Implicit Bias in Explicitly Unbiased Large Language Models
(arXiv:2402.0 4105). arXiv. https://doi.or g/10.48550/arXiv.2402.04105
Birhane, A., Dehdashtian, S., Prabhu, V. U., & Bod deti, V. (2024). “The Dark Side of Dataset Scaling: Evaluating Racial Classifcation 
in 
Multimodal Models.” The 2024 ACM Conference on Fairness, Accountability, and Transparency , 1229–44. https://doi. 
org/10.1145/ 3630106.3658 968
Bommasani, R., Klyman, K., Kapoor, S., Longpre, S., Xiong, B., Maslej, N., & Liang, P. (2025). The 2024 Foundation Model Trans-
parency Index (arXiv:2407.129 29). arXiv. https://doi.org/10.48550/arXiv.2407.12929
Gabriel, I., Manzini, A., Keeling, G., Hendricks, L. A., Rieser, V., Iqbal, H., Tomaš ev, N., Ktena, I., Kenton, Z., Rodriguez, M., El- Sayed, 
S., Brown, S., Akbulut, C., Trask, A., Hughes, E., Bergman, 
A. S., Shelby, R., Marchal, N., Grifn, C., … Manyika, J. (2024). The Ethics 
of Advanced AI Assistants (arXiv:2404.16244). arXiv. https://doi.org/10.48550/arXiv.2404.16244
German i, F., Spitale, G., & Biller-Andorno, N. (2024). The Dual Nature of AI in Information Dissemination: Ethical Considerations . 
Jmir Ai, 3, e535 05. https://doi.org/10.2196/53505
Gu, X., Zheng, X., Pang, T., Du, C., Liu, Q., Wang, Y., Jiang, J., & Lin, M. (2024). Agent Smith: A Single Image Can Jailbreak One 
Million Multimodal LLM Agents Exponentially Fast  (arXiv:2402.08567). arXiv. https://doi.org/10.48550/arXiv.2402.08567
Lafer, J., & Rehman, A. (2023). “Deepfakes and Harm to Women.” Journal of Digital Life and Learning , 3(1), Article 1. https://doi. 
org/10.51357/jdll.v3i1.218
Li, J., Cheng, X., Zhao, W. X., Nie, J.-Y., & Wen, J.-R. (2023). HaluEval: A Large-Scale Hallucination Evaluation Benchmark for 
Large Language Models  (arXiv:2305.11747). arXiv. https://doi.org/10.48550/arXiv.2305.11747
Liebowitz, J., ed. (2024). Regulating Hate Speech Created by Generative AI. Auerbach Publications . https://doi. 
org/10.1201/ 9781032654829
Lin, S., Hilton, J., & Evans, O. (2022). TruthfulQA: Measuring How Models Mimic Human Falsehoods (arXiv:2109.07958). arXiv. 
https://doi.org/10.48 550/arXiv.210 9.07958
Longpre, S., Mahari, R., Chen, A., Obeng-Marnu, N., Sileo, D., Brannon, W., Muennighof, N., Khazam, N., Kabbara, J., Perisetla, K., 
Wu, X., 
Shippole, E., Bollacker, K., Wu, T., Villa, L., Pentland, S., & Hooker, S. (2023). The Data Provenance Initiative: A Large Scale 
Audit of Dataset Licensing and Attribution in AI  (arXiv: 2310.16787). arXiv. https://doi.org/10.48550/arXiv.2310.16787
Longpre, S., Mahari, R., Lee, A., Lund, C., Oderinwale, H., Brannon, W., Saxena, N., Obeng-Marnu, N., South, T., Hunter, C., Klyman, 
K., Klamm, C., Schoelkopf, H., Singh, N., Cherep, M., Anis, A., Dinh, A., Chitongo, C., Yin, D., … Pentland, S. (2024). Consent in 
Crisis: The Rapid Decline of the AI Data Commons (arXiv:240 7.14933) . arXiv. https://doi.org/10.48550/arXiv.2407.14933
目录 附录 429附录
第三章：  负责任的人工智能2025年人工智能
指数报告
Mazeika, M., P han, L., Yin, X., Zou, A., W ang, Z., Mu, N ., Sakh aee, E., Li, N., Bas art, S. , Li, B., Forsyth , D., & Hend rycks, D. (2024a). 
HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal  (arXiv:2402.04249). arXiv. 
https://doi.org/10.48550/arXiv.2402.04249
Parrish, A., Chen, A., Nangia, N., Padmakumar, V., Phang, J., Thompson, J., Htut, P. M., & Bowman, S. R. (2022). BBQ: A Hand- 
Built Bias Benchmark for Question Answering  (arXiv:2110.08193). arXiv. https://doi.org/10.48550/arXiv.2110.08193
Qi, X., Panda, A., Lyu, K., Ma, X., Roy, S., Beirami, A., Mittal, P., & Henderson, P. (2024). Safety Alignment Should Be Made More 
Than Just a Few Tokens Deep  (arXiv:2406.05946). arXiv. https://doi.org/10.48550/arXiv.2406.05946
Reuel, A., Connolly, P., Meimandi, K. J., Tewari, S., Wiatrak, J., Venkatesh, D., & Kochenderfer, M. (2024). Respo nsible AI in the 
Global Context: Maturity Model and Survey (arXiv:2410.09985). arXiv. https://doi.org/10.48550/arXiv.2410.09985
Röttger, P., Kirk, H. R., Vidgen, B., Attanasio, G., Bianchi, F., & Hovy, D. (2024). XSTest: A Test Suite for Identifying Exaggerated 
Safety Behaviours in Large Language Models (arXiv:2308.01263). arXiv. https://doi.org/10.48550/arXiv.2308.01263
Ruan, Y., Dong, H., Wang, A., Pitis, S., Zhou, Y., Ba, J., Dubois, Y., Maddison, C. J., & Hashimoto, T. (2024). Identifying the Risks of 
LM Agents with an LM-Emulated Sandbox (arXiv:2309.15817). arXiv. https://doi.org/10.48550/arXiv.2309.15817
Sheshadri, A., 
Ewart, A., Guo, P., Lynch, A., Wu, C., Hebbar, V., Sleight, H., Stickland, A. C., Perez, E., Hadfeld-Menell, D., & Casper, 
S. (2024). Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs  (arXiv:2407.15549). arXiv. 
https://doi.org/10.48 550/arXiv.24 07.15549
Simchon, A., Edwards, M., & Lewandowsky, S. (2024). The Persuasive Efects of Political Microtargeting in  the Age of Generative 
Artifcial Intelligence.  PNAS Nexus, 3(2), pgae035. https://doi.org/10.1093/pnasnexus/pgae035
Spivak, R. (2018). “Deepfakes”: The Newest Way to Commit One of the Oldest Crimes. Georgetown Law Technology Review,  3, 
339. https://georgetownlawtechreview.org/wp-content/uploads/2019/05/3.1-Spivak-pp-339-400.pdf
Vaccari, C., & Chadwick, A. (2020). Deepfakes and Disinformation: Exploring the Impact of Synthetic Political  Video on Deception, 
Uncertainty, and Trust in News. Social Media + Society,  6(1), 2056305120903408. https://doi.org/10.1177/2056305120903408
Vidgen, B., Scherrer, N., Kirk, H. R., Qian, R., Kannappan, A., Hale, S. A., & Röttger, P. (2024). SimpleSafetyTests: A Test Suite for 
Identifying Critical Safety Risks in Large Language Models  (arXiv:2311.08370). arXiv. https://doi.org/10.48550/arXiv.2311.08370
Wei, J., Karina, N., Chung, H. W., Jiao, Y. J., Papay, S., Glaese, A., Schulman, J., & Fedus, W. (2024). Measuring Short-Form Factu-
ality in Large Language Models (arXiv:2411.04368). arXiv. https://doi.org/10.48550/arXiv.2411.04368
Zeng, Y., 
Yang, Y., Zhou, A., Tan, J. Z., Tu, Y., Mai, Y., Klyman, K., Pan, M., Jia, R., Song, D., Liang, P., & Li, B. (2024). AIR-Bench 
2024: A Safety Benchmark Based on Risk Categories From Regulations and Policies  (arXiv:2407.17436). arXiv. https://-
doi.org/10.4855 0/ arXiv.2407.17436
目录 附录 430附录
第三章：  负责任的人工智能2025年人工智能
指数报告附录
第四章：经济
目录 附录 431第四章：经济
国际机器人联合会 （IFR）
机器人安装量部分的数据来自 World Robotics2024 报告。
Lightcast
Vishy Kamalapuram 和 Elena Magrini 编写
Lightcast 提供就业市场分析， 使雇主、 工人和教育工作者能够
做出数据驱动的决策。 公司的人工智能技术分析了数以亿计的招聘信息和现实生活中的职业转换，以提供对劳动力市场模式的洞察力。 这种实时战略情报提供了重要的洞察力，如哪些工作最有需求、雇主需要的具体技能以及能为工人提供最大潜力的职业方向。 欲了解更多信息， 请访问 https://lightcast.io 。
职位发布数据
为了支持这些分析，Lightcast 挖掘了其自 2010 年以来收集的数百万个招聘信息数据集。 Lightcast 收集了 51,000 多个在线招聘网站的招聘信息，对劳动力市场需求进行全面、实时的描绘。 它汇总招聘信息， 删除重复信息， 并从招聘信息文本中提取数据。 其中包括职位名称、 雇主、 行业和地区信息， 以及所需的经验、 教育和技能。
招聘启事有助于了解劳动力市场的趋势，因为通过招聘启事可
以详细、实时地了解雇主所需的技能。 为了评估职位发布数据的代表性， Lightcast 进行了一系列分析， 将美国职位发布的分布情况与政府官方数据和其他第三方的分布情况进行比较。 美国职位发布的主要政府数据来源是劳工统计局开展的职位空缺和劳动力流动调查（JOLTS）项目。 根据 JOLTS 和 Lightcast 之间的比较，Lightcast 数据捕捉到的劳动力市场需求占劳动力的 99% 以上。 未在网上发布的职位通常出现在小企业（如餐馆橱窗上的 "Help Wanted "招牌）和工会招聘大厅。
衡量对人工智能的需求
为了衡量雇主对人工智能技能的需求，Lightcast 使用其包含 33,000 多种技能的技能分类法。
1  以下是 Lightcast 提供的
人工智能技能列表，以及相关的技能集群。 在本报告中，以下所有技能均被视为人工智能技能。 如果招聘信息中提到这些技能中的任何一项，则被视为人工智能职位。
人工智能伦理、治理和监管：ethical AI, data sovereignty, AI 
security, artifcial intelligence risk.
人工智能：agentic systems, AI/ML inference, AIOps (artifcial 
intelligence for IT operations), AI personalization, AI testing, applications of artifcial intelligence, artifcial general intelligence, artifcial intelligence, artifcial intelligence development, Artifcial Intelligence Markup Language (AIML), artifcial intelligence systems, automated data cleaning, Azure Cognitive Services, Baidu, cognitive automation, cognitive computing, computa-tional intelligence, Cortana, Data Version Control (DVC), Edge Intelligence, embedded AI, expert systems,  explainable AI (XAI), intelligent control, intelligent systems, interactive kiosk, IPSoft Amelia, knowledge distillation, knowledge engineering, knowl-edge- based confguration, knowledge-based systems, knowl-edge representation, multi-agent systems, neuro-symbolic AI,
1、 https://lightcast.io/open-skills2025年人工智能
指数报告
目录 附录 432Open Neural Network Exchange (ONNX), OpenAI Gym, opera-
tionalizing AI, PineCone, Qdrant, reasoning systems, swarm intelligence, synthetic data generation, Watson Conversation, Watson Studio, Weka Weaviate.
自主驾驶： advanced driver-assistance systems, autonomous 
cruise control systems, autonomous system, autonomous 
vehicles, dynamic routing, guidance navigation and control systems, light detection and ranging (LiDAR), object tracking, OpenCV, path analysis, path fnding, remote sensing, scene understanding, unmanned aerial systems (UAS).。
生成式人工智能：Adobe Sensei, ChatGPT, CrewAI, DALL-E 
image generator, generative adversarial networks, generative AI agents, generative artifcial intelligence,Google Bard, image inpainting, image super-resolution, LangGraph, large language modeling, Microsoft Copilot, multimodal learning, multimodal models, prompt engineering, retrieval- augmented generation, Stable Difusion, text summarization, text to speech (TTS), variational autoencoders (VAEs).
机器学习： AdaBoost (adaptive boosting), adversarial machine 
learning, Apache MADlib, Apache Mahout, Apache SINGA, 
Apache Spark, association rule learning, attention mecha-nisms, AutoGen, automated machine learning, autonomic computing, AWS SageMaker, Azure Machine Learning, bag-ging techniques, Bayesian belief networks, Boltzmann Ma-chine, boosting, Chi-Squared Automatic Interaction Detection (CHAID), Classifcation and Regression Tree (CART), cluster analysis, collaborative ﬂtering, concept drift detection, confu-sion matrix, cyber-physical systems, Dask (Software), data classifcation, Dbscan, decision models, decision-tree learning, dimensionality reduction, distributed machine learning, Dlib (C++ library), embedded intelligence, ensemble methods, evo -
lutionary programming, expectation maximization algorithm, feature engineering, feature extraction, feature learning, fea-ture selection, federated learning, game AI, Gaussian process, genetic algorithm, Google AutoML, Google Cloud ML Engine, gradient boosting, gradient boosting machines (GBM), H2O.ai, ai, hidden Markov model, hyperparameter optimization, incre-mental learning, inference engine, k-means clustering, kernel methods, Kubefow, LIBSVM, loss functions, machine learning, machine learning algorithms, machine learning methods, ma -
chine learning model monitoring and evaluation, machine learning model training, Markov chain, matrix factorization, meta learning, Microsoft Cognitive Toolkit (CNTK), MLfow, MLOps (machine learning operations), mlpack (C++ library), ModelOps, Naive Bayes Classifer, neural architecture com -
pression, neural architecture search (NAS), objective function, Oracle Autonomous Database, Perceptron, Predictionio, pre-dictive modeling, programmatic media buying, Pydata, Py-Torch (machine learning library), PyTorch Lightning, Random Forest Algorithm, recommender systems, reinforcement learn-ing, Scikit-Learn (Python package), semi-uupervised learning, soft computing, sorting algorithm, supervised learning, support vector machines (SVM), t-SNE (t-distributed Stochastic Neighbor Embedding),  test datasets, topological data analysis (TDA), Torch (machine learning), training datasets, transfer learning, transformer (machine learning model), unsupervised learning, Vowpal Wabbit, Xgboost, Theano (software).
自然语言处理 ： AI copywriting, Amazon Alexa, Amazon 
Textract, ANTLR, Apache OpenNLP, BERT (NLP Model), chat-
bot, computational linguistics, conversational AI, DeepSpeech, dialog systems, fastText, fuzzy logic, handwriting recognition, Hugging Face (NLP framework), Hugging Face Transformers, intelligent agent, intelligent virtual assistant, Kaldi, language model, latent Dirichlet allocation, Lexalytics, machine transla-tion, Microsoft LUIS, natural language generation (NLG), natu -
ral language processing (NLP), natural language programming, natural language toolkits, natural language understanding (NLU), natural language user interface, nearest neighbour algorithm, Nuance Mix, optical character recognition (OCR), screen reader, semantic analysis, semantic interpretation for speech recognition, semantic kernel, semantic parsing, semantic search, sentence transformers, sentiment analysis, Seq2Seq, Shogun, small language model, speech recognition, speech recognition software, speech synthesis, statistical lan-guage附录
第四章：经济2025年人工智能
指数报告
目录 附录 433领英
Rosie Hood、 Akash Kaura 和 Mar Carpanelli 编写
领英 数据
这组作品代表了通过领英数据所看到的世界，这些数据来自领英全球超过 10 亿会员的匿名和汇总的个人资料信息。 因此，它受到会员选择使用平台方式的影响，而会员选择使用平台的方式可能因职业、社交和地区文化以及网站的整体可用性和可访问性而有所不同。 在When publishing insights from the LinkedIn Economic Map, LinkedIn provides accurate statistics while ensuring the privacy of LinkedIn members. As such, all data is aggregated for the relevant period, following strict data quality thresholds and not disclosing information about any specific individual.
National samples
LinkedIn offers Argentina, Australia, Austria, Belgium, Brazil, Canada, Chile, Costa Rica, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hong Kong SAR, Hungary, Iceland, India, Indonesia, Ireland, Israel, Italy, Latvia, Lithuania, Luxembourg, Mexico, Netherlands, New Zealand, Norway, Poland, Portugal, Romania, Saudi Arabia, Singapore, Slovenia, South Africa, Data from South Korea, Spain, Sweden, Switzerland, Turkey, the United Arab Emirates, the United Kingdom, the United States and Uruguay.
skill
LinkedIn members self-report their skills in their LinkedIn profile. Currently, LinkedIn has identified more than 41,000 different standardized skills.
LinkedIn divides AI skills into two mutually exclusive categories: "Artificial intelligence."
engineering" and "AI literacy". Broadly speaking, AI engineering skills refer to the technical expertise and practical abilities required to design, develop, deploy, and maintain AI systems, while AI literacy skills refer to the knowledge, abilities, and critical thinking skills required to understand, evaluate, and effectively interact with AI technologies. These classifications are regularly maintained and updated as skills evolve. For a list of skills included in this analysis, see the LinkedIn AI skills list below. statistical language acquisition, summarization methods, text 
mining, text retrieval systems, text to speech (TTS), tokeniza-tion, Vespa, voice assistant technology, voice interaction, voice user interface, word embedding, Word2Vec models.
Neural networks : Apache MXNet, artifcial neural networks, autoen-
coders, Cafe (framework), Cafe2, Chainer (Deep Learning 
Framework), convolutional neural networks (CNN), Cudnn, deep learning, deep learning methods, Deeplearning4j, deep reinforcement learning (DRL), evolutionary acquisition of neural topologies, Fast. AI, graph neural networks (GNNs), Keras (neural network library), Long Short-Term Memory (LSTM), neural ordinary diferential equations, OpenVINO, Pad-dlePaddle, Pybrain, recurrent neural network (RNN), reinforce-ment learning (RL), residual networks (ResNet), sequence-to-sequence models (seq2seq), spiking neural net -
works, TensorFlow.
Robotics: Advanced Robotics, Bot Framework, Cognitive Robotics, 
meta-reinforcement learning, motion planning, Nvidia Jetson, 
OpenAI Gym environments, reinforcement learning from human feedback (RLHF), robot framework, robot operating systems, robotic automation software, robotic liquid handling systems, robotic programming, robotic systems, servomotor, SLAM algorithms (Simultaneous Localization and Mapping).
Visual image recognition : 3D reconstruction, activity recognition, 
computer vision, contextual image classifcation, Deck.gl, digi-
tal image processing, digital twin technology, eye tracking, face detection, facial recognition, general-purpose computing on graphics processing units, gesture recognition, image anal-ysis, image captioning, image matching, image recognition, image segmentation, image sensor, ImageNet, instance seg-mentation, machine vision, MNIST, motion analysis, object recognition, OmniPage, pose estimation, RealSense, thermal imaging analysis
Chapter 4: Economic Sectors
LinkedIn's industry taxonomy is a collection of entities that share economic activities and contribute to a specific product or service. An industry represents a product or service offered or sold by a company. LinkedIn analyzes the following industries in the context of artificial intelligence: education; financial services; Manufacturing; professional services; and technology, information and media.
gender
LinkedIn recognizes that some LinkedIn members' gender identities transcend traditional gender constructs of "male" and "female." In the absence of a clear self-identification, LinkedIn inferred the gender of the members in this analysis based on the pronouns used in the LinkedIn profile or based on their names. Members whose gender cannot be inferred to be male or female will be excluded from any gender analysis. Note that LinkedIn filters countries where its gender attribution algorithm doesn't have enough coverage.
Artificial intelligence jobs or careers
LinkedIn member titles are standardized and divided into more than 16,000 occupations. These occupations are not specific to a specific industry or country. AI jobs require AI skills to get the job done efficiently and attentively. Examples of such careers include (but are not limited to): machine learning engineers, artificial intelligence specialists, data scientists, and computer vision engineers.
Artificial intelligence talents
LinkedIn members are considered AI talents if they explicitly add at least two AI skills to their profile and/or if they are or have been employed in an AI job. 2. The fastest growing AI skills: year-over-year growth of the AI skills most frequently added by all members. Note that LinkedIn has set a threshold for skill additions in the most recent year, which is set to the 50th percentile of the distribution of AI skill additions by country in the most recent year.
Interpretation: The world's fastest-growing AI engineering skills are custom GPT, artificial intelligence
Ability to productivity and artificial intelligence agents.
3. Artificial intelligence talent gathering
AI talent counting is used to calculate talent concentration metrics. In other words, when calculating the concentration of AI talent at the national level, LinkedIn divides the number of AI talent in a particular country by the number of LinkedIn members in that country. Note that concentration metrics can be affected by LinkedIn's coverage in these countries and should be used with caution.
Interpretation: AI talents with AI engineering skills account for LinkedIn in the United States
0.78% of members.
4. Relative to the year-on-year ratio of AI talent hiring rate
LinkedIn employment rate is an employment measure normalized by the number of LinkedIn members. It is calculated by dividing the percentage of LinkedIn members of new employers in the same period of employment by the total number of LinkedIn members in that location.
The AI engagement rate is calculated using the overall employment rate methodology, but only those classified as AI in 2025 are considered
Index Report
Table of Contents Appendix 433 Table of Contents Appendix 434 Appendix
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Appendix 435 Members of AI Talent. The year-on-year ratio of the relative AI talent recruitment rate refers to people
The year-on-year change in the recruitment rate of AI talent relative to the overall recruitment rate of the same country. What LinkedIn shares is a 12-month moving average.
Interpretation: In the United States, the proportion of AI talent recruitment relative to overall recruitment has increased
24.7%.
5. Skill penetration
SKILLS GENOME IS AN ORDERED LIST (VECTOR) OF THE 50 MOST CHARACTERISTIC SKILLS OF ANY CATEGORY (OCCUPATION, COUNTRY, INDUSTRY, ETC.). These most characteristic skills are determined by the TF-IDF algorithm, which ranks down those ubiquitous skills that add little information to a specific entity, such as Microsoft Word, and up to skills that are unique to a specific entity, such as artificial intelligence. For more details, see the LinkedIn's skills genome and LinkedIn–World Bank Methodology instructions.
For example, Table 1 details the technology, information, and media industries in the U.S. in 2024
The Skills Genome, which shows the top 10 skills sorted by TF-IDF. Penetration of AI skills
The purpose of this indicator is to measure the strength of AI skills in a category using the following methods:
•LinkedIn calculates the frequency of all skills that LinkedIn members have self-added in a particular entity (occupation, industry, etc.) since 2015. •LinkedIn uses the TF-IDF model to reweight skill frequencies to get the top 50 most representative skills in that entity. These 50 skills make up the entity's "skills genome". •LinkedIn calculates the proportion of skills that belong to the AI skillset out of the top skills of the selected entity.
Explanation: AI skills penetration indicates how widespread AI skills are across occupations, or how strongly LinkedIn members use AI skills at work. For example, the top 50 skills for the profession of engineer are calculated based on how often they appear on LinkedIn member profiles. If four of the skills an engineer has mastered belong to the AI skill set, then this measurement suggests that the penetration of AI skills among engineers is estimated to be 8% (or 4/50).
Relative AI skill penetration
In order to compare skills penetration across countries, the skills genome needs to be calculated and a relevant benchmark (e.g. global average) selected. Then, in the case of controlling occupations, construct a ratio between a country and the penetration rate of AI skills in a comparative baseline.
Explanation: If a country has a relative penetration rate of 1.5 in AI skills, this means
This means that AI skills are used 1.5 times more frequently than the benchmark across an overlapping set of occupations.
Global comparisons
For cross-country comparisons, LinkedIn presents the relative penetration of AI skills, which is the sum of the penetration of each AI skill in each occupation in a given country, divided by the global average penetration of AI in overlapping occupations in the sample countries.
Skill Name: TF-IDF Skill Level
Amazon Web Services (AWS) 1
Softwareas a Service (SaaS) 2
Artifcialintelligence(AI) 3
Python (programminglanguage) 4
Go-to-marketstrategy 5
Customer success 6
Large language models (LLM) 7
Salesforce.com 8
SQL 9
Generative AI 10 Appendix
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Addendum 436 Explanation: Relative PermeabilityA rate of 2 means that in the same group of occupations, the country is AI
The average penetration rate of skills is 2 times higher than the global average.
Global Comparison by Industry
The relative penetration rate of AI skills in specific industries by country provides an in-depth industry breakdown of the penetration rate of AI skills by industry and country.
Explanation: The relative penetration rate of AI skills in the field of education in a country is 2,
It means that in the same group of occupations in this field, the average penetration rate of AI skills in the country is 2 times higher than the global average.
Global comparison: by sex
The relative penetration rate of AI skills by sex provides a cross-country comparison of the penetration of AI skills within a gender. Since the global average is different for each gender, this indicator can only be used to compare country rankings within each gender, not for cross-gender comparisons within countries.
Explanation: A country has a female AI skills penetration rate of 1.5, which means:
Female members in the country are 1.5 times more likely to have AI skills than the average for female members in all countries.
Global comparison: transgender
Because LinkedIn compares a country's AI skills penetration by gender to the same global average, regardless of gender, the relative AI skills penetration between genders can be compared within and across countries across the globe.
6. Representation of women in the field of artificial intelligence
This refers to the percentage of women in AI talent.
Explanation: Globally, AI talent with AI engineering skills
, 30.5% were women. 7. AI talent migration
Immigration data from World Bank Group – LinkedIn Digital Data Boosts Development
Digital Data for Development (see https://linkedindata.worldbank.org/ and Zhu et al. (2018). LinkedIn migration rates come from self-identified locations in LinkedIn member profiles. For example, when a LinkedIn member updates their location from Paris to London, this will count as a migration. Migration data has been available since 2019.
LinkedIn data can help countries gain insight into the number of AI humans that are increasing or decreasing due to migration trends
Just. AI talent migration refers to all members with AI skills / engaged in AI work at time "t", where country A is the relevant country and country B is the inflow of the source country and the outflow destination country. Therefore, the net migration of AI talent between countries A and B is calculated as follows:
Net flow is defined as the number of arrivals minus the number of departures in a specific time period. Different countries
The number of LinkedIn members varies, which can be challenging to explain the absolute flow of members from one country to another. Therefore, we normalized the migration flows for each country. For example, in the case of country A, all absolute net traffic to and from country A (regardless of country of origin and country of destination) is normalized based on the number of LinkedIn members at the end of each year in country A, which is then multiplied by 10,000. Thus, the indicator shows the relative flow of talent from all countries to and from country A. Note that in order for the transition to have a sufficient sample size, we used a minimum threshold.
Explanation: The net flow of AI talent in the U.S. is positive compared to the size of its membership 
There was a net inflow of AI talent out of 10,000 members, 1.07 out of 1.07 members.
8. Career transition into AI jobs
LinkedIn considered the source occupations that feed AI careers and analyzed the proportion of people who switched to AI careers in five years. Career transitions are calculated by moving members from one job
appendix
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Appendix 437 Job Transitions from Industry to Occupation are summarized. LinkedIn excludes new graduates
The first new class and intra-class transitions.
Interpretation: In the United States, 26.9% of AI engineers are software engineers
Converted, followed by 13.3% of data scientists.
LinkedIn AI Skills List
Artificial Intelligence Engineering
3D reconstruction, AI agents, AI productivity, AI strategy, algo -
rithm analysis, algorithm development, Amazon Bedrock, Apache Spark ML, applied machine learning, artifcial intelli-gence (AI), artifcial neural networks, association rules, audio synthesis, autoencoders, automated clustering, automated feature engineering, automated machine learning (AutoML), automated reasoning, autoregressive models, Azure AI Studio, Cafe, chatbot development, chatbots, classifcation, cognitive computing, computational geometry, computational intelli-gence, computational linguistics, concept drift adaptation, conditional generation, conditional image generation, convolu-tional neural networks (CNN), custom GPTs, decision trees, deep convolutional generative adversarial networks (DCGAN), deep convolutional neural nNetworks (DCNN), deep learning, deep neural networks (DNN), evolutionary algorithms, expert systems, facial recognition, feature extraction, feature selec-tion, fuzzy logic, generative adversarial imitation learning, gen-erative adversarial networks (GANs), generative AI, generative design optimization, generative fow models, generative mod-eling, generative neural networks, generative optimization, generative pre-training, generative query networks (GQNs), generative replay memory, generative synthesis, gesture rec-ognition, Google Cloud AutoML, graph embeddings, graph networks, hyperparameter optimization, hyperparameter tuning, image generation, image inpainting, image processing, image synthesis, image-to-image translation, information extraction, intelligent agents, k-means clustering, Keras, knowledge discovery, knowledge representation and reason-ing, LangChain, large language model operations (LLMOps), large language models (LLM), machine learning, machine learning algorithms, machine translation, Microsoft Azure Machine Learning, MLOps, model compression, model interpretation, model training, music generation,nNatural language genera -
tion, natural language processing (NLP), natural language un-derstanding, neural network architecture design, neural net-works, NLTK, object recognition, ontologies, OpenAI API, OpenCV, parsing, pattern recognition, predictive modeling, probabilistic generative models, probabilistic programming, prompt fow, PyTorch, question answering, random forest, RapidMiner, recommender systems, recurrent neural networks (RNN), reinforcement learning, responsible AI, Scikit-Learn, semantic technologies, semantic web, sentiment analysis, speech recognition, Spring AI, statistical inference, style trans-fer, StyleGAN, supervised learning, support vector machine (SVM), synthetic data generation, TensorFlow, text analytics, text classifcation, text generation, text mining, text-to-image generation, Theano, time series forecasting, transformer models, unsupervised learning, variational autoencoders (VAEs), video generation, web mining, Weka, WordNet.
AI literacy
AI Builder, AI prompting, Anthropic Claude, ChatGPT, DALL-E, generative AI, Generative AI Studio, generative AI tools, gener-ative art, GitHub Copilot, Google Bard, Google Gemini, GPT-3, GPT-4, LLaMA, Microsoft Copilot, Microsoft Copilot Studio, Midjourney, multimodal prompting, prompt engineering, Stable Difusion.
Thanks
LinkedIn would like to thank Murat Erer and Carl Shan for their contributions in developing these methodologies and indicators, as well as our work at the OECD Artificial Intelligence Organization (OECD.AI), the Stanford Institute for Human-Centered AI, and Centro Feedback from collaborators at the Nacional de Inteligencia Artificial, Cenia. appendix
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Addendum 438Quid
Quid insights by Heather English and Hansen Yang
Quid leverages its own internal large language model and other intelligent search capabilities as well as passing
A Boolean query that searches for focus areas, topics, and keywords across many datasets: social media, news, forums and blogs, companies, patents, and other customizations (such as survey data). Quid has a variety of visualization options and data delivery endpoints, including semantic similarity-based network diagrams, in-platform dashboard capabilities, and programmatic PostgreSQL database delivery. Quid applies best-in-class AI and NLP to reveal hidden patterns in large data sets, enabling users to make data-driven decisions accurately, quickly, and efficiently.
Search, data source, and scope
Index more than 8 million global public and private company profiles from multiple data sources for search in company descriptions, while filtering and including metadata from investment information to company geographic information such as year of establishment, headquarters location, and more. Company information is updated weekly. The Quid algorithm reads a large amount of textual data from each document, making links between different documents based on their similar language. This process is repeated on a huge scale, resulting in a network of different clusters that identify different topics or areas of focus. Trends are determined based on keywords, phrases, people, companies and institutions, and metadata from other input software identified by Quid.
Data companies
Organizational data comes from Capital IQ and Crunchbase.These companies include various types of organizations (private, public, operating, operating as a subsidiary, discontinued) around the world. Investment data includes private investments, mergers and acquisitions, public offerings, minority stakes held by private/venture capital firms, corporate risk departments, governments, and domestic and foreign institutions. Some data are not available. For example, when the name of the investor or the amount of financing is not disclosed. Quid embeds data from Capital IQ by default and adds data from Crunchbase to data points that are not captured by Capital IQ. This not only provides comprehensive and accurate data on all global institutions, but also captures data on early-stage start-ups and funding events.
Search parameters
Boolean queries are used to search and archive company databases and their business descriptions and focus areas, topics, and keywords within a website. Quid can filter search results based on the location of the headquarters, the amount of investment, the state of operation, the type of organization (private/public), and the year of establishment. Quid then visualizes these companies based on semantic similarity. If there are more than 7,000 companies in the search results, Quid selects the 7,000 most relevant companies for visualization based on a linguistic algorithm. Boolean searches: "artificial intelligence" or "AI" or "machine learning" or "deep learning".
firm
• Investments received between January 1, 2014 and December 31, 2024
(private placements, IPOs, mergers and acquisitions) of global artificial intelligence and machine learning companies.
• In the past 10 years (January 1, 2014 to December 31, 2024
Day) Global AI and machine learning companies that have raised more than $1.5 million • We also extracted global data for generative AI queries (Boolean searches: "generative AI" or "generative AI" or "generative AI") to query companies that have earned more than $1.5 million in the past 10 years (January 1, 2014 to December 31, 2024).
Target event definition
• Private Placement: A private placement is the private sale of newly issued securities (equity or debt) by a company to a specific investor or group of investors. The buyer's equity interest in a private placement is usually a minority stake (less than 50%), although it is possible to obtain an addendum through a private placement
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Appendix 439 Control of a company, in which case a private placement is a majority equity investment.
• Minority Investment: This refers to a minority acquisition by Quid, i.e., the buyer
Acquisition of less than 50% of existing ownership shares in entities, asset products and business units
Right.
• Mergers and acquisitions: refers to the acquisition of more than 50% of the entity, asset products and business units by the buyer
of existing ownership.
McKinsey
The "Corporate Events" section uses data from two McKinsey global surveys: The State of AI in Early 2024: Gen AI Adoption Spikes and Starts to Generate Value and "The State of AI: How Orga-nizations Are Rewiring to Capture Value."
The first online survey for 2024 was conducted from February 22 to March 5 and was collected
To the responses of 1,363 participants, who represented different regions, industries, company sizes, functional specialties and tenures. Of those surveyed, 981 said their organization had adopted AI in at least one business function, and 878 said their organization regularly used AI technology in at least one function. The second online survey for 2024 was conducted from July 16 to July 31 and received responses from 1,491 participants from 101 countries, representing different regions, industries, company sizes, functional specialties, and tenures. 42% of respondents said they work for businesses that generate more than $500 million in annual revenue.
To adjust for the response rate variance, the data is rounded by each respondent's contribution to global GDP
Row weighting.
The AI Index also takes into account data from previous McKinsey surveys. These packets
Including: The State of AI in 2023: Generative AI's Breakout Year The State of AI in 2022—and a Half Decade in Review The State of AI in 2020AI Proves Its Worth, But Few Scale Impact (2019)AI Appendix to Adoption Advances, But Foundational Barriers Remain (2018).
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Appendix 440 Cited Works
Brynjolfsson, E., Li, D., & Raymond, L. (2025). Generative AI at Work. The Quarterly Journal of Economics,  qjae044. https://doi. 
org/10.1093/qje/qjae044
Cui, Z. 
(Kevin), Demirer, M., Jafe, S., Musolf, L., Peng, S., & Salz, T. (2025). The Efects of Generative AI on High-Skilled Work: Evi-
dence From 
Three Field Experiments With Software Developers  (SSRN Scholarly Paper 4945566). https://doi.org/10.2139/ 
ssrn.4945566
Dell’Acqua, F.,  McFowla nd, E., Mollick, E. R., Lifshitz-Assaf, H., Kellogg, K., Rajendran, S., Krayer, L., Candelon, F., & Lakhani, K. 
R. (2023). Navigating the Jagged Technological Frontier: Field Experimental Evidence of the Efects of AI on Knowledge Worker 
Productivity and Qu ality. SSRN Electronic Journal.  https://doi.or g/10.213 9/ssrn.4573321
Handa, K., Tamkin, A., McCain, M., Huang, S., Durmus, E., Heck, S., Mueller, J., Hong, J., Ritchie, S., Belonax, T., Troy, K. K., 
Amodei, D., Kaplan, J., Clark, J., & Ganguli, D. (2025). Which Economic Tasks Are Performed with AI? Evidence From Millions of 
Claude Conversations  (arXiv:2503.04761). arXiv. https://doi.org/10.48550/arXiv.2503.04761
Hofmann, M., Boysel, S., Nagle, F., Peng, S., & Xu, K. (2024). Generative AI and the Nature of Work (No. 11479). CESifo Working 
Paper . https://www.econstor.eu/bitstream/10419/308375/1/cesifo1_wp11479.pdf
Jafe, S., Shah, N. P., Butler, J., Farach, A., Cambon, A., Hecht, B., Schwarz, M., & Teevan, J. (eEds.). (2024). Generative AI in Re-
al-World Workplaces: 
The Second Microsoft Report on AI and Productivity Research . Microsoft. https://www.microsoft.com/ 
en-us/researc h/wp-content/uploads/2024/07/Generative-AI-in-Real-World-Workplaces.pdf
Necula, S.-C ., Fotache, D., & Rie der, E. (2024). A ssessing the Impact of Artifci al Intelligence Tools on Employee Product ivity: 
Insights From a Comprehe nsive Survey Analysis. Electronics, 13(18), Article 18. https://doi.org/10.3390/electronics13183758
Toner-Rodgers, A. (2024). Artifcial Intelligence, Scientifc Discovery, and Product Innovation  (arXiv:2412.17866). arXiv. https://doi. 
org/10.48550/a rXiv.2412.178 66 Addendum
Chapter 4: Artificial Intelligence in the Economy 2025
Index Report
Table of Contents Appendix 441 Appendix
Chapter 5: Science and Medicine
Chapter 5: Science and Medicine
Thanks
The AI Index would like to thank Armin Hamrah for his research on the relationship with AI
work done on major trends in science and medicine.
Benchmarks
1. MedQA: Data on MedQA are from the February 2025 MedQA Papers With Code leaderboard. To learn more about MedQA, read the original article.
AI-driven statistics for protein science papers
Artificial intelligence uses Dimensions 的人工智能文献检索功能来内发表的手稿数量。 搜索范围仅限于 2024 出版年和生物科学类
（987,717 论文统计） 。 然后对每个关键词进行检索， 这些必须同
时出现在标题和摘要。 这一要求限制返回的手稿数量，因为这些手稿可能只是顺带提到了关键词，而不是描述了有关该的研究。 确定手稿数量后，计算每个关键词在生物科学手稿总数中所占的百分比。
图像和多模态人工智能促进科学发现
人工智能指数利用 Semantic Scholar 和谷歌学术（Google Scholar）来衡量 2023 年至 2025 年发表的手稿数量。 然后对每 个 关 键 术 语（如 “foundation models,” “microscopy,” “electron microscopy,” “fuorescence microscopy,” “light microscopy”） 进行搜索， 要求这些术语同时出现在标题和摘要中。 此外，还对搜索进行了改进，以严格遵守基础模型的定义-- 具体来说， 就是在大量数据集上训练出来的、 可广泛应用于各种用例的模型。 为此， 任何被认为是基础模型的模型， 如果在少于 100 万个数据点上进行过训练， 或者没有在多个任务上进行过评估， 则会被舍弃。
FDA 批准的人工智能医疗设备
FDA 批准的人工智能医疗设备数据来自 FDA 网站 ， 该网站跟踪支持人工智能和机器学习 （AI/ML） 的医疗设备。
伦理方面的考虑
人工智能指数使用 PubMedCentral 的 API 查询 2020 年 1 月1 日至 2024 年 12 月 31 日期间发表的英文 - 语言索引文章，搜索关键词涉及人工智能、医学和伦理问题。 为了只获取这三个主题交叉点上的文章，人工智能指数进一步缩小了文章范围， 只收录那些摘要包含与以下内容相关的关键词的文章：(a) 人工智能；(c) 伦理问题：(a) 人工智能， (b) 医学， c) 至少一个伦理问题。 在剔除预印本、被撤回的文章和不符合纳入标准的文章后，还剩下 2,916 篇文章。 人工智能伦理指数利用这批文章摘要中提及伦理问题的频率进行分析。
API 查询：
( “artifcial intelligence” [MeSH] OR “machine learning” [MeSH] OR “deep learning”[All Fields] OR “AI”[All Fields] OR “ML”[All Fields] OR “predictive analytics” [All Fields]) AND (( “ethics”[MeSH] OR “ethical implications” [All Fields] OR “fair*” [All Fields] OR “unfair*” [All Fields] OR “bias” [All Fields] OR “ac-countability” [All Fielzds] OR “transparency” [All Fields] OR “explainability” [All Fields] OR “privacy” [All Fields] OR “trust-worthy AI” [All Fields]) OR ( “bioethics” [MeSH] OR “ELSI” [All Fields] OR “autonomy”[All Fields] OR “equity”[All Fields] OR 2025年人工智能
指数报告
目录 附录 442“equitab*” [All Fields] OR “justice” [All Fields] OR “benef-
cence”[All Fields] OR “non-malefcence”[All Fields] OR “inde-pendent review” [All Fields] OR “oversight” [All Fields] OR “racis*” [All Fields] OR “prejud*” [All Fields] OR “inequit*” [All Fields] OR “community engagement” [All Fields] OR “misuse”[All Fields] OR “dual use”[All Fields])) AND (“medicine”[MeSH] OR “medical AI” [All Fields] OR “clinical decision support” [All Fields] OR “health informatics”[All Fields]) AND (“2020/01/01”[PubDate] :  “2024/12/31”[PubDate]
搜索日期：2/14/2025 摘要纳入标准：
因此， 只包括讨论医学的文章、 人工智能， 以及摘要中至少一个伦理问题 （N= 2,916） 。 • 人工智能关键词 ： “artifcial intelligence,” “ AI,” “algorithm,” 
“ML,” “machine learning,” “deep learning,” predictive analyt-ics.•医学关键词：“medicine,” “medical,” “health,” “healthcare.” • 伦理关键词 ： “ethic*,” “fairness,” “bias,” “accountability,” 
“transparency,” “explainability,” “privacy,” “trustworthy AI,” “bioethics,” “ELSI,” “autonomy,” “equit*,” “justice,” “benef-cence,” “non- malefcence,” “independent review,” “over-sight,” “racism,” “inequit*,” community engagement, misuse, dual use.附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 443 引用作品
Abramson, J., Adler, J ., Dunger, J., Evans, R., Green, T., Pritzel, A., Ronneberger, O., Willmore, L., Ballard, A. J., Bambrick, J., 
Bo
denstein, S. W., Evans, D. A., Hung, C.-C., O’ Neill, M., Reiman, D., Tunyasuvunakool, K., Wu, Z., Že mgulytė,  A., Arvaniti, E., … 
Jumper, J. M. (2024). Accurate Structure Prediction of Biomolecular Interactions With AlphaFold 3. Nature, 630(8016), 493–500. 
https://doi.org/10.1038/s41586-024-07487-w
Acharya, R., Ab anin, D. A., Ag hababaie-Beni, L., Ale iner, I., Andersen, T. I., Ansmann, M., Arute, F., Arya, K., Asfaw, A., Astrakhant-
sev, N., Atalaya, J., Babbush, R., Bacon, D., Bal lard, B., Bardin, J . C., Bausc h, J., Bengtsson, A., Bilmes, A., Blackwell, S., … Goog le 
Quantum AI and Collaborators. (2025). Quantum Error Correction Below the Surface Code Threshold. Nature, 638(8052), 920–26. 
https://doi.org/10.10 38/s41586-0 24-08 449-y
Blankemeier, L., Cohen, J. P., Kumar, A., Veen, D. V., Gardezi, S. J. S., Paschali, M., Chen, Z., Delbrouck, J.-B., Reis, E., Truyts,
C., Bluethgen, C., Jensen, M. E. K., Ostmeier, S., Varma, M., Valanarasu, J. M. J., Fang, Z., Huo, Z., Nabulsi, Z., Ardila, D., … Chaud-
hari, A. S. (2024). Merlin: A Vision Language Foundation Model for 3D Computed Tomography (arXiv:2406.06512). arXiv. https://-
doi.org/10.4855 0/arXiv.2406.06512
Bodnar, C., Bruinsma, W. P., Lucic, A., Stanley, M., Vaughan, A., Brandstetter, J., Garvan, P., Riechert, M., Weyn, J. A., Dong, H., 
Gupta, J. K., Thambiratnam, K., Archibald, A. T., Wu, C.-C., Heider, E., Welling, M., Turner, R. E., & Perdikaris, P. (2024). A Founda-
tion Model for the Earth System  (arXiv:2405.13063). arXiv. https://doi.org/10.48550/arXiv.2405.13063
Burley, 
S. K., Berman, H. M., Kleywegt, G. J., Markley, J. L., Nakamura, H., & Velankar, S. (2017). Protein Data Bank (PDB): The 
Single Global 
Macromolecular Structure Archive. Methods in Molecular Biology  (Clifton, N.J.), 1607, 627–41. https://doi. 
org/10.1007/ 978-1-4939-700 0-1_26
Callahan, A., McElfresh, D., Banda, J. M., Bunney, G., Char, D., Chen, J., Corbin, C. K., Dash, D., Downing, N. L., Jain, S. S., 
Kotecha, N., Masterson, J., Mello, M. M., Morse, K., Nallan, S., Pandya, A., Revri, A., Sharma, A., Sharp, C., … Shah, N. H. (2024). 
Standing on FURM Ground: A Framework for Evaluating Fair, Useful, and Reliable AI Models in Health Care Systems. NEJM Cata-
lyst, 5(10) , CAT.24.0131. https://doi. org/10.1056/CAT.24.0131
Campanella, 
G., Chen, S., Verma, R., Zeng, J., Stock, A., Croken, M., Veremis, B., Elmas, A., Huang, K., Kwan, R., Houldsworth, J., 
Schoenfeld, A. J., & Vanderbilt, C. (2024). A  Clinical Benchmark of Public Self-Supervised Pathology Foundation Models  (arX-
iv:2407.06508) . arXiv. https://doi.org/10.48550/arXiv.2407.06508
Carrillo-Perez, F., Pizurica, M., Zheng, Y., Nandi, T. N., Madduri, R ., Shen, J., & Gevaert, O. (2023). RNA-to-Image Multi- cancer 
Synthesis 
Using Cascaded Difusion Models. bioRxiv: The Preprint Server for Biology,  2023.01.13.523899. https://doi. 
org/10.1101/202 3.01.13.5 23899附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 444 Chambon, P., Bluethgen, C., Delbrouck, J.-B., Sluijs, R. V. der, Połacin, M., Chaves, J. M. Z., Abraham, T. M., Purohit, S., Langlotz, C.  
P., & Chaudhari, A. (2022). RoentGen: Vision-Language Foundation Model for Chest X-ray Generation (arXiv:2211.12737). arXiv.  
https://doi.org/10.48550/arXiv.2211.12737 
Chambon, P., Delbrouck, J.-B., Sounack, T., Huang, S.-C., Chen, Z., Varma, M., Truong, S. Q., Chuong, C. T., & Langlotz, C.
P. (2024). CheXpert Plus: Augmenting a L arge Che st X-ray Dataset With Text Radiology Reports, Patient Demographics and Ad-
ditional Image Formats  (arXiv:2405.19538). arXiv. https://doi.org/10.48550/arXiv.2405.19538
Chen, R. J., Chen,  C., Li, Y., Chen, T. Y., Trister , A. D., Kris hnan, R. G., & Mahmood,  F. (2022). Scaling Vi sion Tra nsformers  to 
Gigapixel Images via Hierarchical Self-Supervised Learning  (arXiv:2206.02647). arXiv. https://doi.org/10.48550/arXiv.2206.02647
Chen, Z., Varma, M., Xu, J., Paschali, M., Veen, D. V., Johnston, A., Youssef, A., Blankemeier, L., Bluethgen, C., Altmayer, S., Vala-
narasu, J. M. J., Muneer, M. S. E., Reis, E. P., Cohen, J. P., Olsen, C., Abraham, T. M., Tsai, E. B., Beaulieu, C. F., Jitsev, J., … Lan-
glotz, 
C. P. (20 24). A Vision-Language Foundation Model to Enhance Efciency of Chest X-ray Interpretation  
(arXiv:2401.12208). arXiv. https://doi.org/10.48550/arXiv.2401.12208
Christensen, M., Vukadinovic, M., Yuan, N., & Ouyang, D. (2024). Vision–Language Foundation Model for Echocardiogram Inter-
pretation. Nature Medicine,  30(5), 1481–88. https://doi.org/10.1038/s41591-024-02959-y
Clark, K., V endt, B., Smith, K., Freymann, J., Kirby, J., Koppel, P., Moore, S., Phillips, S., Maftt, D., Pringle, M., Tarbox, L., & Prior,
F. (2013). The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Infor mation Repository. J ournal of Digital Imag-
ing, 26(6), 1 045–57. https://doi.org/10.1007/s10278-013-9622-7
Ding, S., Li, J., Wang, J., Ying, S., & Shi, J. (2023). Multi-scale Efcient Graph-Transformer for Whole Slide Image Classifcation
(arXiv:2305.1 5773). arXiv. https://doi. org/10.48550/arXiv.2305.15773
Ding, T., Wagner, S. J., Song, A. H., Chen, R. J., Lu, M. Y., Zhang, A., Vaidya, A. J., Jaume, G., Shaban, M., Kim, A., Williamson, D. 
F. K., Chen, B., Almagro-Perez, C., Doucet, P., Sahai, S., Chen, C., Komura, D., Kawabe, A., Ishikawa, S., … Mahmood, F. (2024).  
Multimodal Whole Slide Foundation Model for Pathology( arXiv:2411.19666). arXiv. https://doi.org/10.48550/arXiv.2411.19666
Goh, E., Gallo, R., Hom, J., Strong, E., Weng, Y., Kerman
, H., Cool, J. A., Kanjee, Z., Parsons, A. S., Ahuja, N., Horvitz, E., Yang, D., 
Milstein, A., 
Olson, A. P. J., Rodman, A., & Chen, J. H. (2024). Large Language Model Infuence on Diagnostic Reasoning: A Ran-
domized Clinical Trial. JAMA Ne twork Open,  7(10), e2440969. https://doi.org/10.1001/jamanetworkopen.2024.40969
Goh, E., Gallo, R. J., Strong, E., Weng, Y., Kerman, H., Freed, J. A., Cool, J. A., Kanjee, Z., Lane, K. P., Parsons, A. S., Ahuja, N., Hor-
vitz, E., Yang, D., Milstein, A., Olson, A. P. J., Hom, J., Chen, J. H., & Rodman, A. (2025). GPT-4 Assistance for Improvement of 
Physician Performance on Patient Care Tasks: A Randomized Controlled Trial. Nature Medicine,  1–6. https://doi.org/10.1038/ 
s41591-024-0 3456-y附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 445 Gruver, N., Sriram, A., Madotto, A., Wilson, A. G., Z itnick, C. L., & Ulissi, Z. (2024).  Fine-Tuned Language Models Generate Stable 
Inorganic Materials as Text (arXiv:2402.04379). arXiv. https://doi.org/10.48550/arXiv.2402.04379
Guevara, M., Chen, S., Thomas, S., Chaunzwa, T. L., Fra
nco, I., Kann, B. H., Moningi, S., Qian, J. M., Goldstein, M., Harper, S., Aerts, 
H. J. W. L., Catalano, P. J., Savova, G. K., Mak, R. H., & Bitterman, D. S. (2024). Large Language Models to Identify Social Determi-
nants of Health in  Electronic Health Records. Npj  Digital Medicine,  7(1), 1–14. https://doi.org/10.1038/s41746-023- 00970-0 
Guo,
 Z., Zhao, W., Wang, S., & Yu, L. (2023). HIGT: Hi erarchical Interaction Graph-Transformer for Whole Slide Image Analysis 
(arXiv:2309.0 7400). arXiv. h ttps://doi. org/10.48550/arXiv.2309.07400
Haberle, 
T., Cleveland, C., Snow, G. L., Barber, C., Stookey, N., Thornock, C., Younger, L., Mullahkhel, B., & Ize-Ludlow, D. (2024). 
The Impact of Nuance DAX Ambient Listening AI Documentation: A Cohort Study. Journal of the American Medical Informatics As-
sociation , 31(4), 975–79. https://doi.org/10.1093/jamia/ocae022
Hashmi, A. U. R., Almakky, I., Qazi, M. A., Sanjeev, S., Papineni, V. R., Jagdish, J., & Yaqub, M. (2024). XReal: Realistic Anatomy and 
Pathology-Aware X-ray 
Generation via Controllable Difusion Model (arXiv:2403.09240). arXiv. https://doi.org/10.48550/ arX-
iv.2403.09240
Hayes, 
T., Rao, R., Akin, H., Sofroniew, N. J., Oktay, D., Lin, Z., Verkuil, R., Tran, V. Q., Deaton, J., Wiggert, M., Badkundri, R., 
Shafkat, I., 
Gong, J., Derry, A., Molina, R. S., Thomas, N., Khan, Y. A., Mishra, C., Kim, C., … Rives, A. (2024). Simulating 500 Millio n 
Years of Evolution With a Language Model  (p. 202 4.07.01.600583). bioRxiv. https://doi.org/10.1101/2024.07.01.600583
Hellert, T., Mon tenegro, J., & Pollastro, A. (2024). PhysBE RT: A Text Em bedding Model for Physics Scientifc Literature
(arXiv:2408.0 9574). arXiv. h ttps://doi. org/10.48550/arXiv.2408.09574
Hornick, T., Mao, C., Koynov, A., Yawman
, P., Thool, P., Salish, K., Giles, M., Nagapudi, K., & Zhang, S. (2024). In Silico Formulation 
Optimization and Particle Engineering of Pharmaceutical Products Using a Generative Artifcial Intellig ence Structure Synthesis 
Method. Nature Communications, 15(1), 9622. https://doi.org/10.1038/s41467-024-54011-9
Istasy, P., 
Lee, W. S., Iansavichene, A., Upshur, R., Gyawali, B., Burkell, J., Sadikovic, B., Lazo-Langner, A., & Chin-Yee, B. (2022). 
The Impact of Artifcial Intelligence on Health Equity in Oncology: Scoping Review. Journal of Medical Internet Research,  24(11), 
e39748. https://doi.org/10.2196/39748
Jiang, J. X., Qi, K., Bai, G., & Schulman, K. (2023). Pre-pandemic Assessment: A Decade of Progress in Electronic Health Record 
Adoption Among U.S. Hospitals. Health Afairs Scholar,  1(5), qxad056. https://doi.org/10.1093/haschl/qxad056
Jin, D., Pan, E., Oufattole, N., Weng, W.-H., Fang, H., & Szolovits, P. (2020). What Disease Does This Patient Have? A Large- Scale 
Open Domain 
Question Answering Dataset From Medical Exams  (arXiv:2009.13081). arXiv. https://doi.org/10.48550/ arX-
iv.2009.13081附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 446 Johnson, A. E. W., Po llard, T. J., Berkowi tz, S. J., Greenbaum, N. R., Lungren, M. P., Deng, C., Mark, R. G., & Horng, S. (2019). MIM-
IC-CXR, 
a De-identifed Publicly Available Database of Chest Radiographs With Free-Text Reports. Scientifc Data , 6(1), 317. 
https://doi.org/10.1038/s41597-019-0322-0
Kochkov, D., Yuval, J., Langmore, I., Norgaard, P., Smith, J., Mooers, G., Klwer, M., Lottes, J., Rasp, S., Dben, P., Hatfeld, S., 
Battaglia, P., 
Sanchez-Gonzalez, A., Willson, M., Brenner, M. P., & Hoyer, S. (2024). Neural General Circulation Models for Weather 
and Climate. Nature, 632(8027), 1060–66. https://doi.org/10.1038/s41586-024-07744-ya 
Kudiabor, H. (2024). Virtual Lab Pow-e red by ‘AI Scientists’ Super-Charges Biomedical Research.  Nature , 
636(8043), 532–33. https://-d oi.org/10.1038/d41586-024-01684-3
Kumar, A., Kriz, A., Havaei, M., & Arbel, T. (2025). PRISM: High-Resolution & Precise Counterfactual Medical Image Generation 
Using Language-Guided Stable Difusion (arXiv:2503.00196). arXiv. https://doi.org/10.48550/arXiv.2503.00196
Lu, M. Y., Chen, B., Williamso n, D. F. K., Chen, R. J., Zhao, M., Chow, A. K., Ikemura, K., Kim, A., Pouli, D., Patel, A., Soliman, A., 
Chen, C., Ding, T., Wang, J. J., Gerber, G., Liang, I., Le, L. P., Parwani, A. V., Weishaupt, L. L., & Mahmood, F. (2024). A Multimodal 
Generative AI Copilot for Human Pathology. Nature, 634(8033), 466–73. https://doi.org/10.1038/s41586-024-07618-3
Lutsker, G., Sapir, G., Shilo, S., Merino, J., Godneva, A., Greenfeld, J. R., Samocha-Bonet, D., Dhir, R., Gude, F., Mannor, S., Meirom, 
E., Chechik, G., Rossman, H., & Segal, E. (2025). F rom Glucose Patterns to Health Outcomes: A Generalizable Foundation Model 
for Continuous Glucose Monitor Data Analysis  (arXiv:2408.11876). arXiv. https://doi.org/10.48550/arXiv.2408.11876
Ma, J., He, Y., Li, F., Han, L., You, C., & Wang, B. (2024). Segment Anything in Medical Images. Nature Communications , 15(1), 654. 
https://doi.org/10.1038/s41467-024-44824-z
Ma, S. P., Liang, A. S., Shah, S. J., Smith, M., Jeong, Y., Devon-Sand, A., Crowell, T., Delahaie, C., Hsia, C., Lin, S., Shanafelt, T., 
Pfefer, M. A., Sharp, C., & Garcia, P. (2025). Ambient Artifcial Intelligence Scribes: Utilization and Impact on Documentation Time. 
Journal of the  American Medical Informatics Association,  32(2), 381–85. https://doi.org/10.1093/jamia/ocae304
Madani, A., Krause, B., Greene, E. R., Subramanian, S., Mohr, B. P., Holton, J. M., Olmos, J. L., Xiong, C., Sun, Z. Z., Socher, R., 
Fraser, J. 
S., & Naik, N. (2023). Large Language Models Generate Functional Protein Sequences Across Diverse Families. Nature 
Biotechnology , 41(8), 1099– 1106. https://doi.org/10.1038/s41587-022-01618-2
Maier-Hein, L., Eisenmann, M., Reinke, A., Onogur, S., Stankovic, M., Scholz, P., Arbel, T., Bogunovic, H., Bradley, A. P., Carass, A., 
Feldmann, 
C., Frangi, A. F., Full, P. M., van Ginneken, B., Hanbury, A., Honauer, K., Kozubek, M., Landman, B. A., März, K., … 
Kopp-Schneider, A. 
(2018). Why Rankings of Biomedical Image Analysis Competitions Should Be Interpreted With Care. Nature 
Communications , 9(1), 5217. https://doi.org/10.1038/s41467-018-07619-7附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 447Mei, X., Liu, Z., Ro bson, P. M., Marinelli, B., Huang, M., Doshi, A., Jacobi, A., Cao, C., Link, K. E., Yang, T., Wang, Y., Greenspan, H., 
Deyer, T., 
Fayad, Z. A., & Yang, Y. (2022). RadImageNet: An Open Radiologic Deep Learning Research Dataset for Efective Trans -
fer Learning . Radiolo gy: Artifcial Intellige nce, 4(5), e210315. https://doi.org/10.1148/ryai.210315
Narayanan, S., Braza, J. D., Grifths, R.-R., Ponnapati, M., Bou, A., Laurent, J., Kabeli, O., Wellawatte, G., Cox, S., Rodriques, S. G., & 
White, 
A. D. (2024). Aviary: Training Language Agents on Challenging Scientifc Tasks  (arXiv:2412.21154). arXiv. https://doi. 
org/10.48550/a rXiv.2412.211 54
Nori, H., Lee, Y. T., Zhang, S., Carignan, D., Edgar, R., Fusi, N., King, N., Larson, J., Li, Y., Liu, W., Luo, R., McKinney, S. M., Ness, R.  
O., Poon, H., Qin, T., Usuyama, N., White, C., & Ho rvitz, E. (2023). Can Generalist Foundation Models Outcompete Spec ial- Pur-
pose Tuning? Case Study in Medicine  (arXiv:2311.16452). arXiv. https://doi.org/10.48550/arXiv.2311.16452 
Nori, H., Usuyama, N., King, N., McKinney, S. M., Fernandes, X., Zhang, S., & Horvitz, E. (2024). From Medprompt to o1: 
Exploration of Run-Time Strate-g ies for Medical Challenge Problems and Beyond  (arXiv: 2411.03590). arXiv. https://
doi.org/10.4855 0/ arXiv.2411.0 3590
Pokharel, S., Pratyush, P., Heinzinger, M., Newman, R. H., & Kc, D. B. (2022). Improving Protein Succinylation Sites Prediction Using 
Embeddings Fro m Protein Language M odel. Scientifc Reports,  12(1), 16933. https://doi.org/10.1038/s41598-022-21366-2
Price, I., Sanchez-Gonzalez, A., A let, F., Ande rsson, T. R., El-Kadi , A., Master s, D., Ewalds, T., Stott, J., Mohamed, S., Battaglia, P., 
Lam, 
R., & Willson, M. (2025). Probabilistic Weather Forecasting With Machine Learning. Nature , 637(8044), 84–90. https://-
doi.org/10.1038 /s41586-024-0 8252-9
Qian, Z., Callender, T., Cebere, B., Janes, S. M., Navani, N., & van der Schaar, M. (2024). Synthetic Data for Privacy-Preserving 
Clinical Risk Prediction. Scientifc Re ports, 14(1), 25676. https://doi.org/10.1038/s41598-024-72894-y
Qiu, 
J., Wu, J., Wei, H., Shi, P., Zhang, M., Sun, Y., Li, L., Liu, H., Liu, H., Hou, S., Zhao, Y., Shi, X., Xian, J., Qu, X., Zhu, S., Pan, 
L.,Chen, X., 
Zhang, X., Jiang, S., … Yuan, W. (2024). Development and Validation of a Multimodal Multitask Vision Foundation 
Model for Generalist Ophthalmic Artifcial Intelligence. NEJM AI , 1(12), AIoa2300221. https://doi.org/10.1056/AIoa2300221
Quer, G., & Topol, E. J. (2024). The Potential for Large Language Models to Transform Cardiovascular Medicine. The Lancet Digi-
tal Health , 6(10), e767– 71. https://doi.org/10.1016/S2589-7500(24)00151-1
Rashidi,
 H. H.,  Albahra, S., Rubin, B. P., & Hu, B. (2024). A  Novel and Fully  Automated Platform for Synthetic T abular Data Genera-
tion and Validation. Scientifc Re ports, 14(1), 23312. https://doi.org/10.1038/s41598-024-73608-0
Shah, S. J., Devon-Sand, A., Ma, S. P., Jeong, Y., Crowell, T., Smith, M., Liang, A. S., Delahaie, C., Hsia, C., Shanafelt, T., Pfefer, M. 
A., Sharp, 
C., Lin, S., & Garcia, P. (2025). Ambient Artifcial Intelligence Scribes: Physician Burnout and Perspectives on Usability 
and Documentation Burden. Journal of the American Medical Informatics Association , 32(2), 375–80. https://doi.org/10.1093/ 
jamia/ocae295附录
第五章：科学与医学2025年人工智能
指数报告
Shapson-Coe, A., Januszewski, M., Berger, D. R., Pope, A., Wu, Y., Blakely, T., Schalek, R. L., Li, P. H., Wang, S., Maitin-Shepard, 
J., Karlupia, N., Dorkenwald, S., Sjostedt, E., Leavitt, L., Lee, D., Troidl, J., Collman, F., Bailey, L., Fitzmaurice, A., … Lichtman,
J. W. (2024). A Petavoxel Fragment of Human Cerebral Cortex Reconstructed at Nanoscale Resolution. Science,  384(6696), 
eadk4858. https://doi.org/10.1126/science.adk4858
Sheller, M . J., Edwards, B., Reina, G. A., Martin, J., Pati, S., Kotrotsou, A., Milchenko, M., Xu, W., Marcus, D., Colen, R. R., & Bakas, S.  
(2020). Federated Learning in Medicine: Facilitating Multi-institutional Collaborations Without Sharing Patient Data. Scientifc 
Reports,  10(1), 12598. https://doi.org/10.1038/s41598-020-69250-1
Shi, 
J., Tang, L., Gao, Z., Li, Y., Wang, C., Gong, T., Li, C., & Fu, H. (2023). MG-Trans: Multi-scale Graph Transformer With Infor-
mation Bottleneck for Whole Slide Image Classifcation.  IEEE Transactions on Medical Imaging,  42(12), 3871–83. https://-
doi.org/10.1109/TMI.2023.3313252 
Snel, B., Lehmann, G., Bork, P., & Huynen, M. A. (2000). STRING: A Web-Server to Retrieve and Display the Repeatedly 
Occurring Neighbourhood of a Gene. Nucleic Acids Research , 28(18), 3442–44. https://-d oi.org/10.1093/
nar/28.18.3442
Snowdon, J. 
L., Scheufele, E. L., Pritts, J., Le, P.-T., Mensah, G. A., Zhang, X., & Dankwa-Mullan, I. (2023). Evaluating Social 
Determinants of Health Variables in Advanced Analytic and Artifcial Intelligence Models for Cardiovascular Disease Risk and 
Outcomes: A Targeted Review. Ethnicity & Disease , 33(1), 33–43. https://doi.org/10.18865/1704
Stade, E. 
C., Stirman, S. W., Ungar, L. H., Boland, C. L., Schwartz, H. A., Yaden, D. B., Sedoc, J., DeRubeis, R. J., Willer, R., & 
Eichstaedt, J. C. (2024). Large Language Models Could Change the Future of Behavioral Healthcare: A Proposal for Respon-
sible Development and Evaluation. Npj Mental Health Research,  3(1), 1–12. https://doi.org/10.1038/s44184-024-00056-z
Sudlow, C., Gallach er, J., Allen, N., Beral, V., Burton, P., Danesh, J., Downey, P., Elliott, P., Green, J., Landray, M., Liu, B., Mat-
thews, P., Ong, G., Pell, J., Silman, A., Young, A., Sprosen, T., Peak man, T., & Co llins, R. (2015). UK Bioban k: An Ope n Acc ess 
Resource for I dentifying the Causes of a Wide Range of Complex Diseases of Middle and Old Age. PLoS Medicine , 12(3), 
e1001779. https://doi.org/10.1371/journal.pmed.1001779
Tierney, A. A., Gayre, G., Hoberman, B., Mattern, B., Ballesca, M., Kipnis, P., Liu, V., & Lee, K. (2024). Ambient Artifcial Intelli-
gence 
Scribes to Alleviate the Burden of Clinical Documentation. NEJM Catalyst , 5(3), CAT.23.0404. https://doi.org/10.1056/ 
CAT.23.0404
Varadi, 
M., Anyango, S., Deshpande, M., Nair, S., Natassia, C., Yordanova, G., Yuan, D., Stroe, O., Wood, G., Laydon, A., Žídek, 
A., Green, 
T., Tunyasuvunakool, K., Petersen, S., Jumper, J., Clancy, E., Green, R., Vora, A., Lutf, M., … Velankar, S. (2022). 
AlphaFold Protein 
Structure Database: Massively Expanding the Structural Coverage of Protein-Sequence Space With 
High-Accuracy Models.  Nucleic Acids Research,  50(D1), D439–44. https://doi.org/10.1093/nar/gkab1061
目录 附录 448附录
第五章：科学与医学2025年人工智能
指数报告
Veitch, D. P., Weiner, M. W., Aisen, P. S., Beckett, L. A., Cairns, N. J., Green, R. C., Harvey, D., Jack, C. R., Jagust, W., Morris, 
J. C., Petersen, R. C., Saykin, A.  J., Shaw, L. M ., Toga, A. W ., Trojanowski, J. Q., & Alzheimer’ s Disease Ne uroima ging Initia-
tive. (2019). Understanding Disease Progression and Improving Alzheimer’ s Disease Clinical Trials: Recent Highlights From  
the Alzheimer’
 s Disease Neuroimaging Initiative. Alzheimer’ s & Dementia: The Journal of the Alzheimer’ s Association,  15(1),  
106–52. https://doi. org/10.1016/j.jalz.2018.08.005
Vorontsov, E., B ozkurt, A., Cas son, A., Shaikovski, G., Zelechowski, M., Severson, K., Zimmermann, E., Hall, J., Tenenholtz, N., 
Fusi, 
N., Yang, E., Mathieu, P., van Eck, A., Lee, D., Viret, J., Robert, E., Wang, Y. K., Kunz, J. D., Lee, M. C. H., … Fuchs, T. J. 
(2024). 
A Foundation Model for Clinical-Grade Computational Pathology and Rare Cancers Detection. Nature Medicine,  30 
(10), 2924–35. https://doi.org/10.1038/s41591-024-03141-0
Wang, R., 
Fang, X., Lu, Y., & Wang, S. (2004). The PDBbind Database: Collection of Binding Afnities for Protein−Ligand 
Complexes With Known Three-Dimensional Structures. Journal of Medicinal Chemistry , 47(12), 2977–80. https://-
doi.org/10.1021/jm030580l
Wang, X., Liu, S., Tsaris, A., Choi, J.-Y., Aji, A., Fan, M., Zhang, W., Yin, J., Ashfaq, M., Lu, D., & Balaprakash, P. (2024). 
ORBIT: Oak Ridge Base Foundation Model for Earth System Predictabili ty (arXiv:2404.14712). arXiv. https://-
doi.org/10.48550/arXiv.2404.14712
 Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., & Han, X. (2022a). Transformer-Based Unsuper-
vised Contrastive Learning for Histopathological Image Classifcation. Medical Image Analysis , 81, 102559. https://-
doi.org/10.1016/j. media.2022.102559
Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Yang, W., Huang, J., & Han, X. (2022b). Transformer-Based Unsupervised 
Contrastive Learning for Histopathological Image Classifcation. Medical Image Analysis , 81, 102559. https://doi.org/10.1016/j. 
media.2022.102559
Wang, X., 
Zhao, J., Marostica, E., Yuan, W., Jin, J., Zhang, J., Li, R., Tang, H., Wang, K., Li, Y., Wang, F., Peng, Y., Zhu, J., 
Zhang, J., Jackson, C. R., Zhang, J., Dillon, D., Lin, N. U., Sholl, L., … Yu, K.-H. (2024). A Pathology Foundation Model for 
Cancer Diagnosis and Prognosis Prediction. Nature,  634(8035), 970–78. https://doi.org/10.1038/s41586-024-07894-z
Wang,
 Y., He, J., Du, Y., Chen, X., Li, J. C., Liu, L.-P., Xu, X.,  & Hassoun,  S. (2025).  Large Language Model Is Secretly a Pro -
tein Sequence Optimizer (arXiv:2501.09274). arXiv. https://doi.org/10.48550/arXiv.2501.09274
Xiang, J., Wa ng, X. , Zhang, X., Xi, Y., E weje, F., Che n, Y., Li, Y., Berg strom, C., Gop aulchan , M., Ki m, T., Yu , K.-H., Willens, S. , 
Olguin, F. M., Nirschl, J. J., Neal, J., Diehn, M., Yang, S., & Li, R. (2025). A Vision–Language Foundation Model for Precision 
Oncology. Nature,  638(8051), 769–78. https://doi.org/10.1038/s41586-024-08378-w
Xie, Y., Wu, J., Tu, H., Yang, S., Zhao, B., Zong, Y., Jin, Q., Xie, C., & Zhou, Y. (2024). A Preliminary Study of o1 in Medicine: 
Are We Closer to an AI Doctor? (arXiv:2409.15277). arXiv. https://doi.org/10.48550/arXiv.2409.15277
目录 附录 449附录
第五章：科学与医学2025年人工智能
指数报告
Xu, H., Usuyama, N., Bagga, J., Zhang, S ., Rao, R., Naumann, T., Wong, C., Gero, Z., Gonzlez, J., Gu, Y., Xu, Y., Wei, M., 
Wang, 
W., Ma, S., Wei, F., Yang, J., Li, C., Gao, J., Rosemon, J., … Poon, H. (2024). A Whole-Slide Foundation Model for 
Digital Pathology From Real-World Data. Nature,  630(8015), 181–88. https://doi.org/10.1038/s41586-024-07441-w
Yang, L., 
Xu, S., Sellergren, A., Kohlberger, T., Zhou, Y., Ktena, I., Kiraly, A., Ahmed, F., Hormozdiari, F., Jaroensri, T., Wang, 
E., 
Wulczyn, E., Jamil, F., Guidroz, T., Lau, C., Qiao, S., Liu, Y., Goel, A., Park, K., … Golden, D. (2024). Advancing Multimodal 
Medical Capabilities of Gemini (arXiv:2405.03162). arXiv. https://doi.org/10.48550/arXiv.2405.03162
Yang, X., Chen, A., PourNejatian, N., Shin, H. C., Smith, K. E., Parisien, C., Compas, C., Martin, C., Flores, M. G., Zhang, Y. , 
Magoc, T., Harle, C. A., Lipori, G., Mitchell, D. A., Hogan, W. R., Shenkman, E. A., Bian, J., & Wu, Y. (2022). GatorTron: A 
Large Clinical 
Language Model to Unlock Patient Information from Unstructured Electronic Health Records  (arX-
iv:2203.03540). arXiv. https://doi.org/10.48550/arXiv.2203.03540
Yu, B., 
Baker, F. N., Chen, Z., Ning, X., & Sun, H. (2024). LlaSMol: Advancing Large Language Models for Chemistry With a 
Large-Scale, Comprehensive, 
High-Quality Instruction Tuning Dataset (arXiv:2402.09391). arXiv. https://doi.org/10.48550/ 
arXiv.2402.09391
Zambaldi, V., L a, D., Chu , A. E., Patani, H., Danson,  A. E., Kwan, T.  O. C., Frerix , T., Schneider, R. G., Saxton , D., Thilla isunda-
ram, A., Wu, Z., Moraes, I., Lange, O., Papa, E., Stanton, G., Martin, V., Singh, S., Wong, L. H., Bates, R., … Wang, J. (2024). 
De Novo Design of High-Afnity Protein Binders with AlphaProteo  (arXiv:2409.08022). arXiv. https://doi.org/10.48550/arX-
iv.2409.08022 
Zhao, T., 
Gu, Y., Yang, J., Usuyama, N., Lee, H. H., Kiblawi, S., Naumann, T., Gao, J., Crabtree, A., Abel, J., Moung-Wen, 
C., Piening, B., Bifulco, C., Wei, M., Poon, H., & Wang, S. (2025). A Foundation Model for Joint Segmentation, Detection 
and 
Recognition of Biomedical Objects Across Nine Modalities. Nature Methods , 22(1), 166–76. https://-
doi.org/10.1038/s41592-024-02499-w
Zhou, 
Y., Chia, M. A., Wagner, S. K., Ayhan, M. S., Williamson, D. J., Struyven, R. R., Liu, T., Xu, M., Lozano, M. G., Wood-
ward- Court, P., Kihara, Y., Altmann, A., Lee, A. Y., Topol, E. J., Denniston, A. K., Alexander, D. C., & Keane, P. A. (2023). A 
Foundation Model 
for Generalizable Disease Detection From Retinal Images. Nature , 622(7981), 156–63. https://-
doi.org/10.1038/s41586- 023-06555-x
目录 附录 450附录
第五章：科学与医学2025年人工智能
指数报告
目录 附录 451附录
第六章：政策
第六章：政策
致谢
人 工 智 能 指 数 谨 此 感 谢 Julia Betts Lotufo 和 Alexandra 
Rome 在收集人工智能重大政策事件信息方面所做的努力。 此外， 人工智能指数还要感谢 Lapo Santarlasci 领导了对人工智能公共支出和美国赠款相关人工智能支出的分析工作。
全球人工智能提及率
对于世界各地与人工智能相关的立法程序中提及人工智能的
内容， 人工智能指数在 75 个地理区域的国会或议会网站上， 通常在名为 “minutes,”、 “hansard,”栏目下， 用各自的语言搜索关键词 " 人工智能 "。 提及次数按届计算， 因此在同一届立法会议上多次 " 人工智能 " 算作一次。 人工智能指数小组调查了以下数据库：安道尔、 亚美尼亚、 澳大利亚、 阿塞拜疆、 巴巴多斯、 比利时、 百
慕大、 巴西、 加拿大、 开曼群岛、 中国
1、 捷克共和国、 丹麦、 多米
尼加共和国、 厄瓜多尔、 萨尔瓦多、 爱沙尼亚、 斐济、 芬兰、 法国、
德国、 直布罗陀、 希腊、 香港、 冰岛、 印度、 爱尔兰、 马恩岛、 意大利、 日本、 肯尼亚、 科索沃、 拉脱维亚、 莱索托、 列支敦士登、 卢森堡、 中国澳门特别行政区、 马达加斯加、 马来西亚、 马尔代夫、  马耳他、 毛里求斯、 墨西哥、 摩尔多瓦、 荷兰、 新西兰、 北马里亚纳群岛、 挪威、 巴基斯坦、 巴拿马、 巴Bua New Guinea, Philippines, Poland, Portugal, Romania, Russia, San Marino, Seychelles, Sierra Leone, Singapore, Slovenia, South Africa, South Korea, Spain, Sri Lanka, Sweden, Switzerland, Tanzania, Trinidad and Tobago, Ukraine, United Kingdom, United States, Uruguay, Zambia, Zimbabwe
The United States Commission mentioned
To study the trend of the US Commission mentioning artificial intelligence, we conducted the following search :
Website: Congress.gov Keywords: Artificial Intelligence Filters: Committee ReportsGlobal Legislative Record of Artificial Intelligence
For AI-related bills that have been passed into law, the AI Index searches 116 parliamentary or parliamentary websites for the keyword "artificial intelligence" in their respective languages, texts, and the full text of the bill. It is important to note that only laws that were passed and signed into law by state-level legislatures between 2016 and 2024 (such as those signed by the president or with royal approval) are included. Laws that have been approved but subsequently repealed are not included in the analysis. For laws that have added or amended provisions related to AI since their initial enactment, the AI Index uses the year of inclusion rather than the year of its initial adoption, where relevant. Future AI index reports are expected to include analysis of other types of legal documents, such as regulations and standards adopted by national or supranational, government agencies, etc.
The AI Index panel surveyed databases for the following geographic regions:
Algeria, Andorra, Antigua and Barbuda, Argentina, Armenia, Australia, Austria
Location, Azerbaijan, Bahamas, Bahrain, Bangladesh, Barbados, Belarus, Belgium, Belize, Bermuda, Bhutan, Bolivia, Brazil, Brunei, Bulgaria, Cameroon, Canada, Chile, China, Croatia, Cuba, Curacao, Cyprus, Czech Republic, Denmark, Estonia, Faroe Islands, Fiji, Finland, France, Germany, Gibraltar, Greece, Greenland, Grenada, Guam, Guatemala, Guyana, Hong Kong, Hungary, Iceland, India,  Iraq, Ireland, Isle of Man, Israel Ireland, Isle of Man, Israel, Italy, Jamaica, Japan, Kazakhstan, Kenya, Kiribati, Republic of Korea, Kosovo, Kyrgyz Republic, Latvia, Liechtenstein, Lithuania, Luxembourg, Macau SAR, Malawi, Malaysia, Malta, Mauritius, Mexico, Monaco, Montenegro, Morocco, Mozambique, Nauru, Netherlands, New Zealand, Northern Mariana Islands, Norway, Panama, Philippines, Poland, Portugal, Romania, Russia, Samoa, Saudi Arabia, Serbia, Seychelles, Sierra Leone, Singapore, Slovak Republic, Slovenia, South Africa, Spain, Saint Kitts and Nevis, Suriname, Sweden, Switzerland, Tajikistan, Tanzania, Togo, Tonga, Turkey, Tuvalu, Uganda, Ukraine, United Arab Emirates, United Kingdom, United States, Uruguay, Vietnam, Yemen, Zambia, Zimbabwe.
 1. The National People's Congress is convened once a year and does not provide complete legislative procedures. Therefore, the counts in this analysis are the only public document released at the General Assembly session, that is, the "Government Work Report" delivered by the Prime Minister, which searches for references to "artificial intelligence". Artificial intelligence in 2025
Index Report
Table of Contents Appendix 452 U.S. State-Level Artificial Intelligence Legislation
For AI-related bills that have been passed into law, the AI Index is in the United States
The websites of all 50 states searched for the keyword "artificial intelligence" in the full text of the bill. The bill is only passed into law if it appears in the final version of the bill (not just the introductory version). Please note that only laws passed between 2015 and 2024 are included. Statistics on proposed laws include those that have been adopted and those that have not yet been adopted or are currently inactive. The AI Index team investigated the following databases: Alabama, Alaska, Arizona, Arkansas, California, Colorado, Connecticut, Delaware, Florida, Georgia, Hawaii, Idaho, Illinois, Indiana, Iowa, Kansas, Kentucky, Louisiana, Maine, Maryland, Massachusetts, Michigan, Minnesota, Mississippi, Missouri, Montana, Nebraska, Nevada, New Hampshire, New Jersey, New Mexico, New York, North Carolina, North Dakota, Ohio, Oklahoma, Oregon, Pennsylvania, Rhode Island, South Carolina, South Dakota, Tennessee, Texas, Utah, Vermont, Virginia, Washington, West Virginia, Wisconsin, Wyoming. For a more comprehensive review, the AI Index also includes state laws related to AI listed on the Multistate AI state legislation tracker, even if they don't specifically mention the keyword "AI."
U.S. Artificial Intelligence Regulations
This section examines AI-related regulations promulgated by the following institutions. The AI Index for U.S. Regulators from 2016 to 2024, which analyzes the total number of regulations and their sponsors. To compile this data, the AI Index conducted a keyword search for "AI" in the Federal Register, a comprehensive repository of government documents from more than 436 agencies and nearly every department of the U.S. government.
The United States Commission mentioned
To study the trend of the U.S. Council mentioning AI, we conducted the following search: Website: Congress.gov Keywords: AI Filter: Committee Reports
Public investment in artificial intelligence
The AI Index analyzes government AI spending across European countries and the United States, with a focus on regions where data is more accessible. It is important to note that this analysis may not be fully representative of all countries or regions as the availability and quality of data can vary widely. In addition, while this analysis includes data on government contracts, it only relates to U.S. grant-level expenditures. The reason for this discrepancy is the difficulty of collecting comparable grant data from other countries and regions, such as the European Union and China. However, the case in the United States shows that a large part of government spending on AI is realized through grants. As more data becomes available, the coverage of the AI Index will expand in future iterations, but discrepancies and gaps in existing data may affect the comprehensiveness and accuracy of the findings.
Data source
For European countries, the AI Index collects public tender data from Tenders Electronic Daily (TED) (Publications Ofce of the European Union, 2024), an online supplement to the official journal of the European Union dedicated to reporting on European public procurement. While contracts come in a variety of formats, the most detailed data comes from bulk XML downloads, which include comprehensive information such as the tender process, the awarding entity, the winning contractor, the lot value, the description, the date of the winning bid, and the Common Procurement Vocabulary (CPV) code. The publication of TED is governed by EU legal thresholds: bids that exceed a specific monetary value must be published on TED if they are deemed to have cross-border interests. However, some countries also report purchases below the threshold, resulting in different coverage across countries. appendix
Chapter 6: Policy on Artificial Intelligence in 2025
Index Report
Table of Contents Appendix 453 Data sources in the UK include TED, Find a Tender, Contracts 
Finder and Contracts Finder Archive.  Scotland and Wales data are accessed through the API of their sourcing websites, while Northern Ireland does not provide such a service, so it must be excluded from the analysis and could lead to an underestimation of the UK's public investment in AI. As APIs restrict access to historical data, the AI Index leverages the Open Contracting Partnership's data registry to obtain comprehensive data for Scotland and Wales through Kingfisher Collect.
The data for the United States comes from the publicly accessible USAspending platform, which is one
An official repository for bulk downloads of information related to contract award notices and grant data. While this dataset covers a longer period of time than the TED dataset, it is important to note that there may be differences in data quality. In addition, a study by the U.S. Government Accountability Office (GAO, 2023) found that 49 agencies, including 25 executive branches, did not report data to USAspending, which accounted for more than $5 billion in net spending in fiscal year 2022.
data processing
Due to inconsistent storage of contract descriptions, XML tag names vary depending on the time of publication and the type of purchase, which presents a significant challenge for working with TED data. Some documents contain summary descriptions, while others detail the contracts awarded for each batch. In order to obtain comprehensive information, we have combined the main descriptions of each competition requirement with the existing partial descriptions. The state's standards are adopted by the end of 2024 and are not included
Included in this dataset.
Data from different countries is needed due to its linguistic diversity 
The Deep- Translator tool and Google Translate engine translate all texts into English. After translation, the tender text is processed using natural language processing (NLP) technology. These techniques include removing pauses and special characters, preserving discourse (POS) markup for key grammatical categories, lowercase conversion, lexicalization, and <NUM> replacing numeric amounts with tags. For comparison, all monetary amounts are converted to US dollars and PPPs are used
(PPP) indices adjust for price level differences.
Classification uses regular expressions for full-text search to classify AI-related contracts and grants. An AI dictionary was compiled by generating expressions related to AI and incorporating the "core" expressions in Yamashita et al.'s (2021) glossary. In addition, the Word2Vec model expands the dictionary with cosine words for each baseline expression, which are manually reviewed for inclusion in the final vocabulary. This process provides keywords and co-occurrence patterns that are critical to identifying AI content.
Classification takes a multi-step approach. First, match with a regular expression (regex).
Artificial intelligence terminology in contract and contract. These files are then categorized as "non-AI-related" or "AI-related". To validate AI-related matching, the BERTopic model and a pre-trained DeBERTA Transformer were used to assess probability scores for specific AI-related topics. Awards with a relevance score of less than 20% are subject to human review, while awards with higher scores are identified as AI-related. To ensure a higher rate of accuracy, all high-value bids are also manually reviewed. appendix
Chapter 6: Policy on Artificial Intelligence in 2025
Index Report
Table of Contents Appendix 454 Appendix
Chapter 7: Education
Chapter 7: Education
Code.org, CSTA, ECEP Alliance
State-level data
Appendix 2 of the State of Computer Science Education 2024 report provides a comprehensive overview of the methodology used by the Code.org, CSTA, and ECEP consortiums to collect data. Code.org staff also maintains a database of the status of K-12 education in the U.S. and provides more detailed information about the status of K-12 education in U.S. states in this Policy Primer.
AP Computer Science Data
AP computer science data is provided to Code.org under an agreement between the College Committee and Code.org. AP computer science data from the College Board's national and state summary reports.
Get a computer science education
Data on access to computer science education comes from the State of Computer Science Education 2024 report from Code.org, CSTA, and the ECEP consortium.
2024 K-12 Stage Computer Science
Survey of the status of the faculty in the field
For more information or to access the dataset, please contact membership@c-
steachers.org。
State Standards Comparison
The CSTA and the Association for the Advancement of Computer Education (IACE) released the State Standards Comparison report in December 2024. The dataset contains the K-12 phase standards adopted by about 10,000 states, available in spreadsheet form, as well as a Python note-book, which may be useful for data analysis. Colorado and VirginiaThe standard was adopted at the end of 2024 and is not included in this dataset. Global K-12 stage AI education
The Raspberry Pi Computing Education Research Centre, Department of Computer Science and Technology, University of Cambridge, presented its 2021 report Building Skills for Life: How to Expand and Improve Computer Science Education Around the Brooks Institution for its 2021 report This dataset was compiled on the basis of the research done by World. We've made a modification to their dataset to clarify that CS courses in the U.S. are offered in some schools/regions, rather than as electives everywhere. For more information on methodology, see Reports .
IPEDS
The Integrated Data System for Higher Education (IPEDS) combines an annual survey conducted by the National Center for Education Statistics (NCES) of the U.S. Department of Education. IPEDS collects information from every college, university, technical and vocational institution that participates in the federal student financial aid program.
Complete data
The data used in this section comes from the Completions survey, which collects data on the number of students completing post-secondary education. According to the Classification of Teaching Programs (CIP) code, graduates in AI-related fields are recognized as having a first major in Computer and Information Science, General (11.01); Computer programming (11.02) or computer science (11.07). The number of graduates in AI-related majors included in this year's report is different from previous years because the AI Index uses multiple CIP codes.
Oecd
This section uses data from the OECD Data Explorer, specifically the table "Number of Students, Graduates, and New Entrants by Education Sector". The methodology for this dataset can be found in Education at a Glance2024 Sources, Methodologies and Technical Notes. Artificial intelligence in 2025
Index Report
Ipsos
For the sake of brevity, the 2025 AI Index report chooses not to republish the methodology used in the Ipsos survey as described in the report. Learn more about Ipsos' methodology
Please refer to the survey.  Chapter 8: Public Opinion
Table of Contents Chapter II Preview 455 Appendix
Chapter 8: Public Opinion